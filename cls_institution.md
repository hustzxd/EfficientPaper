<details open><summary>

### institution
</summary> 
<p>

<details open><summary><b>AWS AI Labs</b></summary> 
<p>

|    | meta                          | ttttttttttttttttttttttttttttttitle                                                                                       | ccccccccccccccccccover                                                  | pub             |   year | codeeeee                                                                    | note   |
|---:|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------|:----------------|-------:|:----------------------------------------------------------------------------|:-------|
|  0 | [m](./meta/WDCO13S6.prototxt) | [Structural Pruning of Large Language Models via Neural Architecture Search](https://openreview.net/forum?id=SHlZcInS6C) | <img width='400' alt='image' src='./notes/nas_pruning/nas_pruning.jpg'> | AutoML Workshop |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/awslabs/syne-tune) |        |</p>
</details>
<details open><summary><b>Alibaba Group</b></summary> 
<p>

|    | meta                                   | ttttttttttttttttttttttttttttttitle                                                                                                                      | ccccccccccccccccccover                                          | pub   |   year | codeeeee                                                                            | note                               |
|---:|:---------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------|:------|-------:|:------------------------------------------------------------------------------------|:-----------------------------------|
|  0 | [Flash-LLM](./meta/flash_llm.prototxt) | [Flash-LLM: Enabling Cost-Effective and Highly-Efficient Large Generative Model Inference with Unstructured Sparsity](https://arxiv.org/abs/2309.10285) | <img width='400' alt='image' src='./notes/flash_llm/cover.jpg'> | VLDB  |   2024 | ![GitHub Repo stars](https://img.shields.io/github/stars/AlibabaResearch/flash-llm) | [note](./notes/flash_llm/index.md) |</p>
</details>
<details open><summary><b>Apple</b></summary> 
<p>

|    | meta                                          | ttttttttttttttttttttttttttttttitle                                                                               | ccccccccccccccccccover                                                        | pub       |   year | codeeeee                                                                        | note                                                                                                                              |
|---:|:----------------------------------------------|:-----------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------|:----------|-------:|:--------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------|
|  0 | [ReLU Strikes Back](./meta/HMR7HKFV.prototxt) | [ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models](https://arxiv.org/abs/2310.04564)   | <img width='400' alt='image' src='./notes/ReLU_Strikes_Back.jpg'>             | ICLR oral |   2024 | ![GitHub Repo stars](https://img.shields.io/github/stars/sjtu-ipads/powerinfer) | [note](https://confluence.xilinx.com/display/aialgo/ReLU+Strikes+Back%3A+Exploiting+Activation+Sparsity+in+Large+Language+Models) |
|  1 | [LLM in a flash](./meta/5JWFQDDP.prototxt)    | [LLM in a flash: Efficient Large Language Model Inference with Limited Memory](https://arxiv.org/abs/2312.11514) | <img width='400' alt='image' src='./notes/llm_in_a_flash/llm_in_a_flash.jpg'> | arXiv     |   2024 |                                                                                 | [note](https://z6oqkldvmo.feishu.cn/docx/GBVrdR4iyotc83xMU1Hc9ZOGntb)                                                             |</p>
</details>
<details open><summary><b>Beihang University</b></summary> 
<p>

|    | meta                       | ttttttttttttttttttttttttttttttitle                                                                       | ccccccccccccccccccover                                  | pub   |   year | codeeeee                                                             | note   |
|---:|:---------------------------|:---------------------------------------------------------------------------------------------------------|:--------------------------------------------------------|:------|-------:|:---------------------------------------------------------------------|:-------|
|  0 | [SMP](./meta/smp.prototxt) | [Pruning Pre-trained Language Models Without Fine-Tuning](https://aclanthology.org/2023.acl-long.35.pdf) | <img width='400' alt='image' src='./notes/smp/smp.jpg'> | ACL   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/kongds/SMP) |        |</p>
</details>
<details open><summary><b>Carnegie Mellon University</b></summary> 
<p>

|    | meta                           | ttttttttttttttttttttttttttttttitle                                                                           | ccccccccccccccccccover   | pub   |   year | codeeeee                                                                 | note                                                                                                                            |
|---:|:-------------------------------|:-------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:-------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------|
|  0 | [Wanda](./meta/wanda.prototxt) | [A Simple and Effective Pruning Approach for Large Language Models](https://arxiv.org/pdf/2306.11695.pdf)    |                          | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/locuslab/wanda) | [note](https://confluence.xilinx.com/display/aialgo/Wanda%3A+A+Simple+and+Effective+Pruning+Approach+for+Large+Language+Models) |
|  1 | [Bonsa](./meta/Bonsa.prototxt) | [Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes](https://arxiv.org/abs/2402.05406) |                          | arXiv |   2024 | ![GitHub Repo stars](https://img.shields.io/github/stars/ldery/Bonsai)   |                                                                                                                                 |</p>
</details>
<details open><summary><b>Cerebras Systems</b></summary> 
<p>

|    | meta                                     | ttttttttttttttttttttttttttttttitle                                                                            | ccccccccccccccccccover   | pub   |   year | codeeeee                                                                              | note                                                                                                                             |
|---:|:-----------------------------------------|:--------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:--------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------|
|  0 | [SPDF](./meta/spdf.prototxt)             | [SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models](https://arxiv.org/abs/2303.10464) |                          | UAI   |   2023 |                                                                                       | [note](https://confluence.amd.com/display/~xiandong/SPDF%3A+Sparse+Pre-training+and+Dense+Fine-tuning+for+Large+Language+Models) |
|  1 | [Sparse-IFT](./meta/Sparse-IFT.prototxt) | [Sparse Iso-FLOP Transformations for Maximizing Training Efficiency](https://arxiv.org/abs/2303.11525)        |                          | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/CerebrasResearch/Sparse-IFT) | [note](https://confluence.amd.com/display/~xiandong/Sparse+Iso-FLOP+Transformations+for+Maximizing+Training+Efficiency)          |</p>
</details>
<details open><summary><b>Chongqing University</b></summary> 
<p>

|    | meta                         | ttttttttttttttttttttttttttttttitle                                                       | ccccccccccccccccccover                                    | pub   |   year | codeeeee   | note   |
|---:|:-----------------------------|:-----------------------------------------------------------------------------------------|:----------------------------------------------------------|:------|-------:|:-----------|:-------|
|  0 | [GBDT](./meta/gbdt.prototxt) | [Pruning Large Language Models via Accuracy Predictor](https://arxiv.org/abs/2309.09507) | <img width='400' alt='image' src='./notes/gbdt/gbdt.jpg'> | arXiv |   2023 |            |        |</p>
</details>
<details open><summary><b>Cornell University</b></summary> 
<p>

|    | meta                                                 | ttttttttttttttttttttttttttttttitle                                                     | ccccccccccccccccccover                                              | pub     |   year | codeeeee                                                                                     | note   |
|---:|:-----------------------------------------------------|:---------------------------------------------------------------------------------------|:--------------------------------------------------------------------|:--------|-------:|:---------------------------------------------------------------------------------------------|:-------|
|  0 | [Movement Pruning](./meta/movement_pruning.prototxt) | [Movement Pruning: Adaptive Sparsity by Fine-Tuning](https://arxiv.org/abs/2005.07683) | <img width='400' alt='image' src='./notes/movement_pruning/mp.jpg'> | NeurIPS |   2020 | ![GitHub Repo stars](https://img.shields.io/github/stars/huggingface/block_movement_pruning) |        |
|  1 | [QuIP](./meta/QuIP.prototxt)                         | [QuIP: Quantization with Incoherence Processing](https://arxiv.org/pdf/2307.13304.pdf) |                                                                     | arXiv   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/jerry-chee/QuIP)                    |        |</p>
</details>
<details open><summary><b>DeepMind</b></summary> 
<p>

|    | meta                          | ttttttttttttttttttttttttttttttitle                                                                                            | ccccccccccccccccccover   | pub   |   year | codeeeee                                                                        | note   |
|---:|:------------------------------|:------------------------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:--------------------------------------------------------------------------------|:-------|
|  0 | [m](./meta/2AL79IUH.prototxt) | [Fast Sparse ConvNets](https://openaccess.thecvf.com/content_CVPR_2020/papers/Elsen_Fast_Sparse_ConvNets_CVPR_2020_paper.pdf) |                          | CVPR  |   2020 | ![GitHub Repo stars](https://img.shields.io/github/stars/fastconvnets/cvpr2020) |        |</p>
</details>
<details open><summary><b>Eindhoven University of Technology</b></summary> 
<p>

|    | meta                       | ttttttttttttttttttttttttttttttitle                                                                                                         | ccccccccccccccccccover                                    | pub   |   year | codeeeee                                                             | note   |
|---:|:---------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------|:------|-------:|:---------------------------------------------------------------------|:-------|
|  0 | [OWL](./meta/owl.prototxt) | [Outlier Weighed Layerwise Sparsity (OWL): A Missing Secret Sauce for Pruning LLMs to High Sparsity](https://arxiv.org/pdf/2310.05175.pdf) | <img width='400' alt='image' src='./notes/owl/cover.jpg'> | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/luuyin/OWL) |        |</p>
</details>
<details open><summary><b>Gaoling School of Artificial Intelligence, Renmin University of China</b></summary> 
<p>

|    | meta                          | ttttttttttttttttttttttttttttttitle                                                          | ccccccccccccccccccover                                                 | pub   |   year | codeeeee   | note   |
|---:|:------------------------------|:--------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------|:------|-------:|:-----------|:-------|
|  0 | [m](./meta/L5D7520E.prototxt) | [A Survey on Model Compression for Large Language Models](https://arxiv.org/abs/2308.07633) | <img width='400' alt='image' src='./notes/survey/compression_LLM.jpg'> | arXiv |   2023 |            |        |</p>
</details>
<details open><summary><b>Georgia Institute of Technology</b></summary> 
<p>

|    | meta                               | ttttttttttttttttttttttttttttttitle                                                                              | ccccccccccccccccccover                                          | pub   |   year | codeeeee                                                                      | note                          |
|---:|:-----------------------------------|:----------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------|:------|-------:|:------------------------------------------------------------------------------|:------------------------------|
|  0 | [AdaLoRA](./meta/adalora.prototxt) | [AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning](https://arxiv.org/pdf/2303.10512.pdf) | <img width='400' alt='image' src='./notes/adalora/adalora.jpg'> | ICLR  |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/QingruZhang/AdaLoRA) |                               |
|  1 | [LoftQ](./meta/loftq.prototxt)     | [LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models](https://arxiv.org/abs/2310.08659)        | <img width='400' alt='image' src='./notes/loftq/loftq.jpg'>     | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/yxli2123/LoftQ)      | [note](./notes/loftq/note.md) |</p>
</details>
<details open><summary><b>Google</b></summary> 
<p>

|    | meta                             | ttttttttttttttttttttttttttttttitle                                                                                             | ccccccccccccccccccover                                  | pub   |   year | codeeeee                                                                        | note                                                                                                                 |
|---:|:---------------------------------|:-------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------|:------|-------:|:--------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------|
|  0 | [m](./meta/2AL79IUH.prototxt)    | [Fast Sparse ConvNets](https://openaccess.thecvf.com/content_CVPR_2020/papers/Elsen_Fast_Sparse_ConvNets_CVPR_2020_paper.pdf)  |                                                         | CVPR  |   2020 | ![GitHub Repo stars](https://img.shields.io/github/stars/fastconvnets/cvpr2020) |                                                                                                                      |
|  1 | [Sprint](./meta/Sprint.prototxt) | [Sparse Attention Acceleration with Synergistic In-Memory Pruning and On-Chip Recomputation](https://arxiv.org/abs/2209.00606) |                                                         | MICRO |   2022 |                                                                                 |                                                                                                                      |
|  2 | [m](./meta/WMMGA0AR.prototxt)    | [The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers](https://openreview.net/forum?id=TJ2nxciYCk-) |                                                         | ICLR  |   2023 |                                                                                 |                                                                                                                      |
|  3 | [KCM](./meta/kcm.prototxt)       | [Gradient-Free Structured Pruning with Unlabeled Data](https://arxiv.org/abs/2303.04185)                                       | <img width='400' alt='image' src='./notes/kcm/kcm.jpg'> | arXiv |   2023 |                                                                                 | [note](https://confluence.xilinx.com/display/aialgo/Gradient-Free+Structured+Pruning+with+Unlabeled+Data?moved=true) |</p>
</details>
<details open><summary><b>Google Research</b></summary> 
<p>

|    | meta                           | ttttttttttttttttttttttttttttttitle                                                                                                         | ccccccccccccccccccover                                    | pub   |   year | codeeeee                                                               | note   |
|---:|:-------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------|:------|-------:|:-----------------------------------------------------------------------|:-------|
|  0 | [OWL](./meta/owl.prototxt)     | [Outlier Weighed Layerwise Sparsity (OWL): A Missing Secret Sauce for Pruning LLMs to High Sparsity](https://arxiv.org/pdf/2310.05175.pdf) | <img width='400' alt='image' src='./notes/owl/cover.jpg'> | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/luuyin/OWL)   |        |
|  1 | [Bonsa](./meta/Bonsa.prototxt) | [Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes](https://arxiv.org/abs/2402.05406)                               |                                                           | arXiv |   2024 | ![GitHub Repo stars](https://img.shields.io/github/stars/ldery/Bonsai) |        |</p>
</details>
<details open><summary><b>Habana Labs</b></summary> 
<p>

|    | meta                         | ttttttttttttttttttttttttttttttitle                                                                           | ccccccccccccccccccover   | pub   |   year | codeeeee   | note   |
|---:|:-----------------------------|:-------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:-----------|:-------|
|  0 | [MVUE](./meta/MVUE.prototxt) | [Minimum Variance Unbiased N:M Sparsity for the Neural Gradients](https://openreview.net/pdf?id=vuD2xEtxZcj) |                          | ICLR  |   2023 |            |        |</p>
</details>
<details open><summary><b>Harbin Institute of Technology</b></summary> 
<p>

|    | meta                                     | ttttttttttttttttttttttttttttttitle                                                                        | ccccccccccccccccccover                                                | pub   |   year | codeeeee                                                                     | note                           |
|---:|:-----------------------------------------|:----------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------|:------|-------:|:-----------------------------------------------------------------------------|:-------------------------------|
|  0 | [TextPruner](./meta/TextPruner.prototxt) | [TextPruner: A Model Pruning Toolkit for Pre-Trained Language Models](https://arxiv.org/abs/2203.15996)   | <img width='400' alt='image' src='./notes/textpruner/textpruner.jpg'> | ACL   |   2022 | ![GitHub Repo stars](https://img.shields.io/github/stars/airaria/TextPruner) |                                |
|  1 | [GRAIN](./meta/grain.prototxt)           | [Gradient-based Intra-attention Pruning on Pre-trained Language Models](https://arxiv.org/abs/2212.07634) | <img width='400' alt='image' src='./notes/grain/grain.jpg'>           | ACL   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/airaria/GRAIN)      | [note](./notes/grain/index.md) |</p>
</details>
<details open><summary><b>Houmo AI</b></summary> 
<p>

|    | meta                         | ttttttttttttttttttttttttttttttitle                                                                               | ccccccccccccccccccover   | pub   |   year | codeeeee                                                                    | note   |
|---:|:-----------------------------|:-----------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:----------------------------------------------------------------------------|:-------|
|  0 | [RPTQ](./meta/RPTQ.prototxt) | [RPTQ: Reorder-based Post-training Quantization for Large Language Models](https://arxiv.org/pdf/2304.01089.pdf) |                          | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/hahnyuan/RPTQ4LLM) |        |</p>
</details>
<details open><summary><b>Huawei</b></summary> 
<p>

|    | meta                               | ttttttttttttttttttttttttttttttitle                                                                           | ccccccccccccccccccover                                         | pub   |   year | codeeeee                                                                      | note                            |
|---:|:-----------------------------------|:-------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------|:------|-------:|:------------------------------------------------------------------------------|:--------------------------------|
|  0 | [QA-LoRA](./meta/QA-LoRA.prototxt) | [QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2309.14717) | <img width='400' alt='image' src='./notes/QA-LoRA/qalora.jpg'> | ICLR  |   2024 | ![GitHub Repo stars](https://img.shields.io/github/stars/yuhuixu1993/qa-lora) | [note](./notes/QA-LoRA/note.md) |</p>
</details>
<details open><summary><b>Huawei Noah's Ark Lab</b></summary> 
<p>

|    | meta                                      | ttttttttttttttttttttttttttttttitle                                                                                               | ccccccccccccccccccover                                        | pub          |   year | codeeeee                                                                                                                    | note                            |
|---:|:------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------|:-------------|-------:|:----------------------------------------------------------------------------------------------------------------------------|:--------------------------------|
|  0 | [SIMPLE](./meta/simple.prototxt)          | [Structured Pruning for Efficient Generative Pre-trained Language Models](https://aclanthology.org/2023.findings-acl.692.pdf)    | <img width='400' alt='image' src='./notes/simple/cover.jpg'>  | ACL Findings |   2023 |                                                                                                                             | [note](./notes/simple/index.md) |
|  1 | [Plug-and-Play](./meta/IA8CS3VH.prototxt) | [Plug-and-Play: An Efficient Post-training Pruning Method for Large Language Models](https://openreview.net/forum?id=Tr0lPx9woF) | <img width='400' alt='image' src='./notes/Plug-and-Play.jpg'> | ICLR         |   2024 | ![GitHub Repo stars](https://img.shields.io/github/stars/biomedical-cybernetics/Relative-importance-and-activation-pruning) |                                 |</p>
</details>
<details open><summary><b>Hugging Face</b></summary> 
<p>

|    | meta                                                 | ttttttttttttttttttttttttttttttitle                                                     | ccccccccccccccccccover                                              | pub     |   year | codeeeee                                                                                     | note   |
|---:|:-----------------------------------------------------|:---------------------------------------------------------------------------------------|:--------------------------------------------------------------------|:--------|-------:|:---------------------------------------------------------------------------------------------|:-------|
|  0 | [Movement Pruning](./meta/movement_pruning.prototxt) | [Movement Pruning: Adaptive Sparsity by Fine-Tuning](https://arxiv.org/abs/2005.07683) | <img width='400' alt='image' src='./notes/movement_pruning/mp.jpg'> | NeurIPS |   2020 | ![GitHub Repo stars](https://img.shields.io/github/stars/huggingface/block_movement_pruning) |        |</p>
</details>
<details open><summary><b>IST</b></summary> 
<p>

|    | meta                          | ttttttttttttttttttttttttttttttitle                                                              | ccccccccccccccccccover                                               | pub   |   year | codeeeee   | note   |
|---:|:------------------------------|:------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------|:------|-------:|:-----------|:-------|
|  0 | [m](./meta/68I8KKBV.prototxt) | [Efficient Methods for Natural Language Processing: A Survey](https://arxiv.org/abs/2209.00099) | <img width='400' alt='image' src='./notes/survey/efficient_NLP.jpg'> | TACL  |   2023 |            |        |</p>
</details>
<details open><summary><b>IST Austria</b></summary> 
<p>

|    | meta                                     | ttttttttttttttttttttttttttttttitle                                                                                                        | ccccccccccccccccccover                                           | pub     |   year | codeeeee                                                                              | note                          |
|---:|:-----------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------|:--------|-------:|:--------------------------------------------------------------------------------------|:------------------------------|
|  0 | [m](./meta/V3MFIRLV.prototxt)            | [Inducing and Exploiting Activation Sparsity for Fast Neural Network Inference](http://proceedings.mlr.press/v119/kurtz20a/kurtz20a.pdf)  |                                                                  | ICML    |   2020 |                                                                                       |                               |
|  1 | [m](./meta/ITZS3TU3.prototxt)            | [Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks](https://arxiv.org/abs/2102.00554) |                                                                  | arXiv   |   2021 |                                                                                       |                               |
|  2 | [SPDY](./meta/spdy.prototxt)             | [SPDY: Accurate Pruning with Speedup Guarantees](https://arxiv.org/abs/2201.13096)                                                        | <img width='400' alt='image' src='./notes/spdy/cover.jpg'>       | ICML    |   2022 | ![GitHub Repo stars](https://img.shields.io/github/stars/IST-DASLab/spdy)             | [note](./notes/spdy/index.md) |
|  3 | [OBC](./meta/obc.prototxt)               | [Optimal Brain Compression: A Framework for Accurate Post-Training Quantization and Pruning](https://openreview.net/pdf?id=ksVGCOlOEba)   |                                                                  | NeurIPS |   2022 | ![GitHub Repo stars](https://img.shields.io/github/stars/IST-DASLab/OBC)              |                               |
|  4 | [oBERT](./meta/oBERT.prototxt)           | [The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models](https://arxiv.org/pdf/2203.07259.pdf)    |                                                                  | arXiv   |   2022 | ![GitHub Repo stars](https://img.shields.io/github/stars/neuralmagic/sparseml)        |                               |
|  5 | [GPTQ](./meta/gptq.prototxt)             | [GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers](https://arxiv.org/pdf/2210.17323.pdf)                 |                                                                  | ICLR    |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/IST-DASLab/gptq)             |                               |
|  6 | [ZipLM](./meta/ZipLM.prototxt)           | [ZipLM: Inference-Aware Structured Pruning of Language Models](https://openreview.net/pdf?id=bPFFPueAxm)                                  | <img width='400' alt='image' src='./notes/ziplm/cover.jpg'>      | NeurIPS |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/IST-DASLab/ZipLM)            |                               |
|  7 | [SpQR](./meta/spqr.prototxt)             | [SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression](https://arxiv.org/pdf/2306.03078.pdf)                  |                                                                  | arXiv   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/Vahe1994/SpQR)               |                               |
|  8 | [SquareHead](./meta/SquareHead.prototxt) | [Sparse Fine-tuning for Inference Acceleration of Large Language Models](https://arxiv.org/pdf/2310.06927.pdf)                            | <img width='400' alt='image' src='./notes/squarehead/cover.png'> | arXiv   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/IST-DASLab/SparseFinetuning) |                               |
|  9 | [SparseGPT](./meta/sparsegpt.prototxt)   | [SparseGPT: Massive Language Models Can be Accurately Pruned in one-shot.](https://arxiv.org/pdf/2301.00774.pdf)                          |                                                                  | arXiv   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/IST-DASLab/sparsegpt)        | [note](./notes/SparseGPT.md)  |</p>
</details>
<details open><summary><b>Institute of Automation, Chinese Academy of Sciences</b></summary> 
<p>

|    | meta                                      | ttttttttttttttttttttttttttttttitle                                                                                               | ccccccccccccccccccover                                        | pub   |   year | codeeeee                                                                                                                    | note                                                                  |
|---:|:------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------|:------|-------:|:----------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------|
|  0 | [FLAP](./meta/flap.prototxt)              | [Fluctuation-based Adaptive Structured Pruning for Large Language Models](https://arxiv.org/abs/2312.11983)                      | <img width='400' alt='image' src='./notes/flap.jpg'>          | AAAI  |   2024 | ![GitHub Repo stars](https://img.shields.io/github/stars/CASIA-IVA-Lab/FLAP)                                                | [note](https://z6oqkldvmo.feishu.cn/docx/JFFQdAxz3oWX2Kx6j91c2kamnqd) |
|  1 | [Plug-and-Play](./meta/IA8CS3VH.prototxt) | [Plug-and-Play: An Efficient Post-training Pruning Method for Large Language Models](https://openreview.net/forum?id=Tr0lPx9woF) | <img width='400' alt='image' src='./notes/Plug-and-Play.jpg'> | ICLR  |   2024 | ![GitHub Repo stars](https://img.shields.io/github/stars/biomedical-cybernetics/Relative-importance-and-activation-pruning) |                                                                       |</p>
</details>
<details open><summary><b>Institute of Computing Technology, Chinese Academy of Sciences</b></summary> 
<p>

|    | meta                                   | ttttttttttttttttttttttttttttttitle                                                                                                  | ccccccccccccccccccover                                              | pub   |   year | codeeeee   | note                              |
|---:|:---------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------|:------|-------:|:-----------|:----------------------------------|
|  0 | [ProSparse](./meta/ProSparse.prototxt) | [ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models](https://arxiv.org/abs/2402.13516) | <img width='400' alt='image' src='./notes/ProSparse/prosparse.jpg'> | arXiv |   2024 |            | [note](./notes/ProSparse/note.md) |</p>
</details>
<details open><summary><b>Institute of Information Engineering, Chinese Academy of Sciences</b></summary> 
<p>

|    | meta                          | ttttttttttttttttttttttttttttttitle                                                          | ccccccccccccccccccover                                                 | pub   |   year | codeeeee   | note   |
|---:|:------------------------------|:--------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------|:------|-------:|:-----------|:-------|
|  0 | [m](./meta/L5D7520E.prototxt) | [A Survey on Model Compression for Large Language Models](https://arxiv.org/abs/2308.07633) | <img width='400' alt='image' src='./notes/survey/compression_LLM.jpg'> | arXiv |   2023 |            |        |</p>
</details>
<details open><summary><b>Intel Corporation</b></summary> 
<p>

|    | meta                                 | ttttttttttttttttttttttttttttttitle                                                                                                                                                                                                       | ccccccccccccccccccover   | pub           |   year | codeeeee                                                                                           | note                                                                          |
|---:|:-------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------|:--------------|-------:|:---------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------|
|  0 | [OpenVINO](./meta/OpenVINO.prototxt) | [Post-training deep neural network pruning via layer-wise calibration](https://openaccess.thecvf.com/content/ICCV2021W/LPCV/papers/Lazarevich_Post-Training_Deep_Neural_Network_Pruning_via_Layer-Wise_Calibration_ICCVW_2021_paper.pdf) |                          | ICCV workshop |   2021 | [EfficientCNN](https://gitenterprise.xilinx.com/xiandong/EfficientCNN/tree/post-training-sparsity) | [note](https://confluence.xilinx.com/pages/viewpage.action?pageId=1005133974) |</p>
</details>
<details open><summary><b>MIT</b></summary> 
<p>

|    | meta                                         | ttttttttttttttttttttttttttttttitle                                                                                                                                           | ccccccccccccccccccover                                                   | pub           |   year | codeeeee                                                                          | note                                               |
|---:|:---------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------|:--------------|-------:|:----------------------------------------------------------------------------------|:---------------------------------------------------|
|  0 | [m](./meta/QZ2EJHG9.prototxt)                | [On-Device Training Under 256KB Memory](https://arxiv.org/abs/2206.15472)                                                                                                    | <img width='400' alt='image' src='./notes/on-device-training/cover.jpg'> | NeurIPS       |   2022 | [mit.edu](https://tinyml.mit.edu/on-device-training/)                             | [note](https://tinyml.mit.edu/on-device-training/) |
|  1 | [SparseViT](./meta/SparseViT.prototxt)       | [SparseViT: Revisiting Activation Sparsity for Efficient High-Resolution Vision Transformer](https://arxiv.org/abs/2303.17605)                                               | <img width='400' alt='image' src='./notes/sparsevit/sparsevit.jpg'>      | CVPR          |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/mit-han-lab/sparsevit)   | [note](./notes/sparsevit/index.md)                 |
|  2 | [TorchSparse++](./meta/TorchSparse.prototxt) | [TorchSparse++: Efficient Point Cloud Engine](https://openaccess.thecvf.com/content/CVPR2023W/WAD/papers/Tang_TorchSparse_Efficient_Point_Cloud_Engine_CVPRW_2023_paper.pdf) |                                                                          | CVPR workshop |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/mit-han-lab/torchsparse) |                                                    |
|  3 | [AWQ](./meta/awq.prototxt)                   | [AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration](https://arxiv.org/abs/2306.00978)                                                           |                                                                          | arXiv         |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/mit-han-lab/llm-awq)     |                                                    |</p>
</details>
<details open><summary><b>Meta</b></summary> 
<p>

|    | meta                           | ttttttttttttttttttttttttttttttitle                                                                        | ccccccccccccccccccover   | pub   |   year | codeeeee                                                                 | note                                                                                                                            |
|---:|:-------------------------------|:----------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:-------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------|
|  0 | [Wanda](./meta/wanda.prototxt) | [A Simple and Effective Pruning Approach for Large Language Models](https://arxiv.org/pdf/2306.11695.pdf) |                          | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/locuslab/wanda) | [note](https://confluence.xilinx.com/display/aialgo/Wanda%3A+A+Simple+and+Effective+Pruning+Approach+for+Large+Language+Models) |</p>
</details>
<details open><summary><b>Microsoft</b></summary> 
<p>

|    | meta                                         | ttttttttttttttttttttttttttttttitle                                                                                                               | ccccccccccccccccccover                                            | pub     |   year | codeeeee                                                                      | note                              |
|---:|:---------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------|:--------|-------:|:------------------------------------------------------------------------------|:----------------------------------|
|  0 | [LoRA](./meta/lora.prototxt)                 | [LoRA: Low-rank adaptation of large language models](https://arxiv.org/abs/2106.09685)                                                           | <img width='400' alt='image' src='./notes/lora/lora.jpg'>         | ICLR    |   2022 | ![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/LoRA)      |                                   |
|  1 | [ZeroQuant](./meta/zeroquant.prototxt)       | [ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers](https://openreview.net/forum?id=f-fVCElZ-G1)       |                                                                   | NeurIPS |   2022 | ![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/DeepSpeed) |                                   |
|  2 | [LoSparse](./meta/LoSparse.prototxt)         | [Structured Compression of Large Language Models based on Low-Rank and Sparse Approximation](https://arxiv.org/abs/2306.11222)                   | <img width='400' alt='image' src='./notes/losparse/losparse.jpg'> | ICML    |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/yxli2123/LoSparse)   |                                   |
|  3 | [Compresso](./meta/Compresso.prototxt)       | [Compresso: Structured Pruning with Collaborative Prompting Learns Compact Large Language Models](https://arxiv.org/abs/2310.05015)              | <img width='400' alt='image' src='./notes/compresso/cover.jpg'>   | arXiv   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/Moonlit)   | [note](./notes/compresso/note.md) |
|  4 | [LoRAShear](./meta/lorashear.prototxt)       | [LoRAShear: Efficient Large Language Model Structured Pruning and Knowledge Recovery](https://arxiv.org/abs/2310.18356)                          |                                                                   | arXiv   |   2023 |                                                                               |                                   |
|  5 | [ZeroQuant-V2](./meta/ZeroQuant-V2.prototxt) | [ZeroQuant-V2: Exploring Post-training Quantization in LLMs from Comprehensive Study to Low Rank Compensation](https://arxiv.org/abs/2303.08302) |                                                                   | arXiv   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/DeepSpeed) |                                   |</p>
</details>
<details open><summary><b>Microsoft Azure</b></summary> 
<p>

|    | meta                           | ttttttttttttttttttttttttttttttitle                                                                       | ccccccccccccccccccover                                      | pub   |   year | codeeeee                                                                 | note                          |
|---:|:-------------------------------|:---------------------------------------------------------------------------------------------------------|:------------------------------------------------------------|:------|-------:|:-------------------------------------------------------------------------|:------------------------------|
|  0 | [LoftQ](./meta/loftq.prototxt) | [LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models](https://arxiv.org/abs/2310.08659) | <img width='400' alt='image' src='./notes/loftq/loftq.jpg'> | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/yxli2123/LoftQ) | [note](./notes/loftq/note.md) |</p>
</details>
<details open><summary><b>Microsoft Azure AI</b></summary> 
<p>

|    | meta                               | ttttttttttttttttttttttttttttttitle                                                                              | ccccccccccccccccccover                                          | pub   |   year | codeeeee                                                                      | note   |
|---:|:-----------------------------------|:----------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------|:------|-------:|:------------------------------------------------------------------------------|:-------|
|  0 | [AdaLoRA](./meta/adalora.prototxt) | [AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning](https://arxiv.org/pdf/2303.10512.pdf) | <img width='400' alt='image' src='./notes/adalora/adalora.jpg'> | ICLR  |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/QingruZhang/AdaLoRA) |        |</p>
</details>
<details open><summary><b>Microsoft Research</b></summary> 
<p>

|    | meta                                 | ttttttttttttttttttttttttttttttitle                                                                                                                                              | ccccccccccccccccccover                                          | pub   |   year | codeeeee                                                                   | note   |
|---:|:-------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------|:------|-------:|:---------------------------------------------------------------------------|:-------|
|  0 | [nmSPARSE](./meta/nmSPARSE.prototxt) | [Efficient GPU Kernels for N:M-Sparse Weights in Deep Learning](https://proceedings.mlsys.org/paper_files/paper/2023/file/4552cedd396a308320209f75f56a5ad5-Paper-mlsys2023.pdf) |                                                                 | MLSys |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/SparTA) |        |
|  1 | [m](./meta/ELILXDQG.prototxt)        | [A Survey on Evaluation of Large Language Models](https://arxiv.org/abs/2307.03109)                                                                                             | <img width='400' alt='image' src='./notes/survey/eval_LLM.jpg'> | arXiv |   2023 |                                                                            |        |</p>
</details>
<details open><summary><b>NVIDIA</b></summary> 
<p>

|    | meta                                   | ttttttttttttttttttttttttttttttitle                                                                                                     | ccccccccccccccccccover   | pub     |   year | codeeeee                                                                           | note                                                                                        |
|---:|:---------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------|:-------------------------|:--------|-------:|:-----------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------|
|  0 | [m](./meta/K7GSWQIC.prototxt)          | [Channel Permutations for N:M Sparsity](https://proceedings.neurips.cc/paper/2021/hash/6e8404c3b93a9527c8db241a1846599a-Abstract.html) |                          | NeurIPS |   2021 | [Pytorch](https://gitenterprise.xilinx.com/xiandong/permutation_nm_sparse)         | [note](https://confluence.xilinx.com/display/aialgo/Channel+Permutation+for+N%3AM+Sparsity) |
|  1 | [NMSparse](./meta/PUHJMVCM.prototxt)   | [Accelerating Sparse Deep Neural Networks](https://arxiv.org/abs/2104.08378)                                                           |                          | arXiv   |   2021 |                                                                                    |                                                                                             |
|  2 | [FT](./meta/fastertransfomer.prototxt) | [FasterTransformer](https://github.com/NVIDIA/FasterTransformer)                                                                       |                          | github  |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/NVIDIA/FasterTransformer) |                                                                                             |</p>
</details>
<details open><summary><b>Nanjing University</b></summary> 
<p>

|    | meta                            | ttttttttttttttttttttttttttttttitle                                                                                        | ccccccccccccccccccover   | pub   |   year | codeeeee   | note   |
|---:|:--------------------------------|:--------------------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:-----------|:-------|
|  0 | [STA](./meta/44KWQAWO.prototxt) | [An Algorithm-Hardware Co-Optimized Framework for Accelerating N:M Sparse Transformers](https://arxiv.org/abs/2208.06118) |                          | VLSI  |   2022 |            |        |</p>
</details>
<details open><summary><b>Nanyang Technological University</b></summary> 
<p>

|    | meta                          | ttttttttttttttttttttttttttttttitle                                                                                  | ccccccccccccccccccover   | pub     |   year | codeeeee                                                               | note   |
|---:|:------------------------------|:--------------------------------------------------------------------------------------------------------------------|:-------------------------|:--------|-------:|:-----------------------------------------------------------------------|:-------|
|  0 | [L-OBS](./meta/lobs.prototxt) | [Learning to Prune Deep Neural Networks via Layer-wise Optimal Brain Surgeon](https://arxiv.org/pdf/1705.07565.pdf) |                          | NeurIPS |   2017 | ![GitHub Repo stars](https://img.shields.io/github/stars/csyhhu/L-OBS) |        |</p>
</details>
<details open><summary><b>National University of Singapore</b></summary> 
<p>

|    | meta                                    | ttttttttttttttttttttttttttttttitle                                                                 | ccccccccccccccccccover                                           | pub   |   year | codeeeee                                                                     | note                                                                                                                  |
|---:|:----------------------------------------|:---------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------|:------|-------:|:-----------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------|
|  0 | [LLM-Pruner](./meta/llmpruner.prototxt) | [LLM-Pruner: On the Structural Pruning of Large Language Models](https://arxiv.org/abs/2305.11627) | <img width='400' alt='image' src='./notes/llm_pruner/cover.jpg'> | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/horseee/LLM-Pruner) | [note](https://confluence.xilinx.com/display/aialgo/LLM-Pruner%3A+On+the+Structural+Pruning+of+Large+Language+Models) |</p>
</details>
<details open><summary><b>Neural Magic</b></summary> 
<p>

|    | meta                                     | ttttttttttttttttttttttttttttttitle                                                                                                       | ccccccccccccccccccover                                           | pub     |   year | codeeeee                                                                              | note                          |
|---:|:-----------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------|:--------|-------:|:--------------------------------------------------------------------------------------|:------------------------------|
|  0 | [m](./meta/V3MFIRLV.prototxt)            | [Inducing and Exploiting Activation Sparsity for Fast Neural Network Inference](http://proceedings.mlr.press/v119/kurtz20a/kurtz20a.pdf) |                                                                  | ICML    |   2020 |                                                                                       |                               |
|  1 | [SPDY](./meta/spdy.prototxt)             | [SPDY: Accurate Pruning with Speedup Guarantees](https://arxiv.org/abs/2201.13096)                                                       | <img width='400' alt='image' src='./notes/spdy/cover.jpg'>       | ICML    |   2022 | ![GitHub Repo stars](https://img.shields.io/github/stars/IST-DASLab/spdy)             | [note](./notes/spdy/index.md) |
|  2 | [OBC](./meta/obc.prototxt)               | [Optimal Brain Compression: A Framework for Accurate Post-Training Quantization and Pruning](https://openreview.net/pdf?id=ksVGCOlOEba)  |                                                                  | NeurIPS |   2022 | ![GitHub Repo stars](https://img.shields.io/github/stars/IST-DASLab/OBC)              |                               |
|  3 | [oBERT](./meta/oBERT.prototxt)           | [The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models](https://arxiv.org/pdf/2203.07259.pdf)   |                                                                  | arXiv   |   2022 | ![GitHub Repo stars](https://img.shields.io/github/stars/neuralmagic/sparseml)        |                               |
|  4 | [GPTQ](./meta/gptq.prototxt)             | [GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers](https://arxiv.org/pdf/2210.17323.pdf)                |                                                                  | ICLR    |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/IST-DASLab/gptq)             |                               |
|  5 | [ZipLM](./meta/ZipLM.prototxt)           | [ZipLM: Inference-Aware Structured Pruning of Language Models](https://openreview.net/pdf?id=bPFFPueAxm)                                 | <img width='400' alt='image' src='./notes/ziplm/cover.jpg'>      | NeurIPS |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/IST-DASLab/ZipLM)            |                               |
|  6 | [SpQR](./meta/spqr.prototxt)             | [SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression](https://arxiv.org/pdf/2306.03078.pdf)                 |                                                                  | arXiv   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/Vahe1994/SpQR)               |                               |
|  7 | [SquareHead](./meta/SquareHead.prototxt) | [Sparse Fine-tuning for Inference Acceleration of Large Language Models](https://arxiv.org/pdf/2310.06927.pdf)                           | <img width='400' alt='image' src='./notes/squarehead/cover.png'> | arXiv   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/IST-DASLab/SparseFinetuning) |                               |
|  8 | [SparseGPT](./meta/sparsegpt.prototxt)   | [SparseGPT: Massive Language Models Can be Accurately Pruned in one-shot.](https://arxiv.org/pdf/2301.00774.pdf)                         |                                                                  | arXiv   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/IST-DASLab/sparsegpt)        | [note](./notes/SparseGPT.md)  |</p>
</details>
<details open><summary><b>Northeastern University</b></summary> 
<p>

|    | meta                                     | ttttttttttttttttttttttttttttttitle                                                                                              | ccccccccccccccccccover   | pub   |   year | codeeeee                                                                                | note   |
|---:|:-----------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:----------------------------------------------------------------------------------------|:-------|
|  0 | [ADMM-pruning](./meta/Z9R72EAT.prototxt) | [A Systematic DNN Weight Pruning Framework using Alternating Direction Method of Multipliers](https://arxiv.org/abs/1804.03294) |                          | ECCV  |   2018 | ![GitHub Repo stars](https://img.shields.io/github/stars/bzantium/pytorch-admm-pruning) |        |</p>
</details>
<details open><summary><b>Northwestern University</b></summary> 
<p>

|    | meta                             | ttttttttttttttttttttttttttttttitle                                                                                     | ccccccccccccccccccover                                        | pub   |   year | codeeeee                                                                      | note   |
|---:|:---------------------------------|:-----------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------|:------|-------:|:------------------------------------------------------------------------------|:-------|
|  0 | [SR-STE](./meta/sr-ste.prototxt) | [Learning N:M Fine-grained Structured Sparse Neural Networks From Scratch](https://openreview.net/forum?id=K9bw7vqp_s) | <img width='400' alt='image' src='./notes/sr-ste/sr-ste.jpg'> | ICLR  |   2021 | ![GitHub Repo stars](https://img.shields.io/github/stars/aojunzz/NM-sparsity) |        |</p>
</details>
<details open><summary><b>Numenta</b></summary> 
<p>

|    | meta                                                            | ttttttttttttttttttttttttttttttitle                                                                                                                              | ccccccccccccccccccover                                                      | pub                                    |   year | codeeeee   | note                                          |
|---:|:----------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------|:---------------------------------------|-------:|:-----------|:----------------------------------------------|
|  0 | [Complementary Sparsity](./meta/ComplementarySparsity.prototxt) | [Two Sparsities Are Better Than One: Unlocking the Performance Benefits of Sparse-Sparse Networks](https://iopscience.iop.org/article/10.1088/2634-4386/ac7c8a) | <img width='400' alt='image' src='./notes/ComplementarySparsity/cover.jpg'> | Neuromorphic Computing and Engineering |   2022 |            | [note](./notes/ComplementarySparsity/note.md) |</p>
</details>
<details open><summary><b>OpenAI</b></summary> 
<p>

|    | meta                                       | ttttttttttttttttttttttttttttttitle                                                              | ccccccccccccccccccover   | pub   |   year | codeeeee                                                                     | note   |
|---:|:-------------------------------------------|:------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:-----------------------------------------------------------------------------|:-------|
|  0 | [blocksparse](./meta/blocksparse.prototxt) | [GPU Kernels for Block-Sparse Weights](https://cdn.openai.com/blocksparse/blocksparsepaper.pdf) |                          | arXiv |   2020 | ![GitHub Repo stars](https://img.shields.io/github/stars/openai/blocksparse) |        |</p>
</details>
<details open><summary><b>OpenGVLab</b></summary> 
<p>

|    | meta                                   | ttttttttttttttttttttttttttttttitle                                                                                 | ccccccccccccccccccover                                              | pub   |   year | codeeeee                                                                      | note   |
|---:|:---------------------------------------|:-------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------|:------|-------:|:------------------------------------------------------------------------------|:-------|
|  0 | [OmniQuant](./meta/omniquant.prototxt) | [OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models](https://arxiv.org/abs/2308.13137) | <img width='400' alt='image' src='./notes/omniquant/omniquant.png'> | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/OpenGVLab/OmniQuant) |        |</p>
</details>
<details open><summary><b>Princeton University</b></summary> 
<p>

|    | meta                                         | ttttttttttttttttttttttttttttttitle                                                                                             | ccccccccccccccccccover                                             | pub   |   year | codeeeee                                                                             | note                                                                                                      |
|---:|:---------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------|:------|-------:|:-------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------|
|  0 | [AdaLoRA](./meta/adalora.prototxt)           | [AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning](https://arxiv.org/pdf/2303.10512.pdf)                | <img width='400' alt='image' src='./notes/adalora/adalora.jpg'>    | ICLR  |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/QingruZhang/AdaLoRA)        |                                                                                                           |
|  1 | [MeZO](./meta/mezo.prototxt)                 | [Fine-Tuning Language Models with Just Forward Passes](https://arxiv.org/pdf/2305.17333.pdf)                                   |                                                                    | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/princeton-nlp/MeZO)         | [note](https://confluence.xilinx.com/display/aialgo/Fine-Tuning+Language+Models+with+Just+Forward+Passes) |
|  2 | [LLM-shearing](./meta/LLM_shearing.prototxt) | [Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning](https://xiamengzhou.github.io/sheared-llama/) | <img width='400' alt='image' src='./notes/llm_shearing/cover.jpg'> | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/princeton-nlp/LLM-Shearing) | [note](./notes/llm_shearing/note.md)                                                                      |</p>
</details>
<details open><summary><b>Rice University</b></summary> 
<p>

|    | meta                              | ttttttttttttttttttttttttttttttitle                                                                              | ccccccccccccccccccover                                        | pub   |   year | codeeeee                                                                     | note   |
|---:|:----------------------------------|:----------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------|:------|-------:|:-----------------------------------------------------------------------------|:-------|
|  0 | [Deja Vu](./meta/dejavu.prototxt) | [Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time](https://openreview.net/forum?id=wIPIhHd00i) | <img width='400' alt='image' src='./notes/dejavu/dejavu.jpg'> | ICML  |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/FMInference/DejaVu) |        |</p>
</details>
<details open><summary><b>School of Cyber Security, University of Chinese Academy of Sciences</b></summary> 
<p>

|    | meta                          | ttttttttttttttttttttttttttttttitle                                                          | ccccccccccccccccccover                                                 | pub   |   year | codeeeee   | note   |
|---:|:------------------------------|:--------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------|:------|-------:|:-----------|:-------|
|  0 | [m](./meta/L5D7520E.prototxt) | [A Survey on Model Compression for Large Language Models](https://arxiv.org/abs/2308.07633) | <img width='400' alt='image' src='./notes/survey/compression_LLM.jpg'> | arXiv |   2023 |            |        |</p>
</details>
<details open><summary><b>SenseTime Research</b></summary> 
<p>

|    | meta                             | ttttttttttttttttttttttttttttttitle                                                                                          | ccccccccccccccccccover                                        | pub   |   year | codeeeee                                                                      | note   |
|---:|:---------------------------------|:----------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------|:------|-------:|:------------------------------------------------------------------------------|:-------|
|  0 | [BRECQ](./meta/brecq.prototxt)   | [BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction](https://openreview.net/pdf?id=POWv6hDd9XH) |                                                               | ICLR  |   2021 | ![GitHub Repo stars](https://img.shields.io/github/stars/yhhhli/BRECQ)        |        |
|  1 | [SR-STE](./meta/sr-ste.prototxt) | [Learning N:M Fine-grained Structured Sparse Neural Networks From Scratch](https://openreview.net/forum?id=K9bw7vqp_s)      | <img width='400' alt='image' src='./notes/sr-ste/sr-ste.jpg'> | ICLR  |   2021 | ![GitHub Repo stars](https://img.shields.io/github/stars/aojunzz/NM-sparsity) |        |</p>
</details>
<details open><summary><b>Seoul National University</b></summary> 
<p>

|    | meta                                   | ttttttttttttttttttttttttttttttitle                                                                                                  | ccccccccccccccccccover                                       | pub   |   year | codeeeee   | note                              |
|---:|:---------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------|:------|-------:|:-----------|:----------------------------------|
|  0 | [K-pruning](./meta/k_pruning.prototxt) | [Knowledge-preserving Pruning for Pre-trained Language Models without Retraining](https://arxiv.org/abs/2308.03449)                 | <img width='400' alt='image' src='./notes/k_pruning/kp.jpg'> | arXiv |   2023 |            | [note](./notes/k_pruning/note.md) |
|  1 | [L4Q](./meta/L4Q.prototxt)             | [L4Q: Parameter Efficient Quantization-Aware Training on Large Language Models via LoRA-wise LSQ](https://arxiv.org/abs/2402.04902) | <img width='400' alt='image' src='./notes/L4Q/l4q.jpg'>      | arXiv |   2024 |            | [note](./notes/L4Q/note.md)       |</p>
</details>
<details open><summary><b>Shanghai Jiao Tong University</b></summary> 
<p>

|    | meta                           | ttttttttttttttttttttttttttttttitle                                                                                                        | ccccccccccccccccccover                                           | pub          |   year | codeeeee                                                            | note                          |
|---:|:-------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------|:-------------|-------:|:--------------------------------------------------------------------|:------------------------------|
|  0 | [PINS](./meta/PINS.prototxt)   | [Pruning Pre-trained Language Models with Principled Importance and Self-regularization](https://aclanthology.org/2023.findings-acl.573/) |                                                                  | ACL Findings |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/drsy/pins) |                               |
|  1 | [ReLU2](./meta/ReLU2.prototxt) | [ReLU2 Wins: Discovering Efficient Activation Functions for Sparse LLMs](https://arxiv.org/abs/2402.03804)                                | <img width='400' alt='image' src='./notes/ReLU2/activation.png'> | arXiv        |   2024 |                                                                     | [note](./notes/ReLU2/note.md) |</p>
</details>
<details open><summary><b>Stanford University</b></summary> 
<p>

|    | meta                                                | ttttttttttttttttttttttttttttttitle                                                                                                               | ccccccccccccccccccover                                               | pub     |   year | codeeeee                                                                            | note                                                                                                             |
|---:|:----------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------|:--------|-------:|:------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------|
|  0 | [Deep Compression](./meta/deepcompression.prototxt) | [Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](https://arxiv.org/pdf/1510.00149.pdf) |                                                                      | ICLR    |   2016 |                                                                                     |                                                                                                                  |
|  1 | [DSD](./meta/dsd.prototxt)                          | [DSD: Dense-Sparse-Dense Training for Deep Neural Networks](https://arxiv.org/pdf/1607.04381.pdf)                                                |                                                                      | ICLR    |   2017 |                                                                                     | [note](https://confluence.xilinx.com/display/aialgo/DSD%3A+Dense-Sparse-Dense+Training+for+Deep+Neural+Networks) |
|  2 | [FlashAttention](./meta/flashattention.prototxt)    | [FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/abs/2205.14135)                                  | <img width='400' alt='image' src='./notes/flashattention/cover.jpg'> | NeurIPS |   2022 | ![GitHub Repo stars](https://img.shields.io/github/stars/Dao-AILab/flash-attention) |                                                                                                                  |
|  3 | [Deja Vu](./meta/dejavu.prototxt)                   | [Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time](https://openreview.net/forum?id=wIPIhHd00i)                                  | <img width='400' alt='image' src='./notes/dejavu/dejavu.jpg'>        | ICML    |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/FMInference/DejaVu)        |                                                                                                                  |
|  4 | [FlashAttention-2](./meta/flashattention2.prototxt) | [FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning](https://arxiv.org/abs/2307.08691)                             |                                                                      | arXiv   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/Dao-AILab/flash-attention) |                                                                                                                  |</p>
</details>
<details open><summary><b>Sungkyunkwan University</b></summary> 
<p>

|    | meta                       | ttttttttttttttttttttttttttttttitle                                                                                                  | ccccccccccccccccccover                                  | pub   |   year | codeeeee   | note                        |
|---:|:---------------------------|:------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------|:------|-------:|:-----------|:----------------------------|
|  0 | [L4Q](./meta/L4Q.prototxt) | [L4Q: Parameter Efficient Quantization-Aware Training on Large Language Models via LoRA-wise LSQ](https://arxiv.org/abs/2402.04902) | <img width='400' alt='image' src='./notes/L4Q/l4q.jpg'> | arXiv |   2024 |            | [note](./notes/L4Q/note.md) |</p>
</details>
<details open><summary><b>Tencent AI Lab</b></summary> 
<p>

|    | meta                         | ttttttttttttttttttttttttttttttitle                                                                               | ccccccccccccccccccover   | pub   |   year | codeeeee                                                                    | note   |
|---:|:-----------------------------|:-----------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:----------------------------------------------------------------------------|:-------|
|  0 | [RPTQ](./meta/RPTQ.prototxt) | [RPTQ: Reorder-based Post-training Quantization for Large Language Models](https://arxiv.org/pdf/2304.01089.pdf) |                          | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/hahnyuan/RPTQ4LLM) |        |</p>
</details>
<details open><summary><b>Tencent Machine Learning Platform</b></summary> 
<p>

|    | meta                                   | ttttttttttttttttttttttttttttttitle                                                                                                  | ccccccccccccccccccover                                              | pub   |   year | codeeeee   | note                              |
|---:|:---------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------|:------|-------:|:-----------|:----------------------------------|
|  0 | [ProSparse](./meta/ProSparse.prototxt) | [ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models](https://arxiv.org/abs/2402.13516) | <img width='400' alt='image' src='./notes/ProSparse/prosparse.jpg'> | arXiv |   2024 |            | [note](./notes/ProSparse/note.md) |</p>
</details>
<details open><summary><b>The Hebrew University of Jerusalem, Israel</b></summary> 
<p>

|    | meta                          | ttttttttttttttttttttttttttttttitle                                                              | ccccccccccccccccccover                                               | pub   |   year | codeeeee   | note   |
|---:|:------------------------------|:------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------|:------|-------:|:-----------|:-------|
|  0 | [m](./meta/68I8KKBV.prototxt) | [Efficient Methods for Natural Language Processing: A Survey](https://arxiv.org/abs/2209.00099) | <img width='400' alt='image' src='./notes/survey/efficient_NLP.jpg'> | TACL  |   2023 |            |        |</p>
</details>
<details open><summary><b>The Hong Kong University of Science and Technology</b></summary> 
<p>

|    | meta                         | ttttttttttttttttttttttttttttttitle                                                                                             | ccccccccccccccccccover   | pub   |   year | codeeeee   | note   |
|---:|:-----------------------------|:-------------------------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:-----------|:-------|
|  0 | [LISA](./meta/LISA.prototxt) | [LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning](http://arxiv.org/abs/2403.17919v1) |                          | arXiv |   2024 |            |        |</p>
</details>
<details open><summary><b>The University of Hong Kong</b></summary> 
<p>

|    | meta                                   | ttttttttttttttttttttttttttttttitle                                                                                            | ccccccccccccccccccover                                              | pub          |   year | codeeeee                                                                      | note                            |
|---:|:---------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------|:-------------|-------:|:------------------------------------------------------------------------------|:--------------------------------|
|  0 | [SIMPLE](./meta/simple.prototxt)       | [Structured Pruning for Efficient Generative Pre-trained Language Models](https://aclanthology.org/2023.findings-acl.692.pdf) | <img width='400' alt='image' src='./notes/simple/cover.jpg'>        | ACL Findings |   2023 |                                                                               | [note](./notes/simple/index.md) |
|  1 | [OmniQuant](./meta/omniquant.prototxt) | [OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models](https://arxiv.org/abs/2308.13137)            | <img width='400' alt='image' src='./notes/omniquant/omniquant.png'> | arXiv        |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/OpenGVLab/OmniQuant) |                                 |</p>
</details>
<details open><summary><b>The University of Texas at Austin</b></summary> 
<p>

|    | meta                          | ttttttttttttttttttttttttttttttitle                                                                                                            | ccccccccccccccccccover   | pub   |   year | codeeeee   | note   |
|---:|:------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:-----------|:-------|
|  0 | [m](./meta/AYB1XUO5.prototxt) | [Ten Lessons We Have Learned in the New Sparseland: A Short Handbook for Sparse Neural Network Researchers](https://arxiv.org/abs/2302.02596) |                          | arXiv |   2023 |            |        |</p>
</details>
<details open><summary><b>Tongji University</b></summary> 
<p>

|    | meta                         | ttttttttttttttttttttttttttttttitle                                                       | ccccccccccccccccccover                                    | pub   |   year | codeeeee   | note   |
|---:|:-----------------------------|:-----------------------------------------------------------------------------------------|:----------------------------------------------------------|:------|-------:|:-----------|:-------|
|  0 | [GBDT](./meta/gbdt.prototxt) | [Pruning Large Language Models via Accuracy Predictor](https://arxiv.org/abs/2309.09507) | <img width='400' alt='image' src='./notes/gbdt/gbdt.jpg'> | arXiv |   2023 |            |        |</p>
</details>
<details open><summary><b>Tsinghua University</b></summary> 
<p>

|    | meta                                                | ttttttttttttttttttttttttttttttitle                                                                                                                                              | ccccccccccccccccccover                                              | pub   |   year | codeeeee                                                                                                                    | note                              |
|---:|:----------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------|:------|-------:|:----------------------------------------------------------------------------------------------------------------------------|:----------------------------------|
|  0 | [Deep Compression](./meta/deepcompression.prototxt) | [Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](https://arxiv.org/pdf/1510.00149.pdf)                                |                                                                     | ICLR  |   2016 |                                                                                                                             |                                   |
|  1 | [nmSPARSE](./meta/nmSPARSE.prototxt)                | [Efficient GPU Kernels for N:M-Sparse Weights in Deep Learning](https://proceedings.mlsys.org/paper_files/paper/2023/file/4552cedd396a308320209f75f56a5ad5-Paper-mlsys2023.pdf) |                                                                     | MLSys |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/SparTA)                                                  |                                   |
|  2 | [AWQ](./meta/awq.prototxt)                          | [AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration](https://arxiv.org/abs/2306.00978)                                                              |                                                                     | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/mit-han-lab/llm-awq)                                               |                                   |
|  3 | [m](./meta/23LQ9SVH.prototxt)                       | [Training Transformers with 4-bit Integers](https://arxiv.org/abs//2306.11987)                                                                                                  |                                                                     | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/xijiu9/Train_Transformers_with_INT4)                               |                                   |
|  4 | [Plug-and-Play](./meta/IA8CS3VH.prototxt)           | [Plug-and-Play: An Efficient Post-training Pruning Method for Large Language Models](https://openreview.net/forum?id=Tr0lPx9woF)                                                | <img width='400' alt='image' src='./notes/Plug-and-Play.jpg'>       | ICLR  |   2024 | ![GitHub Repo stars](https://img.shields.io/github/stars/biomedical-cybernetics/Relative-importance-and-activation-pruning) |                                   |
|  5 | [ProSparse](./meta/ProSparse.prototxt)              | [ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models](https://arxiv.org/abs/2402.13516)                                             | <img width='400' alt='image' src='./notes/ProSparse/prosparse.jpg'> | arXiv |   2024 |                                                                                                                             | [note](./notes/ProSparse/note.md) |
|  6 | [ReLU2](./meta/ReLU2.prototxt)                      | [ReLU2 Wins: Discovering Efficient Activation Functions for Sparse LLMs](https://arxiv.org/abs/2402.03804)                                                                      | <img width='400' alt='image' src='./notes/ReLU2/activation.png'>    | arXiv |   2024 |                                                                                                                             | [note](./notes/ReLU2/note.md)     |</p>
</details>
<details open><summary><b>UC Berkeley</b></summary> 
<p>

|    | meta                                      | ttttttttttttttttttttttttttttttitle                                                                                     | ccccccccccccccccccover                                               | pub     |   year | codeeeee                                                                                     | note                                                                         |
|---:|:------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------|:--------|-------:|:---------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------|
|  0 | [ActNN](./meta/actnn.prototxt)            | [ActNN: Reducing Training Memory Footprint via 2-Bit Activation Compressed Training](https://arxiv.org/abs/2104.14129) |                                                                      | ICML    |   2019 | ![GitHub Repo stars](https://img.shields.io/github/stars/ucbrise/actnn)                      |                                                                              |
|  1 | [FisherPruning](./meta/QA8XN7TU.prototxt) | [A Fast Post-Training Pruning Framework for Transformers](https://arxiv.org/abs/2204.09656)                            | <img width='400' alt='image' src='./notes/fisher_pruning/cover.jpg'> | NeurIPS |   2022 | ![GitHub Repo stars](https://img.shields.io/github/stars/WoosukKwon/retraining-free-pruning) | [note](https://confluence.xilinx.com/pages/viewpage.action?pageId=969271620) |
|  2 | [SqueezeLLM](./meta/SqueezeLLM.prototxt)  | [SqueezeLLM: Dense-and-Sparse Quantization](https://arxiv.org/abs/2306.07629)                                          |                                                                      | arXiv   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/SqueezeAILab/SqueezeLLM)            |                                                                              |</p>
</details>
<details open><summary><b>UCSD</b></summary> 
<p>

|    | meta                             | ttttttttttttttttttttttttttttttitle                                                                                  | ccccccccccccccccccover   | pub   |   year | codeeeee                                                  | note                                                                          |
|---:|:---------------------------------|:--------------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:----------------------------------------------------------|:------------------------------------------------------------------------------|
|  0 | [GPFQ](./meta/gpfq.prototxt)     | [A Greedy Algorithm for Quantizing Neural Networks](https://jmlr.csail.mit.edu/papers/volume22/20-1233/20-1233.pdf) |                          | JMLR  |   2021 | [Pytorch](https://gitenterprise.xilinx.com/xiandong/GPFA) | [note](https://confluence.xilinx.com/pages/viewpage.action?pageId=1005133974) |
|  1 | [GPFQv2](./meta/gpfqv2.prototxt) | [Post-training Quantization for Neural Networks with Provable Guarantees](https://arxiv.org/pdf/2201.11113.pdf)     |                          | arXiv |   2023 | [Pytorch](https://gitenterprise.xilinx.com/xiandong/GPFA) | [note](https://confluence.xilinx.com/pages/viewpage.action?pageId=1005133974) |</p>
</details>
<details open><summary><b>Univeristy of Sydney</b></summary> 
<p>

|    | meta                                   | ttttttttttttttttttttttttttttttitle                                                                                                                      | ccccccccccccccccccover                                          | pub   |   year | codeeeee                                                                            | note                               |
|---:|:---------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------|:------|-------:|:------------------------------------------------------------------------------------|:-----------------------------------|
|  0 | [Flash-LLM](./meta/flash_llm.prototxt) | [Flash-LLM: Enabling Cost-Effective and Highly-Efficient Large Generative Model Inference with Unstructured Sparsity](https://arxiv.org/abs/2309.10285) | <img width='400' alt='image' src='./notes/flash_llm/cover.jpg'> | VLDB  |   2024 | ![GitHub Repo stars](https://img.shields.io/github/stars/AlibabaResearch/flash-llm) | [note](./notes/flash_llm/index.md) |</p>
</details>
<details open><summary><b>University of Basel</b></summary> 
<p>

|    | meta                                                                       | ttttttttttttttttttttttttttttttitle                                                                                      | ccccccccccccccccccover                                                                                  | pub   |   year | codeeeee   | note   |
|---:|:---------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------|:------|-------:|:-----------|:-------|
|  0 | [Adaptively Sparse Attention](./meta/adaptively_sparse_attention.prototxt) | [Dynamic Context Pruning for Efficient and Interpretable Autoregressive Transformers](https://arxiv.org/abs/2305.15805) | <img width='400' alt='image' src='./notes/adaptively_sparse_attention/adaptively_sparse_attention.jpg'> | arXiv |   2023 |            |        |</p>
</details>
<details open><summary><b>University of Connecticut</b></summary> 
<p>

|    | meta                          | ttttttttttttttttttttttttttttttitle                                                                                                        | ccccccccccccccccccover   | pub   |   year | codeeeee                                                                                            | note   |
|---:|:------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:----------------------------------------------------------------------------------------------------|:-------|
|  0 | [m](./meta/XZBX1Z9G.prototxt) | [Sparse Progressive Distillation: Resolving Overfitting under Pretrain-and-Finetune Paradigm](https://aclanthology.org/2022.acl-long.16/) |                          | ACL   |   2022 | ![GitHub Repo stars](https://img.shields.io/github/stars/shaoyiHusky/SparseProgressiveDistillation) |        |</p>
</details>
<details open><summary><b>University of Electronic Science and Technology of China</b></summary> 
<p>

|    | meta                           | ttttttttttttttttttttttttttttttitle                                                                                          | ccccccccccccccccccover   | pub   |   year | codeeeee                                                               | note   |
|---:|:-------------------------------|:----------------------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:-----------------------------------------------------------------------|:-------|
|  0 | [BRECQ](./meta/brecq.prototxt) | [BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction](https://openreview.net/pdf?id=POWv6hDd9XH) |                          | ICLR  |   2021 | ![GitHub Repo stars](https://img.shields.io/github/stars/yhhhli/BRECQ) |        |</p>
</details>
<details open><summary><b>University of Illinois Urbana-Champaign</b></summary> 
<p>

|    | meta                         | ttttttttttttttttttttttttttttttitle                                                                                             | ccccccccccccccccccover   | pub   |   year | codeeeee   | note   |
|---:|:-----------------------------|:-------------------------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:-----------|:-------|
|  0 | [LISA](./meta/LISA.prototxt) | [LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning](http://arxiv.org/abs/2403.17919v1) |                          | arXiv |   2024 |            |        |</p>
</details>
<details open><summary><b>University of Surrey, UK</b></summary> 
<p>

|    | meta                                                   | ttttttttttttttttttttttttttttttitle                                                                                                                            | ccccccccccccccccccover                                                              | pub   |   year | codeeeee                                                                                | note   |
|---:|:-------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------|:------|-------:|:----------------------------------------------------------------------------------------|:-------|
|  0 | [Selective Context](./meta/selective_context.prototxt) | [Unlocking Context Constraints of LLMs: Enhancing Context Efficiency of LLMs with Self-Information-Based Content Filtering](https://arxiv.org/abs/2304.12102) | <img width='400' alt='image' src='./notes/selective_context/selective_context.jpg'> | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/liyucheng09/Selective_Context) |        |</p>
</details>
<details open><summary><b>University of Texas at Austin</b></summary> 
<p>

|    | meta                                                    | ttttttttttttttttttttttttttttttitle                                                                                                         | ccccccccccccccccccover                                    | pub   |   year | codeeeee                                                                                | note   |
|---:|:--------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------|:------|-------:|:----------------------------------------------------------------------------------------|:-------|
|  0 | [OWL](./meta/owl.prototxt)                              | [Outlier Weighed Layerwise Sparsity (OWL): A Missing Secret Sauce for Pruning LLMs to High Sparsity](https://arxiv.org/pdf/2310.05175.pdf) | <img width='400' alt='image' src='./notes/owl/cover.jpg'> | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/luuyin/OWL)                    |        |
|  1 | [Essential Sparsity](./meta/EssentialSparsity.prototxt) | [The Emergence of Essential Sparsity in Large Pre-trained Models: The Weights that Matter](https://arxiv.org/abs/2306.03805)               |                                                           | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/VITA-Group/essential_sparsity) |        |</p>
</details>
<details open><summary><b>University of Washington</b></summary> 
<p>

|    | meta                           | ttttttttttttttttttttttttttttttitle                                                                                                         | ccccccccccccccccccover                                      | pub   |   year | codeeeee                                                                 | note   |
|---:|:-------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------|:------|-------:|:-------------------------------------------------------------------------|:-------|
|  0 | [OWL](./meta/owl.prototxt)     | [Outlier Weighed Layerwise Sparsity (OWL): A Missing Secret Sauce for Pruning LLMs to High Sparsity](https://arxiv.org/pdf/2310.05175.pdf) | <img width='400' alt='image' src='./notes/owl/cover.jpg'>   | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/luuyin/OWL)     |        |
|  1 | [QLoRA](./meta/qlora.prototxt) | [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)                                                          | <img width='400' alt='image' src='./notes/qlora/qlora.jpg'> | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/artidoro/qlora) |        |</p>
</details>
<details open><summary><b>VITA Group</b></summary> 
<p>

|    | meta                                                    | ttttttttttttttttttttttttttttttitle                                                                                                            | ccccccccccccccccccover   | pub   |   year | codeeeee                                                                                | note   |
|---:|:--------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------|:------|-------:|:----------------------------------------------------------------------------------------|:-------|
|  0 | [m](./meta/AYB1XUO5.prototxt)                           | [Ten Lessons We Have Learned in the New Sparseland: A Short Handbook for Sparse Neural Network Researchers](https://arxiv.org/abs/2302.02596) |                          | arXiv |   2023 |                                                                                         |        |
|  1 | [Essential Sparsity](./meta/EssentialSparsity.prototxt) | [The Emergence of Essential Sparsity in Large Pre-trained Models: The Weights that Matter](https://arxiv.org/abs/2306.03805)                  |                          | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/VITA-Group/essential_sparsity) |        |</p>
</details>
<details open><summary><b>Xiamen University</b></summary> 
<p>

|    | meta                                   | ttttttttttttttttttttttttttttttitle                                                                                                  | ccccccccccccccccccover                                          | pub   |   year | codeeeee                                                                    | note                              |
|---:|:---------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------|:------|-------:|:----------------------------------------------------------------------------|:----------------------------------|
|  0 | [Compresso](./meta/Compresso.prototxt) | [Compresso: Structured Pruning with Collaborative Prompting Learns Compact Large Language Models](https://arxiv.org/abs/2310.05015) | <img width='400' alt='image' src='./notes/compresso/cover.jpg'> | arXiv |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/Moonlit) | [note](./notes/compresso/note.md) |</p>
</details>
<details open><summary><b>Yale University</b></summary> 
<p>

|    | meta                                 | ttttttttttttttttttttttttttttttitle                                                                                         | ccccccccccccccccccover                                            | pub   |   year | codeeeee                                                                  | note   |
|---:|:-------------------------------------|:---------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------|:------|-------:|:--------------------------------------------------------------------------|:-------|
|  0 | [Diffuser](./meta/diffuser.prototxt) | [Diffuser: Efficient Transformers with Multi-hop Attention Diffusion for Long Sequences](https://arxiv.org/abs/2210.11794) | <img width='400' alt='image' src='./notes/diffuser/diffuser.jpg'> | AAAI  |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/asFeng/Diffuser) |        |</p>
</details>
<details open><summary><b>Zhe Jiang University</b></summary> 
<p>

|    | meta                              | ttttttttttttttttttttttttttttttitle                                                                              | ccccccccccccccccccover                                        | pub   |   year | codeeeee                                                                     | note   |
|---:|:----------------------------------|:----------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------|:------|-------:|:-----------------------------------------------------------------------------|:-------|
|  0 | [Deja Vu](./meta/dejavu.prototxt) | [Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time](https://openreview.net/forum?id=wIPIhHd00i) | <img width='400' alt='image' src='./notes/dejavu/dejavu.jpg'> | ICML  |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/FMInference/DejaVu) |        |</p>
</details>
<details open><summary><b>Zhongguancun Laboratory</b></summary> 
<p>

|    | meta                       | ttttttttttttttttttttttttttttttitle                                                                       | ccccccccccccccccccover                                  | pub   |   year | codeeeee                                                             | note   |
|---:|:---------------------------|:---------------------------------------------------------------------------------------------------------|:--------------------------------------------------------|:------|-------:|:---------------------------------------------------------------------|:-------|
|  0 | [SMP](./meta/smp.prototxt) | [Pruning Pre-trained Language Models Without Fine-Tuning](https://aclanthology.org/2023.acl-long.35.pdf) | <img width='400' alt='image' src='./notes/smp/smp.jpg'> | ACL   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/kongds/SMP) |        |</p>
</details>
<details open><summary><b>iFLYTEK Research</b></summary> 
<p>

|    | meta                           | ttttttttttttttttttttttttttttttitle                                                                        | ccccccccccccccccccover                                      | pub   |   year | codeeeee                                                                | note                           |
|---:|:-------------------------------|:----------------------------------------------------------------------------------------------------------|:------------------------------------------------------------|:------|-------:|:------------------------------------------------------------------------|:-------------------------------|
|  0 | [GRAIN](./meta/grain.prototxt) | [Gradient-based Intra-attention Pruning on Pre-trained Language Models](https://arxiv.org/abs/2212.07634) | <img width='400' alt='image' src='./notes/grain/grain.jpg'> | ACL   |   2023 | ![GitHub Repo stars](https://img.shields.io/github/stars/airaria/GRAIN) | [note](./notes/grain/index.md) |</p>
</details>
</p>
</details>

