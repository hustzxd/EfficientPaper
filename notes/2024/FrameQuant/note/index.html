<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../../img/favicon.ico" />
    <title>FrameQuant: Flexible Low-Bit Quantization for Transformers - Efficient Paper</title>
    <link rel="stylesheet" href="../../../../css/theme.css" />
    <link rel="stylesheet" href="../../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.css" rel="stylesheet" />
        <link href="../../../../css/extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "FrameQuant: Flexible Low-Bit Quantization for Transformers";
        var mkdocs_page_input_path = "notes/2024/FrameQuant/note.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
 <link href="../../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }</style> <script src="../../../../assets/javascripts/glightbox.min.js"></script></head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../../.." class="icon icon-home"> Efficient Paper
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Paper List</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../cls_year/">By Year</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../cls_keyword/">By Keyword</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../cls_publication/">By Publication</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../cls_institution/">By Institution</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../cls_author/">By Author</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Weekly Paper</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../weekly_paper/2025-07-25/">2025-07-25</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../weekly_paper/2025-08-01/">2025-08-01</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../weekly_paper/2025-08-08/">2025-08-08</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../weekly_paper/2025-08-15/">2025-08-15</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../weekly_paper/2025-08-22/">2025-08-22</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../..">Efficient Paper</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">FrameQuant: Flexible Low-Bit Quantization for Transformers</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
  
                <h1 id="framequant-flexible-low-bit-quantization-for-transformers">FrameQuant: Flexible Low-Bit Quantization for Transformers</h1>
<p><a class="glightbox" href="../framequant.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../framequant.png" /></a></p>
<h2 id="abstract">Abstract</h2>
<p>Transformers are the backbone of powerful foundation models for many Vision
and Natural Language Processing tasks. But their compute and memory/storage
footprint is large, and so, serving such models is expensive often requiring
high-end hardware. To mitigate this difficulty, Post-Training Quantization
seeks to modify a pre-trained model and quantize it to eight bits or lower,
significantly boosting compute/memory/latency efficiency. Such models have been
successfully quantized to four bits with some performance loss. In this work,
we outline a simple scheme to quantize Transformer-based models to just two
bits (plus some overhead) with only a small drop in accuracy. Key to our
formulation is a concept borrowed from Harmonic analysis called Fusion Frames.
Our main finding is that the quantization must take place not in the original
weight space, but instead in the Fusion Frame representations. If quantization
is interpreted as the addition of noise, our casting of the problem allows
invoking an extensive body of known consistent recovery and noise robustness
guarantees. Further, if desired, de-noising filters are known in closed form.
We show empirically, via a variety of experiments, that (almost) two-bit
quantization for Transformer models promises sizable efficiency gains.</p>
<blockquote>
<p>https://arxivtools.blob.core.windows.net/xueshuxiangzipaperhtml/2023_12_22/2312.13488.pdf</p>
</blockquote>
<p>直接在original weight space对权重量化不是最优的，论文中提出将weight转化到Fusion Frame空间进行表示，从而能够将weight量化到2bit，比SOTA方法有较大的提升。</p>
<p>与QuIP的区别，如果设置redundancy factor r = 1，且随机设置正交矩阵P,那么就和QuIP一致了。</p>
<p>是否适合更高的bit, 比如3-bit, 4-bit配置，论文没有给出对应的实验结果，并指出OPTQ等方法已经有4-bit的结果了，所以推断这个方法在2-bit上有提升，在3/4-bit上可能提升不明显。</p>
              
  <!-- Giscus只在生产环境中显示，本地开发时隐藏 -->

<div style="padding: 20px; background-color: #f0f0f0; border: 1px solid #ddd; border-radius: 5px; margin: 20px 0;">
    <p><strong>📝 评论功能</strong></p>
    <p>评论功能仅在生产环境中可用。在本地开发环境中，Giscus 无法正常工作。</p>
    <p>请访问线上版本查看完整的评论功能。</p>
</div>


            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../../..";</script>
    <script src="../../../../js/theme_extra.js"></script>
    <script src="../../../../js/theme.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-clike.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
      <script src="../../../../js/prism-prototxt.js"></script>
      <script src="../../../../js/preview.js"></script>
      <script src="../../../../js/back-to-top.js"></script>
      <script src="https://giscus.app/client.js"></script>
      <script src="../../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
</script></body>
</html>
