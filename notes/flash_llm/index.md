# Flash-LLM: Enabling Cost-Effective and Highly-Efficient Large Generative Model Inference with Unstructured Sparsity


<p align="center">
  <img src="./overview.jpg" width="900" title="overview">
</p>

Key idea:

Load-as-Sparse and Compute-as-Dense