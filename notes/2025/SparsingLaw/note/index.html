<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../../img/favicon.ico" />
    <title>Sparsing Law: Towards Large Language Models with Greater Activation Sparsity - Efficient Paper</title>
    <link rel="stylesheet" href="../../../../css/theme.css" />
    <link rel="stylesheet" href="../../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.css" rel="stylesheet" />
        <link href="../../../../css/extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Sparsing Law: Towards Large Language Models with Greater Activation Sparsity";
        var mkdocs_page_input_path = "notes/2025/SparsingLaw/note.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
 <link href="../../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }</style> <script src="../../../../assets/javascripts/glightbox.min.js"></script></head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../../.." class="icon icon-home"> Efficient Paper
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Paper List</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../cls_year/">By Year</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../cls_keyword/">By Keyword</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../cls_publication/">By Publication</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../cls_institution/">By Institution</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../cls_author/">By Author</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Weekly Paper</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../weekly_paper/2025-07-25/">2025-07-25</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../weekly_paper/2025-08-01/">2025-08-01</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../weekly_paper/2025-08-08/">2025-08-08</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../weekly_paper/2025-08-15/">2025-08-15</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../../weekly_paper/2025-08-22/">2025-08-22</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../..">Efficient Paper</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Sparsing Law: Towards Large Language Models with Greater Activation Sparsity</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
  
                <h1 id="sparsing-law-towards-large-language-models-with-greater-activation-sparsity">Sparsing Law: Towards Large Language Models with Greater Activation Sparsity</h1>
<h2 id="abstract">Abstract</h2>
<p>Activation sparsity denotes the existence of substantial weakly-contributed
elements within activation outputs that can be eliminated, benefiting many
important applications concerned with large language models (LLMs). Although
promoting greater activation sparsity within LLMs deserves deep studies,
existing works lack comprehensive and quantitative research on the correlation
between activation sparsity and potentially influential factors. In this paper,
we present a comprehensive study on the quantitative scaling properties and
influential factors of the activation sparsity within decoder-only
Transformer-based LLMs. Specifically, we propose PPL-<script type="math/tex">p\%</script> sparsity, a precise
and performance-aware activation sparsity metric that is applicable to any
activation function. Through extensive experiments, we find several important
phenomena. Firstly, different activation functions exhibit comparable
performance but opposite training-time sparsity trends. The activation ratio
(i.e., <script type="math/tex">1-\mathrm{sparsity\ ratio}</script>) evolves as a convergent increasing
power-law and decreasing logspace power-law with the amount of training data
for SiLU-activated and ReLU-activated LLMs, respectively. These demonstrate
that ReLU is more efficient as the activation function than SiLU and can
leverage more training data to improve activation sparsity. Secondly, the
activation ratio linearly increases with the width-depth ratio below a certain
bottleneck point, indicating the potential advantage of a deeper architecture
at a fixed parameter scale. Finally, at similar width-depth ratios, we
surprisingly find that the limit value of activation sparsity varies weakly
with the parameter scale, i.e., the activation patterns within LLMs are
insensitive to the parameter scale. These empirical laws towards LLMs with
greater activation sparsity have important implications for making LLMs more
efficient and interpretable.</p>
<p><a class="glightbox" href="../fig3.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../fig3.png" /></a></p>
<ul>
<li>æå‡ºPPL-p%è¯„ä¼°æŒ‡æ ‡ï¼Œå…¶å®å°±æ˜¯å¸•ç´¯æ‰˜æ›²çº¿ï¼Œè¿™é‡Œp%è¡¨ç¤ºsparsity ratioï¼Œè¶Šé«˜ä¸€åŠæ¨¡å‹çš„ç²¾åº¦ä¹Ÿä¼šè¶Šå·®ï¼Œæ¯”å¦‚pplè¶Šé«˜ã€‚å›¾ä¸­ç»™çš„æ˜¯activation ratioï¼Œæ­£å¥½ä¸p%ç›¸åŠ =100%ã€‚</li>
</ul>
<p><a class="glightbox" href="../fig4.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../fig4.png" /></a></p>
<ul>
<li>PPL-1%æ¥è¯„ä¼°æ¨¡å‹å¯¹sparseçš„å¿å—ç¨‹åº¦</li>
<li>ReLUï¼šæ›´å¤šçš„è®­ç»ƒæ•°æ®å¯ä»¥å¯¼è‡´æ¨¡å‹æ›´åŠ ç¨€ç–</li>
<li>SiLU: æ›´å¤šçš„è®­ç»ƒæ•°æ®å¯¼è‡´æ¨¡å‹æ›´åŠ ç¨ å¯† ï¼ˆä½¿ç”¨PPL-1%æ¥è¯„ä¼°ï¼‰ï¼Œè¿™å¹¶ä¸èƒ½è¯´dense silu modelæ¯”relu modelå·®ï¼ŒæŒ‰ç…§ç»éªŒå’Œä¹‹å‰çš„å®éªŒç»“æœï¼Œsilu modelæ¯”relu modelå¥½ï¼Œä½†æ˜¯å»æ‰1%çš„æ¿€æ´»åï¼Œsilu modelçš„ç²¾åº¦è¡¨ç°ä¼šé™ä½å¾ˆå¤šï¼Œè€Œä¸”éšç€è®­ç»ƒçš„æ•°æ®è¶Šå¤šï¼Œç²¾åº¦é™ä½çš„å¹…åº¦å°±è¶Šå¤§ï¼›è¿™ä¸ªæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ç»“è®ºã€‚</li>
<li>
<p>æ‰€ä»¥æ¨èä½¿ç”¨ReLUæ¥ä½œä¸ºLLMçš„æ¿€æ´»å‡½æ•°</p>
</li>
<li>
<p>width-depth ratio è¡¨ç¤º hidden dimension ä¸ layer numberçš„æ¯”ä¾‹ï¼Œè¶Šé«˜è¯æ˜è¿™ä¸ªLLMè¶Šèƒ–ï¼Œè¿™ä¸ªå‚æ•°ä¹Ÿä¸activation sparsityè¡¨ç°æœ‰å¯†åˆ‡å…³ç³»</p>
</li>
</ul>
<p><a class="glightbox" href="../fig5.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../fig5.png" /></a></p>
<ul>
<li>ä»¥0.1Bæ¨¡å‹è®­ç»ƒä¸¾ä¾‹</li>
<li>Fig.5è¡¨ç¤ºWidth-Depth Ratioåœ¨[0, 114]ä¹‹é—´ï¼Œæ¨¡å‹ä¼šé€æ¸å˜èƒ–ï¼Œä¸”æ¿€æ´»æ¯”ä¾‹è¶Šæ¥è¶Šé«˜ï¼Œæ‰€ä»¥å¸Œæœ›æ¨¡å‹è¶Šç˜¦è¶Šå¥½ï¼Œæœ‰åˆ©äºactivation sparsity</li>
<li>Fig.6è¡¨ç¤ºWidth-Depth Ratioåœ¨[74, 182]ä¹‹é—´ï¼Œä¸èƒ–ä¸ç˜¦æ—¶è®­ç»ƒlossæœ€å¥½</li>
<li>ç»¼ä¸Šï¼Œå¯ä»¥é€‰å– Width-Depth Ratio=74ï¼Œå¯ä»¥æ»¡è¶³training loss å’Œ activation sparsity éœ€æ±‚</li>
</ul>
<p><a class="glightbox" href="../fig7.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="../fig7.png" /></a></p>
<ul>
<li>ç¡®å®šæ¨¡å‹çš„ Width-Depth ï¼Œä¸”training data è¶³å¤Ÿå¤šæ—¶ï¼Œmodelçš„å‚æ•°é‡å¯¹ activation sparsity å½±å“å¾ˆå°</li>
<li>ä½†æ˜¯å°æ¨¡å‹æ›´åŠ å®¹æ˜“æ”¶æ•› ï¼ˆä» activation sparsityå˜åŒ–çš„è§’åº¦ï¼‰</li>
<li>å¦å¤–ï¼Œä¸åŒscale çš„LLMï¼Œacitvation æ¿€æ´»çš„é¢‘ç‡éƒ½æ˜¯ç›¸ä¼¼çš„ï¼Œä¸”å¯¹ç›¸åŒçš„tokenè¾“å…¥ï¼Œä¸åŒscale LLMæ¿€æ´»çš„æ¯”ä¾‹ä¹Ÿæ˜¯ç›¸ä¼¼çš„ã€‚</li>
</ul>
<p>æ ¹æ®ä»¥ä¸Šè§‚å¯Ÿï¼š
- LLM Architectural design å°½é‡ä½¿ç”¨ReLUï¼Œä¸”æ»¡è¶³loss å‰æä¸‹ï¼Œå°½é‡ç˜¦ä¸€ç‚¹
- Training-time predictable sparsityï¼Œå¯ä»¥æ ¹æ®å°æ¨¡å‹çš„è¡¨ç°é¢„æµ‹å¤§æ¨¡å‹çš„ç»“æœ
- Lens for the convergence of neuron specializationï¼ŒFig4è¡¨ç¤ºtraining lossæ”¶æ•›åï¼Œactivation sparsity ä»ç„¶åœ¨é€æ­¥çš„è¿›åŒ–ï¼Œæ‰€ä»¥å¯ä»¥è®©æ¨¡å‹å¤šè®­ç»ƒï¼Œä»è€Œè®©æ›´å¤šçš„ç¥ç»å…ƒè¿›åŒ–ä¸ºä¸“ç”¨ç¥ç»å…ƒã€‚</p>
              
  <!-- Giscusåªåœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ˜¾ç¤ºï¼Œæœ¬åœ°å¼€å‘æ—¶éšè— -->

<div style="padding: 20px; background-color: #f0f0f0; border: 1px solid #ddd; border-radius: 5px; margin: 20px 0;">
    <p><strong>ğŸ“ è¯„è®ºåŠŸèƒ½</strong></p>
    <p>è¯„è®ºåŠŸèƒ½ä»…åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¯ç”¨ã€‚åœ¨æœ¬åœ°å¼€å‘ç¯å¢ƒä¸­ï¼ŒGiscus æ— æ³•æ­£å¸¸å·¥ä½œã€‚</p>
    <p>è¯·è®¿é—®çº¿ä¸Šç‰ˆæœ¬æŸ¥çœ‹å®Œæ•´çš„è¯„è®ºåŠŸèƒ½ã€‚</p>
</div>


            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../../..";</script>
    <script src="../../../../js/theme_extra.js"></script>
    <script src="../../../../js/theme.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-clike.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
      <script src="../../../../js/prism-prototxt.js"></script>
      <script src="../../../../js/preview.js"></script>
      <script src="../../../../js/back-to-top.js"></script>
      <script src="https://giscus.app/client.js"></script>
      <script src="../../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
</script></body>
</html>
