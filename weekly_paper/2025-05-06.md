# 2025-05-06

# Table of Contents
* [Digital Pathway Curation (DPC) a comparative pipeline to assess the reproducibility, consensus and accuracy across Gemini, PubMed, and scientific reviewers in biomedical research](#Digital-Pathway-Curation-(DPC)-a-comparative-pipeline-to-assess-the-reproducibility,-consensus-and-accuracy-across-Gemini,-PubMed,-and-scientific-reviewers-in-biomedical-research)
* [One Target, Many Views Multi-User Fusion for Collaborative Uplink ISAC](#One-Target,-Many-Views-Multi-User-Fusion-for-Collaborative-Uplink-ISAC)
* [Low-Precision Training of Large Language Models Methods, Challenges, and Opportunities](#Low-Precision-Training-of-Large-Language-Models-Methods,-Challenges,-and-Opportunities)
* [LMDepth Lightweight Mamba-based Monocular Depth Estimation for Real-World Deployment](#LMDepth-Lightweight-Mamba-based-Monocular-Depth-Estimation-for-Real-World-Deployment)
* [Seeking to Collide Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models](#Seeking-to-Collide-Online-Safety-Critical-Scenario-Generation-for-Autonomous-Driving-with-Retrieval-Augmented-Large-Language-Models)
* [Enhancing Realism in Holographic Augmented Reality Displays through Occlusion Handling](#Enhancing-Realism-in-Holographic-Augmented-Reality-Displays-through-Occlusion-Handling)
* [Hardware-Efficient Large-Scale Universal Linear Transformations for Optical Modes in the Synthetic Time Dimension](#Hardware-Efficient-Large-Scale-Universal-Linear-Transformations-for-Optical-Modes-in-the-Synthetic-Time-Dimension)
* [ICQuant Index Coding enables Low-bit LLM Quantization](#ICQuant-Index-Coding-enables-Low-bit-LLM-Quantization)
* [SeLR Sparsity-enhanced Lagrangian Relaxation for Computation Offloading at the Edge](#SeLR-Sparsity-enhanced-Lagrangian-Relaxation-for-Computation-Offloading-at-the-Edge)
* [Improving Routing in Sparse Mixture of Experts with Graph of Tokens](#Improving-Routing-in-Sparse-Mixture-of-Experts-with-Graph-of-Tokens)
* [SA-GAT-SR Self-Adaptable Graph Attention Networks with Symbolic Regression for high-fidelity material property prediction](#SA-GAT-SR-Self-Adaptable-Graph-Attention-Networks-with-Symbolic-Regression-for-high-fidelity-material-property-prediction)
* [FineScope  Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation](#FineScope--Precision-Pruning-for-Domain-Specialized-Large-Language-Models-Using-SAE-Guided-Self-Data-Cultivation)
* [Fast and Low-Cost Genomic Foundation Models via Outlier Removal](#Fast-and-Low-Cost-Genomic-Foundation-Models-via-Outlier-Removal)
* [FreqKV Frequency Domain Key-Value Compression for Efficient Context Window Extension](#FreqKV-Frequency-Domain-Key-Value-Compression-for-Efficient-Context-Window-Extension)
* [Efficient Recommendation with Millions of Items by Dynamic Pruning of Sub-Item Embeddings](#Efficient-Recommendation-with-Millions-of-Items-by-Dynamic-Pruning-of-Sub-Item-Embeddings)
* [Self-Ablating Transformers More Interpretability, Less Sparsity](#Self-Ablating-Transformers-More-Interpretability,-Less-Sparsity)
* [Efficient On-Chip Implementation of 4D Radar-Based 3D Object Detection on Hailo-8L](#Efficient-On-Chip-Implementation-of-4D-Radar-Based-3D-Object-Detection-on-Hailo-8L)
* [P2P-Insole Human Pose Estimation Using Foot Pressure Distribution and Motion Sensors](#P2P-Insole-Human-Pose-Estimation-Using-Foot-Pressure-Distribution-and-Motion-Sensors)
* [Fast Azimuthally Anisotropic 3D Radon Transform by Generalized Fourier Slice Theorem](#Fast-Azimuthally-Anisotropic-3D-Radon-Transform-by-Generalized-Fourier-Slice-Theorem)
* [Optimizing Deep Neural Networks using Safety-Guided Self Compression](#Optimizing-Deep-Neural-Networks-using-Safety-Guided-Self-Compression)
* [Mixture of Sparse Attention Content-Based Learnable Sparse Attention via Expert-Choice Routing](#Mixture-of-Sparse-Attention-Content-Based-Learnable-Sparse-Attention-via-Expert-Choice-Routing)
* [A Unifying Framework for Robust and Efficient Inference with Unstructured Data](#A-Unifying-Framework-for-Robust-and-Efficient-Inference-with-Unstructured-Data)
* [Path to a Single-Stage, 100-GeV Electron Beam via a Flying-Focus-Driven Laser-Plasma Accelerator](#Path-to-a-Single-Stage,-100-GeV-Electron-Beam-via-a-Flying-Focus-Driven-Laser-Plasma-Accelerator)
* [Origins of Thermalization in Semiclassical Cosmology](#Origins-of-Thermalization-in-Semiclassical-Cosmology)
* [Switching Transients in Constrained Transformer-Line/Cable Configurations](#Switching-Transients-in-Constrained-Transformer-Line/Cable-Configurations)
* [PolyQROM Orthogonal-Polynomial-Based Quantum Reduced-Order Model for Flow Field Analysis](#PolyQROM-Orthogonal-Polynomial-Based-Quantum-Reduced-Order-Model-for-Flow-Field-Analysis)
* [Levitated Sensor for Magnetometry in Ambient Environment](#Levitated-Sensor-for-Magnetometry-in-Ambient-Environment)
* [GarmentDiffusion 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers](#GarmentDiffusion-3D-Garment-Sewing-Pattern-Generation-with-Multimodal-Diffusion-Transformers)
* [RWKV-X A Linear Complexity Hybrid Language Model](#RWKV-X-A-Linear-Complexity-Hybrid-Language-Model)
* [Generative QoE Modeling A Lightweight Approach for Telecom Networks](#Generative-QoE-Modeling-A-Lightweight-Approach-for-Telecom-Networks)
* [Orthogonal Factor-Based Biclustering Algorithm (BCBOF) for High-Dimensional Data and Its Application in Stock Trend Prediction](#Orthogonal-Factor-Based-Biclustering-Algorithm-(BCBOF)-for-High-Dimensional-Data-and-Its-Application-in-Stock-Trend-Prediction)
* [Reinforced MLLM A Survey on RL-Based Reasoning in Multimodal Large Language Models](#Reinforced-MLLM-A-Survey-on-RL-Based-Reasoning-in-Multimodal-Large-Language-Models)
* [CachePrune Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks](#CachePrune-Neural-Based-Attribution-Defense-Against-Indirect-Prompt-Injection-Attacks)
* [Efficient LLMs with AMP Attention Heads and MLP Pruning](#Efficient-LLMs-with-AMP-Attention-Heads-and-MLP-Pruning)
* [MCMComm Hardware-Software Co-Optimization for End-to-End Communication in Multi-Chip-Modules](#MCMComm-Hardware-Software-Co-Optimization-for-End-to-End-Communication-in-Multi-Chip-Modules)
* [X-Fusion Introducing New Modality to Frozen Large Language Models](#X-Fusion-Introducing-New-Modality-to-Frozen-Large-Language-Models)
* [Softpick No Attention Sink, No Massive Activations with Rectified Softmax](#Softpick-No-Attention-Sink,-No-Massive-Activations-with-Rectified-Softmax)
* [Towards Understanding the Nature of Attention with Low-Rank Sparse Decomposition](#Towards-Understanding-the-Nature-of-Attention-with-Low-Rank-Sparse-Decomposition)
* [Relativistic ejecta from stellar mass black holes insights from simulations and synthetic radio images](#Relativistic-ejecta-from-stellar-mass-black-holes-insights-from-simulations-and-synthetic-radio-images)
* [Understanding Large Language Model Supply Chain Structure, Domain, and Vulnerabilities](#Understanding-Large-Language-Model-Supply-Chain-Structure,-Domain,-and-Vulnerabilities)
* [Grokking in the Wild Data Augmentation for Real-World Multi-Hop Reasoning with Transformers](#Grokking-in-the-Wild-Data-Augmentation-for-Real-World-Multi-Hop-Reasoning-with-Transformers)
* [Inference of high-dimensional weak instrumental variable regression models without ridge-regularization](#Inference-of-high-dimensional-weak-instrumental-variable-regression-models-without-ridge-regularization)
* [SFi-Former Sparse Flow Induced Attention for Graph Transformer](#SFi-Former-Sparse-Flow-Induced-Attention-for-Graph-Transformer)
* [SNR-aware Semantic Image Transmission with Deep Learning-based Channel Estimation in Fading Channels](#SNR-aware-Semantic-Image-Transmission-with-Deep-Learning-based-Channel-Estimation-in-Fading-Channels)
* [MambaMoE Mixture-of-Spectral-Spatial-Experts State Space Model for Hyperspectral Image Classification](#MambaMoE-Mixture-of-Spectral-Spatial-Experts-State-Space-Model-for-Hyperspectral-Image-Classification)
* [Modeling and Performance Analysis for Semantic Communications Based on Empirical Results](#Modeling-and-Performance-Analysis-for-Semantic-Communications-Based-on-Empirical-Results)
* [APG-MOS Auditory Perception Guided-MOS Predictor for Synthetic Speech](#APG-MOS-Auditory-Perception-Guided-MOS-Predictor-for-Synthetic-Speech)
* [GaLore 2 Large-Scale LLM Pre-Training by Gradient Low-Rank Projection](#GaLore-2-Large-Scale-LLM-Pre-Training-by-Gradient-Low-Rank-Projection)
* [Large-scale artificial intelligence with 41 million nanophotonic neurons on a metasurface](#Large-scale-artificial-intelligence-with-41-million-nanophotonic-neurons-on-a-metasurface)
* [SCOPE-MRI Bankart Lesion Detection as a Case Study in Data Curation and Deep Learning for Challenging Diagnoses](#SCOPE-MRI-Bankart-Lesion-Detection-as-a-Case-Study-in-Data-Curation-and-Deep-Learning-for-Challenging-Diagnoses)
* [Sparse mixed linear modeling with anchor-based guidance for high-entropy alloy discovery](#Sparse-mixed-linear-modeling-with-anchor-based-guidance-for-high-entropy-alloy-discovery)
* [CarbonCall Sustainability-Aware Function Calling for Large Language Models on Edge Devices](#CarbonCall-Sustainability-Aware-Function-Calling-for-Large-Language-Models-on-Edge-Devices)
* [Leveraging Action Relational Structures for Integrated Learning and Planning](#Leveraging-Action-Relational-Structures-for-Integrated-Learning-and-Planning)
* [Acceleration of Convergence of Double Series for the Green's Function of the Helmholtz Equation in Polar Coordinates](#Acceleration-of-Convergence-of-Double-Series-for-the-Green's-Function-of-the-Helmholtz-Equation-in-Polar-Coordinates)
* [ProFi-Net Prototype-based Feature Attention with Curriculum Augmentation for WiFi-based Gesture Recognition](#ProFi-Net-Prototype-based-Feature-Attention-with-Curriculum-Augmentation-for-WiFi-based-Gesture-Recognition)
* [Phase-locking in dynamical systems and quantum mechanics](#Phase-locking-in-dynamical-systems-and-quantum-mechanics)
* [AutoJudge Judge Decoding Without Manual Annotation](#AutoJudge-Judge-Decoding-Without-Manual-Annotation)
* [LIRM Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields](#LIRM-Large-Inverse-Rendering-Model-for-Progressive-Reconstruction-of-Shape,-Materials-and-View-dependent-Radiance-Fields)
* [Feelbert A Feedback Linearization-based Embedded Real-Time Quadrupedal Locomotion Framework](#Feelbert-A-Feedback-Linearization-based-Embedded-Real-Time-Quadrupedal-Locomotion-Framework)
* [Accelerated 3D-3D rigid registration of echocardiographic images obtained from apical window using particle filter](#Accelerated-3D-3D-rigid-registration-of-echocardiographic-images-obtained-from-apical-window-using-particle-filter)
* [Accelerating Mixture-of-Experts Training with Adaptive Expert Replication](#Accelerating-Mixture-of-Experts-Training-with-Adaptive-Expert-Replication)
* [Can AI Agents Design and Implement Drug Discovery Pipelines?](#Can-AI-Agents-Design-and-Implement-Drug-Discovery-Pipelines?)
* [TurboQuant Online Vector Quantization with Near-optimal Distortion Rate](#TurboQuant-Online-Vector-Quantization-with-Near-optimal-Distortion-Rate)
* [semi-PD Towards Efficient LLM Serving via Phase-Wise Disaggregated Computation and Unified Storage](#semi-PD-Towards-Efficient-LLM-Serving-via-Phase-Wise-Disaggregated-Computation-and-Unified-Storage)
* [CoherenDream Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback](#CoherenDream-Boosting-Holistic-Text-Coherence-in-3D-Generation-via-Multimodal-Large-Language-Models-Feedback)
* [Hierarchical Uncertainty-Aware Graph Neural Network](#Hierarchical-Uncertainty-Aware-Graph-Neural-Network)
* [STCOcc Sparse Spatial-Temporal Cascade Renovation for 3D Occupancy and Scene Flow Prediction](#STCOcc-Sparse-Spatial-Temporal-Cascade-Renovation-for-3D-Occupancy-and-Scene-Flow-Prediction)
* [FineQ Software-Hardware Co-Design for Low-Bit Fine-Grained Mixed-Precision Quantization of LLMs](#FineQ-Software-Hardware-Co-Design-for-Low-Bit-Fine-Grained-Mixed-Precision-Quantization-of-LLMs)
* [Taming the Titans A Survey of Efficient LLM Inference Serving](#Taming-the-Titans-A-Survey-of-Efficient-LLM-Inference-Serving)
* [Fitness Landscape of Large Language Model-Assisted Automated Algorithm Search](#Fitness-Landscape-of-Large-Language-Model-Assisted-Automated-Algorithm-Search)
* [DiVE Efficient Multi-View Driving Scenes Generation Based on Video Diffusion Transformer](#DiVE-Efficient-Multi-View-Driving-Scenes-Generation-Based-on-Video-Diffusion-Transformer)
* [SAMBLE Shape-Specific Point Cloud Sampling for an Optimal Trade-Off Between Local Detail and Global Uniformity](#SAMBLE-Shape-Specific-Point-Cloud-Sampling-for-an-Optimal-Trade-Off-Between-Local-Detail-and-Global-Uniformity)
* [Llama-3.1-FoundationAI-SecurityLLM-Base-8B Technical Report](#Llama-3.1-FoundationAI-SecurityLLM-Base-8B-Technical-Report)
* [ResearchCodeAgent An LLM Multi-Agent System for Automated Codification of Research Methodologies](#ResearchCodeAgent-An-LLM-Multi-Agent-System-for-Automated-Codification-of-Research-Methodologies)
* [Bullet Boosting GPU Utilization for LLM Serving via Dynamic Spatial-Temporal Orchestration](#Bullet-Boosting-GPU-Utilization-for-LLM-Serving-via-Dynamic-Spatial-Temporal-Orchestration)
* [Prisma An Open Source Toolkit for Mechanistic Interpretability in Vision and Video](#Prisma-An-Open-Source-Toolkit-for-Mechanistic-Interpretability-in-Vision-and-Video)
* [BRIDGE Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text](#BRIDGE-Benchmarking-Large-Language-Models-for-Understanding-Real-world-Clinical-Practice-Text)
* [R-Sparse Rank-Aware Activation Sparsity for Efficient LLM Inference](#R-Sparse-Rank-Aware-Activation-Sparsity-for-Efficient-LLM-Inference)
* [TreeHop Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering](#TreeHop-Generate-and-Filter-Next-Query-Embeddings-Efficiently-for-Multi-hop-Question-Answering)
* [SAGA A Security Architecture for Governing AI Agentic Systems](#SAGA-A-Security-Architecture-for-Governing-AI-Agentic-Systems)
* [MERA Multimodal and Multiscale Self-Explanatory Model with Considerably Reduced Annotation for Lung Nodule Diagnosis](#MERA-Multimodal-and-Multiscale-Self-Explanatory-Model-with-Considerably-Reduced-Annotation-for-Lung-Nodule-Diagnosis)
* [Spatial-Sign based High dimensional Change Point Inference](#Spatial-Sign-based-High-dimensional-Change-Point-Inference)
* [Quantitative evaluation of brain-inspired vision sensors in high-speed robotic perception](#Quantitative-evaluation-of-brain-inspired-vision-sensors-in-high-speed-robotic-perception)
* [AlphaFuse Learn ID Embeddings for Sequential Recommendation in Null Space of Language Embeddings](#AlphaFuse-Learn-ID-Embeddings-for-Sequential-Recommendation-in-Null-Space-of-Language-Embeddings)
* [Leveraging Modified Ex Situ Tomography Data for Segmentation of In Situ Synchrotron X-Ray Computed Tomography](#Leveraging-Modified-Ex-Situ-Tomography-Data-for-Segmentation-of-In-Situ-Synchrotron-X-Ray-Computed-Tomography)
* [WuNeng Hybrid State with Attention](#WuNeng-Hybrid-State-with-Attention)
* [RadioFormer A Multiple-Granularity Radio Map Estimation Transformer with 1\textpertenthousand Spatial Sampling](#RadioFormer-A-Multiple-Granularity-Radio-Map-Estimation-Transformer-with-1\textpertenthousand-Spatial-Sampling)
* [Muyan-TTS A Trainable Text-to-Speech Model Optimized for Podcast Scenarios with a $50K Budget](#Muyan-TTS-A-Trainable-Text-to-Speech-Model-Optimized-for-Podcast-Scenarios-with-a-$50K-Budget)
* [BQSched A Non-intrusive Scheduler for Batch Concurrent Queries via Reinforcement Learning](#BQSched-A-Non-intrusive-Scheduler-for-Batch-Concurrent-Queries-via-Reinforcement-Learning)
* [Efficient Reasoning for LLMs through Speculative Chain-of-Thought](#Efficient-Reasoning-for-LLMs-through-Speculative-Chain-of-Thought)
* [Improved Molecular Generation through Attribute-Driven Integrative Embeddings and GAN Selectivity](#Improved-Molecular-Generation-through-Attribute-Driven-Integrative-Embeddings-and-GAN-Selectivity)
* ["I Would Have Written My Code Differently'' Beginners Struggle to Understand LLM-Generated Code](#"I-Would-Have-Written-My-Code-Differently''-Beginners-Struggle-to-Understand-LLM-Generated-Code)
* [The Masked Matrix Separation Problem A First Analysis](#The-Masked-Matrix-Separation-Problem-A-First-Analysis)
* [R-Sparse R-CNN SAR Ship Detection Based on Background-Aware Sparse Learnable Proposals](#R-Sparse-R-CNN-SAR-Ship-Detection-Based-on-Background-Aware-Sparse-Learnable-Proposals)
* [Revisiting Transformers through the Lens of Low Entropy and Dynamic Sparsity](#Revisiting-Transformers-through-the-Lens-of-Low-Entropy-and-Dynamic-Sparsity)
* [Action Flow Matching for Continual Robot Learning](#Action-Flow-Matching-for-Continual-Robot-Learning)
* [Efficiency, Expressivity, and Extensibility in a Close-to-Metal NPU Programming Interface](#Efficiency,-Expressivity,-and-Extensibility-in-a-Close-to-Metal-NPU-Programming-Interface)
* [BitNet v2 Native 4-bit Activations with Hadamard Transformation for 1-bit LLMs](#BitNet-v2-Native-4-bit-Activations-with-Hadamard-Transformation-for-1-bit-LLMs)
* [A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1](#A-Method-for-the-Architecture-of-a-Medical-Vertical-Large-Language-Model-Based-on-Deepseek-R1)
* [Large Language Models to Accelerate Organic Chemistry Synthesis](#Large-Language-Models-to-Accelerate-Organic-Chemistry-Synthesis)
* [SSD-Poser Avatar Pose Estimation with State Space Duality from Sparse Observations](#SSD-Poser-Avatar-Pose-Estimation-with-State-Space-Duality-from-Sparse-Observations)
* [Ergodic theorems for bilinear averages, Roth's Theorem and Corners along fractional powers](#Ergodic-theorems-for-bilinear-averages,-Roth's-Theorem-and-Corners-along-fractional-powers)
* [Sharp decay estimates and numerical analysis for weakly coupled systems of two subdiffusion equations](#Sharp-decay-estimates-and-numerical-analysis-for-weakly-coupled-systems-of-two-subdiffusion-equations)
* [Leveraging Decoder Architectures for Learned Sparse Retrieval](#Leveraging-Decoder-Architectures-for-Learned-Sparse-Retrieval)
* [Think, Prune, Train, Improve Scaling Reasoning without Scaling Models](#Think,-Prune,-Train,-Improve-Scaling-Reasoning-without-Scaling-Models)
* [Study on Real-Time Road Surface Reconstruction Using Stereo Vision](#Study-on-Real-Time-Road-Surface-Reconstruction-Using-Stereo-Vision)
* [Disentangle Identity, Cooperate Emotion Correlation-Aware Emotional Talking Portrait Generation](#Disentangle-Identity,-Cooperate-Emotion-Correlation-Aware-Emotional-Talking-Portrait-Generation)
* [Back to Fundamentals Low-Level Visual Features Guided Progressive Token Pruning](#Back-to-Fundamentals-Low-Level-Visual-Features-Guided-Progressive-Token-Pruning)


## Digital Pathway Curation (DPC) a comparative pipeline to assess the reproducibility, consensus and accuracy across Gemini, PubMed, and scientific reviewers in biomedical research

>Authors: Flavio Lichtenstein, Daniel Alexandre de Souza, Carlos Eduardo Madureira Trufen, Victor Wendel da Silva Gonçalves, Juliana de Paula Bernardes, Vinicius Miranda Baroni, Carlos DeOcesano-Pereira, Leonardo Fontoura Ormundo, Fabio Augusto Labre de Souza, Olga Celia Martinez Ibañez, Nancy Starobinas, Luciano Rodrigo Lopes, Aparecida Maria Fontes, Sonia Aparecida de Andrade, Ana Marisa Chudzinski-Tavassi

>2025-05-02

> http://arxiv.org/abs/2505.01259v1

A scientific study begins with a central question, and search engines like
PubMed are the first tools for retrieving knowledge and understanding the
current state of the art. Large Language Models (LLMs) have been used in
research, promising **acceleration** and deeper results. However, besides caution,
they demand rigorous validation. Assessing complex biological relationships
remains challenging for SQL-based tools and LLM models. Here, we introduce the
Digital Pathway Curation (DPC) pipeline to evaluate the reproducibility and
accuracy of the Gemini models against PubMed search and human expert curation.
Using two omics experiments, we created a large dataset (Ensemble) based on
determining pathway-disease associations. With the Ensemble dataset, we
demonstrate that Gemini achieves high run-to-run reproducibility of
approximately 99% and inter-model reproducibility of around 75%. Next, we
calculate the crowdsourced consensus using a smaller dataset. The CSC allows us
to calculate accuracies, and the Gemini multi-model consensus reached a
significant accuracy of about 87%. Our findings demonstrate that LLMs are
reproducible, reliable, and valuable tools for navigating complex biomedical
knowledge.


## One Target, Many Views Multi-User Fusion for Collaborative Uplink ISAC

>Authors: Sajad Daei, Gabor Fodor, Mikael Skoglund

>2025-05-02

> http://arxiv.org/abs/2505.01223v1

We propose a novel pilot-free multi-user uplink framework for integrated
sensing and communication (ISAC) in mm-wave networks, where single-antenna
users transmit orthogonal frequency division multiplexing signals without
dedicated pilots. The base station exploits the spatial and velocity
diversities of users to simultaneously decode messages and detect targets,
transforming user transmissions into a powerful sensing tool. Each user's
signal, structured by a known codebook, propagates through a **sparse** multi-path
channel with shared moving targets and user-specific scatterers. Notably,
common targets induce distinct delay-Doppler-angle signatures, while stationary
scatterers cluster in parameter space. We formulate the joint multi-path
parameter estimation and data decoding as a 3D super-resolution problem,
extracting delays, Doppler shifts, and angles-of-arrival via atomic norm
minimization, efficiently solved using semidefinite programming. A core
innovation is multiuser fusion, where diverse user observations are
collaboratively combined to enhance sensing and decoding. This approach
improves robustness and integrates multi-user perspectives into a unified
estimation framework, enabling high-resolution sensing and reliable
communication. Numerical results show that the proposed framework significantly
enhances both target estimation and communication performance, highlighting its
potential for next-generation ISAC systems.


## Low-Precision Training of Large Language Models Methods, Challenges, and Opportunities

>Authors: Zhiwei Hao, Jianyuan Guo, Li Shen, Yong Luo, Han Hu, Guoxia Wang, Dianhai Yu, Yonggang Wen, Dacheng Tao

>2025-05-02

> http://arxiv.org/abs/2505.01043v1

Large language models (LLMs) have achieved impressive performance across
various domains. However, the substantial hardware resources required for their
training present a significant barrier to efficiency and scalability. To
mitigate this challenge, low-precision training techniques have been widely
adopted, leading to notable advancements in training efficiency. Despite these
gains, low-precision training involves several components$\unicode{x2013}$such
as weights, activations, and gradients$\unicode{x2013}$each of which can be
represented in different numerical formats. The resulting diversity has created
a fragmented landscape in low-precision training research, making it difficult
for researchers to gain a unified overview of the field. This survey provides a
comprehensive review of existing low-precision training methods. To
systematically organize these approaches, we categorize them into three primary
groups based on their underlying numerical formats, which is a key factor
influencing hardware compatibility, computational efficiency, and ease of
reference for readers. The categories are: (1) fixed-point and integer-based
methods, (2) floating-point-based methods, and (3) customized format-based
methods. Additionally, we discuss **quantization**-aware training approaches, which
share key similarities with low-precision training during forward propagation.
Finally, we highlight several promising research directions to advance this
field. A collection of papers discussed in this survey is provided in
https://github.com/Hao840/Awesome-Low-Precision-Training.


## LMDepth Lightweight Mamba-based Monocular Depth Estimation for Real-World Deployment

>Authors: Jiahuan Long, Xin Zhou

>2025-05-02

> http://arxiv.org/abs/2505.00980v1

Monocular depth estimation provides an additional depth dimension to RGB
images, making it widely applicable in various fields such as virtual reality,
autonomous driving and robotic navigation. However, existing depth estimation
algorithms often struggle to effectively balance performance and computational
efficiency, which poses challenges for deployment on resource-constrained
devices. To address this, we propose LMDepth, a lightweight Mamba-based
monocular depth estimation network, designed to reconstruct high-precision
depth information while maintaining low computational overhead. Specifically,
we propose a modified pyramid spatial pooling module that serves as a
multi-scale feature aggregator and context extractor, ensuring global spatial
information for accurate depth estimation. Moreover, we integrate multiple
depth Mamba blocks into the decoder. Designed with linear computations, the
Mamba Blocks enable LMDepth to efficiently decode depth information from global
features, providing a lightweight alternative to Transformer-based
architectures that depend on complex attention mechanisms. Extensive
experiments on the NYUDv2 and KITTI datasets demonstrate the effectiveness of
our proposed LMDepth. Compared to previous lightweight depth estimation
methods, LMDepth achieves higher performance with fewer parameters and lower
computational complexity (measured by GFLOPs). We further deploy LMDepth on an
embedded platform with INT8 **quantization**, validating its practicality for
real-world edge applications.


## Seeking to Collide Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models

>Authors: Yuewen Mei, Tong Nie, Jian Sun, Ye Tian

>2025-05-02

> http://arxiv.org/abs/2505.00972v1

Simulation-based testing is crucial for validating autonomous vehicles (AVs),
yet existing scenario generation methods either overfit to common driving
patterns or operate in an offline, non-interactive manner that fails to expose
rare, safety-critical corner cases. In this paper, we introduce an online,
retrieval-augmented large language model (LLM) framework for generating
safety-critical driving scenarios. Our method first employs an LLM-based
behavior analyzer to infer the most dangerous intent of the background vehicle
from the observed state, then queries additional LLM agents to synthesize
feasible adversarial trajectories. To mitigate catastrophic forgetting and
accelerate adaptation, we augment the framework with a dynamic memorization and
retrieval bank of intent-planner pairs, automatically expanding its behavioral
library when novel intents arise. Evaluations using the Waymo Open Motion
Dataset demonstrate that our model reduces the mean minimum time-to-collision
from 1.62 to 1.08 s and incurs a 75% collision rate, substantially
outperforming baselines.


## Enhancing Realism in Holographic Augmented Reality Displays through Occlusion Handling

>Authors: Woongseob Han, Chanseul Lee, Jae-Hyeung Park

>2025-05-02

> http://arxiv.org/abs/2505.00942v1

In this paper, an occlusion-capable holographic augmented-reality (AR)
display is proposed, and its ability to enhance AR imagery through occlusion is
demonstrated. Holographic displays can generate ideal three-dimensional (3D)
virtual images and have recently shown rapid advancements, particularly in
noise reduction through learning-based approaches. However, these displays
still face challenges in improving image quality for AR scenarios because
holographic virtual images are simply superimposed onto the real world, leading
to a loss of contrast and visibility. To address this, an occlusion optics,
which can mask designated areas of the real world, is incorporated into
holographic AR displays. The proposed system employs a folded 4f system with a
digital micromirror device and sequentially operates as both a real-world mask
and an active Fourier filter. This approach transforms traditionally
translucent holographic images into perceptually opaque ones while
simultaneously eliminating unwanted noise terms from pixelated holographic
displays. Furthermore, active Fourier filtering expands the virtual image field
of view through time-multiplexed operation and supports a novel binary hologram
optimization algorithm that performs especially well for **sparse** virtual
content. The implementation successfully achieves opaque holographic 3D image
presentation, significantly improving contrast and image quality while
producing highly realistic 3D AR scenes with optically cast shadows.


## Hardware-Efficient Large-Scale Universal Linear Transformations for Optical Modes in the Synthetic Time Dimension

>Authors: Jasvith Raj Basani, Chaohan Cui, Jack Postlewaite, Edo Waks, Saikat Guha

>2025-05-01

> http://arxiv.org/abs/2505.00865v1

Recent progress in photonic information processing has generated strong
interest in scalable and dynamically reconfigurable photonic circuitry.
Conventional approaches based on spatial interferometer meshes face a
fundamental scaling bottleneck, requiring a number of components that grows
quadratically with system size. Here, we introduce a hardware-efficient
time-domain photonic processor that achieves at least an exponential reduction
in component count for implementing arbitrary linear transformations. Our
design leverages the favorable scaling properties of the synthetic time
dimension by encoding information in time-binned modes and processing them in
parallel using recursive switchable short and long-range coupling. The dynamic
connectivity of our processor enables systematic **pruning** of circuit depth,
which minimizes optical loss while maintaining all-to-all connectivity. We
benchmark our platform on the task of boosted Bell state measurements - a
critical component in linear optical quantum computing, and demonstrate that
the architecture surpasses the thresholds required for universal cluster-state
quantum computation under realistic hardware parameters. We link the
performance of our device to the geometric nature of multi-photon transport and
show that, contrary to the expectation that redundant faulty hardware degrades
performance, localization effects may contribute to improved robustness against
coherent errors. Our results establish a practical pathway toward near-term,
scalable, and reconfigurable photonic processors for quantum computation and
simulation in the synthetic time dimension.


## ICQuant Index Coding enables Low-bit LLM Quantization

>Authors: Xinlin Li, Osama Hanna, Christina Fragouli, Suhas Diggavi

>2025-05-01

> http://arxiv.org/abs/2505.00850v1

The rapid deployment of Large Language Models (LLMs) highlights the need for
efficient **low-bit** post-training **quantization** (PTQ), due to their high memory
costs. A key challenge in weight **quantization** is the presence of outliers,
which inflate **quantization** ranges and lead to large errors. While a number of
outlier suppression techniques have been proposed, they either: fail to
effectively shrink the **quantization** range, or incur (relatively) high bit
overhead. In this paper, we present ICQuant, a novel framework that leverages
outlier statistics to design an efficient index coding scheme for outlier-aware
weight-only **quantization**. Compared to existing outlier suppression techniques
requiring $\approx 1$ bit overhead to halve the **quantization** range, ICQuant
requires only $\approx 0.3$ bits; a significant saving in extreme compression
regimes (e.g., 2-3 bits per weight). ICQuant can be used on top of any existing
**quantize**rs to eliminate outliers, improving the **quantization** quality. Using
just 2.3 bits per weight and simple scalar **quantize**rs, ICQuant improves the
zero-shot accuracy of the 2-bit Llama3-70B model by up to 130% and 150%
relative to QTIP and QuIP#; and it achieves comparable performance to the
best-known fine-tuned **quantize**r (PV-tuning) without fine-tuning.


## SeLR Sparsity-enhanced Lagrangian Relaxation for Computation Offloading at the Edge

>Authors: Negar Erfaniantaghvayi, Zhongyuan Zhao, Kevin Chan, Ananthram Swami, Santiago Segarra

>2025-05-01

> http://arxiv.org/abs/2505.00848v1

This paper introduces a novel computational approach for offloading sensor
data processing tasks to servers in edge networks for better accuracy and
makespan. A task is assigned with one of several offloading options, each
comprises a server, a route for uploading data to the server, and a service
profile that specifies the performance and resource consumption at the server
and in the network. This offline offloading and routing problem is formulated
as mixed integer programming (MIP), which is non-convex and HP-hard due to the
discrete decision variables associated to the offloading options. The novelty
of our approach is to transform this non-convex problem into iterative convex
optimization by relaxing integer decision variables into continuous space,
combining primal-dual optimization for penalizing constraint violations and
reweighted $L_1$-minimization for promoting solution **sparsity**, which achieves
better convergence through a smoother path in a continuous search space.
Compared to existing greedy heuristics, our approach can achieve a better
Pareto frontier in accuracy and latency, scales better to larger problem
instances, and can achieve a 7.72--9.17$\times$ reduction in computational
overhead of scheduling compared to the optimal solver in hierarchically
organized edge networks with 300 nodes and 50--100 tasks.


## Improving Routing in Sparse Mixture of Experts with Graph of Tokens

>Authors: Tam Nguyen, Ngoc N. Tran, Khai Nguyen, Richard G. Baraniuk

>2025-05-01

> http://arxiv.org/abs/2505.00792v1

Sparse Mixture of Experts (SMoE) has emerged as a key to achieving
unprecedented scalability in deep learning. By activating only a small subset
of parameters per sample, SMoE achieves an exponential increase in parameter
counts while maintaining a constant computational overhead. However, SMoE
models are susceptible to routing fluctuations--changes in the routing of a
given input to its target expert--at the late stage of model training, leading
to model non-robustness. In this work, we unveil the limitation of SMoE through
the perspective of the probabilistic graphical model (PGM). Through this PGM
framework, we highlight the independence in the expert-selection of tokens,
which exposes the model to routing fluctuation and non-robustness. Alleviating
this independence, we propose the novel Similarity-Aware (S)MoE, which
considers interactions between tokens during expert selection. We then derive a
new PGM underlying an (S)MoE-Attention block, going beyond just a single (S)MoE
layer. Leveraging the token similarities captured by the attention matrix, we
propose the innovative Attention-Aware (S)MoE, which employs the attention
matrix to guide the routing of tokens to appropriate experts in (S)MoE. We
theoretically prove that Similarity/Attention-Aware routing help reduce the
entropy of expert selection, resulting in more stable token routing mechanisms.
We empirically validate our models on various tasks and domains, showing
significant improvements in reducing routing fluctuations, enhancing accuracy,
and increasing model robustness over the baseline MoE-Transformer with token
routing via softmax gating.


## SA-GAT-SR Self-Adaptable Graph Attention Networks with Symbolic Regression for high-fidelity material property prediction

>Authors: Liu Junchi, Tang Ying, Tretiak Sergei, Duan Wenhui, Zhou Liujiang

>2025-05-01

> http://arxiv.org/abs/2505.00625v2

Recent advances in machine learning have demonstrated an enormous utility of
deep learning approaches, particularly Graph Neural Networks (GNNs) for
materials science. These methods have emerged as powerful tools for
high-throughput prediction of material properties, offering a compelling
enhancement and alternative to traditional first-principles calculations. While
the community has predominantly focused on developing increasingly complex and
universal models to enhance predictive accuracy, such approaches often lack
physical interpretability and insights into materials behavior. Here, we
introduce a novel computational paradigm, Self-Adaptable Graph Attention
Networks integrated with Symbolic Regression (SA-GAT-SR), that synergistically
combines the predictive capability of GNNs with the interpretative power of
symbolic regression. Our framework employs a self-adaptable encoding algorithm
that automatically identifies and adjust attention weights so as to screen
critical features from an expansive 180-dimensional feature space while
maintaining O(n) computational scaling. The integrated SR module subsequently
distills these features into compact analytical expressions that explicitly
reveal quantum-mechanically meaningful relationships, achieving 23 times
**acceleration** compared to conventional SR implementations that heavily rely on
first principle calculations-derived features as input. This work suggests a
new framework in computational materials science, bridging the gap between
predictive accuracy and physical interpretability, offering valuable physical
insights into material behavior.


## FineScope  Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation

>Authors: Chaitali Bhattacharyya, Yeseong Kim

>2025-05-01

> http://arxiv.org/abs/2505.00624v1

Training large language models (LLMs) from scratch requires significant
computational resources, driving interest in developing smaller,
domain-specific LLMs that maintain both efficiency and strong task performance.
Medium-sized models such as LLaMA, llama} have served as starting points for
domain-specific adaptation, but they often suffer from accuracy degradation
when tested on specialized datasets. We introduce FineScope, a framework for
deriving compact, domain-optimized LLMs from larger pretrained models.
FineScope leverages the Sparse Autoencoder (SAE) framework, inspired by its
ability to produce interpretable feature representations, to extract
domain-specific subsets from large datasets. We apply structured **pruning** with
domain-specific constraints, ensuring that the resulting pruned models retain
essential knowledge for the target domain. To further enhance performance,
these pruned models undergo self-data distillation, leveraging SAE-curated
datasets to restore key domain-specific information lost during **pruning**.
Extensive experiments and ablation studies demonstrate that FineScope achieves
highly competitive performance, outperforming several large-scale
state-of-the-art LLMs in domain-specific tasks. Additionally, our results show
that FineScope enables pruned models to regain a substantial portion of their
original performance when fine-tuned with SAE-curated datasets. Furthermore,
applying these datasets to fine-tune pretrained LLMs without **pruning** also
improves their domain-specific accuracy, highlighting the robustness of our
approach. The code will be released.


## Fast and Low-Cost Genomic Foundation Models via Outlier Removal

>Authors: Haozheng Luo, Chenghao Qiu, Maojiang Su, Zhihan Zhou, Zoe Mehta, Guo Ye, Jerry Yao-Chieh Hu, Han Liu

>2025-05-01

> http://arxiv.org/abs/2505.00598v2

To address the challenge of scarce computational resources in genomic
modeling, we introduce GERM, a genomic foundation model with strong compression
performance and fast adaptability. GERM improves upon models like DNABERT-2 by
eliminating outliers that hinder low-rank adaptation and post-training
**quantization**, enhancing both efficiency and robustness. We replace the vanilla
attention layer with an outlier-free mechanism inspired by associative memory
models. By removing outliers during both pre-training and fine-tuning, this
approach accelerates adaptation, reduces computational costs, and enhances
**quantization** robustness within acceptable loss margins. Additionally, we
propose GERM-T, a strategy that employs small-step continual learning within
the outlier-free framework, leveraging original checkpoints to avoid retraining
from scratch. Empirically, GERM improves fine-tuning performance by 37.98% and
**quantization** by 64.34% over the baseline model. It also reduces average
kurtosis by 92.14% and maximum infinity norm by 82.77%. Compared to leading
methods, GERM consistently delivers superior performance, offering a practical
solution for genomic modeling in resource-constrained settings. Code is
available at https://github.com/MAGICS-LAB/GERM.


## FreqKV Frequency Domain Key-Value Compression for Efficient Context Window Extension

>Authors: Jushi Kai, Boyi Zeng, Yixuan Wang, Haoli Bai, Bo Jiang, Zhouhan Lin

>2025-05-01

> http://arxiv.org/abs/2505.00570v1

Extending the context window in large language models (LLMs) is essential for
applications involving long-form content generation. However, the linear
increase in key-value (**KV**) cache memory requirements and the quadratic
complexity of self-attention with respect to sequence length present
significant challenges during fine-tuning and inference. Existing methods
suffer from performance degradation when extending to longer contexts. In this
work, we introduce a novel context extension method that optimizes both
fine-tuning and inference efficiency. Our method exploits a key observation: in
the frequency domain, the energy distribution of the **KV** cache is primarily
concentrated in low-frequency components. By filtering out the high-frequency
components, the **KV** cache can be effectively compressed with minimal information
loss. Building on this insight, we propose an efficient compression technique,
Freq**KV**, that iteratively compresses the increasing **KV** cache to a fixed size in
the frequency domain, applicable to both fine-tuning and inference. Freq**KV**
introduces no additional parameters or architectural modifications. With
minimal fine-tuning, LLMs can learn to leverage the limited cache that is
compressed in the frequency domain and extend the context window efficiently.
Experiments on various long context language modeling and understanding tasks
demonstrate the efficiency and efficacy of the proposed method.


## Efficient Recommendation with Millions of Items by Dynamic Pruning of Sub-Item Embeddings

>Authors: Aleksandr V. Petrov, Craig Macdonald, Nicola Tonellotto

>2025-05-01

> http://arxiv.org/abs/2505.00560v1

A large item catalogue is a major challenge for deploying modern sequential
recommender models, since it makes the memory footprint of the model large and
increases inference latency. One promising approach to address this is RecJPQ,
which replaces item embeddings with sub-item embeddings. However, slow
inference remains problematic because finding the top highest-scored items
usually requires scoring all items in the catalogue, which may not be feasible
for large catalogues. By adapting dynamic **pruning** concepts from document
retrieval, we propose the RecJPQPrune dynamic **pruning** algorithm to efficiently
find the top highest-scored items without computing the scores of all items in
the catalogue. Our RecJPQPrune algorithm is safe-up-to-rank K since it
theoretically guarantees that no potentially high-scored item is excluded from
the final top K recommendation list, thereby ensuring no impact on
effectiveness. Our experiments on two large datasets and three recommendation
models demonstrate the efficiency achievable using RecJPQPrune: for instance,
on the Tmall dataset with 2.2M items, we can reduce the median model scoring
time by 64 times compared to the Transformer Default baseline, and 5.3 times
compared to a recent scoring approach called PQTopK. Overall, this paper
demonstrates the effective and efficient inference of Transformer-based
recommendation models at catalogue scales not previously reported in the
literature. Indeed, our RecJPQPrune algorithm can score 2 million items in
under 10 milliseconds without GPUs, and without relying on Approximate Nearest
Neighbour (ANN) techniques.


## Self-Ablating Transformers More Interpretability, Less Sparsity

>Authors: Jeremias Ferrao, Luhan Mikaelson, Keenan Pepper, Natalia Perez-Campanero Antolin

>2025-05-01

> http://arxiv.org/abs/2505.00509v1

A growing intuition in machine learning suggests a link between **sparsity** and
interpretability. We introduce a novel self-ablation mechanism to investigate
this connection ante-hoc in the context of language transformers. Our approach
dynamically enforces a k-winner-takes-all constraint, forcing the model to
demonstrate selective activation across neuron and attention units. Unlike
post-hoc methods that analyze already-trained models, our approach integrates
interpretability directly into model training, promoting feature localization
from inception. Training small models on the TinyStories dataset and employing
interpretability tests, we find that self-ablation leads to more localized
circuits, concentrated feature representations, and increased neuron
specialization without compromising language modelling performance.
Surprisingly, our method also decreased overall **sparsity**, indicating that
self-ablation promotes specialization rather than widespread inactivity. This
reveals a complex interplay between **sparsity** and interpretability, where
decreased global **sparsity** can coexist with increased local specialization,
leading to enhanced interpretability. To facilitate reproducibility, we make
our code available at
https://github.com/keenanpepper/self-ablating-transformers.


## Efficient On-Chip Implementation of 4D Radar-Based 3D Object Detection on Hailo-8L

>Authors: Woong-Chan Byun, Dong-Hee Paek, Seung-Hyun Song, Seung-Hyun Kong

>2025-05-01

> http://arxiv.org/abs/2505.00757v1

4D radar has attracted attention in autonomous driving due to its ability to
enable robust 3D object detection even under adverse weather conditions. To
practically deploy such technologies, it is essential to achieve real-time
processing within low-power embedded environments. Addressing this, we present
the first on-chip implementation of a 4D radar-based 3D object detection model
on the Hailo-8L AI accelerator. Although conventional 3D convolutional neural
network (CNN) architectures require 5D inputs, the Hailo-8L only supports 4D
tensors, posing a significant challenge. To overcome this limitation, we
introduce a tensor transformation method that reshapes 5D inputs into 4D
formats during the compilation process, enabling direct deployment without
altering the model structure. The proposed system achieves 46.47% AP_3D and
52.75% AP_BEV, maintaining comparable accuracy to GPU-based models while
achieving an inference speed of 13.76 Hz. These results demonstrate the
applicability of 4D radar-based perception technologies to autonomous driving
systems.


## P2P-Insole Human Pose Estimation Using Foot Pressure Distribution and Motion Sensors

>Authors: Atsuya Watanabe, Ratna Aisuwarya, Lei Jing

>2025-05-01

> http://arxiv.org/abs/2505.00755v1

This work presents P2P-Insole, a low-cost approach for estimating and
visualizing 3D human skeletal data using insole-type sensors integrated with
IMUs. Each insole, fabricated with e-textile garment techniques, costs under
USD 1, making it significantly cheaper than commercial alternatives and ideal
for large-scale production. Our approach uses foot pressure distribution,
**acceleration**, and rotation data to overcome limitations, providing a
lightweight, minimally intrusive, and privacy-aware solution. The system
employs a Transformer model for efficient temporal feature extraction, enriched
by first and second derivatives in the input stream. Including multimodal
information, such as accelerometers and rotational measurements, improves the
accuracy of complex motion pattern recognition. These facts are demonstrated
experimentally, while error metrics show the robustness of the approach in
various posture estimation tasks. This work could be the foundation for a
low-cost, practical application in rehabilitation, injury prevention, and
health monitoring while enabling further development through sensor
optimization and expanded datasets.


## Fast Azimuthally Anisotropic 3D Radon Transform by Generalized Fourier Slice Theorem

>Authors: Ahmadreza Mokhtari, Ali Gholami

>2025-05-01

> http://arxiv.org/abs/2505.00387v1

Expensive computation of the conventional **sparse** Radon transform limits its
use for effective transformation of 3D anisotropic seismic data cubes. We
introduce a fast algorithm for azimuthally anisotropic 3D Radon transform with
**sparsity** constraints, allowing effective transformation of seismic volumes
corresponding to arbitrary anisotropic inhomogeneous media. In particular, a 3D
data (CMP) cube of time and offset coordinates is transformed to a 3D cube of
intercept time, slowness, and azimuth. The recently proposed generalized
Fourier slice theorem is employed for very fast calculation of the 3D inverse
transformation and its adjoint, which are subsequently used for efficient
implementation of the **sparse** transform via a forward-backward splitting
algorithm. The new anisotropic transform improves the temporal resolution of
the resulting seismic data. Furthermore, the Radon transform coefficients
allows constructing azimuthally dependent NMO velocity curve at any horizontal
plane, which can be inverted for the medium anisotropic parameters. Numerical
examples using synthetic data sets are presented showing the effectiveness of
the proposed anisotropic method in improving seismic processing results
compared with conventional isotropic counterpart.


## Optimizing Deep Neural Networks using Safety-Guided Self Compression

>Authors: Mohammad Zbeeb, Mariam Salman, Mohammad Bazzi, Ammar Mohanna

>2025-05-01

> http://arxiv.org/abs/2505.00350v1

The deployment of deep neural networks on resource-constrained devices
necessitates effective model com- pression strategies that judiciously balance
the reduction of model size with the preservation of performance. This study
introduces a novel safety-driven **quantization** framework that leverages
preservation sets to systematically prune and **quantize** neural network weights,
thereby optimizing model complexity without compromising accuracy. The proposed
methodology is rigorously evaluated on both a convolutional neural network
(CNN) and an attention-based language model, demonstrating its applicability
across diverse architectural paradigms. Experimental results reveal that our
framework achieves up to a 2.5% enhancement in test accuracy relative to the
original un**quantize**d models while maintaining 60% of the initial model size. In
comparison to conventional **quantization** techniques, our approach not only
augments generalization by eliminating parameter noise and retaining essential
weights but also reduces variance, thereby ensuring the retention of critical
model features. These findings underscore the efficacy of safety-driven
**quantization** as a robust and reliable strategy for the efficient optimization
of deep learn- ing models. The implementation and comprehensive experimental
evaluations of our framework are publicly accessible at GitHub.


## Mixture of Sparse Attention Content-Based Learnable Sparse Attention via Expert-Choice Routing

>Authors: Piotr Piękos, Róbert Csordás, Jürgen Schmidhuber

>2025-05-01

> http://arxiv.org/abs/2505.00315v1

Recent advances in large language models highlighted the excessive quadratic
cost of self-attention. Despite the significant research efforts, subquadratic
attention methods still suffer from inferior performance in practice. We
hypothesize that dynamic, learned content-based **sparsity** can lead to more
efficient attention mechanisms. We present Mixture of Sparse Attention (MoSA),
a novel approach inspired by Mixture of Experts (MoE) with expert choice
routing. MoSA dynamically selects tokens for each attention head, allowing
arbitrary **sparse** attention patterns. By selecting $k$ tokens from a sequence of
length $T$, MoSA reduces the computational complexity of each attention head
from $O(T^2)$ to $O(k^2 + T)$. This enables using more heads within the same
computational budget, allowing higher specialization. We show that among the
tested **sparse** attention variants, MoSA is the only one that can outperform the
dense baseline, sometimes with up to 27% better perplexity for an identical
compute budget. MoSA can also reduce the resource usage compared to dense
self-attention. Despite using torch implementation without an optimized kernel,
perplexity-matched MoSA models are simultaneously faster in wall-clock time,
require less memory for training, and drastically reduce the size of the
**KV**-cache compared to the dense transformer baselines.


## A Unifying Framework for Robust and Efficient Inference with Unstructured Data

>Authors: Jacob Carlson, Melissa Dell

>2025-05-01

> http://arxiv.org/abs/2505.00282v1

This paper presents a general framework for conducting efficient and robust
inference on parameters derived from unstructured data, which include text,
images, audio, and video. Economists have long incorporated data extracted from
texts and images into their analyses, a practice that has accelerated with
advancements in deep neural networks. However, neural networks do not
generically produce unbiased predictions, potentially propagating bias to
estimators that use their outputs. To address this challenge, we reframe
inference with unstructured data as a missing structured data problem, where
structured data are imputed from unstructured inputs using deep neural
networks. This perspective allows us to apply classic results from
semiparametric inference, yielding valid, efficient, and robust estimators
based on unstructured data. We formalize this approach with MARS (Missing At
Random Structured Data), a unifying framework that integrates and extends
existing methods for debiased inference using machine learning predictions,
linking them to a variety of older, familiar problems such as causal inference.
We develop robust and efficient estimators for both descriptive and causal
estimands and address challenges such as inference using aggregated and
transformed predictions from unstructured data. Importantly, MARS applies to
common empirical settings that have received limited attention in the existing
literature. Finally, we reanalyze prominent studies that use unstructured data,
demonstrating the practical value of MARS.


## Path to a Single-Stage, 100-GeV Electron Beam via a Flying-Focus-Driven Laser-Plasma Accelerator

>Authors: J. L. Shaw, M. V. Ambat, K. G. Miller, R. Boni, I. LaBelle, W. B. Mori, J. J. Pigeon, A. Rigatti, I. Settle, L. Mack, J. P. Palastro, D. H. Froula

>2025-04-30

> http://arxiv.org/abs/2505.00157v1

Dephasingless laser wakefield **acceleration** (DLWFA), a novel laser wakefield
**acceleration** concept based on the recently demonstrated "flying focus"
technology, offers a new paradigm in laser-plasma **acceleration** that could
advance the progress toward a TeV linear accelerator using a single-stage
system without guiding structures. The recently proposed NSF OPAL laser
facility could be the transformative technology that enables this grand
challenge in laser-plasma **acceleration**. We review the viable parameter space
for DLWFA based on the scaling of its performance with laser and plasma
parameters, and we compare that performance to traditional laser wakefield
**acceleration**. These scalings indicate the necessity for ultrashort, high-energy
laser architectures such as NSF OPAL to achieve groundbreaking electron
energies using DLWFA. Initial results from MTW-OPAL, the platform for the 6-J
DLWFA demonstration experiment, show a tight, round focal spot over a distance
of 3.7 mm. New particle-in-cell simulations of that platform indicate that
using hydrogen for DLWFA reduces the amount of laser light that is distorted
due to refraction at ionization fronts. An experimental path, and the
computational and technical design work along that path, from the current
status of the field to a single-stage, 100-GeV electron beam via DLWFA on NSF
OPAL is outlined. Progress along that path is presented.


## Origins of Thermalization in Semiclassical Cosmology

>Authors: Michael Osei

>2025-04-30

> http://arxiv.org/abs/2505.00103v1

We discuss the effect of accelerated frames in cosmology, and obtain origins
of thermalization of the cosmic evolution of the semi-classical universe. We
implement a transformation in super-space, and the WKB wave function defined on
super space has a Bogoliubov transformation. In the transformed frame we find
the density matrix which is mixed, and this is the sign of a thermal system.
Whereas this result does not have the same interpretations of a particle
thermalization in accelerated frames, one can show the super space
transformation similar to a double Rindler transformation of real space-time
coordinates. We also discuss the implications of the super-space transformation
in loop quantum cosmology.


## Switching Transients in Constrained Transformer-Line/Cable Configurations

>Authors: Y. Xiang, L. Wu, K. Velitsikakis, A. L. J. Janssen

>2025-04-30

> http://arxiv.org/abs/2504.21594v1

This paper investigates the transient phenomena that occur in two special
cases in the Netherlands: (A) during the energization of a power transformer
via a cable feeder and (B) the energization of a power transformer together
with an overhead line (OHL). In Case A a 7 km long 150 kV cable and a 150/50 kV
transformer are connected and energized at the same time. In Case B a 150/50 kV
transformer and a short 50 kV OHL are connected and energized simultaneously.
The reason behind this kind of situations is related to space restrictions and
cost efficiency.


## PolyQROM Orthogonal-Polynomial-Based Quantum Reduced-Order Model for Flow Field Analysis

>Authors: Yu Fang, Cheng Xue, Tai-Ping Sun, Xiao-Fan Xu, Xi-Ning Zhuang, Yun-Jie Wang, Chuang-Chao Ye, Teng-Yang Ma, Jia-Xuan Zhang, Huan-Yu Liu, Yu-Chun Wu, Zhao-Yun Chen, Guo-Ping Guo

>2025-04-30

> http://arxiv.org/abs/2504.21567v1

Quantum computing promises exponential **acceleration** for fluid flow
simulations, yet the measurement overhead required to extract flow features
from quantum-encoded flow field data fundamentally undermines this advantage--a
critical challenge termed the ``output problem''. To address this, we propose
an orthogonal-polynomial-based quantum reduced-order model (PolyQROM) that
integrates orthogonal polynomial basis transformations with variational quantum
circuits (VQCs). PolyQROM employs optimized polynomial-based quantum operations
to compress flow field data into low-dimensional representations while
preserving essential features, enabling efficient quantum or classical
post-processing for tasks like reconstruction and classification. By leveraging
the mathematical properties of orthogonal polynomials, the framework enhances
circuit expressivity and stabilizes training compared to conventional
hardware-efficient VQCs. Numerical experiments demonstrate PolyQROM's
effectiveness in reconstructing flow fields with high fidelity and classifying
flow patterns with accuracy surpassing classical methods and quantum
benchmarks, all while reducing computational complexity and parameter counts.
The work bridges quantum simulation outputs with practical fluid analysis,
addressing the ``output problem'' through efficient reduced-order modeling
tailored for quantum-encoded flow data, offering a scalable pathway to exploit
quantum advantages in computational fluid dynamics.


## Levitated Sensor for Magnetometry in Ambient Environment

>Authors: Wei Ji, Changhao Xu, Guofeng Qu, Dmitry Budker

>2025-04-30

> http://arxiv.org/abs/2504.21524v1

Levitated particle systems have gained significant attention as a rapidly
advancing platform for precision sensing, offering low-loss, highly isolated
environments by eliminating mechanical contact and associated noise. Current
room-temperature levitation techniques are primarily sensitive to **acceleration**,
with magnetic sensing often relying on the Meissner effect, which is
impractical under ambient conditions. Here, we demonstrate a diamagnetically
stabilized magnetically levitated magnet magnetometer (LeMaMa), where the
motion of the magnet is detected optically. Leveraging strong spin-lattice
coupling in the ferromagnet to suppress spin-projection noise and minimizing
dissipation through levitation, we achieve a sensitivity of 32 fT $/Hz^{1/2}$.
This sensitivity is adequate for a wide range of applications in biology,
chemistry, and fundamental physics, matching the performance of leading
technologies like SQUIDs and atomic magnetometers, while offering the distinct
advantage of operating at room temperature and under Earth's magnetic field.


## GarmentDiffusion 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers

>Authors: Xinyu Li, Qi Yao, Yuanda Wang

>2025-04-30

> http://arxiv.org/abs/2504.21476v1

Garment sewing patterns are fundamental design elements that bridge the gap
between design concepts and practical manufacturing. The generative modeling of
sewing patterns is crucial for creating diversified garments. However, existing
approaches are limited either by reliance on a single input modality or by
suboptimal generation efficiency. In this work, we present
\textbf{\textit{GarmentDiffusion}}, a new generative model capable of producing
centimeter-precise, vectorized 3D sewing patterns from multimodal inputs (text,
image, and incomplete sewing pattern). Our method efficiently encodes 3D sewing
pattern parameters into compact edge token representations, achieving a
sequence length that is $\textbf{10}\times$ shorter than that of the
autoregressive SewingGPT in DressCode. By employing a diffusion transformer, we
simultaneously denoise all edge tokens along the temporal axis, while
maintaining a constant number of denoising steps regardless of dataset-specific
edge and panel statistics. With all combination of designs of our model, the
sewing pattern generation speed is accelerated by $\textbf{100}\times$ compared
to SewingGPT. We achieve new state-of-the-art results on DressCodeData, as well
as on the largest sewing pattern dataset, namely GarmentCodeData. The project
website is available at https://shenfu-research.github.io/Garment-Diffusion/.


## RWKV-X A Linear Complexity Hybrid Language Model

>Authors: Haowen Hou, Zhiyi Huang, Kaifeng Tan, Rongchang Lu, Fei Richard Yu

>2025-04-30

> http://arxiv.org/abs/2504.21463v1

In this paper, we introduce \textbf{RW**KV**-X}, a novel hybrid architecture that
combines the efficiency of RW**KV** for short-range modeling with a **sparse**
attention mechanism designed to capture long-range context. Unlike previous
hybrid approaches that rely on full attention layers and retain quadratic
complexity, RW**KV**-X achieves linear-time complexity in training and
constant-time complexity in inference decoding. We demonstrate that RW**KV**-X,
when continually pretrained on 64K-token sequences, achieves near-perfect
accuracy on the 64K passkey retrieval benchmark. It consistently outperforms
prior RW**KV**-7 models on long-context benchmarks, while maintaining strong
performance on short-context tasks. These results highlight RW**KV**-X as a
scalable and efficient backbone for general-purpose language modeling, capable
of decoding sequences up to 1 million tokens with stable speed and memory
usage. To facilitate further research and analysis, we have made the
checkpoints and the associated code publicly accessible at:
https://github.com/howard-hou/RW**KV**-X.


## Generative QoE Modeling A Lightweight Approach for Telecom Networks

>Authors: Vinti Nayar, Kanica Sachdev, Brejesh Lall

>2025-04-30

> http://arxiv.org/abs/2504.21353v1

Quality of Experience (QoE) prediction plays a crucial role in optimizing
resource management and enhancing user satisfaction across both
telecommunication and OTT services. While recent advances predominantly rely on
deep learning models, this study introduces a lightweight generative modeling
framework that balances computational efficiency, interpretability, and
predictive accuracy. By validating the use of Vector Quantization (VQ) as a
preprocessing technique, continuous network features are effectively
transformed into discrete categorical symbols, enabling integration with a
Hidden Markov Model (HMM) for temporal sequence modeling. This VQ-HMM pipeline
enhances the model's capacity to capture dynamic QoE patterns while supporting
probabilistic inference on new and unseen data. Experimental results on
publicly available time-series datasets incorporating both objective indicators
and subjective QoE scores demonstrate the viability of this approach in
real-time and resource-constrained environments, where inference latency is
also critical. The framework offers a scalable alternative to complex deep
learning methods, particularly in scenarios with limited computational
resources or where latency constraints are critical.


## Orthogonal Factor-Based Biclustering Algorithm (BCBOF) for High-Dimensional Data and Its Application in Stock Trend Prediction

>Authors: Yan Huang, Da-Qing Zhang

>2025-04-30

> http://arxiv.org/abs/2504.21289v1

Biclustering is an effective technique in data mining and pattern
recognition. Biclustering algorithms based on traditional clustering face two
fundamental limitations when processing high-dimensional data: (1) The distance
concentration phenomenon in high-dimensional spaces leads to data **sparsity**,
rendering similarity measures ineffective; (2) Mainstream linear dimensionality
reduction methods disrupt critical local structural patterns. To apply
biclustering to high-dimensional datasets, we propose an orthogonal
factor-based biclustering algorithm (BCBOF). First, we constructed orthogonal
factors in the vector space of the high-dimensional dataset. Then, we performed
clustering using the coordinates of the original data in the orthogonal
subspace as clustering targets. Finally, we obtained biclustering results of
the original dataset. Since dimensionality reduction was applied before
clustering, the proposed algorithm effectively mitigated the data **sparsity**
problem caused by high dimensionality. Additionally, we applied this
biclustering algorithm to stock technical indicator combinations and stock
price trend prediction. Biclustering results were transformed into fuzzy rules,
and we incorporated profit-preserving and stop-loss rules into the rule set,
ultimately forming a fuzzy inference system for stock price trend predictions
and trading signals. To evaluate the performance of BCBOF, we compared it with
existing biclustering methods using multiple evaluation metrics. The results
showed that our algorithm outperformed other biclustering techniques. To
validate the effectiveness of the fuzzy inference system, we conducted virtual
trading experiments using historical data from 10 A-share stocks. The
experimental results showed that the generated trading strategies yielded
higher returns for investors.


## Reinforced MLLM A Survey on RL-Based Reasoning in Multimodal Large Language Models

>Authors: Guanghao Zhou, Panjia Qiu, Cen Chen, Jie Wang, Zheming Yang, Jian Xu, Minghui Qiu

>2025-04-30

> http://arxiv.org/abs/2504.21277v1

The integration of reinforcement learning (RL) into the reasoning
capabilities of Multimodal Large Language Models (MLLMs) has rapidly emerged as
a transformative research direction. While MLLMs significantly extend Large
Language Models (LLMs) to handle diverse modalities such as vision, audio, and
video, enabling robust reasoning across multimodal inputs remains a major
challenge. This survey systematically reviews recent advances in RL-based
reasoning for MLLMs, covering key algorithmic designs, reward mechanism
innovations, and practical applications. We highlight two main RL
paradigms--value-free and value-based methods--and analyze how RL enhances
reasoning abilities by optimizing reasoning trajectories and aligning
multimodal information. Furthermore, we provide an extensive overview of
benchmark datasets, evaluation protocols, and existing limitations, and propose
future research directions to address current bottlenecks such as **sparse**
rewards, inefficient cross-modal reasoning, and real-world deployment
constraints. Our goal is to offer a comprehensive and structured guide to
researchers interested in advancing RL-based reasoning in the multimodal era.


## CachePrune Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks

>Authors: Rui Wang, Junda Wu, Yu Xia, Tong Yu, Ruiyi Zhang, Ryan Rossi, Lina Yao, Julian McAuley

>2025-04-29

> http://arxiv.org/abs/2504.21228v1

Large Language Models (LLMs) are identified as being susceptible to indirect
prompt injection attack, where the model undesirably deviates from
user-provided instructions by executing tasks injected in the prompt context.
This vulnerability stems from LLMs' inability to distinguish between data and
instructions within a prompt. In this paper, we propose CachePrune that defends
against this attack by identifying and **pruning** task-triggering neurons from the
**KV** cache of the input prompt context. By **pruning** such neurons, we encourage the
LLM to treat the text spans of input prompt context as only pure data, instead
of any indicator of instruction following. These neurons are identified via
feature attribution with a loss function induced from an upperbound of the
Direct Preference Optimization (DPO) objective. We show that such a loss
function enables effective feature attribution with only a few samples. We
further improve on the quality of feature attribution, by exploiting an
observed triggering effect in instruction following. Our approach does not
impose any formatting on the original prompt or introduce extra test-time LLM
calls. Experiments show that CachePrune significantly reduces attack success
rates without compromising the response quality. Note: This paper aims to
defend against indirect prompt injection attacks, with the goal of developing
more secure and robust AI systems.


## Efficient LLMs with AMP Attention Heads and MLP Pruning

>Authors: Leandro Giusti Mugnaini, Bruno Lopes Yamamoto, Lucas Lauton de Alcantara, Victor Zacarias, Edson Bollis, Lucas Pellicer, Anna Helena Reali Costa, Artur Jordao

>2025-04-29

> http://arxiv.org/abs/2504.21174v1

Deep learning drives a new wave in computing systems and triggers the
automation of increasingly complex problems. In particular, Large Language
Models (LLMs) have significantly advanced cognitive tasks, often matching or
even surpassing human-level performance. However, their extensive parameters
result in high computational costs and slow inference, posing challenges for
deployment in resource-limited settings. Among the strategies to overcome the
aforementioned challenges, **pruning** emerges as a successful mechanism since it
reduces model size while maintaining predictive ability. In this paper, we
introduce AMP: Attention Heads and MLP Pruning, a novel structured **pruning**
method that efficiently compresses LLMs by removing less critical structures
within Multi-Head Attention (MHA) and Multilayer Perceptron (MLP). By
projecting the input data onto weights, AMP assesses structural importance and
overcomes the limitations of existing techniques, which often fall short in
flexibility or efficiency. In particular, AMP surpasses the current
state-of-the-art on commonsense reasoning tasks by up to 1.49 percentage
points, achieving a 30% **pruning** ratio with minimal impact on zero-shot task
performance. Moreover, AMP also improves inference speeds, making it
well-suited for deployment in resource-constrained environments. We confirm the
flexibility of AMP on different families of LLMs, including LLaMA and Phi.


## MCMComm Hardware-Software Co-Optimization for End-to-End Communication in Multi-Chip-Modules

>Authors: Ritik Raj, Shengjie Lin, William Won, Tushar Krishna

>2025-04-29

> http://arxiv.org/abs/2505.00041v2

Increasing AI computing demands and slowing transistor scaling have led to
the advent of Multi-Chip-Module (MCMs) based accelerators. MCMs enable
cost-effective scalability, higher yield, and modular reuse by partitioning
large chips into smaller chiplets. However, MCMs come at an increased
communication cost, which requires critical analysis and optimization. This
paper makes three main contributions: (i) an end-to-end, off-chip
congestion-aware and packaging-adaptive analytical framework for detailed
analysis, (ii) hardware software co-optimization incorporating diagonal links,
on-chip redistribution, and non-uniform workload partitioning to optimize the
framework, and (iii) using metaheuristics (genetic algorithms, GA) and mixed
integer quadratic programming (MIQP) to solve the optimized framework.
Experimental results demonstrate significant performance improvements for CNNs
and Vision Transformers, showcasing up to 1.58x and 2.7x EdP (Energy delay
Product) improvement using GA and MIQP, respectively.


## X-Fusion Introducing New Modality to Frozen Large Language Models

>Authors: Sicheng Mo, Thao Nguyen, Xun Huang, Siddharth Srinivasan Iyer, Yijun Li, Yuchen Liu, Abhishek Tandon, Eli Shechtman, Krishna Kumar Singh, Yong Jae Lee, Bolei Zhou, Yuheng Li

>2025-04-29

> http://arxiv.org/abs/2504.20996v1

We propose X-Fusion, a framework that extends pretrained Large Language
Models (LLMs) for multimodal tasks while preserving their language
capabilities. X-Fusion employs a dual-tower design with modality-specific
weights, keeping the LLM's parameters frozen while integrating vision-specific
information for both understanding and generation. Our experiments demonstrate
that X-Fusion consistently outperforms alternative architectures on both
image-to-text and text-to-image tasks. We find that incorporating
understanding-focused data improves generation quality, reducing image data
noise enhances overall performance, and feature alignment accelerates
convergence for smaller models but has minimal impact on larger ones. Our
findings provide valuable insights into building efficient unified multimodal
models.


## Softpick No Attention Sink, No Massive Activations with Rectified Softmax

>Authors: Zayd M. K. Zuhri, Erland Hilman Fuadi, Alham Fikri Aji

>2025-04-29

> http://arxiv.org/abs/2504.20966v1

We introduce softpick, a rectified, not sum-to-one, drop-in replacement for
softmax in transformer attention mechanisms that eliminates attention sink and
massive activations. Our experiments with 340M parameter models demonstrate
that softpick maintains performance parity with softmax on standard benchmarks
while achieving 0% sink rate. The softpick transformer produces hidden states
with significantly lower kurtosis (340 vs 33,510) and creates **sparse** attention
maps (46.97% **sparsity**). Models using softpick consistently outperform softmax
when **quantize**d, with particularly pronounced advantages at lower bit
precisions. Our analysis and discussion shows how softpick has the potential to
open new possibilities for **quantization**, low-precision training, **sparsity**
optimization, **pruning**, and interpretability. Our code is available at
https://github.com/zaydzuhri/softpick-attention.


## Towards Understanding the Nature of Attention with Low-Rank Sparse Decomposition

>Authors: Zhengfu He, Junxuan Wang, Rui Lin, Xuyang Ge, Wentao Shu, Qiong Tang, Junping Zhang, Xipeng Qiu

>2025-04-29

> http://arxiv.org/abs/2504.20938v1

We propose Low-Rank Sparse Attention (Lorsa), a **sparse** replacement model of
Transformer attention layers to disentangle original Multi Head Self Attention
(MHSA) into individually comprehensible components. Lorsa is designed to
address the challenge of attention superposition to understand
attention-mediated interaction between features in different token positions.
We show that Lorsa heads find cleaner and finer-grained versions of previously
discovered MHSA behaviors like induction heads, successor heads and attention
sink behavior (i.e., heavily attending to the first token). Lorsa and Sparse
Autoencoder (SAE) are both **sparse** dictionary learning methods applied to
different Transformer components, and lead to consistent findings in many ways.
For instance, we discover a comprehensive family of arithmetic-specific Lorsa
heads, each corresponding to an atomic operation in Llama-3.1-8B. Automated
interpretability analysis indicates that Lorsa achieves parity with SAE in
interpretability while Lorsa exhibits superior circuit discovery properties,
especially for features computed collectively by multiple MHSA heads. We also
conduct extensive experiments on architectural design ablation, Lorsa scaling
law and error analysis.


## Relativistic ejecta from stellar mass black holes insights from simulations and synthetic radio images

>Authors: Katie Savard, James H. Matthews, Rob Fender, Ian Heywood

>2025-04-29

> http://arxiv.org/abs/2504.20914v1

We present numerical simulations of discrete relativistic ejecta from an
X-ray binary (XRB) with initial conditions directly informed by observations.
XRBs have been observed to launch powerful discrete plasma ejecta during state
transitions, which can propagate up to parsec distances. Understanding these
ejection events unveils new understanding of jet-launching, jet power, and
jet-ISM interaction among other implications. Multi-frequency
quasi-simultaneous radio observations of ejecta from the black hole XRB MAXI
J1820+070 produced both size and calorimetry constraints, which we use as
initial conditions of a relativistic hydrodynamic simulation. We qualitatively
reproduce the observed deceleration of the ejecta in a homogeneous interstellar
medium (ISM). Our simulations demonstrate that the ejecta must be denser than
the ISM, the ISM be significantly low-density, and the launch be extremely
powerful, in order to propagate to the observed distances. The blob propagates
and clears out a high-pressure low-density cavity in its wake, providing an
explanation for this pre-existing low-density environment, as well as
'bubble-like' environments in the vicinity of XRBs inferred from other studies.
As the blob decelerates, we observe the onset of instabilities and a long-lived
reverse shock -- these mechanisms convert kinetic to internal energy in the
blob, responsible for in-situ particle **acceleration**. We transform the outputs
of our simulation into pseudo-radio images, incorporating the u,v coverage of
the MeerKAT and e-MERLIN telescopes from the original observations with
real-sky background. Through this, we maximize the interpretability of the
results and provide direct comparison to current data, as well as provide
prediction capabilities.


## Understanding Large Language Model Supply Chain Structure, Domain, and Vulnerabilities

>Authors: Yanzhe Hu, Shenao Wang, Tianyuan Nie, Yanjie Zhao, Haoyu Wang

>2025-04-29

> http://arxiv.org/abs/2504.20763v1

Large Language Models (LLMs) have revolutionized artificial intelligence
(AI), driving breakthroughs in natural language understanding, text generation,
and autonomous systems. However, the rapid growth of LLMs presents significant
challenges in the security and reliability of the Large Language Model Supply
Chain (LLMSC), a complex network of open-source components, libraries, and
tools essential for LLM development and deployment. Despite its critical
importance, the LLMSC remains underexplored, particularly regarding its
structural characteristics, domain composition, and security vulnerabilities.
To address this gap, we conduct the first empirical study of the LLMSC,
analyzing a curated dataset of open-source packages from PyPI and NPM across 14
functional domains. We construct a directed dependency graph comprising 15,725
nodes, 10,402 edges, and 180 unique vulnerabilities to investigate the
structural characteristics of the LLMSC and analyze how security risks
propagate through its dependency network. Our findings reveal that the LLMSC
exhibits a ``locally dense, globally **sparse**'' topology, with 79.7% of
dependency trees containing fewer than 5 nodes, while a few large trees
dominate the ecosystem, accounting for 77.66% of all nodes. The graph is
characterized by high-degree hubs, with the top 5 most connected nodes
averaging 1,282 dependents each. Security analysis shows that critical
vulnerabilities propagate to an average of 142.1 nodes at the second layer of
dependency trees and peak at 237.8 affected nodes at the third layer. Notably,
cascading risks are concentrated in critical hub nodes such as transformers,
which directly or indirectly affect over 1,300 downstream packages. These
findings provide quantitative insights into the structural and security
dynamics of the LLMSC and emphasize the need for targeted mitigation strategies
to enhance ecosystem resilience.


## Grokking in the Wild Data Augmentation for Real-World Multi-Hop Reasoning with Transformers

>Authors: Roman Abramov, Felix Steinbauer, Gjergji Kasneci

>2025-04-29

> http://arxiv.org/abs/2504.20752v1

Transformers have achieved great success in numerous NLP tasks but continue
to exhibit notable gaps in multi-step factual reasoning, especially when
real-world knowledge is **sparse**. Recent advances in grokking have demonstrated
that neural networks can transition from memorizing to perfectly generalizing
once they detect underlying logical patterns - yet these studies have primarily
used small, synthetic tasks. In this paper, for the first time, we extend
grokking to real-world factual data and address the challenge of dataset
**sparsity** by augmenting existing knowledge graphs with carefully designed
synthetic data to raise the ratio $\phi_r$ of inferred facts to atomic facts
above the threshold required for grokking. Surprisingly, we find that even
factually incorrect synthetic data can strengthen emergent reasoning circuits
rather than degrade accuracy, as it forces the model to rely on relational
structure rather than memorization. When evaluated on multi-hop reasoning
benchmarks, our approach achieves up to 95-100% accuracy on 2WikiMultiHopQA -
substantially improving over strong baselines and matching or exceeding current
state-of-the-art results. We further provide an in-depth analysis of how
increasing $\phi_r$ drives the formation of generalizing circuits inside
Transformers. Our findings suggest that grokking-based data augmentation can
unlock implicit multi-hop reasoning capabilities, opening the door to more
robust and interpretable factual reasoning in large-scale language models.


## Inference of high-dimensional weak instrumental variable regression models without ridge-regularization

>Authors: Jiarong Ding, Xu Guo, Yanmei Shi, Yuxin Wang

>2025-04-29

> http://arxiv.org/abs/2504.20686v1

Inference of instrumental variable regression models with many weak
instruments attracts many attentions recently. To extend the classical
Anderson-Rubin test to high-dimensional setting, many procedures adopt
ridge-regularization. However, we show that it is not necessary to consider
ridge-regularization. Actually we propose a new quadratic-type test statistic
which does not involve tuning parameters. Our quadratic-type test exhibits high
power against dense alternatives. While for **sparse** alternatives, we derive the
asymptotic distribution of an existing maximum-type test, enabling the use of
less conservative critical values. To achieve strong performance across a wide
range of scenarios, we further introduce a combined test procedure that
integrates the strengths of both approaches. This combined procedure is
powerful without requiring prior knowledge of the underlying **sparsity** of the
first-stage model. Compared to existing methods, our proposed tests are easy to
implement, free of tuning parameters, and robust to arbitrarily weak
instruments as well as heteroskedastic errors. Simulation studies and empirical
applications demonstrate the advantages of our methods over existing
approaches.


## SFi-Former Sparse Flow Induced Attention for Graph Transformer

>Authors: Zhonghao Li, Ji Shi, Xinming Zhang, Miao Zhang, Bo Li

>2025-04-29

> http://arxiv.org/abs/2504.20666v1

Graph Transformers (GTs) have demonstrated superior performance compared to
traditional message-passing graph neural networks in many studies, especially
in processing graph data with long-range dependencies. However, GTs tend to
suffer from weak inductive bias, overfitting and over-globalizing problems due
to the dense attention. In this paper, we introduce SFi-attention, a novel
attention mechanism designed to learn **sparse** pattern by minimizing an energy
function based on network flows with l1-norm regularization, to relieve those
issues caused by dense attention. Furthermore, SFi-Former is accordingly
devised which can leverage the **sparse** attention pattern of SFi-attention to
generate **sparse** network flows beyond adjacency matrix of graph data.
Specifically, SFi-Former aggregates features selectively from other nodes
through flexible adaptation of the **sparse** attention, leading to a more robust
model. We validate our SFi-Former on various graph datasets, especially those
graph data exhibiting long-range dependencies. Experimental results show that
our SFi-Former obtains competitive performance on GNN Benchmark datasets and
SOTA performance on LongRange Graph Benchmark (LRGB) datasets. Additionally,
our model gives rise to smaller generalization gaps, which indicates that it is
less prone to over-fitting. Click here for codes.


## SNR-aware Semantic Image Transmission with Deep Learning-based Channel Estimation in Fading Channels

>Authors: Mahmoud M. Salim, Mohamed S. Abdalzaher, Ali H. Muqaibel, Hussein A. Elsayed, Inkyu Lee

>2025-04-29

> http://arxiv.org/abs/2504.20557v2

Semantic communications (SCs) play a central role in shaping the future of
the sixth generation (6G) wireless systems, which leverage rapid advances in
deep learning (DL). In this regard, end-to-end optimized DL-based joint
source-channel coding (JSCC) has been adopted to achieve SCs, particularly in
image transmission. Utilizing vision transformers in the encoder/decoder design
has enabled significant advancements in image semantic extraction, surpassing
traditional convolutional neural networks (CNNs). In this paper, we propose a
new JSCC paradigm for image transmission, namely Swin semantic image
transmission (SwinSIT), based on the Swin transformer. The Swin transformer is
employed to construct both the semantic encoder and decoder for efficient image
semantic extraction and reconstruction. Inspired by the
squeezing-and-excitation (SE) network, we introduce a signal-to-noise-ratio
(SNR)-aware module that utilizes SNR feedback to adaptively perform a
double-phase enhancement for the encoder-extracted semantic map and its noisy
version at the decoder. Additionally, a CNN-based channel estimator and
compensator (CEAC) module repurposes an image-denoising CNN to mitigate fading
channel effects. To optimize deployment in resource-constrained IoT devices, a
joint **pruning** and **quantization** scheme compresses the SwinSIT model. Simulations
evaluate the SwinSIT performance against conventional benchmarks demonstrating
its effectiveness. Moreover, the model's compressed version substantially
reduces its size while maintaining favorable PSNR performance.


## MambaMoE Mixture-of-Spectral-Spatial-Experts State Space Model for Hyperspectral Image Classification

>Authors: Yichu Xu, Di Wang, Hongzan Jiao, Lefei Zhang, Liangpei Zhang

>2025-04-29

> http://arxiv.org/abs/2504.20509v1

The Mamba model has recently demonstrated strong potential in hyperspectral
image (HSI) classification, owing to its ability to perform context modeling
with linear computational complexity. However, existing Mamba-based methods
usually neglect the spectral and spatial directional characteristics related to
heterogeneous objects in hyperspectral scenes, leading to limited
classification performance. To address these issues, we propose MambaMoE, a
novel spectral-spatial mixture-of-experts framework, representing the first
MoE-based approach in the HSI classification community. Specifically, we design
a Mixture of Mamba Expert Block (MoMEB) that leverages **sparse** expert activation
to enable adaptive spectral-spatial modeling. Furthermore, we introduce an
uncertainty-guided corrective learning (UGCL) strategy to encourage the model's
attention toward complex regions prone to prediction ambiguity. Extensive
experiments on multiple public HSI benchmarks demonstrate that MambaMoE
achieves state-of-the-art performance in both accuracy and efficiency compared
to existing advanced approaches, especially for Mamba-based methods. Code will
be released.


## Modeling and Performance Analysis for Semantic Communications Based on Empirical Results

>Authors: Shuai Ma, Bin Shen, Chuanhui Zhang, Youlong Wu, Hang Li, Shiyin Li, Guangming Shi, Naofal Al-Dhahir

>2025-04-29

> http://arxiv.org/abs/2504.21055v1

Due to the black-box characteristics of deep learning based semantic encoders
and decoders, finding a tractable method for the performance analysis of
semantic communications is a challenging problem. In this paper, we propose an
Alpha-Beta-Gamma (ABG) formula to model the relationship between the end-to-end
measurement and SNR, which can be applied for both image reconstruction tasks
and inference tasks. Specifically, for image reconstruction tasks, the proposed
ABG formula can well fit the commonly used DL networks, such as SCUNet, and
Vision Transformer, for semantic encoding with the multi scale-structural
similarity index measure (MS-SSIM) measurement. Furthermore, we find that the
upper bound of the MS-SSIM depends on the number of **quantize**d output bits of
semantic encoders, and we also propose a closed-form expression to fit the
relationship between the MS-SSIM and **quantize**d output bits. To the best of our
knowledge, this is the first theoretical expression between end-to-end
performance metrics and SNR for semantic communications. Based on the proposed
ABG formula, we investigate an adaptive power control scheme for semantic
communications over random fading channels, which can effectively guarantee
quality of service (QoS) for semantic communications, and then design the
optimal power allocation scheme to maximize the energy efficiency of the
semantic communication system. Furthermore, by exploiting the bisection
algorithm, we develop the power allocation scheme to maximize the minimum QoS
of multiple users for OFDMA downlink semantic communication Extensive
simulations verify the effectiveness and superiority of the proposed ABG
formula and power allocation schemes.


## APG-MOS Auditory Perception Guided-MOS Predictor for Synthetic Speech

>Authors: Zhicheng Lian, Lizhi Wang, Hua Huang

>2025-04-29

> http://arxiv.org/abs/2504.20447v1

Automatic speech quality assessment aims to quantify subjective human
perception of speech through computational models to reduce the need for
labor-consuming manual evaluations. While models based on deep learning have
achieved progress in predicting mean opinion scores (MOS) to assess synthetic
speech, the neglect of fundamental auditory perception mechanisms limits
consistency with human judgments. To address this issue, we propose an auditory
perception guided-MOS prediction model (APG-MOS) that synergistically
integrates auditory modeling with semantic analysis to enhance consistency with
human judgments. Specifically, we first design a perceptual module, grounded in
biological auditory mechanisms, to simulate cochlear functions, which encodes
acoustic signals into biologically aligned electrochemical representations.
Secondly, we propose a residual vector **quantization** (RVQ)-based semantic
distortion modeling method to quantify the degradation of speech quality at the
semantic level. Finally, we design a residual cross-attention architecture,
coupled with a progressive learning strategy, to enable multimodal fusion of
encoded electrochemical signals and semantic representations. Experiments
demonstrate that APG-MOS achieves superior performance on two primary
benchmarks. Our code and checkpoint will be available on a public repository
upon publication.


## GaLore 2 Large-Scale LLM Pre-Training by Gradient Low-Rank Projection

>Authors: DiJia Su, Andrew Gu, Jane Xu, Yuandong Tian, Jiawei Zhao

>2025-04-29

> http://arxiv.org/abs/2504.20437v1

Large language models (LLMs) have revolutionized natural language
understanding and generation but face significant memory bottlenecks during
training. GaLore, Gradient Low-Rank Projection, addresses this issue by
leveraging the inherent low-rank structure of weight gradients, enabling
substantial memory savings without sacrificing performance. Recent works
further extend GaLore from various aspects, including **low-bit** **quantization** and
higher-order tensor structures. However, there are several remaining challenges
for GaLore, such as the computational overhead of SVD for subspace updates and
the integration with state-of-the-art training parallelization strategies
(e.g., FSDP). In this paper, we present GaLore 2, an efficient and scalable
GaLore framework that addresses these challenges and incorporates recent
advancements. In addition, we demonstrate the scalability of GaLore 2 by
pre-training Llama 7B from scratch using up to 500 billion training tokens,
highlighting its potential impact on real LLM pre-training scenarios.


## Large-scale artificial intelligence with 41 million nanophotonic neurons on a metasurface

>Authors: Mingcheng Luo, Meirui Jiang, Bhavin J. Shastri, Nansen Zhou, Wenfei Guo, Jianmin Xiong, Dongliang Wang, Renjie Zhou, Chester Shu, Qi Dou, Chaoran Huang

>2025-04-29

> http://arxiv.org/abs/2504.20416v1

Conventional integrated circuits (ICs) struggle to meet the escalating
demands of artificial intelligence (AI). This has sparked a renewed interest in
an unconventional computing paradigm: neuromorphic (brain-inspired) computing.
However, current neuromorphic systems face significant challenges in delivering
a large number of parameters (i.e., weights) required for large-scale AI
models. As a result, most neuromorphic hardware is limited to basic benchmark
demonstrations, hindering its application to real-world AI challenges. Here, we
present a large-scale optical neural network (ONN) for machine learning
**acceleration**, featuring over 41 million photonic neurons. This system not only
surpasses digital electronics in speed and energy efficiency but more
importantly, closes the performance gap with large-scale AI models. Our ONN
leverages an innovative optical metasurface device featuring numerous spatial
modes. This device integrates over 41 million meta-atoms on a 10 mm$^2$
metasurface chip, enabling the processing of tens of millions of weights in a
single operation. For the first time, we demonstrate that an ONN, utilizing a
single-layer metasurface, can match the performance of deep and large-scale
deep learning models, such as ResNet and Vision Transformer, across various
benchmark tasks. Additionally, we show that our system can deliver
high-performance solutions to real-world AI challenges through its
unprecedented scale, such as accelerating the analysis of multi-gigapixel whole
slide images (WSIs) for cancer detection by processing the million-pixel
sub-image in a single shot. Our system reduces computing time and energy
consumption by over 1,000 times compared to state-of-the-art graphic processing
units (GPUs). This work presents a large-scale, low-power, and high-performance
neuromorphic computing system, paving the way for future disruptive AI
technologies.


## SCOPE-MRI Bankart Lesion Detection as a Case Study in Data Curation and Deep Learning for Challenging Diagnoses

>Authors: Sahil Sethi, Sai Reddy, Mansi Sakarvadia, Jordan Serotte, Darlington Nwaudo, Nicholas Maassen, Lewis Shi

>2025-04-29

> http://arxiv.org/abs/2504.20405v1

While deep learning has shown strong performance in musculoskeletal imaging,
existing work has largely focused on pathologies where diagnosis is not a
clinical challenge, leaving more difficult problems underexplored, such as
detecting Bankart lesions (anterior-inferior glenoid labral tears) on standard
MRIs. Diagnosing these lesions is challenging due to their subtle imaging
features, often leading to reliance on invasive MRI arthrograms (MRAs). This
study introduces ScopeMRI, the first publicly available, expert-annotated
dataset for shoulder pathologies, and presents a deep learning (DL) framework
for detecting Bankart lesions on both standard MRIs and MRAs. ScopeMRI includes
586 shoulder MRIs (335 standard, 251 MRAs) from 558 patients who underwent
arthroscopy. Ground truth labels were derived from intraoperative findings, the
gold standard for diagnosis. Separate DL models for MRAs and standard MRIs were
trained using a combination of CNNs and transformers. Predictions from
sagittal, axial, and coronal views were ensembled to optimize performance. The
models were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71
standard MRIs). The models achieved an AUC of 0.91 and 0.93, sensitivity of 83%
and 94%, and specificity of 91% and 86% for standard MRIs and MRAs,
respectively. Notably, model performance on non-invasive standard MRIs matched
or surpassed radiologists interpreting MRAs. External validation demonstrated
initial generalizability across imaging protocols. This study demonstrates that
DL models can achieve radiologist-level diagnostic performance on standard
MRIs, reducing the need for invasive MRAs. By releasing ScopeMRI and a modular
codebase for training and evaluating deep learning models on 3D medical imaging
data, we aim to accelerate research in musculoskeletal imaging and support the
development of new datasets for clinically challenging diagnostic tasks.


## Sparse mixed linear modeling with anchor-based guidance for high-entropy alloy discovery

>Authors: Ryo Murakami, Seiji Miura, Akihiro Endo, Satoshi Minamoto

>2025-04-29

> http://arxiv.org/abs/2504.20354v1

High-entropy alloys have attracted attention for their exceptional mechanical
properties and thermal stability. However, the combinatorial explosion in the
number of possible elemental compositions renders traditional trial-and-error
experimental approaches highly inefficient for materials discovery. To solve
this problem, machine learning techniques have been increasingly employed for
property prediction and high-throughput screening. Nevertheless, highly
accurate nonlinear models often suffer from a lack of interpretability, which
is a major limitation. In this study, we focus on local data structures that
emerge from the greedy search behavior inherent to experimental data
acquisition. By introducing a linear and low-dimensional mixture regression
model, we strike a balance between predictive performance and model
interpretability. In addition, we develop an algorithm that simultaneously
performs prediction and feature selection by considering multiple candidate
descriptors. Through a case study on high-entropy alloys, this study introduces
a method that combines anchor-guided clustering and **sparse** linear modeling to
address biased data structures arising from greedy exploration in materials
science.


## CarbonCall Sustainability-Aware Function Calling for Large Language Models on Edge Devices

>Authors: Varatheepan Paramanayakam, Andreas Karatzas, Iraklis Anagnostopoulos, Dimitrios Stamoulis

>2025-04-29

> http://arxiv.org/abs/2504.20348v2

Large Language Models (LLMs) enable real-time function calling in edge AI
systems but introduce significant computational overhead, leading to high power
consumption and carbon emissions. Existing methods optimize for performance
while neglecting sustainability, making them inefficient for energy-constrained
environments. We introduce CarbonCall, a sustainability-aware function-calling
framework that integrates dynamic tool selection, carbon-aware execution, and
**quantize**d LLM adaptation. CarbonCall adjusts power thresholds based on
real-time carbon intensity forecasts and switches between model variants to
sustain high tokens-per-second throughput under power constraints. Experiments
on an NVIDIA Jetson AGX Orin show that CarbonCall reduces carbon emissions by
up to 52%, power consumption by 30%, and execution time by 30%, while
maintaining high efficiency.


## Leveraging Action Relational Structures for Integrated Learning and Planning

>Authors: Ryan Xiao Wang, Felipe Trevizan

>2025-04-29

> http://arxiv.org/abs/2504.20318v1

Recent advances in planning have explored using learning methods to help
planning. However, little attention has been given to adapting search
algorithms to work better with learning systems. In this paper, we introduce
partial-space search, a new search space for classical planning that leverages
the relational structure of actions given by PDDL action schemas -- a structure
overlooked by traditional planning approaches. Partial-space search provides a
more granular view of the search space and allows earlier **pruning** of poor
actions compared to state-space search. To guide partial-space search, we
introduce action set heuristics that evaluate sets of actions in a state. We
describe how to automatically convert existing heuristics into action set
heuristics. We also train action set heuristics from scratch using large
training datasets from partial-space search. Our new planner, LazyLifted,
exploits our better integrated search and learning heuristics and outperforms
the state-of-the-art ML-based heuristic on IPC 2023 learning track (LT)
benchmarks. We also show the efficiency of LazyLifted on high-branching factor
tasks and show that it surpasses LAMA in the combined IPC 2023 LT and
high-branching factor benchmarks.


## Acceleration of Convergence of Double Series for the Green's Function of the Helmholtz Equation in Polar Coordinates

>Authors: Igor M. Braver

>2025-04-28

> http://arxiv.org/abs/2504.20214v1

The well-known expressions for the Green's functions for the Helmholtz
equation in polar coordinates with Dirichlet and Neumann boundary conditions
are transformed. The slowly converging double series describing these Green's
functions are reduced by means of successive subtraction of several auxiliary
functions to series that converge much more rapidly. A method is given for
constructing the auxiliary functions (the first one is identical with the
Green's function of the Laplace equation) in the form of single series and in
the form of closed expressions. Formulas are presented for summing series of
the Fourier-Bessel and Dini type; they are required to implement the two steps
of the procedure for accelerating convergence. The effectiveness of the
functions constructed is illustrated by the numerical solution of the problem
of the dispersion properties of a slotted line with a coaxial circular
cylindrical screen.


## ProFi-Net Prototype-based Feature Attention with Curriculum Augmentation for WiFi-based Gesture Recognition

>Authors: Zhe Cui, Shuxian Zhang, Kangzhi Lou, Le-Nam Tran

>2025-04-28

> http://arxiv.org/abs/2504.20193v1

This paper presents ProFi-Net, a novel few-shot learning framework for
WiFi-based gesture recognition that overcomes the challenges of limited
training data and **sparse** feature representations. ProFi-Net employs a
prototype-based metric learning architecture enhanced with a feature-level
attention mechanism, which dynamically refines the Euclidean distance by
emphasizing the most discriminative feature dimensions. Additionally, our
approach introduces a curriculum-inspired data augmentation strategy
exclusively on the query set. By progressively incorporating Gaussian noise of
increasing magnitude, the model is exposed to a broader range of challenging
variations, thereby improving its generalization and robustness to overfitting.
Extensive experiments conducted across diverse real-world environments
demonstrate that ProFi-Net significantly outperforms conventional prototype
networks and other state-of-the-art few-shot learning methods in terms of
classification accuracy and training efficiency.


## Phase-locking in dynamical systems and quantum mechanics

>Authors: Artem Alexandrov, Alexey Glutsyuk, Alexander Gorsky

>2025-04-28

> http://arxiv.org/abs/2504.20181v1

In this study, we discuss the Prufer transform that connects the dynamical
system on the torus and the Hill equation, which is interpreted as either the
equation of motion for the parametric oscillator or the Schrodinger equation
with periodic potential. The structure of phase-locking domains in the
dynamical system on torus is mapped into the band-gap structure of the Hill
equation. For the parametric oscillator, we provide the relation between the
non-adiabatic Hannay angle and the Poincare rotation number of the
corresponding dynamical system. In terms of quantum mechanics, the integer
rotation number is connected to the **quantization** number via the Milne
**quantization** approach and exact WKB. Using recent results concerning the exact
WKB approach in quantum mechanics, we discuss the possible non-perturbative
effects in the dynamical systems on the torus and for parametric oscillator.
The semiclassical WKB is interpreted in the framework of a slow-fast dynamical
system. The link between the classification of the coadjoint Virasoro orbits
and the Hill equation yields a classification of the phase-locking domains in
the parameter space in terms of the classification of Virasoro orbits. Our
picture is supported by numerical simulations for the model of the Josephson
junction and Mathieu equation.


## AutoJudge Judge Decoding Without Manual Annotation

>Authors: Roman Garipov, Fedor Velikonivtsev, Ruslan Svirschevski, Vage Egiazarian, Max Ryabinin

>2025-04-28

> http://arxiv.org/abs/2504.20039v1

We introduce AutoJudge, a framework that accelerates large language model
(LLM) inference with task-specific lossy speculative decoding. Instead of
matching the original model output distribution token-by-token, we identify
which of the generated tokens affect the downstream quality of the generated
response, relaxing the guarantee so that the "unimportant" tokens can be
generated faster. Our approach relies on a semi-greedy search algorithm to test
which of the mismatches between target and draft model should be corrected to
preserve quality, and which ones may be skipped. We then train a lightweight
classifier based on existing LLM embeddings to predict, at inference time,
which mismatching tokens can be safely accepted without compromising the final
answer quality. We test our approach with Llama 3.2 1B (draft) and Llama 3.1 8B
(target) models on zero-shot GSM8K reasoning, where it achieves up to 1.5x more
accepted tokens per verification cycle with under 1% degradation in answer
accuracy compared to standard speculative decoding and over 2x with small loss
in accuracy. When applied to the LiveCodeBench benchmark, our approach
automatically detects other, programming-specific important tokens and shows
similar speedups, demonstrating its ability to generalize across tasks.


## LIRM Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields

>Authors: Zhengqin Li, Dilin Wang, Ka Chen, Zhaoyang Lv, Thu Nguyen-Phuoc, Milim Lee, Jia-Bin Huang, Lei Xiao, Cheng Zhang, Yufeng Zhu, Carl S. Marshall, Yufeng Ren, Richard Newcombe, Zhao Dong

>2025-04-28

> http://arxiv.org/abs/2504.20026v1

We present Large Inverse Rendering Model (LIRM), a transformer architecture
that jointly reconstructs high-quality shape, materials, and radiance fields
with view-dependent effects in less than a second. Our model builds upon the
recent Large Reconstruction Models (LRMs) that achieve state-of-the-art
**sparse**-view reconstruction quality. However, existing LRMs struggle to
reconstruct unseen parts accurately and cannot recover glossy appearance or
generate relightable 3D contents that can be consumed by standard Graphics
engines. To address these limitations, we make three key technical
contributions to build a more practical multi-view 3D reconstruction framework.
First, we introduce an update model that allows us to progressively add more
input views to improve our reconstruction. Second, we propose a hexa-plane
neural SDF representation to better recover detailed textures, geometry and
material parameters. Third, we develop a novel neural directional-embedding
mechanism to handle view-dependent effects. Trained on a large-scale shape and
material dataset with a tailored coarse-to-fine training scheme, our model
achieves compelling results. It compares favorably to optimization-based
dense-view inverse rendering methods in terms of geometry and relighting
accuracy, while requiring only a fraction of the inference time.


## Feelbert A Feedback Linearization-based Embedded Real-Time Quadrupedal Locomotion Framework

>Authors: Aristide Emanuele Casucci, Federico Nesti, Mauro Marinoni, Giorgio Buttazzo

>2025-04-28

> http://arxiv.org/abs/2504.19965v2

Quadruped robots have become quite popular for their ability to adapt their
locomotion to generic uneven terrains. For this reason, over time, several
frameworks for quadrupedal locomotion have been proposed, but with little
attention to ensuring a predictable timing behavior of the controller.
  To address this issue, this work presents Feelbert, a modular control
framework for quadrupedal locomotion suitable for execution on an embedded
system under hard real-time execution constraints. It leverages the feedback
linearization control technique to obtain a closed-form control law for the
body, valid for all configurations of the robot. The control law was derived
after defining an appropriate rigid body model that uses the **acceleration**s of
the feet as control variables, instead of the estimated contact forces. This
work also provides a novel algorithm to compute footholds and gait temporal
parameters using the concept of imaginary wheels, and a heuristic algorithm to
select the best gait schedule for the current velocity commands.
  The proposed framework is developed entirely in C++, with no dependencies on
third-party libraries and no dynamic memory allocation, to ensure
predictability and real-time performance. Its implementation allows Feelbert to
be both compiled and executed on an embedded system for critical applications,
as well as integrated into larger systems such as Robot Operating System 2 (ROS
2). For this reason, Feelbert has been tested in both scenarios, demonstrating
satisfactory results both in terms of reference tracking and temporal
predictability, whether integrated into ROS 2 or compiled as a standalone
application on a Raspberry Pi 5.


## Accelerated 3D-3D rigid registration of echocardiographic images obtained from apical window using particle filter

>Authors: Thanuja Uruththirakodeeswaran, Harald Becher, Michelle Noga, Lawrence H. Le, Pierre Boulanger, Jonathan Windram, Kumaradevan Punithakumar

>2025-04-28

> http://arxiv.org/abs/2504.19930v1

The perfect alignment of 3D echocardiographic images captured from various
angles has improved image quality and broadened the field of view. This study
proposes an accelerated sequential Monte Carlo (SMC) algorithm for 3D-3D rigid
registration of transthoracic echocardiographic images with significant and
limited overlap taken from apical window that is robust to the noise and
intensity variation in ultrasound images. The algorithm estimates the
translational and rotational components of the rigid transform through an
iterative process and requires an initial approximation of the rotation and
translation limits. We perform registration in two ways: the image-based
registration computes the transform to align the end-diastolic frame of the
apical nonstandard image to the apical standard image and applies the same
transform to all frames of the cardiac cycle, whereas the mask-based
registration approach uses the binary masks of the left ventricle in the same
way. The SMC and exhaustive search (EX) algorithms were evaluated for 4D
temporal sequences recorded from 7 volunteers who participated in a study
conducted at the Mazankowski Alberta Heart Institute. The evaluations
demonstrate that the mask-based approach of the accelerated SMC yielded a Dice
score value of 0.819 +/- 0.045 for the left ventricle and gained 16.7x speedup
compared to the CPU version of the SMC algorithm.


## Accelerating Mixture-of-Experts Training with Adaptive Expert Replication

>Authors: Athinagoras Skiadopoulos, Mark Zhao, Swapnil Gandhi, Thomas Norrie, Shrijeet Mukherjee, Christos Kozyrakis

>2025-04-28

> http://arxiv.org/abs/2504.19925v1

Mixture-of-Experts (MoE) models have become a widely adopted solution to
continue scaling model sizes without a corresponding linear increase in
compute. During MoE model training, each input token is dynamically routed to a
subset of experts -- **sparse**ly-activated feed-forward networks -- within each
transformer layer. The distribution of tokens assigned to each expert varies
widely and rapidly over the course of training. To handle the wide load
imbalance across experts, current systems are forced to either drop tokens
assigned to popular experts, degrading convergence, or frequently rebalance
resources allocated to each expert based on popularity, incurring high state
migration overheads.
  To break this performance-accuracy tradeoff, we introduce SwiftMoE, an
adaptive MoE training system. The key insight of SwiftMoE is to decouple the
placement of expert parameters from their large optimizer state. SwiftMoE
statically partitions the optimizer of each expert across all training nodes.
Meanwhile, SwiftMoE dynamically adjusts the placement of expert parameters by
repurposing existing weight updates, avoiding migration overheads. In doing so,
SwiftMoE right-sizes the GPU resources allocated to each expert, on a
per-iteration basis, with minimal overheads. Compared to state-of-the-art MoE
training systems, DeepSpeed and FlexMoE, SwiftMoE is able to achieve a 30.5%
and 25.9% faster time-to-convergence, respectively.


## Can AI Agents Design and Implement Drug Discovery Pipelines?

>Authors: Khachik Smbatyan, Tsolak Ghukasyan, Tigran Aghajanyan, Hovhannes Dabaghyan, Sergey Adamyan, Aram Bughdaryan, Vahagn Altunyan, Gagik Navasardyan, Aram Davtyan, Anush Hakobyan, Aram Gharibyan, Arman Fahradyan, Artur Hakobyan, Hasmik Mnatsakanyan, Narek Ginoyan, Garik Petrosyan

>2025-04-28

> http://arxiv.org/abs/2504.19912v1

The rapid advancement of artificial intelligence, particularly autonomous
agentic systems based on Large Language Models (LLMs), presents new
opportunities to accelerate drug discovery by improving in-silico modeling and
reducing dependence on costly experimental trials. Current AI agent-based
systems demonstrate proficiency in solving programming challenges and
conducting research, indicating an emerging potential to develop software
capable of addressing complex problems such as pharmaceutical design and drug
discovery. This paper introduces DO Challenge, a benchmark designed to evaluate
the decision-making abilities of AI agents in a single, complex problem
resembling virtual screening scenarios. The benchmark challenges systems to
independently develop, implement, and execute efficient strategies for
identifying promising molecular structures from extensive datasets, while
navigating chemical space, selecting models, and managing limited resources in
a multi-objective context. We also discuss insights from the DO Challenge 2025,
a competition based on the proposed benchmark, which showcased diverse
strategies explored by human participants. Furthermore, we present the Deep
Thought multi-agent system, which demonstrated strong performance on the
benchmark, outperforming most human teams. Among the language models tested,
Claude 3.7 Sonnet, Gemini 2.5 Pro and o3 performed best in primary agent roles,
and GPT-4o, Gemini 2.0 Flash were effective in auxiliary roles. While
promising, the system's performance still fell short of expert-designed
solutions and showed high instability, highlighting both the potential and
current limitations of AI-driven methodologies in transforming drug discovery
and broader scientific research.


## TurboQuant Online Vector Quantization with Near-optimal Distortion Rate

>Authors: Amir Zandieh, Majid Daliri, Majid Hadian, Vahab Mirrokni

>2025-04-28

> http://arxiv.org/abs/2504.19874v1

Vector **quantization**, a problem rooted in Shannon's source coding theory, aims
to **quantize** high-dimensional Euclidean vectors while minimizing distortion in
their geometric structure. We propose TurboQuant to address both mean-squared
error (MSE) and inner product distortion, overcoming limitations of existing
methods that fail to achieve optimal distortion rates. Our data-oblivious
algorithms, suitable for online applications, achieve near-optimal distortion
rates (within a small constant factor) across all bit-widths and dimensions.
TurboQuant achieves this by randomly rotating input vectors, inducing a
concentrated Beta distribution on coordinates, and leveraging the
near-independence property of distinct coordinates in high dimensions to simply
apply optimal scalar **quantize**rs per each coordinate. Recognizing that
MSE-optimal **quantize**rs introduce bias in inner product estimation, we propose a
two-stage approach: applying an MSE **quantize**r followed by a 1-bit Quantized JL
(QJL) transform on the residual, resulting in an unbiased inner product
**quantize**r. We also provide a formal proof of the information-theoretic lower
bounds on best achievable distortion rate by any vector **quantize**r,
demonstrating that TurboQuant closely matches these bounds, differing only by a
small constant ($\approx 2.7$) factor. Experimental results validate our
theoretical findings, showing that for **KV** cache **quantization**, we achieve
absolute quality neutrality with 3.5 bits per channel and marginal quality
degradation with 2.5 bits per channel. Furthermore, in nearest neighbor search
tasks, our method outperforms existing product **quantization** techniques in
recall while reducing indexing time to virtually zero.


## semi-PD Towards Efficient LLM Serving via Phase-Wise Disaggregated Computation and Unified Storage

>Authors: Ke Hong, Lufang Chen, Zhong Wang, Xiuhong Li, Qiuli Mao, Jianping Ma, Chao Xiong, Guanyu Wu, Buhe Han, Guohao Dai, Yun Liang, Yu Wang

>2025-04-28

> http://arxiv.org/abs/2504.19867v1

Existing large language model (LLM) serving systems fall into two categories:
1) a unified system where prefill phase and decode phase are co-located on the
same GPU, sharing the unified computational resource and storage, and 2) a
disaggregated system where the two phases are disaggregated to different GPUs.
The design of the disaggregated system addresses the latency interference and
sophisticated scheduling issues in the unified system but leads to storage
challenges including 1) replicated weights for both phases that prevent
flexible deployment, 2) **KV** cache transfer overhead between the two phases, 3)
storage imbalance that causes substantial wasted space of the GPU capacity, and
4) suboptimal resource adjustment arising from the difficulties in migrating **KV**
cache. Such storage inefficiency delivers poor serving performance under high
request rates.
  In this paper, we identify that the advantage of the disaggregated system
lies in the disaggregated computation, i.e., partitioning the computational
resource to enable the asynchronous computation of two phases. Thus, we propose
a novel LLM serving system, semi-PD, characterized by disaggregated computation
and unified storage. In semi-PD, we introduce a computation resource controller
to achieve disaggregated computation at the streaming multi-processor (SM)
level, and a unified memory manager to manage the asynchronous memory access
from both phases. semi-PD has a low-overhead resource adjustment mechanism
between the two phases, and a service-level objective (SLO) aware dynamic
partitioning algorithm to optimize the SLO attainment. Compared to
state-of-the-art systems, semi-PD maintains lower latency at higher request
rates, reducing the average end-to-end latency per request by 1.27-2.58x on
DeepSeek series models, and serves 1.55-1.72x more requests adhering to latency
constraints on Llama series models.


## CoherenDream Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback

>Authors: Chenhan Jiang, Yihan Zeng, Hang Xu, Dit-Yan Yeung

>2025-04-28

> http://arxiv.org/abs/2504.19860v1

Score Distillation Sampling (SDS) has achieved remarkable success in
text-to-3D content generation. However, SDS-based methods struggle to maintain
semantic fidelity for user prompts, particularly when involving multiple
objects with intricate interactions. While existing approaches often address 3D
consistency through multiview diffusion model fine-tuning on 3D datasets, this
strategy inadvertently exacerbates text-3D alignment degradation. The
limitation stems from SDS's inherent accumulation of view-independent biases
during optimization, which progressively diverges from the ideal text alignment
direction. To alleviate this limitation, we propose a novel SDS objective,
dubbed as Textual Coherent Score Distillation (TCSD), which integrates
alignment feedback from multimodal large language models (MLLMs). Our TCSD
leverages cross-modal understanding capabilities of MLLMs to assess and guide
the text-3D correspondence during the optimization. We further develop
3DLLaVA-CRITIC - a fine-tuned MLLM specialized for evaluating multiview text
alignment in 3D generations. Additionally, we introduce an LLM-layout
initialization that significantly accelerates optimization convergence through
semantic-aware spatial configuration. Comprehensive evaluations demonstrate
that our framework, CoherenDream, establishes state-of-the-art performance in
text-aligned 3D generation across multiple benchmarks, including T$^3$Bench and
TIFA subset. Qualitative results showcase the superior performance of
CoherenDream in preserving textual consistency and semantic interactions. As
the first study to incorporate MLLMs into SDS optimization, we also conduct
extensive ablation studies to explore optimal MLLM adaptations for 3D
generation tasks.


## Hierarchical Uncertainty-Aware Graph Neural Network

>Authors: Yoonhyuk Choi, Jiho Choi, Taewook Ko, Chong-Kwon Kim

>2025-04-28

> http://arxiv.org/abs/2504.19820v2

Recent research on graph neural networks (GNNs) has explored mechanisms for
capturing local uncertainty and exploiting graph hierarchies to mitigate data
**sparsity** and leverage structural properties. However, the synergistic
integration of these two approaches remains underexplored. This work introduces
a novel architecture, the Hierarchical Uncertainty-Aware Graph Neural Network
(HU-GNN), which unifies multi-scale representation learning, principled
uncertainty estimation, and self-supervised embedding diversity within a single
end-to-end framework. Specifically, HU-GNN adaptively forms node clusters and
estimates uncertainty at multiple structural scales from individual nodes to
higher levels. These uncertainty estimates guide a robust message-passing
mechanism and attention weighting, effectively mitigating noise and adversarial
perturbations while preserving predictive accuracy on semi-supervised
classification tasks. We also offer key theoretical contributions, including a
probabilistic formulation, rigorous uncertainty-calibration guarantees, and
formal robustness bounds. Extensive experiments on standard benchmarks
demonstrate that our model achieves state-of-the-art robustness and
interpretability.


## STCOcc Sparse Spatial-Temporal Cascade Renovation for 3D Occupancy and Scene Flow Prediction

>Authors: Zhimin Liao, Ping Wei, Shuaijia Chen, Haoxuan Wang, Ziyang Ren

>2025-04-28

> http://arxiv.org/abs/2504.19749v1

3D occupancy and scene flow offer a detailed and dynamic representation of 3D
scene. Recognizing the **sparsity** and complexity of 3D space, previous
vision-centric methods have employed implicit learning-based approaches to
model spatial and temporal information. However, these approaches struggle to
capture local details and diminish the model's spatial discriminative ability.
To address these challenges, we propose a novel explicit state-based modeling
method designed to leverage the occupied state to renovate the 3D features.
Specifically, we propose a **sparse** occlusion-aware attention mechanism,
integrated with a cascade refinement strategy, which accurately renovates 3D
features with the guidance of occupied state information. Additionally, we
introduce a novel method for modeling long-term dynamic interactions, which
reduces computational costs and preserves spatial information. Compared to the
previous state-of-the-art methods, our efficient explicit renovation strategy
not only delivers superior performance in terms of RayIoU and mAVE for
occupancy and scene flow prediction but also markedly reduces GPU memory usage
during training, bringing it down to 8.7GB. Our code is available on
https://github.com/lzzzzzm/STCOcc


## FineQ Software-Hardware Co-Design for Low-Bit Fine-Grained Mixed-Precision Quantization of LLMs

>Authors: Xilong Xie, Liang Wang, Limin Xiao, Meng Han, Lin Sun, Shuai Zheng, Xiangrong Xu

>2025-04-28

> http://arxiv.org/abs/2504.19746v1

Large language models (LLMs) have significantly advanced the natural language
processing paradigm but impose substantial demands on memory and computational
resources. Quantization is one of the most effective ways to reduce memory
consumption of LLMs. However, advanced single-precision **quantization** methods
experience significant accuracy degradation when quantizing to ultra-low bits.
Existing mixed-precision **quantization** methods are **quantize**d by groups with
coarse granularity. Employing high precision for group data leads to
substantial memory overhead, whereas low precision severely impacts model
accuracy. To address this issue, we propose FineQ, software-hardware co-design
for **low-bit** fine-grained mixed-precision **quantization** of LLMs. First, FineQ
partitions the weights into finer-grained clusters and considers the
distribution of outliers within these clusters, thus achieving a balance
between model accuracy and memory overhead. Then, we propose an outlier
protection mechanism within clusters that uses 3 bits to represent outliers and
introduce an encoding scheme for index and data concatenation to enable aligned
memory access. Finally, we introduce an accelerator utilizing temporal coding
that effectively supports the **quantization** algorithm while simplifying the
multipliers in the systolic array. FineQ achieves higher model accuracy
compared to the SOTA mixed-precision **quantization** algorithm at a close average
bit-width. Meanwhile, the accelerator achieves up to 1.79x energy efficiency
and reduces the area of the systolic array by 61.2%.


## Taming the Titans A Survey of Efficient LLM Inference Serving

>Authors: Ranran Zhen, Juntao Li, Yixin Ji, Zhenlin Yang, Tong Liu, Qingrong Xia, Xinyu Duan, Zhefeng Wang, Baoxing Huai, Min Zhang

>2025-04-28

> http://arxiv.org/abs/2504.19720v1

Large Language Models (LLMs) for Generative AI have achieved remarkable
progress, evolving into sophisticated and versatile tools widely adopted across
various domains and applications. However, the substantial memory overhead
caused by their vast number of parameters, combined with the high computational
demands of the attention mechanism, poses significant challenges in achieving
low latency and high throughput for LLM inference services. Recent
advancements, driven by groundbreaking research, have significantly accelerated
progress in this field. This paper provides a comprehensive survey of these
methods, covering fundamental instance-level approaches, in-depth cluster-level
strategies, emerging scenario directions, and other miscellaneous but important
areas. At the instance level, we review model placement, request scheduling,
decoding length prediction, storage management, and the disaggregation
paradigm. At the cluster level, we explore GPU cluster deployment,
multi-instance load balancing, and cloud service solutions. For emerging
scenarios, we organize the discussion around specific tasks, modules, and
auxiliary methods. To ensure a holistic overview, we also highlight several
niche yet critical areas. Finally, we outline potential research directions to
further advance the field of LLM inference serving.


## Fitness Landscape of Large Language Model-Assisted Automated Algorithm Search

>Authors: Fei Liu, Qingfu Zhang, Xialiang Tong, Kun Mao, Mingxuan Yuan

>2025-04-28

> http://arxiv.org/abs/2504.19636v2

Large Language Models (LLMs) have demonstrated significant potential in
algorithm design. However, when integrated into search frameworks for iterative
algorithm search, the underlying fitness landscape--critical for understanding
search behaviou--remains underexplored. In this paper, we illustrate and
analyze the fitness landscape of LLM-assisted Algorithm Search (LAS) using a
graph-based approach, where nodes represent algorithms and edges denote
transitions between them. We conduct extensive evaluations across six algorithm
design tasks and six commonly used LLMs. Our findings reveal that LAS
landscapes are highly multimodal and rugged, particularly in combinatorial
optimization tasks, with distinct structural variations across tasks and LLMs.
For instance, heuristic design tasks exhibit dense clusters of high-performing
algorithms, while symbolic regression tasks show **sparse**, scattered
distributions. Additionally, we demonstrate how population size influences
exploration-exploitation trade-offs and the evolving trajectory of elite
algorithms. These insights not only advance our understanding of LAS landscapes
but also provide practical guidance for designing more effective LAS methods.


## DiVE Efficient Multi-View Driving Scenes Generation Based on Video Diffusion Transformer

>Authors: Junpeng Jiang, Gangyi Hong, Miao Zhang, Hengtong Hu, Kun Zhan, Rui Shao, Liqiang Nie

>2025-04-28

> http://arxiv.org/abs/2504.19614v1

Collecting multi-view driving scenario videos to enhance the performance of
3D visual perception tasks presents significant challenges and incurs
substantial costs, making generative models for realistic data an appealing
alternative. Yet, the videos generated by recent works suffer from poor quality
and spatiotemporal consistency, undermining their utility in advancing
perception tasks under driving scenarios. To address this gap, we propose DiVE,
a diffusion transformer-based generative framework meticulously engineered to
produce high-fidelity, temporally coherent, and cross-view consistent
multi-view videos, aligning seamlessly with bird's-eye view layouts and textual
descriptions. DiVE leverages a unified cross-attention and a SketchFormer to
exert precise control over multimodal data, while incorporating a view-inflated
attention mechanism that adds no extra parameters, thereby guaranteeing
consistency across views. Despite these advancements, synthesizing
high-resolution videos under multimodal constraints introduces dual challenges:
investigating the optimal classifier-free guidance coniguration under intricate
multi-condition inputs and mitigating excessive computational latency in
high-resolution rendering--both of which remain underexplored in prior
researches. To resolve these limitations, we introduce two innovations:
Multi-Control Auxiliary Branch Distillation, which streamlines multi-condition
CFG selection while circumventing high computational overhead, and Resolution
Progressive Sampling, a training-free **acceleration** strategy that staggers
resolution scaling to reduce high latency due to high resolution. These
innovations collectively achieve a 2.62x speedup with minimal quality
degradation. Evaluated on the nuScenes dataset, DiVE achieves SOTA performance
in multi-view video generation, yielding photorealistic outputs with
exceptional temporal and cross-view coherence.


## SAMBLE Shape-Specific Point Cloud Sampling for an Optimal Trade-Off Between Local Detail and Global Uniformity

>Authors: Chengzhi Wu, Yuxin Wan, Hao Fu, Julius Pfrommer, Zeyun Zhong, Junwei Zheng, Jiaming Zhang, Jürgen Beyerer

>2025-04-28

> http://arxiv.org/abs/2504.19581v1

Driven by the increasing demand for accurate and efficient representation of
3D data in various domains, point cloud sampling has emerged as a pivotal
research topic in 3D computer vision. Recently, learning-to-sample methods have
garnered growing interest from the community, particularly for their ability to
be jointly trained with downstream tasks. However, previous learning-based
sampling methods either lead to unrecognizable sampling patterns by generating
a new point cloud or biased sampled results by focusing excessively on sharp
edge details. Moreover, they all overlook the natural variations in point
distribution across different shapes, applying a similar sampling strategy to
all point clouds. In this paper, we propose a Sparse Attention Map and
Bin-based Learning method (termed SAMBLE) to learn shape-specific sampling
strategies for point cloud shapes. SAMBLE effectively achieves an improved
balance between sampling edge points for local details and preserving
uniformity in the global shape, resulting in superior performance across
multiple common point cloud downstream tasks, even in scenarios with few-point
sampling.


## Llama-3.1-FoundationAI-SecurityLLM-Base-8B Technical Report

>Authors: Paul Kassianik, Baturay Saglam, Alexander Chen, Blaine Nelson, Anu Vellore, Massimo Aufiero, Fraser Burch, Dhruv Kedia, Avi Zohary, Sajana Weerawardhena, Aman Priyanshu, Adam Swanda, Amy Chang, Hyrum Anderson, Kojin Oshiba, Omar Santos, Yaron Singer, Amin Karbasi

>2025-04-28

> http://arxiv.org/abs/2504.21039v1

As transformer-based large language models (LLMs) increasingly permeate
society, they have revolutionized domains such as software engineering,
creative writing, and digital arts. However, their adoption in cybersecurity
remains limited due to challenges like scarcity of specialized training data
and complexity of representing cybersecurity-specific knowledge. To address
these gaps, we present Foundation-Sec-8B, a cybersecurity-focused LLM built on
the Llama 3.1 architecture and enhanced through continued pretraining on a
carefully curated cybersecurity corpus. We evaluate Foundation-Sec-8B across
both established and new cybersecurity benchmarks, showing that it matches
Llama 3.1-70B and GPT-4o-mini in certain cybersecurity-specific tasks. By
releasing our model to the public, we aim to accelerate progress and adoption
of AI-driven tools in both public and private cybersecurity contexts.


## ResearchCodeAgent An LLM Multi-Agent System for Automated Codification of Research Methodologies

>Authors: Shubham Gandhi, Dhruv Shah, Manasi Patwardhan, Lovekesh Vig, Gautam Shroff

>2025-04-28

> http://arxiv.org/abs/2504.20117v2

In this paper we introduce ResearchCodeAgent, a novel multi-agent system
leveraging large language models (LLMs) agents to automate the codification of
research methodologies described in machine learning literature. The system
bridges the gap between high-level research concepts and their practical
implementation, allowing researchers auto-generating code of existing research
papers for benchmarking or building on top-of existing methods specified in the
literature with availability of partial or complete starter code.
ResearchCodeAgent employs a flexible agent architecture with a comprehensive
action suite, enabling context-aware interactions with the research
environment. The system incorporates a dynamic planning mechanism, utilizing
both short and long-term memory to adapt its approach iteratively. We evaluate
ResearchCodeAgent on three distinct machine learning tasks with distinct task
complexity and representing different parts of the ML pipeline: data
augmentation, optimization, and data batching. Our results demonstrate the
system's effectiveness and generalizability, with 46.9% of generated code being
high-quality and error-free, and 25% showing performance improvements over
baseline implementations. Empirical analysis shows an average reduction of
57.9% in coding time compared to manual implementation. We observe higher gains
for more complex tasks. ResearchCodeAgent represents a significant step towards
automating the research implementation process, potentially accelerating the
pace of machine learning research.


## Bullet Boosting GPU Utilization for LLM Serving via Dynamic Spatial-Temporal Orchestration

>Authors: Zejia Lin, Hongxin Xu, Guanyi Chen, Xianwei Zhang, Yutong Lu

>2025-04-28

> http://arxiv.org/abs/2504.19516v1

Modern LLM serving systems confront inefficient GPU utilization due to the
fundamental mismatch between compute-intensive prefill and memory-bound decode
phases. While current practices attempt to address this by organizing these
phases into hybrid batches, such solutions create an inefficient tradeoff that
sacrifices either throughput or latency, leaving substantial GPU resources
underutilized. We identify two key root causes: 1) the prefill phase suffers
from suboptimal compute utilization due to wave **quantization** and attention
bottlenecks. 2) hybrid batches disproportionately prioritize latency over
throughput, resulting in wasted compute and memory bandwidth. To mitigate the
issues, we present Bullet, a novel spatial-temporal orchestration system that
eliminates these inefficiencies through precise phase coordination. Bullet
enables concurrent execution of prefill and decode phases, while dynamically
provisioning GPU resources using real-time performance modeling. By integrating
SLO-aware scheduling and adaptive resource allocation, Bullet maximizes
utilization without compromising latency targets. Experimental evaluations on
real-world workloads demonstrate that Bullet delivers 1.26x average throughput
gains (up to 1.55x) over state-of-the-arts, while consistently meeting latency
constraints.


## Prisma An Open Source Toolkit for Mechanistic Interpretability in Vision and Video

>Authors: Sonia Joseph, Praneet Suresh, Lorenz Hufe, Edward Stevinson, Robert Graham, Yash Vadi, Danilo Bzdok, Sebastian Lapuschkin, Lee Sharkey, Blake Aaron Richards

>2025-04-28

> http://arxiv.org/abs/2504.19475v1

Robust tooling and publicly available pre-trained models have helped drive
recent advances in mechanistic interpretability for language models. However,
similar progress in vision mechanistic interpretability has been hindered by
the lack of accessible frameworks and pre-trained weights. We present Prisma
(Access the codebase here: https://github.com/Prisma-Multimodal/ViT-Prisma), an
open-source framework designed to accelerate vision mechanistic
interpretability research, providing a unified toolkit for accessing 75+ vision
and video transformers; support for **sparse** autoencoder (SAE), transcoder, and
crosscoder training; a suite of 80+ pre-trained SAE weights; activation
caching, circuit analysis tools, and visualization tools; and educational
resources. Our analysis reveals surprising findings, including that effective
vision SAEs can exhibit substantially lower **sparsity** patterns than language
SAEs, and that in some instances, SAE reconstructions can decrease model loss.
Prisma enables new research directions for understanding vision model internals
while lowering barriers to entry in this emerging field.


## BRIDGE Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text

>Authors: Jiageng Wu, Bowen Gu, Ren Zhou, Kevin Xie, Doug Snyder, Yixing Jiang, Valentina Carducci, Richard Wyss, Rishi J Desai, Emily Alsentzer, Leo Anthony Celi, Adam Rodman, Sebastian Schneeweiss, Jonathan H. Chen, Santiago Romero-Brufau, Kueiyu Joshua Lin, Jie Yang

>2025-04-28

> http://arxiv.org/abs/2504.19467v2

Large language models (LLMs) hold great promise for medical applications and
are evolving rapidly, with new models being released at an accelerated pace.
However, current evaluations of LLMs in clinical contexts remain limited. Most
existing benchmarks rely on medical exam-style questions or PubMed-derived
text, failing to capture the complexity of real-world electronic health record
(EHR) data. Others focus narrowly on specific application scenarios, limiting
their generalizability across broader clinical use. To address this gap, we
present BRIDGE, a comprehensive multilingual benchmark comprising 87 tasks
sourced from real-world clinical data sources across nine languages. We
systematically evaluated 52 state-of-the-art LLMs (including DeepSeek-R1,
GPT-4o, Gemini, and Llama 4) under various inference strategies. With a total
of 13,572 experiments, our results reveal substantial performance variation
across model sizes, languages, natural language processing tasks, and clinical
specialties. Notably, we demonstrate that open-source LLMs can achieve
performance comparable to proprietary models, while medically fine-tuned LLMs
based on older architectures often underperform versus updated general-purpose
models. The BRIDGE and its corresponding leaderboard serve as a foundational
resource and a unique reference for the development and evaluation of new LLMs
in real-world clinical text understanding.
  The BRIDGE leaderboard:
https://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard


## R-Sparse Rank-Aware Activation Sparsity for Efficient LLM Inference

>Authors: Zhenyu Zhang, Zechun Liu, Yuandong Tian, Harshit Khaitan, Zhangyang Wang, Steven Li

>2025-04-28

> http://arxiv.org/abs/2504.19449v1

Large Language Models (LLMs), while demonstrating remarkable capabilities
across various applications, present significant challenges during inference
due to their substantial model size, especially when deployed on edge devices.
Activation **sparsity** offers a promising solution to reduce computation and
memory movement, enabling more efficient inference, particularly for
small-batch on-device applications. However, current approaches face
limitations with non-ReLU activation function, which are foundational to most
advanced LLMs, or require heavy continual training. Additionally, the
difficulty in predicting active channels and limited achievable **sparsity** ratios
constrain the effectiveness of activation **sparsity**-based methods. In this
paper, we introduce R-Sparse, a training-free activation **sparsity** approach
capable of achieving high **sparsity** levels in advanced LLMs. We conducted two
preliminary investigations into how different components contribute to the
output within a single linear layer and found two key observations: (i) the
non-**sparse** components of the input function can be regarded as a few bias
terms, and (ii) The full computation can be effectively approximated by an
appropriate combination of input channels and weight singular values. Building
on this, we replace the linear layers in LLMs with a rank-aware **sparse**
inference method that leverages the **sparsity** of input channels and singular
value components, eliminating the need for active channel prediction like the
output **sparsity** based approaches. Experiments on Llama-2/3 and Mistral models
across ten diverse tasks demonstrate that R-Sparse achieves comparable
performance at 50% model-level **sparsity**, resulting in a significant 43%
end-to-end efficient improvements with customized kernels.


## TreeHop Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering

>Authors: Zhonghao Li, Kunpeng Zhang, Jinghuai Ou, Shuliang Liu, Xuming Hu

>2025-04-28

> http://arxiv.org/abs/2504.20114v2

Retrieval-augmented generation (RAG) systems face significant challenges in
multi-hop question answering (MHQA), where complex queries require synthesizing
information across multiple document chunks. Existing approaches typically rely
on iterative LLM-based query rewriting and routing, resulting in high
computational costs due to repeated LLM invocations and multi-stage processes.
To address these limitations, we propose TreeHop, an embedding-level framework
without the need for LLMs in query refinement. TreeHop dynamically updates
query embeddings by fusing semantic information from prior queries and
retrieved documents, enabling iterative retrieval through embedding-space
operations alone. This method replaces the traditional
"Retrieve-Rewrite-Vectorize-Retrieve" cycle with a streamlined
"Retrieve-Embed-Retrieve" loop, significantly reducing computational overhead.
Moreover, a rule-based stop criterion is introduced to further prune redundant
retrievals, balancing efficiency and recall rate. Experimental results show
that TreeHop rivals advanced RAG methods across three open-domain MHQA
datasets, achieving comparable performance with only 5\%-0.4\% of the model
parameter size and reducing the query latency by approximately 99\% compared to
concurrent approaches. This makes TreeHop a faster and more cost-effective
solution for deployment in a range of knowledge-intensive applications. For
reproducibility purposes, codes and data are available here:
https://github.com/allen-li1231/TreeHop-RAG.


## SAGA A Security Architecture for Governing AI Agentic Systems

>Authors: Georgios Syros, Anshuman Suri, Cristina Nita-Rotaru, Alina Oprea

>2025-04-27

> http://arxiv.org/abs/2504.21034v1

Large Language Model (LLM)-based agents increasingly interact, collaborate,
and delegate tasks to one another autonomously with minimal human interaction.
Industry guidelines for agentic system governance emphasize the need for users
to maintain comprehensive control over their agents, mitigating potential
damage from malicious agents. Several proposed agentic system designs address
agent identity, authorization, and delegation, but remain purely theoretical,
without concrete implementation and evaluation. Most importantly, they do not
provide user-controlled agent management. To address this gap, we propose SAGA,
a Security Architecture for Governing Agentic systems, that offers user
oversight over their agents' lifecycle. In our design, users register their
agents with a central entity, the Provider, that maintains agents contact
information, user-defined access control policies, and helps agents enforce
these policies on inter-agent communication. We introduce a cryptographic
mechanism for deriving access control tokens, that offers fine-grained control
over an agent's interaction with other agents, balancing security and
performance consideration. We evaluate SAGA on several agentic tasks, using
agents in different geolocations, and multiple on-device and cloud LLMs,
demonstrating minimal performance overhead with no impact on underlying task
utility in a wide range of conditions. Our architecture enables secure and
trustworthy deployment of autonomous agents, accelerating the responsible
adoption of this technology in sensitive environments.


## MERA Multimodal and Multiscale Self-Explanatory Model with Considerably Reduced Annotation for Lung Nodule Diagnosis

>Authors: Jiahao Lu, Chong Yin, Silvia Ingala, Kenny Erleben, Michael Bachmann Nielsen, Sune Darkner

>2025-04-27

> http://arxiv.org/abs/2504.19357v1

Lung cancer, a leading cause of cancer-related deaths globally, emphasises
the importance of early detection for better patient outcomes. Pulmonary
nodules, often early indicators of lung cancer, necessitate accurate, timely
diagnosis. Despite Explainable Artificial Intelligence (XAI) advances, many
existing systems struggle providing clear, comprehensive explanations,
especially with limited labelled data. This study introduces MERA, a Multimodal
and Multiscale self-Explanatory model designed for lung nodule diagnosis with
considerably Reduced Annotation requirements. MERA integrates unsupervised and
weakly supervised learning strategies (self-supervised learning techniques and
Vision Transformer architecture for unsupervised feature extraction) and a
hierarchical prediction mechanism leveraging **sparse** annotations via
semi-supervised active learning in the learned latent space. MERA explains its
decisions on multiple levels: model-level global explanations via semantic
latent space clustering, instance-level case-based explanations showing similar
instances, local visual explanations via attention maps, and concept
explanations using critical nodule attributes. Evaluations on the public LIDC
dataset show MERA's superior diagnostic accuracy and self-explainability. With
only 1% annotated samples, MERA achieves diagnostic accuracy comparable to or
exceeding state-of-the-art methods requiring full annotation. The model's
inherent design delivers comprehensive, robust, multilevel explanations aligned
closely with clinical practice, enhancing trustworthiness and transparency.
Demonstrated viability of unsupervised and weakly supervised learning lowers
the barrier to deploying diagnostic AI in broader medical domains. Our complete
code is open-source available: https://github.com/diku-dk/credanno.


## Spatial-Sign based High dimensional Change Point Inference

>Authors: Jixuan Liu, Long Feng, Liuhua Peng, Zhaojun Wang

>2025-04-27

> http://arxiv.org/abs/2504.19306v1

High-dimensional changepoint inference, adaptable to diverse alternative
scenarios, has attracted significant attention in recent years. In this paper,
we propose an adaptive and robust approach to changepoint testing.
Specifically, by generalizing the classical mean-based cumulative sum (CUSUM)
statistic, we construct CUSUM statistics based on spatial medians and spatial
signs. We introduce test statistics that consider the maximum and summation of
the CUSUM statistics across different dimensions, respectively, and take the
maximum across all potential changepoint locations. The asymptotic
distributions of test statistics under the null hypothesis are derived.
Furthermore, the test statistics exhibit asymptotic independence under mild
conditions. Building on these results, we propose an adaptive testing procedure
that combines the max-$L_\infty$-type and max-$L_2$-type statistics to achieve
high power under both **sparse** and dense alternatives. Through numerical
experiments and theoretical analysis, the proposed method demonstrates strong
performance and exhibits robustness across a wide range of signal **sparsity**
levels and heavy-tailed distributions.


## Quantitative evaluation of brain-inspired vision sensors in high-speed robotic perception

>Authors: Taoyi Wang, Lijian Wang, Yihan Lin, Mingtao Ou, Yuguo Chen, Xinglong Ji, Rong Zhao

>2025-04-27

> http://arxiv.org/abs/2504.19253v1

Perception systems in robotics encounter significant challenges in high-speed
and dynamic conditions when relying on traditional cameras, where motion blur
can compromise spatial feature integrity and task performance. Brain-inspired
vision sensors (BVS) have recently gained attention as an alternative, offering
high temporal resolution with reduced bandwidth and power requirements. Here,
we present the first quantitative evaluation framework for two representative
classes of BVSs in variable-speed robotic sensing, including event-based vision
sensors (EVS) that detect asynchronous temporal contrasts, and the
primitive-based sensor Tianmouc that employs a complementary mechanism to
encode both spatiotemporal changes and intensity. A unified testing protocol is
established, including crosssensor calibrations, standardized testing
platforms, and quality metrics to address differences in data modality. From an
imaging standpoint, we evaluate the effects of sensor non-idealities, such as
motion-induced distortion, on the capture of structural information. For
functional benchmarking, we examine task performance in corner detection and
motion estimation under different rotational speeds. Results indicate that EVS
performs well in highspeed, **sparse** scenarios and in modestly fast, complex
scenes, but exhibits performance limitations in high-speed, cluttered settings
due to pixel-level bandwidth variations and event rate saturation. In
comparison, Tianmouc demonstrates consistent performance across **sparse** and
complex scenarios at various speeds, supported by its global, precise,
high-speed spatiotemporal gradient samplings. These findings offer valuable
insights into the applicationdependent suitability of BVS technologies and
support further advancement in this area.


## AlphaFuse Learn ID Embeddings for Sequential Recommendation in Null Space of Language Embeddings

>Authors: Guoqing Hu, An Zhang, Shuo Liu, Zhibo Cai, Xun Yang, Xiang Wang

>2025-04-27

> http://arxiv.org/abs/2504.19218v2

Recent advancements in sequential recommendation have underscored the
potential of Large Language Models (LLMs) for enhancing item embeddings.
However, existing approaches face three key limitations: 1) the degradation of
the semantic space when high-dimensional language embeddings are mapped to
lower-dimensional ID embeddings, 2) the underutilization of language
embeddings, and 3) the reliance on additional trainable parameters, such as an
adapter, to bridge the gap between the semantic and behavior spaces. In this
paper, we introduce AlphaFuse, a simple but effective language-guided learning
strategy that addresses these challenges by learning ID embeddings within the
null space of language embeddings. Specifically, we decompose the semantic
space of language embeddings via Singular Value Decomposition (SVD),
distinguishing it into a semantic-rich row space and a semantic-**sparse** null
space. Collaborative signals are then injected into the null space, while
preserving the rich semantics of the row space. AlphaFuse prevents degradation
of the semantic space, integrates the retained language embeddings into the
final item embeddings, and eliminates the need for auxiliary trainable modules,
enabling seamless adaptation to any sequential recommendation framework. We
validate the effectiveness and flexibility of AlphaFuse through extensive
experiments on three benchmark datasets, including cold-start user and
long-tail settings, showcasing significant improvements in both discriminative
and diffusion-based generative sequential recommenders. Our codes and datasets
are available at https://github.com/Hugo-Chinn/AlphaFuse.


## Leveraging Modified Ex Situ Tomography Data for Segmentation of In Situ Synchrotron X-Ray Computed Tomography

>Authors: Tristan Manchester, Adam Anders, Julio Spadotto, Hannah Eccleston, William Beavan, Hugues Arcis, Brian J. Connolly

>2025-04-27

> http://arxiv.org/abs/2504.19200v1

In situ synchrotron X-ray computed tomography enables dynamic material
studies, but automated segmentation remains challenging due to complex imaging
artefacts and limited training data. We present a methodology for deep
learning-based segmentation by transforming high-quality ex situ laboratory
data to train models for binary segmentation of in situ synchrotron data,
demonstrated through copper oxide dissolution studies. Using a modified
SegFormer architecture, our approach achieves high segmentation performance on
unseen data while reducing processing time from hours to seconds per 3D
dataset. The method maintains consistent performance over significant
morphological changes during experiments, despite training only on static
specimens. This methodology can be readily applied to diverse materials
systems, accelerating the analysis of time-resolved tomographic data across
scientific disciplines.


## WuNeng Hybrid State with Attention

>Authors: Liu Xiao, Li Zhiyuan, Lin Yueyu

>2025-04-27

> http://arxiv.org/abs/2504.19191v1

The WuNeng architecture introduces a novel approach to enhancing the
expressivity and power of large language models by integrating recurrent neural
network (RNN)-based RW**KV**-7 with advanced attention mechanisms, prioritizing
heightened contextual coherence over reducing **KV** cache size. Building upon the
hybrid-head concept from Hymba, WuNeng augments standard multi-head attention
with additional RW**KV**-7 state-driven heads, rather than replacing existing
heads, to enrich the model's representational capacity. A cross-head
interaction technique fosters dynamic synergy among standard, state-driven, and
newly introduced middle heads, leveraging concatenation, additive modulation,
and gated fusion for robust information integration. Furthermore, a multi-token
state processing mechanism harnesses the continuous RW**KV**-7 state to capture
intricate, sequence-wide dependencies, significantly boosting expressivity.
Remarkably, these enhancements are achieved with minimal additional parameters,
ensuring efficiency while empowering the model to excel in complex reasoning
and sequence generation tasks. WuNeng sets a new standard for balancing
expressivity and computational efficiency in modern neural architectures.


## RadioFormer A Multiple-Granularity Radio Map Estimation Transformer with 1\textpertenthousand Spatial Sampling

>Authors: Zheng Fang, Kangjun Liu, Ke Chen, Qingyu Liu, Jianguo Zhang, Lingyang Song, Yaowei Wang

>2025-04-27

> http://arxiv.org/abs/2504.19161v1

The task of radio map estimation aims to generate a dense representation of
electromagnetic spectrum quantities, such as the received signal strength at
each grid point within a geographic region, based on measurements from a subset
of spatially distributed nodes (represented as pixels). Recently, deep vision
models such as the U-Net have been adapted to radio map estimation, whose
effectiveness can be guaranteed with sufficient spatial observations (typically
0.01% to 1% of pixels) in each map, to model local dependency of observed
signal power. However, such a setting of sufficient measurements can be less
practical in real-world scenarios, where extreme **sparsity** in spatial sampling
can be widely encountered. To address this challenge, we propose RadioFormer, a
novel multiple-granularity transformer designed to handle the constraints posed
by spatial **sparse** observations. Our RadioFormer, through a dual-stream
self-attention (DSA) module, can respectively discover the correlation of
pixel-wise observed signal power and also learn patch-wise buildings'
geometries in a style of multiple granularities, which are integrated into
multi-scale representations of radio maps by a cross stream cross-attention
(CCA) module. Extensive experiments on the public RadioMapSeer dataset
demonstrate that RadioFormer outperforms state-of-the-art methods in radio map
estimation while maintaining the lowest computational cost. Furthermore, the
proposed approach exhibits exceptional generalization capabilities and robust
zero-shot performance, underscoring its potential to advance radio map
estimation in a more practical setting with very limited observation nodes.


## Muyan-TTS A Trainable Text-to-Speech Model Optimized for Podcast Scenarios with a $50K Budget

>Authors: Xin Li, Kaikai Jia, Hao Sun, Jun Dai, Ziyang Jiang

>2025-04-27

> http://arxiv.org/abs/2504.19146v1

Recent advancements in text-to-speech (TTS) models have been driven by the
integration of large language models (LLMs), enhancing semantic comprehension
and improving speech naturalness. However, existing LLM-based TTS models often
lack open-source training code and efficient inference **acceleration** frameworks,
limiting their accessibility and adaptability. Additionally, there is no
publicly available TTS model specifically optimized for podcast scenarios,
which are in high demand for voice interaction applications. To address these
limitations, we introduce Muyan-TTS, an open-source trainable TTS model
designed for podcast applications within a $50,000 budget. Our model is
pre-trained on over 100,000 hours of podcast audio data, enabling zero-shot TTS
synthesis with high-quality voice generation. Furthermore, Muyan-TTS supports
speaker adaptation with dozens of minutes of target speech, making it highly
customizable for individual voices. In addition to open-sourcing the model, we
provide a comprehensive data collection and processing pipeline, a full
training procedure, and an optimized inference framework that accelerates
LLM-based TTS synthesis. Our code and models are available at
https://github.com/MYZY-AI/Muyan-TTS.


## BQSched A Non-intrusive Scheduler for Batch Concurrent Queries via Reinforcement Learning

>Authors: Chenhao Xu, Chunyu Chen, Jinglin Peng, Jiannan Wang, Jun Gao

>2025-04-27

> http://arxiv.org/abs/2504.19142v1

Most large enterprises build predefined data pipelines and execute them
periodically to process operational data using SQL queries for various tasks. A
key issue in minimizing the overall makespan of these pipelines is the
efficient scheduling of concurrent queries within the pipelines. Existing tools
mainly rely on simple heuristic rules due to the difficulty of expressing the
complex features and mutual influences of queries. The latest reinforcement
learning (RL) based methods have the potential to capture these patterns from
feedback, but it is non-trivial to apply them directly due to the large
scheduling space, high sampling cost, and poor sample utilization.
  Motivated by these challenges, we propose BQSched, a non-intrusive Scheduler
for Batch concurrent Queries via reinforcement learning. Specifically, BQSched
designs an attention-based state representation to capture the complex query
patterns, and proposes IQ-PPO, an auxiliary task-enhanced proximal policy
optimization (PPO) algorithm, to fully exploit the rich signals of Individual
Query completion in logs. Based on the RL framework above, BQSched further
introduces three optimization strategies, including adaptive masking to prune
the action space, scheduling gain-based query clustering to deal with large
query sets, and an incremental simulator to reduce sampling cost. To our
knowledge, BQSched is the first non-intrusive batch query scheduler via RL.
Extensive experiments show that BQSched can significantly improve the
efficiency and stability of batch query scheduling, while also achieving
remarkable scalability and adaptability in both data and queries. For example,
across all DBMSs and scales tested, BQSched reduces the overall makespan of
batch queries on TPC-DS benchmark by an average of 34% and 13%, compared with
the commonly used heuristic strategy and the adapted RL-based scheduler,
respectively.


## Efficient Reasoning for LLMs through Speculative Chain-of-Thought

>Authors: Jikai Wang, Juntao Li, Lijun Wu, Min Zhang

>2025-04-27

> http://arxiv.org/abs/2504.19095v1

Large reasoning language models such as OpenAI-o1 and Deepseek-R1 have
recently attracted widespread attention due to their impressive task-solving
abilities. However, the enormous model size and the generation of lengthy
thought chains introduce significant reasoning costs and response latency.
Existing methods for efficient reasoning mainly focus on reducing the number of
model parameters or shortening the chain-of-thought length. In this paper, we
introduce Speculative Chain-of-Thought (SCoT), which reduces reasoning latency
from another perspective by accelerated average reasoning speed through large
and small model collaboration. SCoT conducts thought-level drafting using a
lightweight draft model. Then it selects the best CoT draft and corrects the
error cases with the target model. The proposed thinking behavior alignment
improves the efficiency of drafting and the draft selection strategy maintains
the prediction accuracy for complex problems. Experimental results on GSM8K,
MATH, GaoKao, CollegeMath and Olympiad datasets show that SCoT reduces
reasoning latency by 48\%$\sim$66\% for Deepseek-R1-Distill-Qwen-32B while
achieving near-target-model-level performance. Our code is available at
https://github.com/Jikai0Wang/Speculative_CoT.


## Improved Molecular Generation through Attribute-Driven Integrative Embeddings and GAN Selectivity

>Authors: Nandan Joshi, Erhan Guven

>2025-04-26

> http://arxiv.org/abs/2504.19040v1

The growing demand for molecules with tailored properties in fields such as
drug discovery and chemical engineering has driven advancements in
computational methods for molecular design. Machine learning-based approaches
for de-novo molecular generation have recently garnered significant attention.
This paper introduces a transformer-based vector embedding generator combined
with a modified Generative Adversarial Network (GAN) to generate molecules with
desired properties. The embedding generator utilizes a novel molecular
descriptor, integrating Morgan fingerprints with global molecular attributes,
enabling the transformer to capture local functional groups and broader
molecular characteristics. Modifying the GAN generator loss function ensures
the generation of molecules with specific desired properties. The transformer
achieves a reconversion accuracy of 94% while translating molecular descriptors
back to SMILES strings, validating the utility of the proposed embeddings for
generative tasks. The approach is validated by generating novel odorant
molecules using a labeled dataset of odorant and non-odorant compounds. With
the modified range-loss function, the GAN exclusively generates odorant
molecules. This work underscores the potential of combining novel vector
embeddings with transformers and modified GAN architectures to accelerate the
discovery of tailored molecules, offering a robust tool for diverse molecular
design applications.


## "I Would Have Written My Code Differently'' Beginners Struggle to Understand LLM-Generated Code

>Authors: Yangtian Zi, Luisa Li, Arjun Guha, Carolyn Jane Anderson, Molly Q Feldman

>2025-04-26

> http://arxiv.org/abs/2504.19037v1

Large language models (LLMs) are being increasingly adopted for programming
work. Prior work shows that while LLMs accelerate task completion for
professional programmers, beginning programmers struggle to prompt models
effectively. However, prompting is just half of the code generation process --
when code is generated, it must be read, evaluated, and integrated (or
rejected). How accessible are these tasks for beginning programmers?
  This paper measures how well beginners comprehend LLM-generated code and
explores the challenges students face in judging code correctness. We compare
how well students understand natural language descriptions of functions and
LLM-generated implementations, studying 32 CS1 students on 160 task instances.
Our results show a low per-task success rate of 32.5\%, with indiscriminate
struggles across demographic populations. Key challenges include barriers for
non-native English speakers, unfamiliarity with Python syntax, and automation
bias. Our findings highlight the barrier that code comprehension presents to
beginning programmers seeking to write code with LLMs.


## The Masked Matrix Separation Problem A First Analysis

>Authors: Xuemei Chen, Rongrong Wang

>2025-04-26

> http://arxiv.org/abs/2504.19025v1

Given a known matrix that is the sum of a low rank matrix and a masked **sparse**
matrix, we wish to recover both the low rank component and the **sparse**
component. The **sparse** matrix is masked in the sense that a linear
transformation has been applied on its left. We propose a convex optimization
problem to recover the low rank and **sparse** matrices, which generalizes the
robust PCA framework. We provide incoherence conditions for the success of the
proposed convex optimizaiton problem, adapting to the masked setting. The
``mask'' matrix can be quite general as long as a so-called restricted infinity
norm condition is satisfied. Further analysis on the incoherence condition is
provided and we conclude with promising numerical experiments.


## R-Sparse R-CNN SAR Ship Detection Based on Background-Aware Sparse Learnable Proposals

>Authors: Kamirul Kamirul, Odysseas Pappas, Alin Achim

>2025-04-26

> http://arxiv.org/abs/2504.18959v1

We introduce R-Sparse R-CNN, a novel pipeline for oriented ship detection in
Synthetic Aperture Radar (SAR) images that leverages **sparse** learnable proposals
enriched with background contextual information, termed background-aware
proposals (BAPs). The adoption of **sparse** proposals streamlines the pipeline by
eliminating the need for proposal generators and post-processing for
overlapping predictions. The proposed BAPs enrich object representation by
integrating ship and background features, allowing the model to learn their
contextual relationships for more accurate distinction of ships in complex
environments. To complement BAPs, we propose Dual-Context Pooling (DCP), a
novel strategy that jointly extracts ship and background features in a single
unified operation. This unified design improves efficiency by eliminating
redundant computation inherent in separate pooling. Moreover, by ensuring that
ship and background features are pooled from the same feature map level, DCP
provides aligned features that improve contextual relationship learning.
Finally, as a core component of contextual relationship learning in R-Sparse
R-CNN, we design a dedicated transformer-based Interaction Module. This module
interacts pooled ship and background features with corresponding proposal
features and models their relationships. Experimental results show that
R-Sparse R-CNN delivers outstanding accuracy, surpassing state-of-the-art
models by margins of up to 12.8% and 11.9% on SSDD and RSDD-SAR inshore
datasets, respectively. These results demonstrate the effectiveness and
competitiveness of R-Sparse R-CNN as a robust framework for oriented ship
detection in SAR imagery. The code is available at:
www.github.com/ka-mirul/R-Sparse-R-CNN.


## Revisiting Transformers through the Lens of Low Entropy and Dynamic Sparsity

>Authors: Ruifeng Ren, Yong Liu

>2025-04-26

> http://arxiv.org/abs/2504.18929v1

Compression has been a critical lens to understand the success of
Transformers. In the past, we have typically taken the target distribution as a
criterion to evaluate a model's compression performance. Nevertheless,it often
remains challenging to precisely assess how well the model achieves compression
and to compare the information content of the learned distribution with that of
the target distribution during compression,as the target distribution is
typically unknown and entropy computation often incurs exponential cost. In
this work, we explore these issues under a controlled experimental setup. We
find that Transformers exhibit a unique inductive bias in data compression:
beyond approaching the target distribution, they tend to favor learning
lower-entropy distributions, with this tendency becoming more pronounced as the
model size increases. This preference prevents Transformers from perfectly
aligning with the target distribution, instead further compressing its
information content. Furthermore, we show that the FFN module plays a critical
role in driving this bias. In addition, while models remove informational
redundancy from data during compression, they also exhibit redundancy within
their parameters, which enables compression and can be characterized through
dynamic **sparsity**. However, the dynamic **sparsity** patterns in Transformers,
particularly in attention and FFN modules, demand further exploration. As for
this, we show that larger Transformers show stronger preferences for bypassing
attention computations via residual connections and have lower proportion of
active neurons. Interestingly, we also find that training instability in larger
models strongly correlates with sudden increases in dead neurons. Our work
contributes to a deeper understanding of Transformers from the lens of entropy
and dynamic **sparsity**.


## Action Flow Matching for Continual Robot Learning

>Authors: Alejandro Murillo-Gonzalez, Lantao Liu

>2025-04-25

> http://arxiv.org/abs/2504.18471v1

Continual learning in robotics seeks systems that can constantly adapt to
changing environments and tasks, mirroring human adaptability. A key challenge
is refining dynamics models, essential for planning and control, while
addressing issues such as safe adaptation, catastrophic forgetting, outlier
management, data efficiency, and balancing exploration with exploitation -- all
within task and onboard resource constraints. Towards this goal, we introduce a
generative framework leveraging flow matching for online robot dynamics model
alignment. Rather than executing actions based on a misaligned model, our
approach refines planned actions to better match with those the robot would
take if its model was well aligned. We find that by transforming the actions
themselves rather than exploring with a misaligned model -- as is traditionally
done -- the robot collects informative data more efficiently, thereby
accelerating learning. Moreover, we validate that the method can handle an
evolving and possibly imperfect model while reducing, if desired, the
dependency on replay buffers or legacy model snapshots. We validate our
approach using two platforms: an unmanned ground vehicle and a quadrotor. The
results highlight the method's adaptability and efficiency, with a record
34.2\% higher task success rate, demonstrating its potential towards enabling
continual robot learning. Code:
https://github.com/AlejandroMllo/action_flow_matching.


## Efficiency, Expressivity, and Extensibility in a Close-to-Metal NPU Programming Interface

>Authors: Erika Hunhoff, Joseph Melber, Kristof Denolf, Andra Bisca, Samuel Bayliss, Stephen Neuendorffer, Jeff Fifield, Jack Lo, Pranathi Vasireddy, Phil James-Roxby, Eric Keller

>2025-04-25

> http://arxiv.org/abs/2504.18430v1

Accelerators such as neural processing units (NPUs) deliver an enticing
balance of performance and efficiency compared to general purpose compute
architectures. However, effectively leveraging accelerator capabilities is not
always simple: low-level programming toolkits may require substantial developer
effort while high-level programming toolkits may abstract critical optimization
features.
  This work aims to increase efficiency of designers using IRON, a toolkit for
close-to-metal NPU performance engineers. We provide an updated programmer
interface to IRON containing new and refined programming constructs. The new
interface includes extensible features for placement and data transformation.
These contributions are evaluated in terms of 1) efficiency, with analysis
showing ~26% average reduction in lines of code and decreases in Halstead
metrics for a variety of designs; 2) expressivity, demonstrating the new
interface supports the wide range of features and patterns already supported by
IRON; and 3) extensibility, illustrating the new tooling for placement and
tiling can be extended to accommodate common use-cases.


## BitNet v2 Native 4-bit Activations with Hadamard Transformation for 1-bit LLMs

>Authors: Hongyu Wang, Shuming Ma, Furu Wei

>2025-04-25

> http://arxiv.org/abs/2504.18415v1

Efficient deployment of 1-bit Large Language Models (LLMs) is hindered by
activation outliers, which complicate **quantization** to low bit-widths. We
introduce BitNet v2, a novel framework enabling native 4-bit activation
**quantization** for 1-bit LLMs. To tackle outliers in attention and feed-forward
network activations, we propose H-BitLinear, a module applying an online
Hadamard transformation prior to activation **quantization**. This transformation
smooths sharp activation distributions into more Gaussian-like forms, suitable
for **low-bit** representation. Experiments show BitNet v2 trained from scratch
with 8-bit activations matches BitNet b1.58 performance. Crucially, BitNet v2
achieves minimal performance degradation when trained with native 4-bit
activations, significantly reducing memory footprint and computational cost for
batched inference.


## A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1

>Authors: Mingda Zhang, Jianglong Qin

>2025-04-25

> http://arxiv.org/abs/2505.00025v1

In recent years, despite foundation models like DeepSeek-R1 and ChatGPT
demonstrating significant capabilities in general tasks, professional knowledge
barriers, computational resource requirements, and deployment environment
limitations have severely hindered their application in actual medical
scenarios. Addressing these challenges, this paper proposes an efficient
lightweight medical vertical large language model architecture method,
systematically solving the lightweight problem of medical large models from
three dimensions: knowledge acquisition, model compression, and computational
optimization. At the knowledge acquisition level, a knowledge transfer pipeline
is designed from the fine-tuned DeepSeek-R1-Distill-70B teacher model to the
DeepSeek-R1-Distill-7B student model, and Low-Rank Adaptation (LoRA) technology
is adopted to precisely adjust key attention layers. At the model compression
level, compression techniques including 4-bit weight **quantization** are
implemented while preserving the core representation ability for medical
reasoning. At the computational optimization level, inference optimization
techniques such as Flash Attention **acceleration** and continuous batching are
integrated, and a professional prompt template system is constructed to adapt
to different types of medical problems. Experimental results on medical
question-answering datasets show that the method proposed in this paper
maintains professional accuracy while reducing memory consumption by 64.7\% and
inference latency by 12.4\%, providing an effective solution for the
application of medical large models in resource-constrained environments such
as edge computing devices.


## Large Language Models to Accelerate Organic Chemistry Synthesis

>Authors: Yu Zhang, Yang Han, Shuai Chen, Ruijie Yu, Xin Zhao, Xianbin Liu, Kaipeng Zeng, Mengdi Yu, Jidong Tian, Feng Zhu, Xiaokang Yang, Yaohui Jin, Yanyan Xu

>2025-04-25

> http://arxiv.org/abs/2504.18340v1

Chemical synthesis, as a foundational methodology in the creation of
transformative molecules, exerts substantial influence across diverse sectors
from life sciences to materials and energy. Current chemical synthesis
practices emphasize laborious and costly trial-and-error workflows,
underscoring the urgent need for advanced AI assistants. Nowadays, large
language models (LLMs), typified by GPT-4, have been introduced as an efficient
tool to facilitate scientific research. Here, we present Chemma, a fully
fine-tuned LLM with 1.28 million pairs of Q&A about reactions, as an assistant
to accelerate organic chemistry synthesis. Chemma surpasses the best-known
results in multiple chemical tasks, e.g., single-step retrosynthesis and yield
prediction, which highlights the potential of general AI for organic chemistry.
Via predicting yields across the experimental reaction space, Chemma
significantly improves the reaction exploration capability of Bayesian
optimization. More importantly, integrated in an active learning framework,
Chemma exhibits advanced potential for autonomous experimental exploration and
optimization in open reaction spaces. For an unreported Suzuki-Miyaura
cross-coupling reaction of cyclic aminoboronates and aryl halides for the
synthesis of $\alpha$-Aryl N-heterocycles, the human-AI collaboration
successfully explored suitable ligand and solvent (1,4-dioxane) within only 15
runs, achieving an isolated yield of 67%. These results reveal that, without
quantum-chemical calculations, Chemma can comprehend and extract chemical
insights from reaction data, in a manner akin to human experts. This work opens
avenues for accelerating organic chemistry synthesis with adapted large
language models.


## SSD-Poser Avatar Pose Estimation with State Space Duality from Sparse Observations

>Authors: Shuting Zhao, Linxin Bai, Liangjing Shao, Ye Zhang, Xinrong Chen

>2025-04-25

> http://arxiv.org/abs/2504.18332v1

The growing applications of AR/VR increase the demand for real-time full-body
pose estimation from Head-Mounted Displays (HMDs). Although HMDs provide joint
signals from the head and hands, reconstructing a full-body pose remains
challenging due to the unconstrained lower body. Recent advancements often rely
on conventional neural networks and generative models to improve performance in
this task, such as Transformers and diffusion models. However, these approaches
struggle to strike a balance between achieving precise pose reconstruction and
maintaining fast inference speed. To overcome these challenges, a lightweight
and efficient model, SSD-Poser, is designed for robust full-body motion
estimation from **sparse** observations. SSD-Poser incorporates a well-designed
hybrid encoder, State Space Attention Encoders, to adapt the state space
duality to complex motion poses and enable real-time realistic pose
reconstruction. Moreover, a Frequency-Aware Decoder is introduced to mitigate
jitter caused by variable-frequency motion signals, remarkably enhancing the
motion smoothness. Comprehensive experiments on the AMASS dataset demonstrate
that SSD-Poser achieves exceptional accuracy and computational efficiency,
showing outstanding inference efficiency compared to state-of-the-art methods.


## Ergodic theorems for bilinear averages, Roth's Theorem and Corners along fractional powers

>Authors: Leonidas Daskalakis

>2025-04-25

> http://arxiv.org/abs/2504.18307v1

We prove that for every $c\in(1,23/22)$, every probability space
$(X,\mathcal{B},\mu)$ equipped with two commuting measure-preserving
transformations $T,S\colon X\to X$ and every $f,g\in L^{\infty}_{\mu}(X)$ we
have that the $L^2_{\mu}(X)$-limit \[
\lim_{N\to\infty}\frac{1}{N}\sum_{n=1}^Nf(T^{\lfloor n^c\rfloor}x)g(S^{\lfloor
n^c\rfloor}x) \] equals the $L^2_{\mu}(X)$-limit
$\lim_{N\to\infty}\frac{1}{N}\sum_{n=1}^Nf(T^{n}x)g(S^{n}x)$. The approach is
based on the author's recently developed technique which may be thought of as a
change of variables. We employ it to establish several new results along
fractional powers including a Roth-type result for patterns of the form
$x,x+\lfloor y^c \rfloor,x+2\lfloor y^c \rfloor$ as well as its ''corner''
counterpart. The quantitative nature of the former result allows us to recover
the analogous one in the primes. Our considerations give partial answers to
Problem 29 and Problem 30 from Frantzikinakis' open problems survey on multiple
ergodic averages. Notably, we cover more general **sparse** orbits $(\lfloor
h(n)\rfloor)_{n\in\mathbb{N}}$, where $h$ belongs to the class of the so-called
$c$-regularly varying functions, addressing for example even the orbit
$(\lfloor n\log n\rfloor)_{n\in\mathbb{N}}$.


## Sharp decay estimates and numerical analysis for weakly coupled systems of two subdiffusion equations

>Authors: Zhiyuan Li, Yikan Liu, Kazuma Wada

>2025-04-25

> http://arxiv.org/abs/2504.18295v1

This paper investigates the initial-boundary value problem for weakly coupled
systems of time-fractional subdiffusion equations with spatially and temporally
varying coupling coefficients. By combining the energy method with the
coercivity of fractional derivatives, we convert the original partial
differential equations into a coupled ordinary differential system. Through
Laplace transform and maximum principle arguments, we reveal a dichotomy in
decay behavior: When the highest fractional order is less than one, solutions
exhibit sublinear decay, whereas systems with the highest order equal to one
demonstrate a distinct superlinear decay pattern. This phenomenon fundamentally
distinguishes coupled systems from single fractional diffusion equations, where
such accelerated superlinear decay never occurs. Numerical experiments
employing finite difference methods and implicit discretization schemes
validate the theoretical findings.


## Leveraging Decoder Architectures for Learned Sparse Retrieval

>Authors: Jingfen Qiao, Thong Nguyen, Evangelos Kanoulas, Andrew Yates

>2025-04-25

> http://arxiv.org/abs/2504.18151v1

Learned Sparse Retrieval (LSR) has traditionally focused on small-scale
encoder-only transformer architectures. With the advent of large-scale
pre-trained language models, their capability to generate **sparse**
representations for retrieval tasks across different transformer-based
architectures, including encoder-only, decoder-only, and encoder-decoder
models, remains largely unexplored. This study investigates the effectiveness
of LSR across these architectures, exploring various **sparse** representation
heads and model scales. Our results highlight the limitations of using large
language models to create effective **sparse** representations in zero-shot
settings, identifying challenges such as inappropriate term expansions and
reduced performance due to the lack of expansion. We find that the
encoder-decoder architecture with multi-tokens decoding approach achieves the
best performance among the three backbones. While the decoder-only model
performs worse than the encoder-only model, it demonstrates the potential to
outperform when scaled to a high number of parameters.


## Think, Prune, Train, Improve Scaling Reasoning without Scaling Models

>Authors: Caia Costello, Simon Guo, Anna Goldie, Azalia Mirhoseini

>2025-04-25

> http://arxiv.org/abs/2504.18116v1

Large language models (LLMs) have demonstrated strong capabilities in
programming and mathematical reasoning tasks, but are constrained by limited
high-quality training data. Synthetic data can be leveraged to enhance
fine-tuning outcomes, but several factors influence this process, including
model size, synthetic data volume, **pruning** strategy, and number of fine-tuning
rounds. We explore these axes and investigate which conditions enable model
self-improvement. We introduce the Think, Prune, Train process, a scalable
framework that iteratively fine-tunes models on their own reasoning traces,
using ground-truth **pruning** to ensure high-quality training data. This approach
yields improved performance: on GSM8K, Gemma2-2B achieves a Pass@1 of 57.6%
(from 41.9%), Gemma2-9B reaches 82%, matching LLaMA-3.1-70B, and LLaMA-3.1-70B
attains 91%, even surpassing GPT-4o, demonstrating the effectiveness of
self-generated reasoning and systematic data selection for improving LLM
capabilities.


## Study on Real-Time Road Surface Reconstruction Using Stereo Vision

>Authors: Deepak Ghimire, Byoungjun Kim, Donghoon Kim, SungHwan Jeong

>2025-04-25

> http://arxiv.org/abs/2504.18112v1

Road surface reconstruction plays a crucial role in autonomous driving,
providing essential information for safe and smooth navigation. This paper
enhances the RoadBEV [1] framework for real-time inference on edge devices by
optimizing both efficiency and accuracy. To achieve this, we proposed to apply
Isomorphic Global Structured Pruning to the stereo feature extraction backbone,
reducing network complexity while maintaining performance. Additionally, the
head network is redesigned with an optimized hourglass structure, dynamic
attention heads, reduced feature channels, mixed precision inference, and
efficient probability volume computation. Our approach improves inference speed
while achieving lower reconstruction error, making it well-suited for real-time
road surface reconstruction in autonomous driving.


## Disentangle Identity, Cooperate Emotion Correlation-Aware Emotional Talking Portrait Generation

>Authors: Weipeng Tan, Chuming Lin, Chengming Xu, FeiFan Xu, Xiaobin Hu, Xiaozhong Ji, Junwei Zhu, Chengjie Wang, Yanwei Fu

>2025-04-25

> http://arxiv.org/abs/2504.18087v1

Recent advances in Talking Head Generation (THG) have achieved impressive lip
synchronization and visual quality through diffusion models; yet existing
methods struggle to generate emotionally expressive portraits while preserving
speaker identity. We identify three critical limitations in current emotional
talking head generation: insufficient utilization of audio's inherent emotional
cues, identity leakage in emotion representations, and isolated learning of
emotion correlations. To address these challenges, we propose a novel framework
dubbed as DICE-Talk, following the idea of disentangling identity with emotion,
and then cooperating emotions with similar characteristics. First, we develop a
disentangled emotion embedder that jointly models audio-visual emotional cues
through cross-modal attention, representing emotions as identity-agnostic
Gaussian distributions. Second, we introduce a correlation-enhanced emotion
conditioning module with learnable Emotion Banks that explicitly capture
inter-emotion relationships through vector **quantization** and attention-based
feature aggregation. Third, we design an emotion discrimination objective that
enforces affective consistency during the diffusion process through
latent-space classification. Extensive experiments on MEAD and HDTF datasets
demonstrate our method's superiority, outperforming state-of-the-art approaches
in emotion accuracy while maintaining competitive lip-sync performance.
Qualitative results and user studies further confirm our method's ability to
generate identity-preserving portraits with rich, correlated emotional
expressions that naturally adapt to unseen identities.


## Back to Fundamentals Low-Level Visual Features Guided Progressive Token Pruning

>Authors: Yuanbing Ouyang, Yizhuo Liang, Qingpeng Li, Xinfei Guo, Yiming Luo, Di Wu, Hao Wang, Yushan Pan

>2025-04-25

> http://arxiv.org/abs/2504.17996v1

Vision Transformers (ViTs) excel in semantic segmentation but demand
significant computation, posing challenges for deployment on
resource-constrained devices. Existing token **pruning** methods often overlook
fundamental visual data characteristics. This study introduces 'LVTP', a
progressive token **pruning** framework guided by multi-scale Tsallis entropy and
low-level visual features with twice clustering. It integrates high-level
semantics and basic visual attributes for precise segmentation. A novel dynamic
scoring mechanism using multi-scale Tsallis entropy weighting overcomes
limitations of traditional single-parameter entropy. The framework also
incorporates low-level feature analysis to preserve critical edge information
while optimizing computational cost. As a plug-and-play module, it requires no
architectural changes or additional training. Evaluations across multiple
datasets show 20%-45% computational reductions with negligible performance
loss, outperforming existing methods in balancing cost and accuracy, especially
in complex edge regions.

