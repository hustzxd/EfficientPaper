# 2025-02-07

# Table of Contents
* [Adapt-Pruner Adaptive Structural Pruning for Efficient Small Language Model Training](#Adapt-Pruner-Adaptive-Structural-Pruning-for-Efficient-Small-Language-Model-Training)
* [Intent Representation Learning with Large Language Model for Recommendation](#Intent-Representation-Learning-with-Large-Language-Model-for-Recommendation)
* [Single Antenna Terahertz Sensing using Preconfigured Metasurfaces](#Single-Antenna-Terahertz-Sensing-using-Preconfigured-Metasurfaces)
* [GARAD-SLAM 3D GAussian splatting for Real-time Anti Dynamic SLAM](#GARAD-SLAM-3D-GAussian-splatting-for-Real-time-Anti-Dynamic-SLAM)
* [Analyze Feature Flow to Enhance Interpretation and Steering in Language Models](#Analyze-Feature-Flow-to-Enhance-Interpretation-and-Steering-in-Language-Models)
* [Matching Criterion for Identifiability in Sparse Factor Analysis](#Matching-Criterion-for-Identifiability-in-Sparse-Factor-Analysis)
* [Every Angle Is Worth A Second Glance Mining Kinematic Skeletal Structures from Multi-view Joint Cloud](#Every-Angle-Is-Worth-A-Second-Glance-Mining-Kinematic-Skeletal-Structures-from-Multi-view-Joint-Cloud)
* [SensorChat Answering Qualitative and Quantitative Questions during Long-Term Multimodal Sensor Interactions](#SensorChat-Answering-Qualitative-and-Quantitative-Questions-during-Long-Term-Multimodal-Sensor-Interactions)
* [Speculative Prefill Turbocharging TTFT with Lightweight and Training-Free Token Importance Estimation](#Speculative-Prefill-Turbocharging-TTFT-with-Lightweight-and-Training-Free-Token-Importance-Estimation)


## Adapt-Pruner Adaptive Structural Pruning for Efficient Small Language Model Training

>Authors: Boyao Wang, Rui Pan, Shizhe Diao, Xingyuan Pan, Jipeng Zhang, Renjie Pi, Tong Zhang

>2025-02-05

> http://arxiv.org/abs/2502.03460v1

Small language models (SLMs) have attracted considerable attention from both
academia and industry due to their broad range of applications in edge devices.
To obtain SLMs with strong performance, conventional approaches either
pre-train the models from scratch, which incurs substantial computational
costs, or compress/prune existing large language models (LLMs), which results
in performance drops and falls short in comparison to pre-training. In this
paper, we investigate the family of **acceleration** methods that involve both
structured **pruning** and model training. We found 1) layer-wise adaptive **pruning**
(Adapt-Pruner) is extremely effective in LLMs and yields significant
improvements over existing **pruning** techniques, 2) adaptive **pruning** equipped
with further training leads to models comparable to those pre-training from
scratch, 3) incremental **pruning** brings non-trivial performance gain by
interleaving **pruning** with training and only removing a small portion of neurons
($\sim$5%) at a time. Experimental results on LLaMA-3.1-8B demonstrate that
Adapt-Pruner outperforms conventional **pruning** methods, such as LLM-Pruner,
FLAP, and SliceGPT, by an average of 1%-7% in accuracy on commonsense
benchmarks. Additionally, Adapt-Pruner restores the performance of
MobileLLM-125M to 600M on the MMLU benchmark with 200$\times$ fewer tokens via
**pruning** from its larger counterparts, and discovers a new 1B model that
surpasses LLaMA-3.2-1B in multiple benchmarks.


## Intent Representation Learning with Large Language Model for Recommendation

>Authors: Yu Wang, Lei Sang, Yi Zhang, Yiwen Zhang

>2025-02-05

> http://arxiv.org/abs/2502.03307v1

Intent-based recommender systems have garnered significant attention for
uncovering latent fine-grained preferences. Intents, as underlying factors of
interactions, are crucial for improving recommendation interpretability. Most
methods define intents as learnable parameters updated alongside interactions.
However, existing frameworks often overlook textual information (e.g., user
reviews, item descriptions), which is crucial for alleviating the **sparsity** of
interaction intents. Exploring these multimodal intents, especially the
inherent differences in representation spaces, poses two key challenges: i) How
to align multimodal intents and effectively mitigate noise issues; ii) How to
extract and match latent key intents across modalities. To tackle these
challenges, we propose a model-agnostic framework, Intent Representation
Learning with Large Language Model (IRLLRec), which leverages large language
models (LLMs) to construct multimodal intents and enhance recommendations.
Specifically, IRLLRec employs a dual-tower architecture to learn multimodal
intent representations. Next, we propose pairwise and translation alignment to
eliminate inter-modal differences and enhance robustness against noisy input
features. Finally, to better match textual and interaction-based intents, we
employ momentum distillation to perform teacher-student learning on fused
intent representations. Empirical evaluations on three datasets show that our
IRLLRec framework outperforms baselines. The implementation is available at
https://github.com/wangyu0627/IRLLRec.


## Single Antenna Terahertz Sensing using Preconfigured Metasurfaces

>Authors: Furkan Ilgac, Aydin Sezgin

>2025-02-05

> http://arxiv.org/abs/2502.03291v1

The development of mobile terahertz (THz) sensing and localization with
minimal infrastructure has garnered significant attention due to its
substantial practical implications. Single-antenna radar systems are a favored
choice for mobile platforms, as they offer notable advantages in terms of cost,
weight, and simplicity. However, these systems face a critical limitation: the
inability to extract angular information using a single antenna, which
consequently prevents the achievement of complete localization. This paper
proposes an angular estimation method for a single-antenna radar augmented with
a pair of preconfigured metasurfaces. The metasurface pair is used for creating
an interference pattern in the scene, which depends on the target angles and
operating frequency. Moreover, the beam squint effects caused by the wide
frequency range in the THz band provides suitable conditions for using **sparse**
reconstruction techniques to obtain angular estimates. We utilize these
properties to perform angular estimation with a single antenna. The simulation
results show that with this method it is possible to perform fast and accurate
multi-target estimation for a broad operating range.


## GARAD-SLAM 3D GAussian splatting for Real-time Anti Dynamic SLAM

>Authors: Mingrui Li, Weijian Chen, Na Cheng, Jingyuan Xu, Dong Li, Hongyu Wang

>2025-02-05

> http://arxiv.org/abs/2502.03228v1

The 3D Gaussian Splatting (3DGS)-based SLAM system has garnered widespread
attention due to its excellent performance in real-time high-fidelity
rendering. However, in real-world environments with dynamic objects, existing
3DGS-based SLAM systems often face mapping errors and tracking drift issues. To
address these problems, we propose GARAD-SLAM, a real-time 3DGS-based SLAM
system tailored for dynamic scenes. In terms of tracking, unlike traditional
methods, we directly perform dynamic segmentation on Gaussians and map them
back to the front-end to obtain dynamic point labels through a Gaussian pyramid
network, achieving precise dynamic removal and robust tracking. For mapping, we
impose rendering penalties on dynamically labeled Gaussians, which are updated
through the network, to avoid irreversible erroneous removal caused by simple
**pruning**. Our results on real-world datasets demonstrate that our method is
competitive in tracking compared to baseline methods, generating fewer
artifacts and higher-quality reconstructions in rendering.


## Analyze Feature Flow to Enhance Interpretation and Steering in Language Models

>Authors: Daniil Laptev, Nikita Balagansky, Yaroslav Aksenov, Daniil Gavrilov

>2025-02-05

> http://arxiv.org/abs/2502.03032v2

We introduce a new approach to systematically map features discovered by
**sparse** autoencoder across consecutive layers of large language models,
extending earlier work that examined inter-layer feature links. By using a
data-free cosine similarity technique, we trace how specific features persist,
transform, or first appear at each stage. This method yields granular flow
graphs of feature evolution, enabling fine-grained interpretability and
mechanistic insights into model computations. Crucially, we demonstrate how
these cross-layer feature maps facilitate direct steering of model behavior by
amplifying or suppressing chosen features, achieving targeted thematic control
in text generation. Together, our findings highlight the utility of a causal,
cross-layer interpretability framework that not only clarifies how features
develop through forward passes but also provides new means for transparent
manipulation of large language models.


## Matching Criterion for Identifiability in Sparse Factor Analysis

>Authors: Nils Sturma, Miriam Kranzlmueller, Irem Portakal, Mathias Drton

>2025-02-05

> http://arxiv.org/abs/2502.02986v1

Factor analysis models explain dependence among observed variables by a
smaller number of unobserved factors. A main challenge in confirmatory factor
analysis is determining whether the factor loading matrix is identifiable from
the observed covariance matrix. The factor loading matrix captures the linear
effects of the factors and, if unrestricted, can only be identified up to an
orthogonal transformation of the factors. However, in many applications the
factor loadings exhibit an interesting **sparsity** pattern that may lead to
identifiability up to column signs. We study this phenomenon by connecting
**sparse** factor models to bipartite graphs and providing sufficient graphical
conditions for identifiability of the factor loading matrix up to column signs.
In contrast to previous work, our main contribution, the matching criterion,
exploits **sparsity** by operating locally on the graph structure, thereby
improving existing conditions. Our criterion is efficiently decidable in time
that is polynomial in the size of the graph, when restricting the search steps
to sets of bounded size.


## Every Angle Is Worth A Second Glance Mining Kinematic Skeletal Structures from Multi-view Joint Cloud

>Authors: Junkun Jiang, Jie Chen, Ho Yin Au, Mingyuan Chen, Wei Xue, Yike Guo

>2025-02-05

> http://arxiv.org/abs/2502.02936v1

Multi-person motion capture over **sparse** angular observations is a challenging
problem under interference from both self- and mutual-occlusions. Existing
works produce accurate 2D joint detection, however, when these are triangulated
and lifted into 3D, available solutions all struggle in selecting the most
accurate candidates and associating them to the correct joint type and target
identity. As such, in order to fully utilize all accurate 2D joint location
information, we propose to independently triangulate between all same-typed 2D
joints from all camera views regardless of their target ID, forming the Joint
Cloud. Joint Cloud consist of both valid joints lifted from the same joint type
and target ID, as well as falsely constructed ones that are from different 2D
sources. These redundant and inaccurate candidates are processed over the
proposed Joint Cloud Selection and Aggregation Transformer (JCSAT) involving
three cascaded encoders which deeply explore the trajectile, skeletal
structural, and view-dependent correlations among all 3D point candidates in
the cross-embedding space. An Optimal Token Attention Path (OTAP) module is
proposed which subsequently selects and aggregates informative features from
these redundant observations for the final prediction of human motion. To
demonstrate the effectiveness of JCSAT, we build and publish a new multi-person
motion capture dataset BUMocap-X with complex interactions and severe
occlusions. Comprehensive experiments over the newly presented as well as
benchmark datasets validate the effectiveness of the proposed framework, which
outperforms all existing state-of-the-art methods, especially under challenging
occlusion scenarios.


## SensorChat Answering Qualitative and Quantitative Questions during Long-Term Multimodal Sensor Interactions

>Authors: Xiaofan Yu, Lanxiang Hu, Benjamin Reichman, Dylan Chu, Rushil Chandrupatla, Xiyuan Zhang, Larry Heck, Tajana Rosing

>2025-02-05

> http://arxiv.org/abs/2502.02883v1

Natural language interaction with sensing systems is crucial for enabling all
users to comprehend sensor data and its impact on their everyday lives.
However, existing systems, which typically operate in a Question Answering (QA)
manner, are significantly limited in terms of the duration and complexity of
sensor data they can handle. In this work, we introduce SensorChat, the first
end-to-end QA system designed for long-term sensor monitoring with multimodal
and high-dimensional data including time series. SensorChat effectively answers
both qualitative (requiring high-level reasoning) and quantitative (requiring
accurate responses derived from sensor data) questions in real-world scenarios.
To achieve this, SensorChat uses an innovative three-stage pipeline that
includes question decomposition, sensor data query, and answer assembly. The
first and third stages leverage Large Language Models (LLMs) for intuitive
human interactions and to guide the sensor data query process. Unlike existing
multimodal LLMs, SensorChat incorporates an explicit query stage to precisely
extract factual information from long-duration sensor data. We implement
SensorChat and demonstrate its capability for real-time interactions on a cloud
server while also being able to run entirely on edge platforms after
**quantization**. Comprehensive QA evaluations show that SensorChat achieves up to
26% higher answer accuracy than state-of-the-art systems on quantitative
questions. Additionally, a user study with eight volunteers highlights
SensorChat's effectiveness in handling qualitative and open-ended questions.


## Speculative Prefill Turbocharging TTFT with Lightweight and Training-Free Token Importance Estimation

>Authors: Jingyu Liu, Beidi Chen, Ce Zhang

>2025-02-05

> http://arxiv.org/abs/2502.02789v1

Improving time-to-first-token (TTFT) is an essentially important objective in
modern large language model (LLM) inference engines. Because optimizing TTFT
directly results in higher maximal QPS and meets the requirements of many
critical applications. However, boosting TTFT is notoriously challenging since
it is purely compute-bounded and the performance bottleneck shifts from the
self-attention to the MLP part. We present SpecPrefill, a training free
framework that accelerates the inference TTFT for both long and medium context
queries based on the following insight: LLMs are generalized enough to still
preserve the quality given only a carefully chosen subset of prompt tokens. At
its core, SpecPrefill leverages a lightweight model to speculate locally
important tokens based on the context. These tokens, along with the necessary
positional information, are then sent to the main model for processing. We
evaluate SpecPrefill with a diverse set of tasks, followed by a comprehensive
benchmarking of performance improvement both in a real end-to-end setting and
ablation studies. SpecPrefill manages to serve Llama-3.1-405B-Instruct-FP8 with
up to $7\times$ maximal end-to-end QPS on real downstream tasks and
$7.66\times$ TTFT improvement during benchmarking.

