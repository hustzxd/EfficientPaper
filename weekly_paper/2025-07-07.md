# 2025-07-07

# Table of Contents
* [Less is Enough Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching](#Less-is-Enough-Training-Free-Video-Diffusion-Acceleration-via-Runtime-Adaptive-Caching)
* [AREE-Based Decoupled Design of Hybrid Beamformers in mmWave XL-MIMO Systems](#AREE-Based-Decoupled-Design-of-Hybrid-Beamformers-in-mmWave-XL-MIMO-Systems)
* [Time-Masked Transformers with Lightweight Test-Time Adaptation for Neural Speech Decoding](#Time-Masked-Transformers-with-Lightweight-Test-Time-Adaptation-for-Neural-Speech-Decoding)
* [Bourbaki Self-Generated and Goal-Conditioned MDPs for Theorem Proving](#Bourbaki-Self-Generated-and-Goal-Conditioned-MDPs-for-Theorem-Proving)
* [Moments, Time-Inversion and Source Identification for the Heat Equation](#Moments,-Time-Inversion-and-Source-Identification-for-the-Heat-Equation)
* [FlowSpec Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference](#FlowSpec-Continuous-Pipelined-Speculative-Decoding-for-Efficient-Distributed-LLM-Inference)
* [MedFormer Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention](#MedFormer-Hierarchical-Medical-Vision-Transformer-with-Content-Aware-Dual-Sparse-Selection-Attention)
* [TABNet A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation](#TABNet-A-Triplet-Augmentation-Self-Recovery-Framework-with-Boundary-Aware-Pseudo-Labels-for-Medical-Image-Segmentation)
* [Split-Merge Revisited A Scalable Approach to Generalized Eigenvalue Problems](#Split-Merge-Revisited-A-Scalable-Approach-to-Generalized-Eigenvalue-Problems)
* [Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection](#Efficient-Code-LLM-Training-via-Distribution-Consistent-and-Diversity-Aware-Data-Selection)
* [Holistic Tokenizer for Autoregressive Image Generation](#Holistic-Tokenizer-for-Autoregressive-Image-Generation)
* [LMPNet for Weakly-supervised Keypoint Discovery](#LMPNet-for-Weakly-supervised-Keypoint-Discovery)
* [A scalable and programmable optical neural network in a time-synthetic dimension](#A-scalable-and-programmable-optical-neural-network-in-a-time-synthetic-dimension)
* [Content filtering methods for music recommendation A review](#Content-filtering-methods-for-music-recommendation-A-review)
* [High-Fidelity Differential-information Driven Binary Vision Transformer](#High-Fidelity-Differential-information-Driven-Binary-Vision-Transformer)
* [High-Layer Attention Pruning with Rescaling](#High-Layer-Attention-Pruning-with-Rescaling)
* [Eka-Eval  A Comprehensive Evaluation Framework for Large Language Models in Indian Languages](#Eka-Eval--A-Comprehensive-Evaluation-Framework-for-Large-Language-Models-in-Indian-Languages)
* [Topological Braiding of Bloch Eigenmodes Protected by Non-Abelian Quaternion Invariants](#Topological-Braiding-of-Bloch-Eigenmodes-Protected-by-Non-Abelian-Quaternion-Invariants)
* [BranchNet A Neuro-Symbolic Learning Framework for Structured Multi-Class Classification](#BranchNet-A-Neuro-Symbolic-Learning-Framework-for-Structured-Multi-Class-Classification)
* [Rethinking Discrete Tokens Treating Them as Conditions for Continuous Autoregressive Image Synthesis](#Rethinking-Discrete-Tokens-Treating-Them-as-Conditions-for-Continuous-Autoregressive-Image-Synthesis)
* [High dimensional convergence rates for sparse precision estimators for matrix-variate data](#High-dimensional-convergence-rates-for-sparse-precision-estimators-for-matrix-variate-data)
* [Gold after Randomized Sand Model-X Split Knockoffs for Controlled Transformation Selection](#Gold-after-Randomized-Sand-Model-X-Split-Knockoffs-for-Controlled-Transformation-Selection)
* [SPoT Subpixel Placement of Tokens in Vision Transformers](#SPoT-Subpixel-Placement-of-Tokens-in-Vision-Transformers)
* [GradMetaNet An Equivariant Architecture for Learning on Gradients](#GradMetaNet-An-Equivariant-Architecture-for-Learning-on-Gradients)
* [Exploring Classical Piano Performance Generation with Expressive Music Variational AutoEncoder](#Exploring-Classical-Piano-Performance-Generation-with-Expressive-Music-Variational-AutoEncoder)
* [SafePTR Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism](#SafePTR-Token-Level-Jailbreak-Defense-in-Multimodal-LLMs-via-Prune-then-Restore-Mechanism)
* [Multi-Revolution Low-Thrust Trajectory Optimization With Very Sparse Mesh Pseudospectral Method](#Multi-Revolution-Low-Thrust-Trajectory-Optimization-With-Very-Sparse-Mesh-Pseudospectral-Method)
* [LogitSpec Accelerating Retrieval-based Speculative Decoding via Next Next Token Speculation](#LogitSpec-Accelerating-Retrieval-based-Speculative-Decoding-via-Next-Next-Token-Speculation)
* [Clinical NLP with Attention-Based Deep Learning for Multi-Disease Prediction](#Clinical-NLP-with-Attention-Based-Deep-Learning-for-Multi-Disease-Prediction)
* [Decomposing Prediction Mechanisms for In-Context Recall](#Decomposing-Prediction-Mechanisms-for-In-Context-Recall)
* [Dose-Escalation Trial Protocols that Extend Naturally to Admit Titration](#Dose-Escalation-Trial-Protocols-that-Extend-Naturally-to-Admit-Titration)
* [Long-Tailed Distribution-Aware Router For Mixture-of-Experts in Large Vision-Language Model](#Long-Tailed-Distribution-Aware-Router-For-Mixture-of-Experts-in-Large-Vision-Language-Model)
* [SpeechAccentLLM A Unified Framework for Foreign Accent Conversion and Text to Speech](#SpeechAccentLLM-A-Unified-Framework-for-Foreign-Accent-Conversion-and-Text-to-Speech)
* [Robust Multi-generation Learned Compression of Point Cloud Attribute](#Robust-Multi-generation-Learned-Compression-of-Point-Cloud-Attribute)
* [SD-Acc Accelerating Stable Diffusion through Phase-aware Sampling and Hardware Co-Optimizations](#SD-Acc-Accelerating-Stable-Diffusion-through-Phase-aware-Sampling-and-Hardware-Co-Optimizations)
* [La RoSA Enhancing LLM Efficiency via Layerwise Rotated Sparse Activation](#La-RoSA-Enhancing-LLM-Efficiency-via-Layerwise-Rotated-Sparse-Activation)
* [PAE MobiLLM Privacy-Aware and Efficient LLM Fine-Tuning on the Mobile Device via Additive Side-Tuning](#PAE-MobiLLM-Privacy-Aware-and-Efficient-LLM-Fine-Tuning-on-the-Mobile-Device-via-Additive-Side-Tuning)
* [An Adaptive Estimation Approach based on Fisher Information to Overcome the Challenges of LFP Battery SOC Estimation](#An-Adaptive-Estimation-Approach-based-on-Fisher-Information-to-Overcome-the-Challenges-of-LFP-Battery-SOC-Estimation)
* [Turning AI Data Centers into Grid-Interactive Assets Results from a Field Demonstration in Phoenix, Arizona](#Turning-AI-Data-Centers-into-Grid-Interactive-Assets-Results-from-a-Field-Demonstration-in-Phoenix,-Arizona)
* [Enhancing Vehicular Platooning with Wireless Federated Learning A Resource-Aware Control Framework](#Enhancing-Vehicular-Platooning-with-Wireless-Federated-Learning-A-Resource-Aware-Control-Framework)
* [VEDA Efficient LLM Generation Through Voting-based KV Cache Eviction and Dataflow-flexible Accelerator](#VEDA-Efficient-LLM-Generation-Through-Voting-based-KV-Cache-Eviction-and-Dataflow-flexible-Accelerator)
* [OptiPrune Boosting Prompt-Image Consistency with Attention-Guided Noise and Dynamic Token Selection](#OptiPrune-Boosting-Prompt-Image-Consistency-with-Attention-Guided-Noise-and-Dynamic-Token-Selection)
* [Echoes of AI Investigating the Downstream Effects of AI Assistants on Software Maintainability](#Echoes-of-AI-Investigating-the-Downstream-Effects-of-AI-Assistants-on-Software-Maintainability)
* [Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess](#Can-Large-Language-Models-Develop-Strategic-Reasoning?-Post-training-Insights-from-Learning-Chess)
* [EARN Efficient Inference Acceleration for LLM-based Generative Recommendation by Register Tokens](#EARN-Efficient-Inference-Acceleration-for-LLM-based-Generative-Recommendation-by-Register-Tokens)
* [SAFER Probing Safety in Reward Models with Sparse Autoencoder](#SAFER-Probing-Safety-in-Reward-Models-with-Sparse-Autoencoder)
* [MTCNet Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound](#MTCNet-Motion-and-Topology-Consistency-Guided-Learning-for-Mitral-Valve-Segmentationin-4D-Ultrasound)
* [ChatHLS Towards Systematic Design Automation and Optimization for High-Level Synthesis](#ChatHLS-Towards-Systematic-Design-Automation-and-Optimization-for-High-Level-Synthesis)
* [Quantize-Sample-and-Verify LLM Acceleration via Adaptive Edge-Cloud Speculative Decoding](#Quantize-Sample-and-Verify-LLM-Acceleration-via-Adaptive-Edge-Cloud-Speculative-Decoding)
* [Neural translation for Stokes inversion and synthesis](#Neural-translation-for-Stokes-inversion-and-synthesis)
* [Cyber Attacks Detection, Prevention, and Source Localization in Digital Substation Communication using Hybrid Statistical-Deep Learning](#Cyber-Attacks-Detection,-Prevention,-and-Source-Localization-in-Digital-Substation-Communication-using-Hybrid-Statistical-Deep-Learning)
* [LLM-Mesh Enabling Elastic Sharing for Serverless LLM Inference](#LLM-Mesh-Enabling-Elastic-Sharing-for-Serverless-LLM-Inference)
* [On Mitigating Data Sparsity in Conversational Recommender Systems](#On-Mitigating-Data-Sparsity-in-Conversational-Recommender-Systems)
* [Overcoming Long-Context Limitations of State-Space Models via Context-Dependent Sparse Attention](#Overcoming-Long-Context-Limitations-of-State-Space-Models-via-Context-Dependent-Sparse-Attention)
* [Serving LLMs in HPC Clusters A Comparative Study of Qualcomm Cloud AI 100 Ultra and High-Performance GPUs](#Serving-LLMs-in-HPC-Clusters-A-Comparative-Study-of-Qualcomm-Cloud-AI-100-Ultra-and-High-Performance-GPUs)
* [Accurate and Efficient Fetal Birth Weight Estimation from 3D Ultrasound](#Accurate-and-Efficient-Fetal-Birth-Weight-Estimation-from-3D-Ultrasound)
* [Origami of Multi-Layered Spaced Sheets](#Origami-of-Multi-Layered-Spaced-Sheets)
* [When Digital Twins Meet Large Language Models Realistic, Interactive, and Editable Simulation for Autonomous Driving](#When-Digital-Twins-Meet-Large-Language-Models-Realistic,-Interactive,-and-Editable-Simulation-for-Autonomous-Driving)
* [Open-ended Scientific Discovery via Bayesian Surprise](#Open-ended-Scientific-Discovery-via-Bayesian-Surprise)
* [Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime](#Data-Uniformity-Improves-Training-Efficiency-and-More,-with-a-Convergence-Framework-Beyond-the-NTK-Regime)
* [Scaling Human Judgment in Community Notes with LLMs](#Scaling-Human-Judgment-in-Community-Notes-with-LLMs)
* [Agent.xpu Efficient Scheduling of Agentic LLM Workloads on Heterogeneous SoC](#Agent.xpu-Efficient-Scheduling-of-Agentic-LLM-Workloads-on-Heterogeneous-SoC)
* [Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data](#Foundation-Models-for-Zero-Shot-Segmentation-of-Scientific-Images-without-AI-Ready-Data)
* [Unveiling Decision-Making in LLMs for Text Classification  Extraction of influential and interpretable concepts with Sparse Autoencoders](#Unveiling-Decision-Making-in-LLMs-for-Text-Classification--Extraction-of-influential-and-interpretable-concepts-with-Sparse-Autoencoders)
* [The Trilemma of Truth in Large Language Models](#The-Trilemma-of-Truth-in-Large-Language-Models)
* [VMoBA Mixture-of-Block Attention for Video Diffusion Models](#VMoBA-Mixture-of-Block-Attention-for-Video-Diffusion-Models)
* [Low-latency vision transformers via large-scale multi-head attention](#Low-latency-vision-transformers-via-large-scale-multi-head-attention)
* [Large-scale Neural Network Quantum States for ab initio Quantum Chemistry Simulations on Fugaku](#Large-scale-Neural-Network-Quantum-States-for-ab-initio-Quantum-Chemistry-Simulations-on-Fugaku)
* [DABstep Data Agent Benchmark for Multi-step Reasoning](#DABstep-Data-Agent-Benchmark-for-Multi-step-Reasoning)
* [Pruning by Block Benefit Exploring the Properties of Vision Transformer Blocks during Domain Adaptation](#Pruning-by-Block-Benefit-Exploring-the-Properties-of-Vision-Transformer-Blocks-during-Domain-Adaptation)
* [Towards Building Private LLMs Exploring Multi-Node Expert Parallelism on Apple Silicon for Mixture-of-Experts Large Language Model](#Towards-Building-Private-LLMs-Exploring-Multi-Node-Expert-Parallelism-on-Apple-Silicon-for-Mixture-of-Experts-Large-Language-Model)
* [A unified framework on the universal approximation of transformer-type architectures](#A-unified-framework-on-the-universal-approximation-of-transformer-type-architectures)
* [Sensing for Free Learn to Localize More Sources than Antennas without Pilots](#Sensing-for-Free-Learn-to-Localize-More-Sources-than-Antennas-without-Pilots)
* [FD-DiT Frequency Domain-Directed Diffusion Transformer for Low-Dose CT Reconstruction](#FD-DiT-Frequency-Domain-Directed-Diffusion-Transformer-for-Low-Dose-CT-Reconstruction)
* [What to Keep and What to Drop Adaptive Table Filtering Framework](#What-to-Keep-and-What-to-Drop-Adaptive-Table-Filtering-Framework)
* [CycleVAR Repurposing Autoregressive Model for Unsupervised One-Step Image Translation](#CycleVAR-Repurposing-Autoregressive-Model-for-Unsupervised-One-Step-Image-Translation)
* [Sub-MoE Efficient Mixture-of-Expert LLMs Compression via Subspace Expert Merging](#Sub-MoE-Efficient-Mixture-of-Expert-LLMs-Compression-via-Subspace-Expert-Merging)
* [BridgeShape Latent Diffusion Schrödinger Bridge for 3D Shape Completion](#BridgeShape-Latent-Diffusion-Schrödinger-Bridge-for-3D-Shape-Completion)
* [Benchmarking Deep Search over Heterogeneous Enterprise Data](#Benchmarking-Deep-Search-over-Heterogeneous-Enterprise-Data)
* [Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning](#Unleashing-Embodied-Task-Planning-Ability-in-LLMs-via-Reinforcement-Learning)
* [TOMI Transforming and Organizing Music Ideas for Multi-Track Compositions with Full-Song Structure](#TOMI-Transforming-and-Organizing-Music-Ideas-for-Multi-Track-Compositions-with-Full-Song-Structure)
* [Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems](#Multi-task-Offline-Reinforcement-Learning-for-Online-Advertising-in-Recommender-Systems)
* [CSBrain A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding](#CSBrain-A-Cross-scale-Spatiotemporal-Brain-Foundation-Model-for-EEG-Decoding)
* [Spectra 1.1 Scaling Laws and Efficient Inference for Ternary Language Models](#Spectra-1.1-Scaling-Laws-and-Efficient-Inference-for-Ternary-Language-Models)
* [SparStencil Retargeting Sparse Tensor Cores to Scientific Stencil Computations via Structured Sparsity Transformation](#SparStencil-Retargeting-Sparse-Tensor-Cores-to-Scientific-Stencil-Computations-via-Structured-Sparsity-Transformation)
* [Attention to Burstiness Low-Rank Bilinear Prompt Tuning](#Attention-to-Burstiness-Low-Rank-Bilinear-Prompt-Tuning)
* [ReasonBridge Efficient Reasoning Transfer from Closed to Open-Source Language Models](#ReasonBridge-Efficient-Reasoning-Transfer-from-Closed-to-Open-Source-Language-Models)
* [DOBB-BVH Efficient Ray Traversal by Transforming Wide BVHs into Oriented Bounding Box Trees using Discrete Rotations](#DOBB-BVH-Efficient-Ray-Traversal-by-Transforming-Wide-BVHs-into-Oriented-Bounding-Box-Trees-using-Discrete-Rotations)
* [Size-Dependent Tensile Behavior of Nanocrystalline HfNbTaTiZr High-Entropy Alloy Roles of Solid-Solution and Short-Range Order](#Size-Dependent-Tensile-Behavior-of-Nanocrystalline-HfNbTaTiZr-High-Entropy-Alloy-Roles-of-Solid-Solution-and-Short-Range-Order)
* [TriADA Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations](#TriADA-Massively-Parallel-Trilinear-Matrix-by-Tensor-Multiply-Add-Algorithm-and-Device-Architecture-for-the-Acceleration-of-3D-Discrete-Transformations)
* [SPI-BoTER Error Compensation for Industrial Robots via Sparse Attention Masking and Hybrid Loss with Spatial-Physical Information](#SPI-BoTER-Error-Compensation-for-Industrial-Robots-via-Sparse-Attention-Masking-and-Hybrid-Loss-with-Spatial-Physical-Information)
* [Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching](#Single-Frame-Point-Pixel-Registration-via-Supervised-Cross-Modal-Feature-Matching)
* [Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation](#Smaller-=-Weaker?-Benchmarking-Robustness-of-Quantized-LLMs-in-Code-Generation)
* [Can We Reliably Predict the Fed's Next Move? A Multi-Modal Approach to U.S. Monetary Policy Forecasting](#Can-We-Reliably-Predict-the-Fed's-Next-Move?-A-Multi-Modal-Approach-to-U.S.-Monetary-Policy-Forecasting)
* [Prompt Mechanisms in Medical Imaging A Comprehensive Survey](#Prompt-Mechanisms-in-Medical-Imaging-A-Comprehensive-Survey)
* [Beyond Code The Multidimensional Impacts of Large Language Models in Software Development](#Beyond-Code-The-Multidimensional-Impacts-of-Large-Language-Models-in-Software-Development)
* [A new sparsity promoting residual transform operator for Lasso regression](#A-new-sparsity-promoting-residual-transform-operator-for-Lasso-regression)
* [URSA The Universal Research and Scientific Agent](#URSA-The-Universal-Research-and-Scientific-Agent)
* [Hydrodynamic interactions of low-aspect-ratio oscillating panels in a tip-to-tip formation](#Hydrodynamic-interactions-of-low-aspect-ratio-oscillating-panels-in-a-tip-to-tip-formation)
* [HyperCLOVA X THINK Technical Report](#HyperCLOVA-X-THINK-Technical-Report)
* [QuickSilver -- Speeding up LLM Inference through Dynamic Token Halting, KV Skipping, Contextual Token Fusion, and Adaptive Matryoshka Quantization](#QuickSilver----Speeding-up-LLM-Inference-through-Dynamic-Token-Halting,-KV-Skipping,-Contextual-Token-Fusion,-and-Adaptive-Matryoshka-Quantization)
* [Towards Distributed Neural Architectures](#Towards-Distributed-Neural-Architectures)
* [Closing the Performance Gap in Biometric Cryptosystems A Deeper Analysis on Unlinkable Fuzzy Vaults](#Closing-the-Performance-Gap-in-Biometric-Cryptosystems-A-Deeper-Analysis-on-Unlinkable-Fuzzy-Vaults)
* [Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment](#Rethinking-Visual-Token-Reduction-in-LVLMs-under-Cross-modal-Misalignment)
* [Projected Compression Trainable Projection for Efficient Transformer Compression](#Projected-Compression-Trainable-Projection-for-Efficient-Transformer-Compression)
* [Exploring Modularity of Agentic Systems for Drug Discovery](#Exploring-Modularity-of-Agentic-Systems-for-Drug-Discovery)
* [Learning to Solve Multi-Objective Routing Problems on Multigraphs](#Learning-to-Solve-Multi-Objective-Routing-Problems-on-Multigraphs)
* [Transformers are Graph Neural Networks](#Transformers-are-Graph-Neural-Networks)
* [Query as Test An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios](#Query-as-Test-An-Intelligent-Driving-Test-and-Data-Storage-Method-for-Integrated-Cockpit-Vehicle-Road-Scenarios)
* [SPTCStencil Unleashing Sparse Tensor Cores for Stencil Computation via Strided Swap](#SPTCStencil-Unleashing-Sparse-Tensor-Cores-for-Stencil-Computation-via-Strided-Swap)
* [SiPipe Bridging the CPU-GPU Utilization Gap for Efficient Pipeline-Parallel LLM Inference](#SiPipe-Bridging-the-CPU-GPU-Utilization-Gap-for-Efficient-Pipeline-Parallel-LLM-Inference)
* [A Survey of LLM Inference Systems](#A-Survey-of-LLM-Inference-Systems)


## Less is Enough Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching

>Authors: Xin Zhou, Dingkang Liang, Kaijin Chen, Tianrui Feng, Xiwu Chen, Hongkai Lin, Yikang Ding, Feiyang Tan, Hengshuang Zhao, Xiang Bai

>2025-07-03

> http://arxiv.org/abs/2507.02860v1

Video generation models have demonstrated remarkable performance, yet their
broader adoption remains constrained by slow inference speeds and substantial
computational costs, primarily due to the iterative nature of the denoising
process. Addressing this bottleneck is essential for democratizing advanced
video synthesis technologies and enabling their integration into real-world
applications. This work proposes EasyCache, a training-free **acceleration**
framework for video diffusion models. EasyCache introduces a lightweight,
runtime-adaptive caching mechanism that dynamically reuses previously computed
transformation vectors, avoiding redundant computations during inference.
Unlike prior approaches, EasyCache requires no offline profiling,
pre-computation, or extensive parameter tuning. We conduct comprehensive
studies on various large-scale video generation models, including OpenSora,
Wan2.1, and HunyuanVideo. Our method achieves leading **acceleration** performance,
reducing inference time by up to 2.1-3.3$\times$ compared to the original
baselines while maintaining high visual fidelity with a significant up to 36%
PSNR improvement compared to the previous SOTA method. This improvement makes
our EasyCache a efficient and highly accessible solution for high-quality video
generation in both research and practical applications. The code is available
at https://github.com/H-EmbodVis/EasyCache.


## AREE-Based Decoupled Design of Hybrid Beamformers in mmWave XL-MIMO Systems

>Authors: Jiazhe Li, Nicolò Decarli, Francesco Guidi, Heng Dong, Anna Guerra, Alessandro Bazzi, Zhuoming Li

>2025-07-03

> http://arxiv.org/abs/2507.02802v1

Hybrid beamforming has been widely employed in mmWave communications such as
vehicular-to-everything (V2X) scenarios, as a compromise between hardware
complexity and spectral efficiency. However, the inherent coupling between
analog and digital precoders in hybrid array architecture significantly limits
the computational and spectral efficiency of existing algorithms. To address
this issue, we propose an alternating residual error elimination (AREE)
algorithm, which decomposes the hybrid beamforming problem into two
low-dimensional subproblems, each exhibiting a favorable matrix structure that
enables effective decoupling of analog and digital precoders from the matrix
product formulation. These subproblems iteratively eliminate each other's
residual errors, driving the original problem toward the optimal hybrid
beamforming performance. The proposed initialization ensures rapid convergence,
while a low-complexity geometric channel SVD algorithm is developed by
transforming the high-dimensional **sparse** channel into a low-dimensional
equivalent, thereby simplifying the derivation of subproblems. Simulation
results demonstrate that the AREE algorithm effectively decouples analog and
digital precoders with low complexity, achieves fast convergence, and offers
higher spectral efficiency than existing beamforming methods.


## Time-Masked Transformers with Lightweight Test-Time Adaptation for Neural Speech Decoding

>Authors: Ebrahim Feghhi, Shreyas Kaasyap, Nima Hadidi, Jonathan C. Kao

>2025-07-03

> http://arxiv.org/abs/2507.02800v1

Speech neuroprostheses aim to restore communication for people with severe
paralysis by decoding speech directly from neural activity. To accelerate
algorithmic progress, a recent benchmark released intracranial recordings from
a paralyzed participant attempting to speak, along with a baseline decoding
algorithm. Prior work on the benchmark showed impressive accuracy gains.
However, these gains increased computational costs and were not demonstrated in
a real-time decoding setting. Here, we make three contributions that pave the
way towards accurate, efficient, and real-time neural speech decoding. First,
we incorporate large amounts of time masking during training. On average, over
$50\%$ of each trial is masked. Second, we replace the gated recurrent unit
(GRU) architecture used in the baseline algorithm with a compact Transformer.
The Transformer architecture uses $77\%$ fewer parameters, cuts peak GPU memory
usage by $36\%$ relative, and is significantly faster to calibrate relative to
the GRU. Third, we design a lightweight variant of an existing test-time
adaptation method developed for decoding handwriting from neural activity. Our
variant adapts the model using multiple time masked augmentations of a single
trial and requires only one gradient step per trial. Together, these
contributions reduce word error rate by $19.5\%$ and effectively mitigate
performance degradations across held-out days in a real-time decoding setting
while substantially lowering computational costs.


## Bourbaki Self-Generated and Goal-Conditioned MDPs for Theorem Proving

>Authors: Matthieu Zimmer, Xiaotong Ji, Rasul Tutunov, Anthony Bordg, Jun Wang, Haitham Bou Ammar

>2025-07-03

> http://arxiv.org/abs/2507.02726v1

Reasoning remains a challenging task for large language models (LLMs),
especially within the logically constrained environment of automated theorem
proving (ATP), due to **sparse** rewards and the vast scale of proofs. These
challenges are amplified in benchmarks like PutnamBench, which contains
university-level problems requiring complex, multi-step reasoning. To address
this, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new
framework in which agents generate and pursue their subgoals based on the
evolving proof state. Given this more structured generation of goals, the
resulting problem becomes more amenable to search. We then apply Monte Carlo
Tree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our
approach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs
for subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B)
solves 26 problems, achieving new state-of-the-art results with models at this
scale.


## Moments, Time-Inversion and Source Identification for the Heat Equation

>Authors: Kang Liu, Enrique Zuazua

>2025-07-03

> http://arxiv.org/abs/2507.02677v1

We address the initial source identification problem for the heat equation, a
notably ill-posed inverse problem characterized by exponential instability.
Departing from classical Tikhonov regularization, we propose a novel approach
based on moment analysis of the heat flow, transforming the problem into a more
stable inverse moment formulation. By evolving the measured terminal time
moments backward through their governing ODE system, we recover the moments of
the initial distribution. We then reconstruct the source by solving a convex
optimization problem that minimizes the total variation of a measure subject to
these moment constraints. This formulation naturally promotes **sparsity**,
yielding atomic solutions that are sums of Dirac measures. Compared to existing
methods, our moment-based approach reduces exponential error growth to
polynomial growth with respect to the terminal time. We provide explicit error
estimates on the recovered initial distributions in terms of moment order,
terminal time, and measurement errors. In addition, we develop efficient
numerical discretization schemes and demonstrate significant stability
improvements of our approach through comprehensive numerical experiments.


## FlowSpec Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference

>Authors: Xing Liu, Lizhuo Luo, Ming Tang, Chao Huang

>2025-07-03

> http://arxiv.org/abs/2507.02620v1

Distributed inference serves as a promising approach to enabling the
inference of large language models (LLMs) at the network edge. It distributes
the inference process to multiple devices to ensure that the LLMs can fit into
the device memory. Recent pipeline-based approaches have the potential to
parallelize communication and computation, which helps reduce inference
latency. However, the benefit diminishes when the inference request at the
network edge is **sparse**, where pipeline is typically at low utilization. To
enable efficient distributed LLM inference at the edge, we propose
\textbf{FlowSpec}, a pipeline-parallel tree-based speculative decoding
framework. FlowSpec incorporates three key mechanisms to improve decoding
efficiency: 1) score-based step-wise verification prioritizes more important
draft tokens to bring earlier accpeted tokens; 2) efficient draft management to
prune invalid tokens while maintaining correct causal relationship during
verification; 3) dynamic draft expansion strategies to supply high-quality
speculative inputs. These techniques work in concert to enhance both pipeline
utilization and speculative efficiency. We evaluate FlowSpec on a real-world
testbed with other baselines. Experimental results demonstrate that our
proposed framework significantly improves inference speed across diverse models
and configurations, achieving speedup ratios 1.36$\times$-1.77$\times$ compared
to baselines. Our code is publicly available at
\href{https://github.com/Leosang-lx/FlowSpec#}{https://github.com/Leosang-lx/FlowSpec\#}


## MedFormer Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention

>Authors: Zunhui Xia, Hongxing Li, Libin Lan

>2025-07-03

> http://arxiv.org/abs/2507.02488v1

Medical image recognition serves as a key way to aid in clinical diagnosis,
enabling more accurate and timely identification of diseases and abnormalities.
Vision transformer-based approaches have proven effective in handling various
medical recognition tasks. However, these methods encounter two primary
challenges. First, they are often task-specific and architecture-tailored,
limiting their general applicability. Second, they usually either adopt full
attention to model long-range dependencies, resulting in high computational
costs, or rely on handcrafted **sparse** attention, potentially leading to
suboptimal performance. To tackle these issues, we present MedFormer, an
efficient medical vision transformer with two key ideas. First, it employs a
pyramid scaling structure as a versatile backbone for various medical image
recognition tasks, including image classification and dense prediction tasks
such as semantic segmentation and lesion detection. This structure facilitates
hierarchical feature representation while reducing the computation load of
feature maps, highly beneficial for boosting performance. Second, it introduces
a novel Dual Sparse Selection Attention (DSSA) with content awareness to
improve computational efficiency and robustness against noise while maintaining
high performance. As the core building technique of MedFormer, DSSA is
explicitly designed to attend to the most relevant content. In addition, a
detailed theoretical analysis has been conducted, demonstrating that MedFormer
has superior generality and efficiency in comparison to existing medical vision
transformers. Extensive experiments on a variety of imaging modality datasets
consistently show that MedFormer is highly effective in enhancing performance
across all three above-mentioned medical image recognition tasks. The code is
available at https://github.com/XiaZunhui/MedFormer.


## TABNet A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation

>Authors: Peilin Zhang, Shaouxan Wua, Jun Feng, Zhuo Jin, Zhizezhang Gao, Jingkun Chen, Yaqiong Xing, Xiao Zhang

>2025-07-03

> http://arxiv.org/abs/2507.02399v1

Background and objective: Medical image segmentation is a core task in
various clinical applications. However, acquiring large-scale, fully annotated
medical image datasets is both time-consuming and costly. Scribble annotations,
as a form of **sparse** labeling, provide an efficient and cost-effective
alternative for medical image segmentation. However, the **sparsity** of scribble
annotations limits the feature learning of the target region and lacks
sufficient boundary supervision, which poses significant challenges for
training segmentation networks. Methods: We propose TAB Net, a novel
weakly-supervised medical image segmentation framework, consisting of two key
components: the triplet augmentation self-recovery (TAS) module and the
boundary-aware pseudo-label supervision (BAP) module. The TAS module enhances
feature learning through three complementary augmentation strategies: intensity
transformation improves the model's sensitivity to texture and contrast
variations, cutout forces the network to capture local anatomical structures by
masking key regions, and jigsaw augmentation strengthens the modeling of global
anatomical layout by disrupting spatial continuity. By guiding the network to
recover complete masks from diverse augmented inputs, TAS promotes a deeper
semantic understanding of medical images under **sparse** supervision. The BAP
module enhances pseudo-supervision accuracy and boundary modeling by fusing
dual-branch predictions into a loss-weighted pseudo-label and introducing a
boundary-aware loss for fine-grained contour refinement. Results: Experimental
evaluations on two public datasets, ACDC and MSCMR seg, demonstrate that TAB
Net significantly outperforms state-of-the-art methods for scribble-based
weakly supervised segmentation. Moreover, it achieves performance comparable to
that of fully supervised methods.


## Split-Merge Revisited A Scalable Approach to Generalized Eigenvalue Problems

>Authors: Xiaozhi Liu, Yong Xia

>2025-07-03

> http://arxiv.org/abs/2507.02389v1

The generalized eigenvalue problem (GEP) serves as a cornerstone in a wide
range of applications in numerical linear algebra and scientific computing.
However, traditional approaches that aim to maximize the classical Rayleigh
quotient often suffer from numerical instability and limited computational
efficiency, especially in large-scale settings. In this work, we explore an
alternative difference-based formulation of GEP by minimizing a structured
quadratic polynomial objective, which enables the application of efficient
first-order optimization methods. We establish global convergence guarantees
for these methods without requiring line search, and further introduce a
transform-domain perspective that reveals the intrinsic connection and
performance gap between classical first-order algorithms and the power method.
Based on this insight, we develop an accelerated preconditioned mirror descent
algorithm, which allows for flexible preconditioner design and improved
convergence behavior. Lastly, we extend the recently proposed Split-Merge
algorithm to the general GEP setting, incorporating richer second-order
information to further accelerate convergence. Empirical results on both
synthetic and real-world datasets demonstrate that our proposed methods achieve
significant improvements over existing baselines in terms of both computational
efficiency and numerical stability.


## Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection

>Authors: Weijie Lyu, Sheng-Jun Huang, Xuan Xia

>2025-07-03

> http://arxiv.org/abs/2507.02378v1

Recent advancements in large language models (LLMs) have significantly
improved code generation and program comprehension, accelerating the evolution
of software engineering. Current methods primarily enhance model performance by
leveraging vast amounts of data, focusing on data quantity while often
overlooking data quality, thereby reducing training efficiency. To address
this, we introduce an approach that utilizes a parametric model for code data
selection, aimed at improving both training efficiency and model performance.
Our method optimizes the parametric model to ensure distribution consistency
and diversity within the selected subset, guaranteeing high-quality data.
Experimental results demonstrate that using only 10K samples, our method
achieves gains of 2.4% (HumanEval) and 2.3% (MBPP) over 92K full-sampled
baseline, outperforming other sampling approaches in both performance and
efficiency. This underscores that our method effectively boosts model
performance while significantly reducing computational costs.


## Holistic Tokenizer for Autoregressive Image Generation

>Authors: Anlin Zheng, Haochen Wang, Yucheng Zhao, Weipeng Deng, Tiancai Wang, Xiangyu Zhang, Xiaojuan Qi

>2025-07-03

> http://arxiv.org/abs/2507.02358v1

The vanilla autoregressive image generation model generates visual tokens in
a step-by-step fashion, which limits the ability to capture holistic
relationships among token sequences. Moreover, most visual tokenizers map local
image patches into latent tokens, leading to limited global information. To
address this, we introduce \textit{Hita}, a novel image tokenizer for
autoregressive (AR) image generation. It introduces a holistic-to-local
tokenization scheme with learnable holistic queries and local patch tokens.
Besides, Hita incorporates two key strategies for improved alignment with the
AR generation process: 1) it arranges a sequential structure with holistic
tokens at the beginning followed by patch-level tokens while using causal
attention to maintain awareness of previous tokens; and 2) before feeding the
de-**quantize**d tokens into the decoder, Hita adopts a lightweight fusion module
to control information flow to prioritize holistic tokens. Extensive
experiments show that Hita accelerates the training speed of AR generators and
outperforms those trained with vanilla tokenizers, achieving \textbf{2.59 FID}
and \textbf{281.9 IS} on the ImageNet benchmark. A detailed analysis of the
holistic representation highlights its ability to capture global image
properties such as textures, materials, and shapes. Additionally, Hita also
demonstrates effectiveness in zero-shot style transfer and image in-painting.
The code is available at
\href{https://github.com/CVMI-Lab/Hita}{https://github.com/CVMI-Lab/Hita}


## LMPNet for Weakly-supervised Keypoint Discovery

>Authors: Pei Guo, Ryan Farrell

>2025-07-03

> http://arxiv.org/abs/2507.02308v1

In this work, we explore the task of semantic object keypoint discovery
weakly-supervised by only category labels. This is achieved by transforming
discriminatively-trained intermediate layer filters into keypoint detectors. We
begin by identifying three preferred characteristics of keypoint detectors: (i)
spatially **sparse** activations, (ii) consistency and (iii) diversity. Instead of
relying on hand-crafted loss terms, a novel computationally-efficient leaky max
pooling (LMP) layer is proposed to explicitly encourage final conv-layer
filters to learn "non-repeatable local patterns" that are well aligned with
object keypoints. Informed by visualizations, a simple yet effective selection
strategy is proposed to ensure consistent filter activations and attention
mask-out is then applied to force the network to distribute its attention to
the whole object instead of just the most discriminative region. For the final
keypoint prediction, a learnable clustering layer is proposed to group keypoint
proposals into keypoint predictions. The final model, named LMPNet, is highly
interpretable in that it directly manipulates network filters to detect
predefined concepts. Our experiments show that LMPNet can (i) automatically
discover semantic keypoints that are robust to object pose and (ii) achieves
strong prediction accuracy comparable to a supervised pose estimation model.


## A scalable and programmable optical neural network in a time-synthetic dimension

>Authors: Bei Wu, Yudong Ren, Rui Zhao, Haiyao Luo, Fujia Chen, Li Zhang, Hongsheng Chen, Yihao Yang

>2025-07-03

> http://arxiv.org/abs/2507.02297v1

Programmable optical neural networks (ONNs) can offer high-throughput and
energy-efficient solutions for accelerating artificial intelligence (AI)
computing. However, existing ONN architectures, typically based on cascaded
unitary transformations such as Mach-Zehnder interferometer meshes, face
inherent scalability limitations due to spatial encoding, which causes optical
components and system complexity to scale quadratically with network size. A
promising solution to this challenge is the use of synthetic dimensions to
enhance scalability, though experimental demonstration has remained scarce.
Here, we present the first experimental demonstration of an all-optical, highly
scalable, programmable ONN operating in a time-synthetic dimension. By
implementing a time-cycle computation paradigm analogous to gate cycling in
conventional spatial photonic circuits, our approach achieves a gate count
surpassing that of state-of-the-art programmable photonic processors. Unlike
conventional ONN architectures that rely on real-space wave interferences, our
framework exploits time-reflection and time-refraction to perform computations,
fundamentally eliminating backscattering errors through causality constraints.
To bridge the gap between simulation and reality, we introduce an in-situ
training framework that dynamically adapts to experimental errors, achieving
performance exceeding traditional in silico learning paradigms. Our
synthetic-dimension-based approach provides a compact, scalable,
backscattering-free, and programmable neuromorphic computing architecture,
advancing the potential for next-generation photonic AI systems.


## Content filtering methods for music recommendation A review

>Authors: Terence Zeng, Abhishek K. Umrawal

>2025-07-03

> http://arxiv.org/abs/2507.02282v1

Recommendation systems have become essential in modern music streaming
platforms, shaping how users discover and engage with songs. One common
approach in recommendation systems is collaborative filtering, which suggests
content based on the preferences of users with similar listening patterns to
the target user. However, this method is less effective on media where
interactions are **sparse**. Music is one such medium, since the average user of a
music streaming service will never listen to the vast majority of tracks. Due
to this **sparsity**, there are several challenges that have to be addressed with
other methods. This review examines the current state of research in addressing
these challenges, with an emphasis on the role of content filtering in
mitigating biases inherent in collaborative filtering approaches. We explore
various methods of song classification for content filtering, including lyrical
analysis using Large Language Models (LLMs) and audio signal processing
techniques. Additionally, we discuss the potential conflicts between these
different analysis methods and propose avenues for resolving such
discrepancies.


## High-Fidelity Differential-information Driven Binary Vision Transformer

>Authors: Tian Gao, Zhiyuan Zhang, Kaijie Yin, Xu-Cheng Zhong, Hui Kong

>2025-07-03

> http://arxiv.org/abs/2507.02222v1

The binarization of vision transformers (ViTs) offers a promising approach to
addressing the trade-off between high computational/storage demands and the
constraints of edge-device deployment. However, existing binary ViT methods
often suffer from severe performance degradation or rely heavily on
full-precision modules. To address these issues, we propose DIDB-ViT, a novel
binary ViT that is highly informative while maintaining the original ViT
architecture and computational efficiency. Specifically, we design an
informative attention module incorporating differential information to mitigate
information loss caused by binarization and enhance high-frequency retention.
To preserve the fidelity of the similarity calculations between binary Q and K
tensors, we apply frequency decomposition using the discrete Haar wavelet and
integrate similarities across different frequencies. Additionally, we introduce
an improved RPReLU activation function to restructure the activation
distribution, expanding the model's representational capacity. Experimental
results demonstrate that our DIDB-ViT significantly outperforms
state-of-the-art network **quantization** methods in multiple ViT architectures,
achieving superior image classification and segmentation performance.


## High-Layer Attention Pruning with Rescaling

>Authors: Songtao Liu, Peng Liu

>2025-07-02

> http://arxiv.org/abs/2507.01900v1

Pruning is a highly effective approach for compressing large language models
(LLMs), significantly reducing inference latency. However, conventional
training-free structured **pruning** methods often employ a heuristic metric that
indiscriminately removes some attention heads across all **pruning** layers,
without considering their positions within the network architecture. In this
work, we propose a novel **pruning** algorithm that strategically prunes attention
heads in the model's higher layers. Since the removal of attention heads can
alter the magnitude of token representations, we introduce an adaptive
rescaling parameter that calibrates the representation scale post-**pruning** to
counteract this effect. We conduct comprehensive experiments on a wide range of
LLMs, including LLaMA3.1-8B, Mistral-7B-v0.3, Qwen2-7B, and Gemma2-9B. Our
evaluation includes both generation and discriminative tasks across 27
datasets. The results consistently demonstrate that our method outperforms
existing structured **pruning** methods. This improvement is particularly notable
in generation tasks, where our approach significantly outperforms existing
baselines.


## Eka-Eval  A Comprehensive Evaluation Framework for Large Language Models in Indian Languages

>Authors: Samridhi Raj Sinha, Rajvee Sheth, Abhishek Upperwal, Mayank Singh

>2025-07-02

> http://arxiv.org/abs/2507.01853v1

The rapid advancement of Large Language Models (LLMs) has intensified the
need for evaluation frameworks that go beyond English centric benchmarks and
address the requirements of linguistically diverse regions such as India. We
present EKA-EVAL, a unified and production-ready evaluation framework that
integrates over 35 benchmarks, including 10 Indic-specific datasets, spanning
categories like reasoning, mathematics, tool use, long-context understanding,
and reading comprehension. Compared to existing Indian language evaluation
tools, EKA-EVAL offers broader benchmark coverage, with built-in support for
distributed inference, **quantization**, and multi-GPU usage. Our systematic
comparison positions EKA-EVAL as the first end-to-end, extensible evaluation
suite tailored for both global and Indic LLMs, significantly lowering the
barrier to multilingual benchmarking. The framework is open-source and publicly
available at https://github.com/lingo-iitgn/ eka-eval and a part of ongoing EKA
initiative (https://eka.soket.ai), which aims to scale up to over 100
benchmarks and establish a robust, multilingual evaluation ecosystem for LLMs.


## Topological Braiding of Bloch Eigenmodes Protected by Non-Abelian Quaternion Invariants

>Authors: Xiao-Ming Wang, Jiaying Xu, Xulong Wang, Zhen Li, Guancong Ma

>2025-07-02

> http://arxiv.org/abs/2507.01809v1

Braiding has attracted significant attention in physics because of its
important role in describing the fundamental exchange of particles. Infusing
the braiding with topological protection will make it robust against
imperfections and perturbations, but such topological braiding is believed to
be possible only in interacting quantum systems, e.g., topological
superconductors. Here, we propose and demonstrate a new strategy of topological
braiding that emerges from non-Abelian topological insulators, a class of
recently discovered multi-band topological phase. We unveil a mathematical
connection between braiding and non-Abelian quaternion invariants, by which
Bloch eigenmodes under parallel transport produce braid sequences protected by
the non-Abelian band topology. The braiding is also associated with geometric
phases **quantize**d over half the Brillouin zone. This new type of non-Abelian
topological braiding is experimentally realized in acoustic systems with
periodic synthetic dimensions. The results show that the principle discovered
here is a new strategy towards topological braiding and can be extended for
other types of classical waves and non-interacting quantum systems.


## BranchNet A Neuro-Symbolic Learning Framework for Structured Multi-Class Classification

>Authors: Dalia Rodríguez-Salas, Christian Riess

>2025-07-02

> http://arxiv.org/abs/2507.01781v1

We introduce BranchNet, a neuro-symbolic learning framework that transforms
decision tree ensembles into **sparse**, partially connected neural networks. Each
branch, defined as a decision path from root to a parent of leaves, is mapped
to a hidden neuron, preserving symbolic structure while enabling gradient-based
optimization. The resulting models are compact, interpretable, and require no
manual architecture tuning. Evaluated on a suite of structured multi-class
classification benchmarks, BranchNet consistently outperforms XGBoost in
accuracy, with statistically significant gains. We detail the architecture,
training procedure, and **sparsity** dynamics, and discuss the model's strengths in
symbolic interpretability as well as its current limitations, particularly on
binary tasks where further adaptive calibration may be beneficial.


## Rethinking Discrete Tokens Treating Them as Conditions for Continuous Autoregressive Image Synthesis

>Authors: Peng Zheng, Junke Wang, Yi Chang, Yizhou Yu, Rui Ma, Zuxuan Wu

>2025-07-02

> http://arxiv.org/abs/2507.01756v1

Recent advances in large language models (LLMs) have spurred interests in
encoding images as discrete tokens and leveraging autoregressive (AR)
frameworks for visual generation. However, the **quantization** process in AR-based
visual generation models inherently introduces information loss that degrades
image fidelity. To mitigate this limitation, recent studies have explored to
autoregressively predict continuous tokens. Unlike discrete tokens that reside
in a structured and bounded space, continuous representations exist in an
unbounded, high-dimensional space, making density estimation more challenging
and increasing the risk of generating out-of-distribution artifacts. Based on
the above findings, this work introduces DisCon (Discrete-Conditioned
Continuous Autoregressive Model), a novel framework that reinterprets discrete
tokens as conditional signals rather than generation targets. By modeling the
conditional probability of continuous representations conditioned on discrete
tokens, DisCon circumvents the optimization challenges of continuous token
modeling while avoiding the information loss caused by **quantization**. DisCon
achieves a gFID score of 1.38 on ImageNet 256$\times$256 generation,
outperforming state-of-the-art autoregressive approaches by a clear margin.


## High dimensional convergence rates for sparse precision estimators for matrix-variate data

>Authors: Hongqiang Sun, Kshitij Khare

>2025-07-02

> http://arxiv.org/abs/2507.01741v1

In several applications, the underlying structure of the data allows for the
samples to be organized into a matrix variate form. In such settings, the
underlying row and column covariance matrices are fundamental quantities of
interest. We focus our attention on two popular estimators that have been
proposed in the literature: a penalized **sparse** estimator called SMGM and a
heuristic sample covariance estimator. We establish convergence rates for these
estimators in relevant high-dimensional settings, where the row and column
dimensions of the matrix are allowed to increase with the sample size. We show
that high-dimensional convergence rate analyses for the SMGM estimator in
previous literature are incorrect. We discuss the critical errors in these
proofs, and present a different and novel approach.


## Gold after Randomized Sand Model-X Split Knockoffs for Controlled Transformation Selection

>Authors: Yang Cao, Hangyu Lin, Xinwei Sun, Yuan Yao

>2025-07-02

> http://arxiv.org/abs/2507.01732v1

Controlling the False Discovery Rate (FDR) in variable selection is crucial
for reproducibility and preventing over-selection, particularly with the
increasing prevalence of predictive modeling. The Split Knockoff method, a
recent extension of the canonical Knockoffs framework, offers finite-sample FDR
control for selecting **sparse** transformations, finding applications across
signal processing, economics, information technology, and the life sciences.
However, its current formulation is limited to fixed design settings,
restricting its use to linear models. The question of whether it can be
generalized to random designs, thereby accommodating a broader range of models
beyond the linear case -- similar to the Model-X Knockoff framework -- remains
unanswered. A major challenge in addressing transformational **sparsity** within
random design settings lies in reconciling the combination of a random design
with a deterministic transformation. To overcome this limitation, we propose
the Model-X Split Knockoff method. Our method achieves FDR control for
transformation selection in random designs, bridging the gap between existing
approaches. This is accomplished by introducing an auxiliary randomized design
that interacts with both the existing random design and the deterministic
transformation, enabling the construction of Model-X Split Knockoffs. Like the
classical Model-X framework, our method provides provable finite-sample FDR
control under known or accurately estimated covariate distributions, regardless
of the conditional distribution of the response. Importantly, it guarantees at
least the same selection power as Model-X Knockoffs when both are applicable.
Empirical studies, including simulations and real-world applications to
Alzheimer's disease imaging and university ranking analysis, demonstrate robust
FDR control and suggest improved selection power over the original Model-X
approach.


## SPoT Subpixel Placement of Tokens in Vision Transformers

>Authors: Martine Hjelkrem-Tan, Marius Aasan, Gabriel Y. Arteaga, Adín Ramírez Rivera

>2025-07-02

> http://arxiv.org/abs/2507.01654v1

Vision Transformers naturally accommodate **sparsity**, yet standard tokenization
methods confine features to discrete patch grids. This constraint prevents
models from fully exploiting **sparse** regimes, forcing awkward compromises. We
propose Subpixel Placement of Tokens (SPoT), a novel tokenization strategy that
positions tokens continuously within images, effectively sidestepping
grid-based limitations. With our proposed oracle-guided search, we uncover
substantial performance gains achievable with ideal subpixel token positioning,
drastically reducing the number of tokens necessary for accurate predictions
during inference. SPoT provides a new direction for flexible, efficient, and
interpretable ViT architectures, redefining **sparsity** as a strategic advantage
rather than an imposed limitation.


## GradMetaNet An Equivariant Architecture for Learning on Gradients

>Authors: Yoav Gelberg, Yam Eitan, Aviv Navon, Aviv Shamsian, Theo, Putterman, Michael Bronstein, Haggai Maron

>2025-07-02

> http://arxiv.org/abs/2507.01649v1

Gradients of neural networks encode valuable information for optimization,
editing, and analysis of models. Therefore, practitioners often treat gradients
as inputs to task-specific algorithms, e.g. for **pruning** or optimization. Recent
works explore learning algorithms that operate directly on gradients but use
architectures that are not specifically designed for gradient processing,
limiting their applicability. In this paper, we present a principled approach
for designing architectures that process gradients. Our approach is guided by
three principles: (1) equivariant design that preserves neuron permutation
symmetries, (2) processing sets of gradients across multiple data points to
capture curvature information, and (3) efficient gradient representation
through rank-1 decomposition. Based on these principles, we introduce
GradMetaNet, a novel architecture for learning on gradients, constructed from
simple equivariant blocks. We prove universality results for GradMetaNet, and
show that previous approaches cannot approximate natural gradient-based
functions that GradMetaNet can. We then demonstrate GradMetaNet's effectiveness
on a diverse set of gradient-based tasks on MLPs and transformers, such as
learned optimization, INR editing, and estimating loss landscape curvature.


## Exploring Classical Piano Performance Generation with Expressive Music Variational AutoEncoder

>Authors: Jing Luo, Xinyu Yang, Jie Wei

>2025-07-02

> http://arxiv.org/abs/2507.01582v1

The creativity of classical music arises not only from composers who craft
the musical sheets but also from performers who interpret the static notations
with expressive nuances. This paper addresses the challenge of generating
classical piano performances from scratch, aiming to emulate the dual roles of
composer and pianist in the creative process. We introduce the Expressive
Compound Word (ECP) representation, which effectively captures both the
metrical structure and expressive nuances of classical performances. Building
on this, we propose the Expressive Music Variational AutoEncoder (XMVAE), a
model featuring two branches: a Vector Quantized Variational AutoEncoder
(VQ-VAE) branch that generates score-related content, representing the
Composer, and a vanilla VAE branch that produces expressive details, fulfilling
the role of Pianist. These branches are jointly trained with similar Seq2Seq
architectures, leveraging a multiscale encoder to capture beat-level contextual
information and an orthogonal Transformer decoder for efficient compound tokens
decoding. Both objective and subjective evaluations demonstrate that XMVAE
generates classical performances with superior musical quality compared to
state-of-the-art models. Furthermore, pretraining the Composer branch on extra
musical score datasets contribute to a significant performance gain.


## SafePTR Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism

>Authors: Beitao Chen, Xinyu Lyu, Lianli Gao, Jingkuan Song, Heng Tao Shen

>2025-07-02

> http://arxiv.org/abs/2507.01513v1

By incorporating visual inputs, Multimodal Large Language Models (MLLMs)
extend LLMs to support visual reasoning. However, this integration also
introduces new vulnerabilities, making MLLMs susceptible to multimodal
jailbreak attacks and hindering their safe deployment.Existing defense methods,
including Image-to-Text Translation, Safe Prompting, and Multimodal Safety
Tuning, attempt to address this by aligning multimodal inputs with LLMs'
built-in safeguards.Yet, they fall short in uncovering root causes of
multimodal vulnerabilities, particularly how harmful multimodal tokens trigger
jailbreak in MLLMs? Consequently, they remain vulnerable to text-driven
multimodal jailbreaks, often exhibiting overdefensive behaviors and imposing
heavy training overhead.To bridge this gap, we present an comprehensive
analysis of where, how and which harmful multimodal tokens bypass safeguards in
MLLMs. Surprisingly, we find that less than 1% tokens in early-middle layers
are responsible for inducing unsafe behaviors, highlighting the potential of
precisely removing a small subset of harmful tokens, without requiring safety
tuning, can still effectively improve safety against jailbreaks. Motivated by
this, we propose Safe Prune-then-Restore (SafePTR), an training-free defense
framework that selectively prunes harmful tokens at vulnerable layers while
restoring benign features at subsequent layers.Without incurring additional
computational overhead, SafePTR significantly enhances the safety of MLLMs
while preserving efficiency. Extensive evaluations across three MLLMs and five
benchmarks demonstrate SafePTR's state-of-the-art performance in mitigating
jailbreak risks without compromising utility.


## Multi-Revolution Low-Thrust Trajectory Optimization With Very Sparse Mesh Pseudospectral Method

>Authors: Yilin Zou, Fanghua Jiang

>2025-07-02

> http://arxiv.org/abs/2507.01450v1

Multi-revolution low-thrust trajectory optimization problems are important
and challenging in space mission design. In this paper, an efficient, accurate,
and widely applicable pseudospectral method is proposed to solve
multi-revolution low-thrust trajectory optimization problems with various
objective functions and perturbations. The method is based on the Sundman
transformation and pseudospectral method, together with a **sparse** mesh that is
monotonic, near-uniformly spaced, and uniformly scattered on the unit circle.
Two methods are proposed to construct the mesh: a deterministic method based on
rotation mapping; a stochastic method utilizing autocorrelated random
sequences. Core mechanisms ensuring the correctness of the method are analyzed,
including the dual roles of mesh points as both integration points in the
temporal domain and sampling points in the angular domain, the slow dynamics of
the system excluding the fast angle variable, and the nearly commutative vector
fields generated by applying different control inputs. The method is
demonstrated through a multi-revolution low-thrust orbital rendezvous problem.
Results show that the proposed method achieves high accuracy with only a few
seconds of computational time for challenging problems.


## LogitSpec Accelerating Retrieval-based Speculative Decoding via Next Next Token Speculation

>Authors: Tianyu Liu, Qitan Lv, Hao Li, Xing Gao, Xiao Sun

>2025-07-02

> http://arxiv.org/abs/2507.01449v1

Speculative decoding (SD), where a small draft model is employed to propose
draft tokens in advance and then the target model validates them in parallel,
has emerged as a promising technique for LLM inference **acceleration**. Many
endeavors to improve SD are to eliminate the need for a draft model and
generate draft tokens in a retrieval-based manner in order to further alleviate
the drafting overhead and significantly reduce the difficulty in deployment and
applications. However, retrieval-based SD relies on a matching paradigm to
retrieval the most relevant reference as the draft tokens, where these methods
often fail to find matched and accurate draft tokens. To address this
challenge, we propose LogitSpec to effectively expand the retrieval range and
find the most relevant reference as drafts. Our LogitSpec is motivated by the
observation that the logit of the last token can not only predict the next
token, but also speculate the next next token. Specifically, LogitSpec
generates draft tokens in two steps: (1) utilizing the last logit to speculate
the next next token; (2) retrieving relevant reference for both the next token
and the next next token. LogitSpec is training-free and plug-and-play, which
can be easily integrated into existing LLM inference frameworks. Extensive
experiments on a wide range of text generation benchmarks demonstrate that
LogitSpec can achieve up to 2.61 $\times$ speedup and 3.28 mean accepted tokens
per decoding step. Our code is available at
https://github.com/smart-lty/LogitSpec.


## Clinical NLP with Attention-Based Deep Learning for Multi-Disease Prediction

>Authors: Ting Xu, Xiaoxiao Deng, Xiandong Meng, Haifeng Yang, Yan Wu

>2025-07-02

> http://arxiv.org/abs/2507.01437v1

This paper addresses the challenges posed by the unstructured nature and
high-dimensional semantic complexity of electronic health record texts. A deep
learning method based on attention mechanisms is proposed to achieve unified
modeling for information extraction and multi-label disease prediction. The
study is conducted on the MIMIC-IV dataset. A Transformer-based architecture is
used to perform representation learning over clinical text. Multi-layer
self-attention mechanisms are employed to capture key medical entities and
their contextual relationships. A Sigmoid-based multi-label classifier is then
applied to predict multiple disease labels. The model incorporates a
context-aware semantic alignment mechanism, enhancing its representational
capacity in typical medical scenarios such as label co-occurrence and **sparse**
information. To comprehensively evaluate model performance, a series of
experiments were conducted, including baseline comparisons, hyperparameter
sensitivity analysis, data perturbation studies, and noise injection tests.
Results demonstrate that the proposed method consistently outperforms
representative existing approaches across multiple performance metrics. The
model maintains strong generalization under varying data scales, interference
levels, and model depth configurations. The framework developed in this study
offers an efficient algorithmic foundation for processing real-world clinical
texts and presents practical significance for multi-label medical text modeling
tasks.


## Decomposing Prediction Mechanisms for In-Context Recall

>Authors: Sultan Daniels, Dylan Davis, Dhruv Gautam, Wentinn Liao, Gireeja Ranade, Anant Sahai

>2025-07-02

> http://arxiv.org/abs/2507.01414v1

We introduce a new family of toy problems that combine features of
linear-regression-style continuous in-context learning (ICL) with discrete
associative recall. We pretrain transformer models on sample traces from this
toy, specifically symbolically-labeled interleaved state observations from
randomly drawn linear deterministic dynamical systems. We study if the
transformer models can recall the state of a sequence previously seen in its
context when prompted to do so with the corresponding in-context label. Taking
a closer look at this task, it becomes clear that the model must perform two
functions: (1) identify which system's state should be recalled and apply that
system to its last seen state, and (2) continuing to apply the correct system
to predict the subsequent states. Training dynamics reveal that the first
capability emerges well into a model's training. Surprisingly, the second
capability, of continuing the prediction of a resumed sequence, develops much
earlier.
  Via out-of-distribution experiments, and a mechanistic analysis on model
weights via edge **pruning**, we find that next-token prediction for this toy
problem involves at least two separate mechanisms. One mechanism uses the
discrete symbolic labels to do the associative recall required to predict the
start of a resumption of a previously seen sequence. The second mechanism,
which is largely agnostic to the discrete symbolic labels, performs a
"Bayesian-style" prediction based on the previous token and the context. These
two mechanisms have different learning dynamics.
  To confirm that this multi-mechanism (manifesting as separate phase
transitions) phenomenon is not just an artifact of our toy setting, we used
OLMo training checkpoints on an ICL translation task to see a similar
phenomenon: a decisive gap in the emergence of first-task-token performance vs
second-task-token performance.


## Dose-Escalation Trial Protocols that Extend Naturally to Admit Titration

>Authors: David C. Norris

>2025-07-02

> http://arxiv.org/abs/2507.01370v1

Dose-escalation trials in oncology drug development still today typically aim
to identify 1-size-fits-all dose recommendations, as arbitrary quantiles of the
toxicity thresholds evident in patient samples. In the late 1990s efforts to
individualize dosing emerged fleetingly in the oncology trial methods
literature, but these have gained little traction due to a nexus of conceptual,
technical, commercial, and regulatory barriers. To reduce the activation energy
needed for transforming current 1-size-fits-all dose-escalation trial designs
to the dose-titration designs required for patient-centered dose
individualization, we demonstrate a categorical formulation of dose-escalation
protocols that extends readily to allow gradual introduction of dose titration.
  Central to this formulation is a symmetric monoidal preorder on the
accessible states of dose-escalation trials, embodying pharmacologic intuitions
regarding dose-monotonicity of drug toxicity and ethical intuitions relating to
the therapeutic intent of such trials. A trial protocol that assigns doses to
enrolling participants consistently with these intuitions is then a monotone
map from this preorder to the sequence of doses being trialed. We illustrate
this formulation by reference to the ubiquitous 3+3 dose-escalation design,
which despite its many widely discussed flaws remains familiar to oncology
trialists and moreover has available an executable specification in Prolog.
Remarkably, examined in light of our preorder the 3+3 protocol discloses a new
flaw not previously described: a non-monotone dose recommendation. The right
Kan extension approximates this protocol from the side of safety, dissolving
its triplet cohorts to allow incremental enrollment, and rectifying said
non-monotonicity. It also facilitates accelerated enrollment while toxicity
assessments remain pending, as well as discretionary dose titration.


## Long-Tailed Distribution-Aware Router For Mixture-of-Experts in Large Vision-Language Model

>Authors: Chaoxiang Cai, Longrong Yang, Kaibing Chen, Fan Yang, Xi Li

>2025-07-02

> http://arxiv.org/abs/2507.01351v1

The mixture-of-experts (MoE), which replaces dense models with **sparse**
architectures, has gained attention in large vision-language models (LVLMs) for
achieving comparable performance with fewer activated parameters. Existing MoE
frameworks for LVLMs focus on token-to-expert routing (TER), encouraging
different experts to specialize in processing distinct tokens. However, these
frameworks often rely on the load balancing mechanism, overlooking the inherent
distributional differences between vision and language. To this end, we propose
a Long-Tailed Distribution-aware Router (LTDR) for vision-language TER,
tackling two challenges: (1) Distribution-aware router for modality-specific
routing. We observe that language TER follows a uniform distribution, whereas
vision TER exhibits a long-tailed distribution. This discrepancy necessitates
distinct routing strategies tailored to each modality. (2) Enhancing expert
activation for vision tail tokens. Recognizing the importance of vision tail
tokens, we introduce an oversampling-like strategy by increasing the number of
activated experts for these tokens. Experiments on extensive benchmarks
validate the effectiveness of our approach.


## SpeechAccentLLM A Unified Framework for Foreign Accent Conversion and Text to Speech

>Authors: Cheng Zhuangfei, Zhang Guangyan, Tu Zehai, Song Yangyang, Mao Shuiyang, Jiao Xiaoqi, Li Jingyu, Guo Yiwen, Wu Jiasong

>2025-07-02

> http://arxiv.org/abs/2507.01348v1

Foreign accent conversion (FAC) in speech processing remains a challenging
task. Building on the remarkable success of large language models (LLMs) in
Text-to-Speech (TTS) tasks, this study investigates the adaptation of LLM-based
techniques for FAC, which we term SpeechAccentLLM. At the core of this
framework, we introduce SpeechCodeVAE, the first model to integrate
connectionist temporal classification (CTC) directly into codebook
discretization for speech content tokenization. This novel architecture
generates tokens with a unique "locality" property, as validated by experiments
demonstrating optimal trade-offs among content faithfulness, temporal
coherence, and structural recoverability. Then, to address data scarcity for
the FAC module, we adopted a multitask learning strategy that jointly trains
the FAC and TTS modules. Beyond mitigating data limitations, this approach
yielded accelerated convergence and superior speech quality compared to
standalone FAC training. Moreover, leveraging the salient properties of our
discrete speech representations, we introduce SpeechRestorer, a postprocessing
architecture designed to refine LLM-generated outputs. This module effectively
mitigates stochastic errors prevalent in LLM inference pipelines while
enhancing prosodic continuity, as validated by ablation experiments.


## Robust Multi-generation Learned Compression of Point Cloud Attribute

>Authors: Xiangzuo Liu, Zhikai Liu, PengPeng Yu, Ruishan Huang, Fan Liang

>2025-07-02

> http://arxiv.org/abs/2507.01320v1

Existing learned point cloud attribute compression methods primarily focus on
single-pass rate-distortion optimization, while overlooking the issue of
cumulative distortion in multi-generation compression scenarios. This paper,
for the first time, investigates the multi-generation issue in learned point
cloud attribute compression. We identify two primary factors contributing to
quality degradation in multi-generation compression: **quantization**-induced
non-idempotency and transformation irreversibility. To address the former, we
propose a Mapping Idempotency Constraint, that enables the network to learn the
complete compression-decompression mapping, enhancing its robustness to
repeated processes. To address the latter, we introduce a Transformation
Reversibility Constraint, which preserves reversible information flow via a
**quantization**-free training path. Further, we propose a Latent Variable
Consistency Constraint which enhances the multi-generation compression
robustness by incorporating a decompression-compression cross-generation path
and a latent variable consistency loss term. Extensive experiments conducted on
the Owlii and 8iVFB datasets verify that the proposed methods can effectively
suppress multi-generation loss while maintaining single-pass rate-distortion
performance comparable to baseline models.


## SD-Acc Accelerating Stable Diffusion through Phase-aware Sampling and Hardware Co-Optimizations

>Authors: Zhican Wang, Guanghui He, Hongxiang Fan

>2025-07-02

> http://arxiv.org/abs/2507.01309v1

The emergence of diffusion models has significantly advanced generative AI,
improving the quality, realism, and creativity of image and video generation.
Among them, Stable Diffusion (StableDiff) stands out as a key model for
text-to-image generation and a foundation for next-generation multi-modal
algorithms. However, its high computational and memory demands hinder inference
speed and energy efficiency. To address these challenges, we identify three
core issues: (1) intensive and often redundant computations, (2) heterogeneous
operations involving convolutions and attention mechanisms, and (3) diverse
weight and activation sizes.
  We present SD-Acc, a novel algorithm and hardware co-optimization framework.
At the algorithm level, we observe that high-level features in certain
denoising phases show significant similarity, enabling approximate computation.
Leveraging this, we propose an adaptive, phase-aware sampling strategy that
reduces compute and memory loads. This framework automatically balances image
quality and complexity based on the StableDiff model and user requirements. At
the hardware level, we design an address-centric dataflow to efficiently handle
heterogeneous operations within a simple systolic array. We address the
bottleneck of nonlinear functions via a two-stage streaming architecture and a
reconfigurable vector processing unit. Additionally, we implement adaptive
dataflow optimizations by combining dynamic reuse and operator fusion tailored
to StableDiff workloads, significantly reducing memory access. Across multiple
StableDiff models, our method achieves up to a 3x reduction in computational
demand without compromising image quality. Combined with our optimized hardware
accelerator, SD-Acc delivers higher speed and energy efficiency than
traditional CPU and GPU implementations.


## La RoSA Enhancing LLM Efficiency via Layerwise Rotated Sparse Activation

>Authors: Kai Liu, Bowen Xu, Shaoyu Wu, Xin Chen, Hao Zhou, Yongliang Tao, Lulu Hu

>2025-07-02

> http://arxiv.org/abs/2507.01299v1

Activation **sparsity** can reduce the computational overhead and memory
transfers during the forward pass of Large Language Model (LLM) inference.
Existing methods face limitations, either demanding time-consuming recovery
training that hinders real-world adoption, or relying on empirical
magnitude-based **pruning**, which causes fluctuating **sparsity** and unstable
inference speed-up. This paper introduces LaRoSA (Layerwise Rotated Sparse
Activation), a novel method for activation sparsification designed to improve
LLM efficiency without requiring additional training or magnitude-based
**pruning**. We leverage layerwise orthogonal rotations to transform input
activations into rotated forms that are more suitable for sparsification. By
employing a Top-K selection approach within the rotated activations, we achieve
consistent model-level **sparsity** and reliable wall-clock time speed-up. LaRoSA
is effective across various sizes and types of LLMs, demonstrating minimal
performance degradation and robust inference **acceleration**. Specifically, for
LLaMA2-7B at 40% **sparsity**, LaRoSA achieves a mere 0.17 perplexity gap with a
consistent 1.30x wall-clock time speed-up, and reduces the accuracy gap in
zero-shot tasks compared to the dense model to just 0.54%, while surpassing
TEAL by 1.77% and CATS by 17.14%.


## PAE MobiLLM Privacy-Aware and Efficient LLM Fine-Tuning on the Mobile Device via Additive Side-Tuning

>Authors: Xingke Yang, Liang Li, Zhiyi Wan, Sicong Li, Hao Wang, Xiaoqi Qi, Jiang Liu, Tomoaki Ohtsuki, Xin Fu, Miao Pan

>2025-07-01

> http://arxiv.org/abs/2507.01216v1

There is a huge gap between numerous intriguing applications fostered by
on-device large language model (LLM) fine-tuning (FT) from fresh mobile data
and the limited resources of a mobile device. While existing server-assisted
methods (e.g., split learning or side-tuning) may enable LLM FT on the local
mobile device, they suffer from heavy communication burdens of activation
transmissions, and may disclose data, labels or fine-tuned models to the
server. To address those issues, we develop PAE MobiLLM, a privacy-aware and
efficient LLM FT method which can be deployed on the mobile device via
server-assisted additive side-tuning. To further accelerate FT convergence and
improve computing efficiency, PAE MobiLLM integrates activation caching on the
server side, which allows the server to reuse historical activations and saves
the mobile device from repeatedly computing forward passes for the recurring
data samples. Besides, to reduce communication cost, PAE MobiLLM develops a
one-token (i.e., ``pivot'' token) activation shortcut that transmits only a
single activation dimension instead of full activation matrices to guide the
side network tuning. Last but not least, PAE MobiLLM introduces the additive
adapter side-network design which makes the server train the adapter modules
based on device-defined prediction differences rather than raw ground-truth
labels. In this way, the server can only assist device-defined side-network
computing, and learn nothing about data, labels or fine-tuned models.


## An Adaptive Estimation Approach based on Fisher Information to Overcome the Challenges of LFP Battery SOC Estimation

>Authors: Junzhe Shi, Shida Jiang, Shengyu Tao, Jaewong Lee, Manashita Borah, Scott Moura

>2025-07-01

> http://arxiv.org/abs/2507.01173v1

Robust and Real-time State of Charge (SOC) estimation is essential for
Lithium Iron Phosphate (LFP) batteries, which are widely used in electric
vehicles (EVs) and energy storage systems due to safety and longevity. However,
the flat Open Circuit Voltage (OCV)-SOC curve makes this task particularly
challenging. This challenge is complicated by hysteresis effects, and
real-world conditions such as current bias, voltage **quantization** errors, and
temperature that must be considered in the battery management system use. In
this paper, we proposed an adaptive estimation approach to overcome the
challenges of LFPSOC estimation. Specifically, the method uses an adaptive
fisher information fusion strategy that adaptively combines the SOC estimation
from two different models, which are Coulomb counting and equivalent circuit
model-based parameter identification. The effectiveness of this strategy is
rationalized by the information richness excited by external cycling signals. A
3D OCV-H-SOC map that captures the relationship between OCV, hysteresis, and
SOC was proposed as the backbone, and can be generalizable to other widely
adopted parameter-identification methods. Extensive validation under ideal and
real-world use scenarios, including SOC-OCV flat zones, current bias, voltage
**quantization** errors, low temperatures, and insufficient current excitations,
have been performed using 4 driving profiles, i.e., the Orange County Transit
Bus Cycle, the California Unified Cycle, the US06 Drive Cycle, and the New York
City Cycle, where the results demonstrate superiority over the state-of-the-art
unscented Kalman filter, long short-term memory networks and transformer in all
validation cases.


## Turning AI Data Centers into Grid-Interactive Assets Results from a Field Demonstration in Phoenix, Arizona

>Authors: Philip Colangelo, Ayse K. Coskun, Jack Megrue, Ciaran Roberts, Shayan Sengupta, Varun Sivaram, Ethan Tiao, Aroon Vijaykar, Chris Williams, Daniel C. Wilson, Zack MacFarland, Daniel Dreiling, Nathan Morey, Anuja Ratnayake, Baskar Vairamohan

>2025-07-01

> http://arxiv.org/abs/2507.00909v1

Artificial intelligence (AI) is fueling exponential electricity demand
growth, threatening grid reliability, raising prices for communities paying for
new energy infrastructure, and stunting AI innovation as data centers wait for
interconnection to constrained grids. This paper presents the first field
demonstration, in collaboration with major corporate partners, of a
software-only approach--Emerald Conductor--that transforms AI data centers into
flexible grid resources that can efficiently and immediately harness existing
power systems without massive infrastructure buildout. Conducted at a 256-GPU
cluster running representative AI workloads within a commercial, hyperscale
cloud data center in Phoenix, Arizona, the trial achieved a 25% reduction in
cluster power usage for three hours during peak grid events while maintaining
AI quality of service (QoS) guarantees. By orchestrating AI workloads based on
real-time grid signals without hardware modifications or energy storage, this
platform reimagines data centers as grid-interactive assets that enhance grid
reliability, advance affordability, and accelerate AI's development.


## Enhancing Vehicular Platooning with Wireless Federated Learning A Resource-Aware Control Framework

>Authors: Beining Wu, Jun Huang, Qiang Duan, Liang Dong, Zhipeng Cai

>2025-07-01

> http://arxiv.org/abs/2507.00856v1

This paper aims to enhance the performance of Vehicular Platooning (VP)
systems integrated with Wireless Federated Learning (WFL). In highly dynamic
environments, vehicular platoons experience frequent communication changes and
resource constraints, which significantly affect information exchange and
learning model synchronization. To address these challenges, we first formulate
WFL in VP as a joint optimization problem that simultaneously considers Age of
Information (AoI) and Federated Learning Model Drift (FLMD) to ensure timely
and accurate control. Through theoretical analysis, we examine the impact of
FLMD on convergence performance and develop a two-stage Resource-Aware Control
framework (RACE). The first stage employs a Lagrangian dual decomposition
method for resource configuration, while the second stage implements a
multi-agent deep reinforcement learning approach for vehicle selection. The
approach integrates Multi-Head Self-Attention and Long Short-Term Memory
networks to capture spatiotemporal correlations in communication states.
Experimental results demonstrate that, compared to baseline methods, the
proposed framework improves AoI optimization by up to 45%, accelerates learning
convergence, and adapts more effectively to dynamic VP environments on the
AI4MARS dataset.


## VEDA Efficient LLM Generation Through Voting-based KV Cache Eviction and Dataflow-flexible Accelerator

>Authors: Zhican Wang, Hongxiang Fan, Haroon Waris, Gang Wang, Zhenyu Li, Jianfei Jiang, Yanan Sun, Guanghui He

>2025-07-01

> http://arxiv.org/abs/2507.00797v1

Large Language Models (LLMs) excel in natural language processing tasks but
pose significant computational and memory challenges for edge deployment due to
their intensive resource demands. This work addresses the efficiency of LLM
inference by algorithm-hardware-dataflow tri-optimizations. We propose a novel
voting-based **KV** cache eviction algorithm, balancing hardware efficiency and
algorithm accuracy by adaptively identifying unimportant kv vectors. From a
dataflow perspective, we introduce a flexible-product dataflow and a runtime
reconfigurable PE array for matrix-vector multiplication. The proposed approach
effectively handles the diverse dimensional requirements and solves the
challenges of incrementally varying sequence lengths. Additionally, an
element-serial scheduling scheme is proposed for nonlinear operations, such as
softmax and layer normalization (layernorm). Results demonstrate a substantial
reduction in latency, accompanied by a significant decrease in hardware
complexity, from O(N) to O(1). The proposed solution is realized in a
custom-designed accelerator, VEDA, which outperforms existing hardware
platforms. This research represents a significant advancement in LLM inference
on resource-constrained edge devices, facilitating real-time processing,
enhancing data privacy, and enabling model customization.


## OptiPrune Boosting Prompt-Image Consistency with Attention-Guided Noise and Dynamic Token Selection

>Authors: Ziji Lu

>2025-07-01

> http://arxiv.org/abs/2507.00789v1

Text-to-image diffusion models often struggle to achieve accurate semantic
alignment between generated images and text prompts while maintaining
efficiency for deployment on resource-constrained hardware. Existing approaches
either incur substantial computational overhead through noise optimization or
compromise semantic fidelity by aggressively **pruning** tokens. In this work, we
propose OptiPrune, a unified framework that combines distribution-aware initial
noise optimization with similarity-based token **pruning** to address both
challenges simultaneously. Specifically, (1) we introduce a distribution-aware
noise optimization module guided by attention scores to steer the initial
latent noise toward semantically meaningful regions, mitigating issues such as
subject neglect and feature entanglement; (2) we design a hardware-efficient
token **pruning** strategy that selects representative base tokens via patch-wise
similarity, injects randomness to enhance generalization, and recovers pruned
tokens using maximum similarity copying before attention operations. Our method
preserves the Gaussian prior during noise optimization and enables efficient
inference without sacrificing alignment quality. Experiments on benchmark
datasets, including Animal-Animal, demonstrate that OptiPrune achieves
state-of-the-art prompt-image consistency with significantly reduced
computational cost.


## Echoes of AI Investigating the Downstream Effects of AI Assistants on Software Maintainability

>Authors: Markus Borg, Dave Hewett, Nadim Hagatulah, Noric Couderc, Emma Söderberg, Donald Graham, Uttam Kini, Dave Farley

>2025-07-01

> http://arxiv.org/abs/2507.00788v1

[Context] AI assistants, like GitHub Copilot and Cursor, are transforming
software engineering. While several studies highlight productivity
improvements, their impact on maintainability requires further investigation.
[Objective] This study investigates whether co-development with AI assistants
affects software maintainability, specifically how easily other developers can
evolve the resulting source code. [Method] We conducted a two-phase controlled
experiment involving 151 participants, 95% of whom were professional
developers. In Phase 1, participants added a new feature to a Java web
application, with or without AI assistance. In Phase 2, a randomized controlled
trial, new participants evolved these solutions without AI assistance.
[Results] AI-assisted development in Phase 1 led to a modest speedup in
subsequent evolution and slightly higher average CodeHealth. Although neither
difference was significant overall, the increase in CodeHealth was
statistically significant when habitual AI users completed Phase 1. For Phase
1, we also observed a significant effect that corroborates previous
productivity findings: using an AI assistant yielded a 30.7% median decrease in
task completion time. Moreover, for habitual AI users, the mean speedup was
55.9%. [Conclusions] Our study adds to the growing evidence that AI assistants
can effectively accelerate development. Moreover, we did not observe warning
signs of degraded code-level maintainability. We recommend that future research
focus on risks such as code bloat from excessive code generation and the
build-up of cognitive debt as developers invest less mental effort during
implementation.


## Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess

>Authors: Dongyoon Hwang, Hojoon Lee, Jaegul Choo, Dongmin Park, Jongho Park

>2025-07-01

> http://arxiv.org/abs/2507.00726v2

While reinforcement learning (RL) for large language models (LLMs) has shown
promise in mathematical reasoning, strategic reasoning for LLMs using RL
remains largely unexplored. We investigate whether LLMs can develop strategic
reasoning capabilities through RL in chess. To this end, we leverage a
chess-pretrained action-value network to provide dense reward on the LLM's
output move quality, which can be seen as a form of knowledge distillation. Our
experiments show that our distillation-based dense rewards often outperform
**sparse** binary rewards. However, surprisingly, all models plateau far below
expert levels. We provide SFT and RL ablations on chess reasoning training and
find evidence that this limitation stems from a deficit in the pretrained
models' internal understanding of chess--a deficit which RL alone may not be
able to fully overcome.


## EARN Efficient Inference Acceleration for LLM-based Generative Recommendation by Register Tokens

>Authors: Chaoqun Yang, Xinyu Lin, Wenjie Wang, Yongqi Li, Teng Sun, Xianjing Han, Tat-Seng Chua

>2025-07-01

> http://arxiv.org/abs/2507.00715v1

Large Language Model-based generative recommendation (LLMRec) has achieved
notable success, but it suffers from high inference latency due to massive
computational overhead and memory pressure of **KV** Cache. Existing **KV** Cache
reduction methods face critical limitations: cache compression offers marginal
**acceleration** given recommendation tasks' short decoding steps, while prompt
compression risks discarding vital interaction history. Through systematic
analysis of attention patterns in LLMRec, we uncover two pivotal insights: 1)
layer-wise attention **sparsity** inversion where early layers retain dense
informative patterns while later layers exhibit high redundancy, and 2) dual
attention sinks phenomenon where attention scores concentrate on both head and
tail tokens of input sequences. Motivated by these insights, we propose EARN,
an efficient inference framework that leverages the early layers to compress
information into register tokens placed at the input sequence boundaries, then
focuses solely on these tokens in the subsequent layers. Extensive experiments
on three datasets, two LLMRec methods and two LLM architectures demonstrate
EARN's superiority, achieving up to 3.79x speedup and 80.8% **KV** Cache reduction
with better accuracy than the general finetuning approach. Our work bridges the
efficiency-effectiveness gap in LLMRec, offering practical deployment
advantages for industrial scenarios.


## SAFER Probing Safety in Reward Models with Sparse Autoencoder

>Authors: Sihang Li, Wei Shi, Ziyuan Xie, Tao Liang, Guojun Ma, Xiang Wang

>2025-07-01

> http://arxiv.org/abs/2507.00665v1

Reinforcement learning from human feedback (RLHF) is a key paradigm for
aligning large language models (LLMs) with human values, yet the reward models
at its core remain largely opaque. In this work, we present **sparse** Autoencoder
For Enhanced Reward model (\textbf{SAFER}), a novel framework for interpreting
and improving reward models through mechanistic analysis. Leveraging Sparse
Autoencoders (SAEs), we uncover human-interpretable features in reward model
activations, enabling insight into safety-relevant decision-making. We apply
SAFER to safety-oriented preference datasets and quantify the salience of
individual features by activation differences between chosen and rejected
responses. Using these feature-level signals, we design targeted data poisoning
and denoising strategies. Experiments show that SAFER can precisely degrade or
enhance safety alignment with minimal data modification, without sacrificing
general chat performance. Our approach contributes to interpreting, auditing
and refining reward models in high-stakes LLM alignment tasks. Our codes are
available at https://github.com/xzy-101/SAFER-code. \textit{This paper
discusses topics related to large language model safety and may include
discussions or examples that highlight potential risks or unsafe outcomes.}


## MTCNet Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound

>Authors: Rusi Chen, Yuanting Yang, Jiezhi Yao, Hongning Song, Ji Zhang, Yongsong Zhou, Yuhao Huang, Ronghao Yang, Dan Jia, Yuhan Zhang, Xing Tao, Haoran Dou, Qing Zhou, Xin Yang, Dong Ni

>2025-07-01

> http://arxiv.org/abs/2507.00660v2

Mitral regurgitation is one of the most prevalent cardiac disorders.
Four-dimensional (4D) ultrasound has emerged as the primary imaging modality
for assessing dynamic valvular morphology. However, 4D mitral valve (MV)
analysis remains challenging due to limited phase annotations, severe motion
artifacts, and poor imaging quality. Yet, the absence of inter-phase dependency
in existing methods hinders 4D MV analysis. To bridge this gap, we propose a
Motion-Topology guided consistency network (MTCNet) for accurate 4D MV
ultrasound segmentation in semi-supervised learning (SSL). MTCNet requires only
**sparse** end-diastolic and end-systolic annotations. First, we design a
cross-phase motion-guided consistency learning strategy, utilizing a
bi-directional attention memory bank to propagate spatio-temporal features.
This enables MTCNet to achieve excellent performance both per- and inter-phase.
Second, we devise a novel topology-guided correlation regularization that
explores physical prior knowledge to maintain anatomically plausible.
Therefore, MTCNet can effectively leverage structural correspondence between
labeled and unlabeled phases. Extensive evaluations on the first largest 4D MV
dataset, with 1408 phases from 160 patients, show that MTCNet performs superior
cross-phase consistency compared to other advanced methods (Dice: 87.30%, HD:
1.75mm). Both the code and the dataset are available at
https://github.com/crs524/MTCNet.


## ChatHLS Towards Systematic Design Automation and Optimization for High-Level Synthesis

>Authors: Runkai Li, Jia Xiong, Xiuyuan He, Jieru Zhao, Qiang Xu, Xi Wang

>2025-07-01

> http://arxiv.org/abs/2507.00642v1

The increasing complexity of computational demands has accelerated the
adoption of domain-specific accelerators, yet traditional hardware design
methodologies remain constrained by prolonged development and verification
cycles. High-Level Synthesis (HLS) bridges the gap between software and
hardware by enabling hardware design from high-level programming languages.
However, its widespread adoption is hindered by strict coding constraints and
intricate hardware-specific optimizations, creating significant obstacles for
developers. Recent advancements in Large Language Models (LLMs) demonstrate
substantial potential in hardware design automation. However, their
effectiveness is limited by the scarcity of high-quality datasets, particularly
in the context of HLS. To address these challenges, we introduce ChatHLS, an
agile HLS design automation and optimization workflow that leverages fine-tuned
LLMs integrated within a multi-agent framework for error correction and design
optimization. Our extensive evaluations reveal that ChatHLS achieves an average
repair pass rate of 82.7% over 612 test cases, outperforming the GPT-4o and
Llama3-8B by 19.1% and 63.0%, respectively. Furthermore, ChatHLS delivers
performance enhancements ranging from 1.9$\times$ to 14.8$\times$ upon
resource-constrained kernels. By enabling sophisticated optimization reasoning
within practical computational budgets, ChatHLS attains a 4.9$\times$ geometric
mean speedup compared to state-of-the-art DSL-based approaches. These results
underscore the potential of ChatHLS in substantially expediting hardware
development cycles while maintaining rigorous standards of design reliability
and optimization quality.


## Quantize-Sample-and-Verify LLM Acceleration via Adaptive Edge-Cloud Speculative Decoding

>Authors: Guangyi Zhang, Yunlong Cai, Guanding Yu, Petar Popovski, Osvaldo Simeone

>2025-07-01

> http://arxiv.org/abs/2507.00605v1

In edge-cloud speculative decoding (SD), edge devices equipped with small
language models (SLMs) generate draft tokens that are verified by large
language models (LLMs) in the cloud. A key bottleneck in such systems is the
limited communication bandwidth between edge and cloud, which necessitates
**quantization** of the information transmitted about generated tokens. In this
work, we introduce a novel **quantize**-sample (Q-S) strategy that provably
preserves the output distribution of the cloud-based model, ensuring that the
verified tokens match the distribution of those that would have been generated
directly by the LLM. We develop a throughput model for edge-cloud SD that
explicitly accounts for communication latency. Leveraging this model, we
propose an adaptive mechanism that optimizes token throughput by dynamically
adjusting the draft length and **quantization** precision in response to both
semantic uncertainty and channel conditions. Simulations demonstrate that the
proposed Q-S approach significantly improves decoding efficiency in realistic
edge-cloud deployment scenarios.


## Neural translation for Stokes inversion and synthesis

>Authors: A. Asensio Ramos, J. de la Cruz Rodriguez

>2025-07-01

> http://arxiv.org/abs/2507.00594v1

[Abridged] The physical conditions in stellar atmospheres can be obtained
from the interpretation of solar spectro-polarimetric observations. However,
traditional inversion codes are computationally demanding, especially for lines
whose formation is complex. The necessity of faster alternatives has motivated
the emergence of machine learning solutions. This paper introduces an approach
to the inversion and synthesis of Stokes profiles inspired by neural machine
translation. Our aim is to develop a generative model that treats Stokes
profiles and atmospheric models as two distinct ``languages'' encoding the same
physical reality. We build a model that learns how to translate between them,
also providing estimates of the uncertainty. We employ a tokenization strategy
for both Stokes parameters and model atmospheres, which is learned using a
VQ-VAE, a neural model used to compress the data into a lower dimensionality
form. The core of our inversion code utilizes a transformer encoder-decoder
architecture to perform the translation between these tokenized
representations. The model is trained on a database of synthetic Stokes
profiles derived from perturbations to various semi-empirical solar atmospheric
models, ensuring a wide range of expected solar physical conditions. The method
effectively reconstructs atmospheric models from observed Stokes profiles,
showing better constrained models within the region of sensitivity of the
considered spectral lines. The latent representation induced by the VQ-VAE
helps accelerate the inversion by compressing the length of the Stokes profiles
and model atmospheres. Additionally, it helps regularize the solution by
reducing the chances of obtaining unphysical models. As a final advantage, the
method provides the generative nature of our model, which naturally yields an
estimate of the uncertainty in the solution.


## Cyber Attacks Detection, Prevention, and Source Localization in Digital Substation Communication using Hybrid Statistical-Deep Learning

>Authors: Nicola Cibin, Bas Mulder, Herman Carstens, Peter Palensky, Alexandru Ştefanov

>2025-07-01

> http://arxiv.org/abs/2507.00522v1

The digital transformation of power systems is accelerating the adoption of
IEC 61850 standard. However, its communication protocols, including Sampled
Values (SV), lack built-in security features such as authentication and
encryption, making them vulnerable to malicious packet injection. Such cyber
attacks can delay fault clearance or trigger unintended circuit breaker
operations. While most existing research focuses on detecting cyber attacks in
digital substations, intrusion prevention systems have been disregarded because
of the risk of potential communication network disruptions. This paper proposes
a novel method using hybrid statistical-deep learning for the detection,
prevention, and source localization of IEC 61850 SV injection attacks. The
method uses exponentially modified Gaussian distributions to model
communication network latency and long short-term memory and Elman recurrent
neural network to detect anomalous variations in the estimated probability
distributions. It effectively discards malicious SV frames with minimal
processing overhead and latency, maintains robustness against communication
network latency variation and time-synchronization issues, and guarantees a
near-zero false positive rate in non-attack scenarios. Comprehensive validation
is conducted on three testbeds involving industrial-grade devices,
hardware-in-the-loop simulations, virtualized intelligent electronic devices
and merging units, and high-fidelity emulated communication networks. Results
demonstrate the method's suitability for practical deployment in IEC
61850-compliant digital substations.


## LLM-Mesh Enabling Elastic Sharing for Serverless LLM Inference

>Authors: Chuhao Xu, Zijun Li, Quan Chen, Han Zhao, Minyi Guo

>2025-07-01

> http://arxiv.org/abs/2507.00507v1

The rise of LLMs has driven demand for private serverless deployments,
characterized by moderate-scale models and infrequent requests. While existing
solutions follow exclusive GPU deployment, we take a step back to explore
modern platforms and find that: Emerging CPU architectures with built-in
accelerators are capable of serving LLMs but remain underutilized, and both
CPUs and GPUs can accommodate multiple LLMs simultaneously.
  We propose LLM-Mesh, a serverless inference scheme for small-to-mid-sized
LLMs that enables elastic sharing across heterogeneous hardware. LLM-Mesh
tackles three fundamental challenges: (1) precise, fine-grained compute
resource allocation at token-level to handle fluctuating computational demands;
(2) a coordinated and forward-looking memory scaling mechanism to detect
out-of-memory hazards and reduce operational overhead; and (3) a dual approach
that reduces resource fragmentation through proactive preemption and reactive
bin-packing. Experimental results on 4 32-core CPUs and 4 A100 GPUs show that
LLM-Meshimproves service capacity by 44% - 63% through sharing, while further
leveraging CPUs boosts this to 91% - 159%.


## On Mitigating Data Sparsity in Conversational Recommender Systems

>Authors: Sixiao Zhang, Mingrui Liu, Cheng Long, Wei Yuan, Hongxu Chen, Xiangyu Zhao, Hongzhi Yin

>2025-07-01

> http://arxiv.org/abs/2507.00479v1

Conversational recommender systems (CRSs) capture user preference through
textual information in dialogues. However, they suffer from data **sparsity** on
two fronts: the dialogue space is vast and linguistically diverse, while the
item space exhibits long-tail and **sparse** distributions. Existing methods
struggle with (1) generalizing to varied dialogue expressions due to
underutilization of rich textual cues, and (2) learning informative item
representations under severe **sparsity**. To address these problems, we propose a
CRS model named DACRS. It consists of three modules, namely Dialogue
Augmentation, Knowledge-Guided Entity Modeling, and Dialogue-Entity Matching.
In the Dialogue Augmentation module, we apply a two-stage augmentation pipeline
to augment the dialogue context to enrich the data and improve
generalizability. In the Knowledge-Guided Entity Modeling, we propose a
knowledge graph (KG) based entity substitution and an entity similarity
constraint to enhance the expressiveness of entity embeddings. In the
Dialogue-Entity Matching module, we fuse the dialogue embedding with the
mentioned entity embeddings through a dialogue-guided attention aggregation to
acquire user embeddings that contain both the explicit and implicit user
preferences. Extensive experiments on two public datasets demonstrate the
state-of-the-art performance of DACRS.


## Overcoming Long-Context Limitations of State-Space Models via Context-Dependent Sparse Attention

>Authors: Zhihao Zhan, Jianan Zhao, Zhaocheng Zhu, Jian Tang

>2025-07-01

> http://arxiv.org/abs/2507.00449v1

Efficient long-context modeling remains a critical challenge for natural
language processing (NLP), as the time complexity of the predominant
Transformer architecture scales quadratically with the sequence length. While
state-space models (SSMs) offer alternative sub-quadratic solutions, they
struggle to capture long-range dependencies effectively. In this work, we focus
on analyzing and improving the long-context modeling capabilities of SSMs. We
show that the widely used synthetic task, associative recall, which requires a
model to recall a value associated with a single key without context,
insufficiently represents the complexities of real-world long-context modeling.
To address this limitation, we extend the associative recall to a novel
synthetic task, \emph{joint recall}, which requires a model to recall the value
associated with a key given in a specified context. Theoretically, we prove
that SSMs do not have the expressiveness to solve multi-query joint recall in
sub-quadratic time complexity. To resolve this issue, we propose a solution
based on integrating SSMs with Context-Dependent Sparse Attention (CDSA), which
has the expressiveness to solve multi-query joint recall with sub-quadratic
computation. To bridge the gap between theoretical analysis and real-world
applications, we propose locality-sensitive Hashing Attention with **sparse** Key
Selection (HAX), which instantiates the theoretical solution and is further
tailored to natural language domains. Extensive experiments on both synthetic
and real-world long-context benchmarks show that HAX consistently outperforms
SSM baselines and SSMs integrated with context-independent **sparse** attention
(CISA).


## Serving LLMs in HPC Clusters A Comparative Study of Qualcomm Cloud AI 100 Ultra and High-Performance GPUs

>Authors: Mohammad Firas Sada, John J. Graham, Elham E Khoda, Mahidhar Tatineni, Dmitry Mishin, Rajesh K. Gupta, Rick Wagner, Larry Smarr, Thomas A. DeFanti, Frank Würthwein

>2025-07-01

> http://arxiv.org/abs/2507.00418v1

This study presents a benchmarking analysis of the Qualcomm Cloud AI 100
Ultra (QAic) accelerator for large language model (LLM) inference, evaluating
its energy efficiency (throughput per watt) and performance against leading
NVIDIA (A100, H200) and AMD (MI300A) GPUs within the National Research Platform
(NRP) ecosystem. A total of 15 open-source LLMs, ranging from 117 million to 90
billion parameters, are served using the vLLM framework. The QAic inference
cards appears to be energy efficient and performs well in the energy efficiency
metric in most cases. The findings offer insights into the potential of the
Qualcomm Cloud AI 100 Ultra for high-performance computing (HPC) applications
within the National Research Platform (NRP).


## Accurate and Efficient Fetal Birth Weight Estimation from 3D Ultrasound

>Authors: Jian Wang, Qiongying Ni, Hongkui Yu, Ruixuan Yao, Jinqiao Ying, Bin Zhang, Xingyi Yang, Jin Peng, Jiongquan Chen, Junxuan Yu, Wenlong Shi, Chaoyu Chen, Zhongnuo Yan, Mingyuan Luo, Gaocheng Cai, Dong Ni, Jing Lu, Xin Yang

>2025-07-01

> http://arxiv.org/abs/2507.00398v1

Accurate fetal birth weight (FBW) estimation is essential for optimizing
delivery decisions and reducing perinatal mortality. However, clinical methods
for FBW estimation are inefficient, operator-dependent, and challenging to
apply in cases of complex fetal anatomy. Existing deep learning methods are
based on 2D standard ultrasound (US) images or videos that lack spatial
information, limiting their prediction accuracy. In this study, we propose the
first method for directly estimating FBW from 3D fetal US volumes. Our approach
integrates a multi-scale feature fusion network (MFFN) and a synthetic
sample-based learning framework (SSLF). The MFFN effectively extracts and fuses
multi-scale features under **sparse** supervision by incorporating channel
attention, spatial attention, and a ranking-based loss function. SSLF generates
synthetic samples by simply combining fetal head and abdomen data from
different fetuses, utilizing semi-supervised learning to improve prediction
performance. Experimental results demonstrate that our method achieves superior
performance, with a mean absolute error of $166.4\pm155.9$ $g$ and a mean
absolute percentage error of $5.1\pm4.6$%, outperforming existing methods and
approaching the accuracy of a senior doctor. Code is available at:
https://github.com/Qioy-i/EFW.


## Origami of Multi-Layered Spaced Sheets

>Authors: Guowei Wayne Tu, Evgueni T. Filipov

>2025-07-01

> http://arxiv.org/abs/2507.00341v1

Two-dimensional (2D) origami tessellations such as the Miura-ori are often
generalized to build three-dimensional (3D) architected materials with sandwich
or cellular structures. However, such 3D blocks are densely packed with
continuity of the internal material, while for many engineering structures with
multi-physical functionality, it is necessary to have thin sheets that are
separately spaced and **sparse**ly connected. This work presents a framework for
the design and analysis of multi-layered spaced origami, which provides an
origami solution for 3D structures where multiple flat sheets are intentionally
spaced apart. We connect Miura-ori sheets with **sparse**ly installed thin-sheet
parallelogram-like linkages. To explore how this connectivity approach affects
the behavior of the origami system, we model the rigid-folding kinematics using
analytic trigonometry and rigid-body transformations, and we characterize the
elastic-folding mechanics by generalizing a reduced order bar and hinge model
for these 3D assemblies. The orientation of the linkages in the multi-layered
spaced origami determines which of three folding paths the system will follow
including a flat foldable type, a self-locking type, and a double-branch type.
When the origami is flat foldable, a maximized packing ratio and a uniform
in-plane shear stiffness can be achieved by strategically choosing the link
orientation. We show possible applications by demonstrating how the
multi-layered spaced origami can be used to build deployable acoustic cloaks
and heat shields.


## When Digital Twins Meet Large Language Models Realistic, Interactive, and Editable Simulation for Autonomous Driving

>Authors: Tanmay Vilas Samak, Chinmay Vilas Samak, Bing Li, Venkat Krovi

>2025-06-30

> http://arxiv.org/abs/2507.00319v1

Simulation frameworks have been key enablers for the development and
validation of autonomous driving systems. However, existing methods struggle to
comprehensively address the autonomy-oriented requirements of balancing: (i)
dynamical fidelity, (ii) photorealistic rendering, (iii) context-relevant
scenario orchestration, and (iv) real-time performance. To address these
limitations, we present a unified framework for creating and curating
high-fidelity digital twins to accelerate advancements in autonomous driving
research. Our framework leverages a mix of physics-based and data-driven
techniques for developing and simulating digital twins of autonomous vehicles
and their operating environments. It is capable of reconstructing real-world
scenes and assets (real2sim) with geometric and photorealistic accuracy and
infusing them with various physical properties to enable real-time dynamical
simulation of the ensuing driving scenarios. Additionally, it also incorporates
a large language model (LLM) interface to flexibly edit the driving scenarios
online via natural language prompts. We analyze the presented framework in
terms of its fidelity, performance, and serviceability. Results indicate that
our framework can reconstruct 3D scenes and assets with up to 97% structural
similarity, while maintaining frame rates above 60 Hz. We also demonstrate that
it can handle natural language prompts to generate diverse driving scenarios
with up to 95% repeatability and 85% generalizability.


## Open-ended Scientific Discovery via Bayesian Surprise

>Authors: Dhruv Agarwal, Bodhisattwa Prasad Majumder, Reece Adamson, Megha Chakravorty, Satvika Reddy Gavireddy, Aditya Parashar, Harshit Surana, Bhavana Dalvi Mishra, Andrew McCallum, Ashish Sabharwal, Peter Clark

>2025-06-30

> http://arxiv.org/abs/2507.00310v1

The promise of autonomous scientific discovery (ASD) hinges not only on
answering questions, but also on knowing which questions to ask. Most recent
works in ASD explore the use of large language models (LLMs) in goal-driven
settings, relying on human-specified research questions to guide hypothesis
generation. However, scientific discovery may be accelerated further by
allowing the AI system to drive exploration by its own criteria. The few
existing approaches in open-ended ASD select hypotheses based on diversity
heuristics or subjective proxies for human interestingness, but the former
struggles to meaningfully navigate the typically vast hypothesis space, and the
latter suffers from imprecise definitions. This paper presents AutoDS -- a
method for open-ended ASD that instead drives scientific exploration using
Bayesian surprise. Here, we quantify the epistemic shift from the LLM's prior
beliefs about a hypothesis to its posterior beliefs after gathering
experimental results. To efficiently explore the space of nested hypotheses,
our method employs a Monte Carlo tree search (MCTS) strategy with progressive
widening using surprisal as the reward function. We evaluate AutoDS in the
setting of data-driven discovery across 21 real-world datasets spanning domains
such as biology, economics, finance, and behavioral science. Our results
demonstrate that under a fixed budget, AutoDS substantially outperforms
competitors by producing 5--29\% more discoveries deemed surprising by the LLM.
Our human evaluation further finds that two-thirds of AutoDS discoveries are
surprising to the domain experts, suggesting this is an important step forward
towards building open-ended ASD systems.


## Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime

>Authors: Yuqing Wang, Shangding Gu

>2025-06-30

> http://arxiv.org/abs/2506.24120v1

Data selection plays a crucial role in data-driven decision-making, including
in large language models (LLMs), and is typically task-dependent. Properties
such as data quality and diversity have been extensively studied and are known
to enhance model performance. However, it remains unclear whether there exist
other quantitative and general principles of data selection that can
consistently improve performance, especially for complex tasks with limited
prior knowledge. In this paper, we demonstrate that selecting more uniformly
distributed data can improve training efficiency while enhancing performance.
Specifically, we establish that more uniform (less biased) distribution leads
to a larger minimum pairwise distance between data points, denoted by
$h_{\min}$, and prove that a smaller $h_{\min}$ can slow down the training
dynamics of gradient descent (GD). Moreover, we theoretically show that the
approximation error of neural networks decreases as $h_{\min}$ increases. Our
analysis introduces a convergence framework for GD beyond the Neural Tangent
Kernel (NTK) regime, applicable to a broad class of architectures, including
transformers, without requiring Lipschitz smoothness. This framework further
provides theoretical justification for the use of residual connections and
function compositions in deep neural architectures. In the end, we conduct
comprehensive experiments for supervised fine-tuning across various settings,
including different optimization strategies, model sizes, and training
datasets. The results consistently demonstrate that selecting data by
maximizing pairwise distance significantly accelerates training and achieves
comparable or better performance in LLMs across diverse datasets. Code and
Datasets are available at the link:
https://github.com/SafeRL-Lab/data-uniformity.


## Scaling Human Judgment in Community Notes with LLMs

>Authors: Haiwen Li, Soham De, Manon Revel, Andreas Haupt, Brad Miller, Keith Coleman, Jay Baxter, Martin Saveski, Michiel A. Bakker

>2025-06-30

> http://arxiv.org/abs/2506.24118v1

This paper argues for a new paradigm for Community Notes in the LLM era: an
open ecosystem where both humans and LLMs can write notes, and the decision of
which notes are helpful enough to show remains in the hands of humans. This
approach can accelerate the delivery of notes, while maintaining trust and
legitimacy through Community Notes' foundational principle: A community of
diverse human raters collectively serve as the ultimate evaluator and arbiter
of what is helpful. Further, the feedback from this diverse community can be
used to improve LLMs' ability to produce accurate, unbiased, broadly helpful
notes--what we term Reinforcement Learning from Community Feedback (RLCF). This
becomes a two-way street: LLMs serve as an asset to humans--helping deliver
context quickly and with minimal effort--while human feedback, in turn,
enhances the performance of LLMs. This paper describes how such a system can
work, its benefits, key new risks and challenges it introduces, and a research
agenda to solve those challenges and realize the potential of this approach.


## Agent.xpu Efficient Scheduling of Agentic LLM Workloads on Heterogeneous SoC

>Authors: Xinming Wei, Jiahao Zhang, Haoran Li, Jiayu Chen, Rui Qu, Maoliang Li, Xiang Chen, Guojie Luo

>2025-06-30

> http://arxiv.org/abs/2506.24045v1

The proliferation of agentic Large Language Models (LLMs) on personal devices
introduces a new class of workloads characterized by a dichotomy of objectives.
Reactive tasks, initiated by users, demand immediate, low-latency responses,
while proactive tasks operate invisibly and prioritize throughput. Existing
on-device LLM engines, designed for isolated inferences, fail to efficiently
manage these concurrent and conflicting requests on consumer-grade
heterogeneous SoCs with CPU, integrated GPU, and NPU. This paper introduces
Agent.xpu, an efficient serving system for agentic LLM workloads on
memory-unified heterogeneous SoCs. With dedicated offline profiling, Agent.xpu
first constructs a heterogeneous execution graph, which fuses and chunks model
kernels for affinity-guided, elastic accelerator mapping with predictive kernel
annotation. At runtime, its online scheduler enables fine-grained, kernel-level
preemption to guarantee the responsiveness of reactive tasks. To maximize SoC
utilization, it adopts slack-aware kernel backfill to opportunistically append
proactive tasks, and mitigates NPU-iGPU contention via bandwidth-aware
dispatch. Evaluation on an Intel Core Ultra SoC shows that Agent.xpu achieves
4.6$\times$ lower latency for reactive tasks and sustains
1.6$\times$-6.8$\times$ higher throughput for proactive tasks compared to
state-of-the-art inference engines.


## Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data

>Authors: Shubhabrata Mukherjee, Jack Lang, Obeen Kwon, Iryna Zenyuk, Valerie Brogden, Adam Weber, Daniela Ushizima

>2025-06-30

> http://arxiv.org/abs/2506.24039v1

Zero-shot and prompt-based technologies capitalized on using frequently
occurring images to transform visual reasoning tasks, which explains why such
technologies struggle with valuable yet scarce scientific image sets. In this
work, we propose Zenesis, a comprehensive no-code interactive platform designed
to minimize barriers posed by data readiness for scientific images. We develop
lightweight multi-modal adaptation techniques that enable zero-shot operation
on raw scientific data, along with human-in-the-loop refinement and
heuristic-based temporal enhancement options. We demonstrate the performance of
our approach through comprehensive comparison and validation on challenging
Focused Ion Beam Scanning Electron Microscopy (FIB-SEM) data of catalyst-loaded
membranes. Zenesis significantly outperforms baseline methods, achieving an
average accuracy of 0.947, an Intersection over Union (IOU) of 0.858, and a
Dice score of 0.923 for amorphous catalyst samples and accuracy of 0.987, an
IOU of 0.857, and a Dice score of 0.923 for crystalline samples. These results
mark a substantial improvement over traditional methods like Otsu thresholding
and even advanced models like Segment Anything Model (SAM) when used in
isolation. Our results demonstrate that Zenesis is a powerful tool for
scientific applications, particularly in fields where high-quality annotated
datasets are unavailable, accelerating accurate analysis of experimental
imaging.


## Unveiling Decision-Making in LLMs for Text Classification  Extraction of influential and interpretable concepts with Sparse Autoencoders

>Authors: Mathis Le Bail, Jérémie Dentan, Davide Buscaldi, Sonia Vanier

>2025-06-30

> http://arxiv.org/abs/2506.23951v1

Sparse Autoencoders (SAEs) have been successfully used to probe Large
Language Models (LLMs) and extract interpretable concepts from their internal
representations. These concepts are linear combinations of neuron activations
that correspond to human-interpretable features. In this paper, we investigate
the effectiveness of SAE-based explainability approaches for sentence
classification, a domain where such methods have not been extensively explored.
We present a novel SAE-based architecture tailored for text classification,
leveraging a specialized classifier head and incorporating an activation rate
**sparsity** loss. We benchmark this architecture against established methods such
as ConceptShap, Independent Component Analysis, and other SAE-based concept
extraction techniques. Our evaluation covers two classification benchmarks and
four fine-tuned LLMs from the Pythia family. We further enrich our analysis
with two novel metrics for measuring the precision of concept-based
explanations, using an external sentence encoder. Our empirical results show
that our architecture improves both the causality and interpretability of the
extracted features.


## The Trilemma of Truth in Large Language Models

>Authors: Germans Savcisens, Tina Eliassi-Rad

>2025-06-30

> http://arxiv.org/abs/2506.23921v1

We often attribute human characteristics to large language models (LLMs) and
claim that they "know" certain things. LLMs have an internal probabilistic
knowledge that represents information retained during training. How can we
assess the veracity of this knowledge? We examine two common methods for
probing the veracity of LLMs and discover several assumptions that are flawed.
To address these flawed assumptions, we introduce sAwMIL (short for Sparse
Aware Multiple-Instance Learning), a probing method that utilizes the internal
activations of LLMs to separate statements into true, false, and neither.
sAwMIL is based on multiple-instance learning and conformal prediction. We
evaluate sAwMIL on 5 validity criteria across 16 open-source LLMs, including
both default and chat-based variants, as well as on 3 new datasets. Among the
insights we provide are: (1) the veracity signal is often concentrated in the
third quarter of an LLM's depth; (2) truth and falsehood signals are not always
symmetric; (3) linear probes perform better on chat models than on default
models; (4) nonlinear probes may be required to capture veracity signals for
some LLMs with reinforcement learning from human feedback or knowledge
distillation; and (5) LLMs capture a third type of signal that is distinct from
true and false and is neither true nor false. These findings provide a reliable
method for verifying what LLMs "know" and how certain they are of their
probabilistic internal knowledge.


## VMoBA Mixture-of-Block Attention for Video Diffusion Models

>Authors: Jianzong Wu, Liang Hou, Haotian Yang, Xin Tao, Ye Tian, Pengfei Wan, Di Zhang, Yunhai Tong

>2025-06-30

> http://arxiv.org/abs/2506.23858v1

The quadratic complexity of full attention mechanisms poses a significant
bottleneck for Video Diffusion Models (VDMs) aiming to generate long-duration,
high-resolution videos. While various **sparse** attention methods have been
proposed, many are designed as training-free inference accelerators or do not
optimally capture the unique spatio-temporal characteristics inherent in video
data when trained natively. This paper introduces Video Mixture of Block
Attention (VMoBA), a novel **sparse** attention mechanism specifically adapted for
VDMs. Motivated by an in-depth analysis of attention patterns within
pre-trained video transformers, which revealed strong spatio-temporal locality,
varying query importance, and head-specific concentration levels, VMoBA
enhances the original MoBA framework with three key modifications: (1) a
layer-wise recurrent block partition scheme (1D-2D-3D) to dynamically adapt to
diverse spatio-temporal attention patterns and improve efficiency; (2) global
block selection to prioritize the most salient query-key block interactions
across an entire attention head; and (3) threshold-based block selection to
dynamically determine the number of attended blocks based on their cumulative
similarity. Extensive experiments demonstrate that VMoBA significantly
accelerates the training of VDMs on longer sequences, achieving 2.92x FLOPs and
1.48x latency speedup, while attaining comparable or even superior generation
quality to full attention. Furthermore, VMoBA exhibits competitive performance
in training-free inference, offering 2.40x FLOPs and 1.35x latency speedup for
high-res video generation.


## Low-latency vision transformers via large-scale multi-head attention

>Authors: Ronit D. Gross, Tal Halevi, Ella Koresh, Yarden Tzach, Ido Kanter

>2025-06-30

> http://arxiv.org/abs/2506.23832v1

The emergence of spontaneous symmetry breaking among a few heads of
multi-head attention (MHA) across transformer blocks in classification tasks
was recently demonstrated through the quantification of single-nodal
performance (SNP). This finding indicates that each head focuses its attention
on a subset of labels through cooperation among its SNPs. This underlying
learning mechanism is generalized to large-scale MHA (LS-MHA) using a single
matrix value representing single-head performance (SHP), analogous to
single-filter performance in convolutional neural networks (CNNs). The results
indicate that each SHP matrix comprises multiple unit clusters such that each
label being explicitly recognized by a few heads with negligible noise. This
leads to an increased signal-to-noise ratio (SNR) along the transformer blocks,
thereby improving classification accuracy. These features give rise to several
distinct vision transformer (ViT) architectures that achieve the same accuracy
but differ in their LS-MHA structures. As a result, their soft committee yields
superior accuracy, an outcome not typically observed in CNNs which rely on
hundreds of filters. In addition, a significant reduction in latency is
achieved without affecting the accuracy by replacing the initial transformer
blocks with convolutional layers. This substitution accelerates early-stage
learning, which is then improved by subsequent transformer layers. The
extension of this learning mechanism to natural language processing tasks,
based on quantitative differences between CNNs and ViT architectures, has the
potential to yield new insights in deep learning. The findings are demonstrated
using compact convolutional transformer architectures trained on the CIFAR-100
dataset.


## Large-scale Neural Network Quantum States for ab initio Quantum Chemistry Simulations on Fugaku

>Authors: Hongtao Xu, Zibo Wu, Mingzhen Li, Weile Jia

>2025-06-30

> http://arxiv.org/abs/2506.23809v1

Solving quantum many-body problems is one of the fundamental challenges in
quantum chemistry. While neural network quantum states (NQS) have emerged as a
promising computational tool, its training process incurs exponentially growing
computational demands, becoming prohibitively expensive for large-scale
molecular systems and creating fundamental scalability barriers for real-world
applications. To address above challenges, we present \ours, a high-performance
NQS training framework for \textit{ab initio} electronic structure
calculations. First, we propose a scalable sampling parallelism strategy with
multi-layers workload division and hybrid sampling scheme, which break the
scalability barriers for large-scale NQS training. Then, we introduce
multi-level parallelism local energy parallelism, enabling more efficient local
energy computation. Last, we employ cache-centric optimization for
transformer-based \textit{ansatz} and incorporate it with sampling parallelism
strategy, which further speedup up the NQS training and achieve stable memory
footprint at scale. Experiments demonstrate that \ours accelerate NQS training
with up to 8.41x speedup and attains a parallel efficiency up to 95.8\% when
scaling to 1,536 nodes.


## DABstep Data Agent Benchmark for Multi-step Reasoning

>Authors: Alex Egg, Martin Iglesias Goyanes, Friso Kingma, Andreu Mora, Leandro von Werra, Thomas Wolf

>2025-06-30

> http://arxiv.org/abs/2506.23719v1

We introduce DABstep, a novel benchmark for evaluating AI agents on realistic
multi-step data analysis tasks. DABstep comprises over 450 real-world
challenges derived from a financial analytics platform, requiring models to
combine code-based data processing with contextual reasoning over heterogeneous
documentation. Each task demands an iterative, multi-step problem-solving
approach, testing capabilities in data manipulation, cross-referencing multiple
sources, and precise result reporting. The benchmark provides a factoid-style
answer format with automatic correctness checks for objective scoring at scale.
We evaluate leading LLM-based agents, revealing a substantial performance gap:
even the best agent achieves only 14.55% accuracy on the hardest tasks. We
detail our benchmark's design, dataset composition, task formulation,
evaluation protocol, report baseline results and analyze failure modes. DABstep
is released with a public leaderboard and toolkit to accelerate research in
autonomous data analysis.


## Pruning by Block Benefit Exploring the Properties of Vision Transformer Blocks during Domain Adaptation

>Authors: Patrick Glandorf, Bodo Rosenhahn

>2025-06-30

> http://arxiv.org/abs/2506.23675v1

Vision Transformer have set new benchmarks in several tasks, but these models
come with the lack of high computational costs which makes them impractical for
resource limited hardware. Network **pruning** reduces the computational complexity
by removing less important operations while maintaining performance. However,
**pruning** a model on an unseen data domain, leads to a misevaluation of weight
significance, resulting in suboptimal resource assignment. In this work, we
find that task-sensitive layers initially fail to improve the feature
representation on downstream tasks, leading to performance loss for early
**pruning** decisions. To address this problem, we introduce Pruning by Block
Benefit (P3B), a **pruning** method that utilizes the relative contribution on
block level to globally assign parameter resources. P3B identifies low-impact
components to reduce parameter allocation while preserving critical ones.
Classical **pruning** mask optimization struggles to reactivate zero-mask-elements.
In contrast, P3B sets a layerwise keep ratio based on global performance
metrics, ensuring the reactivation of late-converging blocks. We show in
extensive experiments that P3B is a state of the art **pruning** method with most
noticeable gains in transfer learning tasks. Notably, P3B is able to conserve
high performance, even in high **sparsity** regimes of 70% parameter reduction
while only losing 0.64% in accuracy.


## Towards Building Private LLMs Exploring Multi-Node Expert Parallelism on Apple Silicon for Mixture-of-Experts Large Language Model

>Authors: Mu-Chi Chen, Po-Hsuan Huang, Xiangrui Ke, Chia-Heng Tu, Chun Jason Xue, Shih-Hao Hung

>2025-06-30

> http://arxiv.org/abs/2506.23635v1

Large Language Models (LLMs) have revolutionized Artificial Intelligence (AI)
with significant advancements such as OpenAI's ChatGPT, Meta's Llama, and
Databricks' DBRX. This paper addresses the cost and scalability challenges
encountered when constructing private LLM systems for personal or small group
services, as aimed by Apple Intelligence. A Mac Studio cluster with Apple's M2
Ultra chips is established as a cost-efficient solution to host and accelerate
the pretrained DBRX model with the Mixture-of-Experts (MoE) architecture. Our
performance analysis reveal that parallel execution of the model's experts
across two to four machine nodes significantly reduces inference time. We find
that computation time for the experts is comparable to the communication time
for exchanging their outputs, emphasizing the importance of network latency
over bandwidth. We also observe significant management overhead due to Apple
software stack's memory management logic. Based on these findings, we develop
optimization schemes to eliminate the memory management overhead. As a result,
the Mac Studio cluster is 1.15 times more cost-efficient than the
state-of-the-art AI supercomputer with NVIDIA H100 GPUs. In addition, we
construct a performance model to estimate system performance under varying
configurations, and the model provides valuable insights for designing private
LLM systems.


## A unified framework on the universal approximation of transformer-type architectures

>Authors: Jingpu Cheng, Qianxiao Li, Ting Lin, Zuowei Shen

>2025-06-30

> http://arxiv.org/abs/2506.23551v1

We investigate the universal approximation property (UAP) of transformer-type
architectures, providing a unified theoretical framework that extends prior
results on residual networks to models incorporating attention mechanisms. Our
work identifies token distinguishability as a fundamental requirement for UAP
and introduces a general sufficient condition that applies to a broad class of
architectures. Leveraging an analyticity assumption on the attention layer, we
can significantly simplify the verification of this condition, providing a
non-constructive approach in establishing UAP for such architectures. We
demonstrate the applicability of our framework by proving UAP for transformers
with various attention mechanisms, including kernel-based and **sparse** attention
mechanisms. The corollaries of our results either generalize prior works or
establish UAP for architectures not previously covered. Furthermore, our
framework offers a principled foundation for designing novel transformer
architectures with inherent UAP guarantees, including those with specific
functional symmetries. We propose examples to illustrate these insights.


## Sensing for Free Learn to Localize More Sources than Antennas without Pilots

>Authors: Wentao Yu, Khaled B. Letaief, Lizhong Zheng

>2025-06-30

> http://arxiv.org/abs/2506.23525v1

Integrated sensing and communication (ISAC) represents a key paradigm for
future wireless networks. However, existing approaches require waveform
modifications, dedicated pilots, or overhead that complicates standards
integration. We propose sensing for free - performing multi-source localization
without pilots by reusing uplink data symbols, making sensing occur during
transmission and directly compatible with 3GPP 5G NR and 6G specifications.
With ever-increasing devices in dense 6G networks, this approach is
particularly compelling when combined with **sparse** arrays, which can localize
more sources than uniform arrays via an enlarged virtual array. Existing
pilot-free multi-source localization algorithms first reconstruct an extended
covariance matrix and apply subspace methods, incurring cubic complexity and
limited to second-order statistics. Performance degrades under non-Gaussian
data symbols and few snapshots, and higher-order statistics remain unexploited.
We address these challenges with an attention-only transformer that directly
processes raw signal snapshots for grid-less end-to-end direction-of-arrival
(DOA) estimation. The model efficiently captures higher-order statistics while
being permutation-invariant and adaptive to varying snapshot counts. Our
algorithm greatly outperforms state-of-the-art AI-based benchmarks with over
30x reduction in parameters and runtime, and enjoys excellent generalization
under practical mismatches. Applied to multi-user MIMO beam training, our
algorithm can localize uplink DOAs of multiple users during data transmission.
Through angular reciprocity, estimated uplink DOAs prune downlink beam sweeping
candidates and improve throughput via sensing-assisted beam management. This
work shows how reusing existing data transmission for sensing can enhance both
multi-source localization and beam management in 3GPP efforts towards 6G.


## FD-DiT Frequency Domain-Directed Diffusion Transformer for Low-Dose CT Reconstruction

>Authors: Qiqing Liu, Guoquan Wei, Zekun Zhou, Yiyang Wen, Liu Shi, Qiegen Liu

>2025-06-30

> http://arxiv.org/abs/2506.23466v1

Low-dose computed tomography (LDCT) reduces radiation exposure but suffers
from image artifacts and loss of detail due to quantum and electronic noise,
potentially impacting diagnostic accuracy. Transformer combined with diffusion
models has been a promising approach for image generation. Nevertheless,
existing methods exhibit limitations in preserving finegrained image details.
To address this issue, frequency domain-directed diffusion transformer (FD-DiT)
is proposed for LDCT reconstruction. FD-DiT centers on a diffusion strategy
that progressively introduces noise until the distribution statistically aligns
with that of LDCT data, followed by denoising processing. Furthermore, we
employ a frequency decoupling technique to concentrate noise primarily in
high-frequency domain, thereby facilitating effective capture of essential
anatomical structures and fine details. A hybrid denoising network is then
utilized to optimize the overall data reconstruction process. To enhance the
capability in recognizing high-frequency noise, we incorporate sliding **sparse**
local attention to leverage the **sparsity** and locality of shallow-layer
information, propagating them via skip connections for improving feature
representation. Finally, we propose a learnable dynamic fusion strategy for
optimal component integration. Experimental results demonstrate that at
identical dose levels, LDCT images reconstructed by FD-DiT exhibit superior
noise and artifact suppression compared to state-of-the-art methods.


## What to Keep and What to Drop Adaptive Table Filtering Framework

>Authors: Jang Won June

>2025-06-30

> http://arxiv.org/abs/2506.23463v1

Large language models (LLMs) for table-based reasoning often struggle with
large tables due to input length limits. We propose ATF (Adaptive Table
Filtering Framework), a modular and question-aware filtering pipeline that
prunes uninformative columns and rows using LLM-generated column descriptions,
clustering, and **sparse**-dense alignment scores. ATF integrates seamlessly with
existing models (e.g., TAPAS, TAPEX) without retraining. Experiments show that
ATF reduces table cells by ~70\%, boosting performance on out-of-domain TableQA
tasks while causing slight performance drops on Table Fact Verification, where
full-table context is more critical. These results highlight ATF's ability to
adaptively balance informativeness and minimalism across tasks.


## CycleVAR Repurposing Autoregressive Model for Unsupervised One-Step Image Translation

>Authors: Yi Liu, Shengqian Li, Zuzeng Lin, Feng Wang, Si Liu

>2025-06-29

> http://arxiv.org/abs/2506.23347v1

The current conditional autoregressive image generation methods have shown
promising results, yet their potential remains largely unexplored in the
practical unsupervised image translation domain, which operates without
explicit cross-domain correspondences. A critical limitation stems from the
discrete **quantization** inherent in traditional Vector Quantization-based
frameworks, which disrupts gradient flow between the Variational Autoencoder
decoder and causal Transformer, impeding end-to-end optimization during
adversarial training in image space. To tackle this issue, we propose using
Softmax Relaxed Quantization, a novel approach that reformulates codebook
selection as a continuous probability mixing process via Softmax, thereby
preserving gradient propagation. Building upon this differentiable foundation,
we introduce CycleVAR, which reformulates image-to-image translation as
image-conditional visual autoregressive generation by injecting multi-scale
source image tokens as contextual prompts, analogous to prefix-based
conditioning in language models. CycleVAR exploits two modes to generate the
target image tokens, including (1) serial multi-step generation, enabling
iterative refinement across scales, and (2) parallel one-step generation
synthesizing all resolution outputs in a single forward pass. Experimental
findings indicate that the parallel one-step generation mode attains superior
translation quality with quicker inference speed than the serial multi-step
mode in unsupervised scenarios. Furthermore, both quantitative and qualitative
results indicate that CycleVAR surpasses previous state-of-the-art unsupervised
image translation models, \textit{e}.\textit{g}., CycleGAN-Turbo.


## Sub-MoE Efficient Mixture-of-Expert LLMs Compression via Subspace Expert Merging

>Authors: Lujun Li, Zhu Qiyuan, Jiacheng Wang, Wei Li, Hao Gu, Sirui Han, Yike Guo

>2025-06-29

> http://arxiv.org/abs/2506.23266v1

Mixture of Experts (MoE) LLMs face significant obstacles due to their massive
parameter scale, which imposes memory, storage, and deployment challenges.
Although recent expert merging methods promise greater efficiency by
consolidating multiple experts, they are fundamentally hindered by parameter
conflicts arising from expert specialization. In this paper, we present
Sub-MoE, a novel MoE compression framework via Subspace Expert Merging. Our key
insight is to perform joint Singular Value Decomposition (SVD) on concatenated
expert weights, reducing conflicting parameters by extracting shared
$U$-matrices while enabling effective merging of the expert-specific $V$
components. Specifically, Sub-MoE consists of two innovative phases: (1)
Adaptive Expert Clustering, which groups functionally coherent experts via
K-means clustering based on cosine similarity of expert outputs; and (2)
Subspace Expert Merging, which first enforces Experts Union Decomposition to
derive the shared $U$-matrix across experts in the same group, then pursues
frequency-based merging for individual $V$-matrices, and finalizes expert
reconstruction using the merged $V$-matrix. In this way, we align and fuse
experts in a shared subspace, and can be extended with intra-expert compression
for further inference optimization. Extensive experiments on Mixtral, DeepSeek,
and Qwen-1.5|3 MoE LLMs demonstrate that our Sub-MoE significantly outperforms
existing expert **pruning** and merging methods. Notably, our Sub-MoE maintains
96\%|86\% of original performance with 25\%|50\% expert reduction on
Mixtral-8x7B in zero-shot benchmarks. Code will be released at
https://github.com/lliai/MoERazor.


## BridgeShape Latent Diffusion Schrödinger Bridge for 3D Shape Completion

>Authors: Dequan Kong, Zhe Zhu, Honghua Chen, Mingqiang Wei

>2025-06-29

> http://arxiv.org/abs/2506.23205v1

Existing diffusion-based 3D shape completion methods typically use a
conditional paradigm, injecting incomplete shape information into the denoising
network via deep feature interactions (e.g., concatenation, cross-attention) to
guide sampling toward complete shapes, often represented by voxel-based
distance functions. However, these approaches fail to explicitly model the
optimal global transport path, leading to suboptimal completions. Moreover,
performing diffusion directly in voxel space imposes resolution constraints,
limiting the generation of fine-grained geometric details. To address these
challenges, we propose BridgeShape, a novel framework for 3D shape completion
via latent diffusion Schr\"odinger bridge. The key innovations lie in two
aspects: (i) BridgeShape formulates shape completion as an optimal transport
problem, explicitly modeling the transition between incomplete and complete
shapes to ensure a globally coherent transformation. (ii) We introduce a
Depth-Enhanced Vector Quantized Variational Autoencoder (VQ-VAE) to encode 3D
shapes into a compact latent space, leveraging self-projected multi-view depth
information enriched with strong DINOv2 features to enhance geometric
structural perception. By operating in a compact yet structurally informative
latent space, BridgeShape effectively mitigates resolution constraints and
enables more efficient and high-fidelity 3D shape completion. BridgeShape
achieves state-of-the-art performance on large-scale 3D shape completion
benchmarks, demonstrating superior fidelity at higher resolutions and for
unseen object classes.


## Benchmarking Deep Search over Heterogeneous Enterprise Data

>Authors: Prafulla Kumar Choubey, Xiangyu Peng, Shilpa Bhagavath, Kung-Hsiang Huang, Caiming Xiong, Chien-Sheng Wu

>2025-06-29

> http://arxiv.org/abs/2506.23139v1

We present a new benchmark for evaluating Deep Search--a realistic and
complex form of retrieval-augmented generation (RAG) that requires
source-aware, multi-hop reasoning over diverse, **sparse**d, but related sources.
These include documents, meeting transcripts, Slack messages, GitHub, and URLs,
which vary in structure and often contain human-to-human interactions. We build
it using a synthetic data pipeline that simulates business workflows across
product planning, development, and support stages, generating interconnected
content with realistic noise and multi-hop questions with guaranteed
ground-truth answers. We release our benchmark with both answerable and
unanswerable queries, and retrieval pool of 39,190 enterprise artifacts,
enabling fine-grained evaluation of long-context LLM and RAG systems. Our
experiments reveal that even the best-performing agentic RAG methods achieve an
average performance score of 32.96 on our benchmark. With further analysis, we
highlight retrieval as the main bottleneck: existing methods struggle to
conduct deep searches and retrieve all necessary evidence. Consequently, they
often reason over partial context, leading to significant performance
degradation.


## Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning

>Authors: Zhaoye Fei, Li Ji, Siyin Wang, Junhao Shi, Jingjing Gong, Xipeng Qiu

>2025-06-29

> http://arxiv.org/abs/2506.23127v1

Large Language Models (LLMs) have demonstrated remarkable capabilities across
various tasks, yet they face significant challenges in embodied task planning
scenarios that require continuous environmental understanding and action
generation. Existing approaches generate open-loop action scripts based on
static knowledge, making it difficult to learn causal relationships between
actions and environmental feedback, particularly in partially observable
environments. We introduce Embodied Planner-R1, a novel outcome-driven
reinforcement learning framework that enables LLMs to develop interactive
capabilities through autonomous exploration with minimal supervision. Our
framework incorporates three key innovations: (1) Without human annotations, we
employ pure reinforcement learning with group rollout, incorporating
in-environment interaction through parallel exploration; (2) completion-driven
**sparse** reward; and (3) Interactive Policy Optimization (IPO) for efficient
learning from grouped trajectories. Across two challenging text-based Embodied
planning benchmarks, Embodied Planner-R1 achieves impressive completion rates
of 97.78% on ALFWorld and 79.92% on ScienceWorld, surpassing prior methods by a
large margin, and suffers only a -3.66% drop in previously unseen environments,
evidencing strong generalization.


## TOMI Transforming and Organizing Music Ideas for Multi-Track Compositions with Full-Song Structure

>Authors: Qi He, Gus Xia, Ziyu Wang

>2025-06-29

> http://arxiv.org/abs/2506.23094v1

Hierarchical planning is a powerful approach to model long sequences
structurally. Aside from considering hierarchies in the temporal structure of
music, this paper explores an even more important aspect: concept hierarchy,
which involves generating music ideas, transforming them, and ultimately
organizing them--across musical time and space--into a complete composition. To
this end, we introduce TOMI (Transforming and Organizing Music Ideas) as a
novel approach in deep music generation and develop a TOMI-based model via
instruction-tuned foundation LLM. Formally, we represent a multi-track
composition process via a **sparse**, four-dimensional space characterized by clips
(short audio or MIDI segments), sections (temporal positions), tracks
(instrument layers), and transformations (elaboration methods). Our model is
capable of generating multi-track electronic music with full-song structure,
and we further integrate the TOMI-based model with the REAPER digital audio
workstation, enabling interactive human-AI co-creation. Experimental results
demonstrate that our approach produces higher-quality electronic music with
stronger structural coherence compared to baselines.


## Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems

>Authors: Langming Liu, Wanyu Wang, Chi Zhang, Bo Li, Hongzhi Yin, Xuetao Wei, Wenbo Su, Bo Zheng, Xiangyu Zhao

>2025-06-29

> http://arxiv.org/abs/2506.23090v1

Online advertising in recommendation platforms has gained significant
attention, with a predominant focus on channel recommendation and budget
allocation strategies. However, current offline reinforcement learning (RL)
methods face substantial challenges when applied to **sparse** advertising
scenarios, primarily due to severe overestimation, distributional shifts, and
overlooking budget constraints. To address these issues, we propose MTORL, a
novel multi-task offline RL model that targets two key objectives. First, we
establish a Markov Decision Process (MDP) framework specific to the nuances of
advertising. Then, we develop a causal state encoder to capture dynamic user
interests and temporal dependencies, facilitating offline RL through
conditional sequence modeling. Causal attention mechanisms are introduced to
enhance user sequence representations by identifying correlations among causal
states. We employ multi-task learning to decode actions and rewards,
simultaneously addressing channel recommendation and budget allocation.
Notably, our framework includes an automated system for integrating these tasks
into online advertising. Extensive experiments on offline and online
environments demonstrate MTORL's superiority over state-of-the-art methods.


## CSBrain A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding

>Authors: Yuchen Zhou, Jiamin Wu, Zichen Ren, Zhouheng Yao, Weiheng Lu, Kunyu Peng, Qihao Zheng, Chunfeng Song, Wanli Ouyang, Chao Gou

>2025-06-29

> http://arxiv.org/abs/2506.23075v1

Understanding and decoding brain activity from electroencephalography (EEG)
signals is a fundamental challenge in neuroscience and AI, with applications in
cognition, emotion recognition, diagnosis, and brain-computer interfaces. While
recent EEG foundation models advance generalized decoding via unified
architectures and large-scale pretraining, they adopt a scale-agnostic dense
modeling paradigm inherited from NLP and vision. This design neglects a core
property of neural activity: cross-scale spatiotemporal structure. EEG task
patterns span a wide range of temporal and spatial scales, from short bursts to
slow rhythms, and from localized cortical responses to distributed
interactions. Ignoring this diversity leads to suboptimal representations and
weak generalization. We propose CSBrain, a Cross-scale Spatiotemporal Brain
foundation model for generalized EEG decoding. CSBrain introduces: (i)
Cross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scale
features from localized temporal windows and anatomical brain regions into
compact scale-aware tokens; and (ii) Structured Sparse Attention (SSA), which
captures cross-window and cross-region dependencies, enhancing scale diversity
while removing spurious correlations. CST and SSA are alternately stacked to
progressively integrate multi-scale dependencies. Experiments on 11 EEG tasks
across 16 datasets show that CSBrain consistently outperforms task-specific and
foundation model baselines. These results establish cross-scale modeling as a
key inductive bias and position CSBrain as a robust backbone for future
brain-AI research.


## Spectra 1.1 Scaling Laws and Efficient Inference for Ternary Language Models

>Authors: Tejas Vaidhya, Ayush Kaushal, Vineet Jain, Francis Couture Harpin, Prashant Shishodia, Majid Behbahani, Yuriy Nevmyvaka, Irina Rish

>2025-06-28

> http://arxiv.org/abs/2506.23025v1

Large language models (LLMs) are increasingly used across research and
industry applications, yet their inference efficiency remains a significant
challenge. As the computational power of modern GPU architectures continuously
improves, their memory bandwidth and capacity have not scaled proportionally,
creating a critical bottleneck during inference. To address this, we
investigate ternary language models (TriLMs) that employ **quantization**-aware
training to significantly reduce memory requirements. We first analyze the
scalability of TriLMs by conducting a scaling law analysis, revealing that
TriLMs benefit more from increasing training data than from scaling model
parameters. Based on this observation, we introduce Spectra-1.1, an open suite
of TriLMs trained on up to 1.2 trillion tokens, demonstrating sustained
performance gains at scale. Furthermore, to improve inference efficiency, we
propose novel 2-bit and 1.6-bit packing schemes for ternary weights, which
demonstrate accelerated inference across various CPU architectures. Also,
building on the 2-bit packing, we develop a GPU kernel called TriRun that
accelerates end-to-end model inference by up to 5 times compared to
floating-point baselines. To encourage further exploration and development of
TriLMs, we will release the Spectra-1.1 suite and TriRun inference kernels.
Overall, our work lays the foundation for building and deploying efficient
LLMs, providing a valuable resource for the research community.


## SparStencil Retargeting Sparse Tensor Cores to Scientific Stencil Computations via Structured Sparsity Transformation

>Authors: Qi Li, Kun Li, Haozhi Han, Liang Yuan, Junshi Chen, Yunquan Zhang, Yifeng Chen, Hong An, Ting Cao, Mao Yang

>2025-06-28

> http://arxiv.org/abs/2506.22969v1

Sparse Tensor Cores offer exceptional performance gains for AI workloads by
exploiting structured 2:4 **sparsity**. However, their potential remains untapped
for core scientific workloads such as stencil computations, which exhibit
irregular **sparsity** patterns.This paper presents SparStencil, the first system
to retarget **sparse** TCUs for scientific stencil computations through structured
**sparsity** transformation. SparStencil introduces three key techniques: (1)
Adaptive Layout Morphing, which restructures stencil patterns into
staircase-aligned **sparse** matrices via a flatten-and-crush pipeline; (2)
Structured Sparsity Conversion, which formulates transformation as a graph
matching problem to ensure compatibility with 2:4 **sparsity** constraints; (3)
Automatic Kernel Generation, which compiles transformed stencils into optimized
**sparse** MMA kernels via layout search and table-driven memory mapping. Evaluated
on 79 stencil kernels spanning diverse scientific domains, SparStencil achieves
up to 7.1x speedup (3.1x on average) over state-of-the-art framework while
reducing code complexity and matching or exceeding expert-tuned performance in
both compute throughput and memory efficiency.


## Attention to Burstiness Low-Rank Bilinear Prompt Tuning

>Authors: Yuzhu Wang, Manni Duan, Shu Kong

>2025-06-28

> http://arxiv.org/abs/2506.22908v1

Visual Prompt Tuning (VPT) is a parameter-efficient fune-tuning technique
that adapts a pre-trained vision Transformer (ViT) by learning a small set of
parameters in the input space, known as prompts. In VPT, we uncover
``burstiness'' in the values arising from the interaction of image patch
embeddings, and the key and query projectors within Transformer's
self-attention module. Furthermore, the values of patch embeddings and the key
and query projectors exhibit Laplacian and hyper-Laplacian distribution,
respectively. Intuitively, these non-Gaussian distributions pose challenges for
learning prompts. To address this, we propose whitening these data,
de-correlating them and equalizing their variance towards more Gaussian before
learning prompts. We derive the whitening matrix over random image patch
embeddings and ViT's key and query projectors, and multiply it with the prompt
to be learned in a bilinear manner. Surprisingly, this method significantly
accelerates prompt tuning and boosts accuracy, e.g., $>$25 accuracy points on
the CUB dataset; interestingly, it learns ``bursty prompts''. Extending the
bilinear model which is known to introduce burstiness, we present a compact,
low-rank version by learning two smaller matrices whose multiplication yields
the final prompts. We call the proposed methods Bilinear Prompt Tuning (BPT).
Extensive experiments across multiple benchmark datasets demonstrate that BPT
methods not only outperform various VPT methods but also reduce parameter count
and computation overhead.


## ReasonBridge Efficient Reasoning Transfer from Closed to Open-Source Language Models

>Authors: Ziqi Zhong, Xunzhu Tang

>2025-06-28

> http://arxiv.org/abs/2506.22865v1

Recent advancements in Large Language Models (LLMs) have revealed a
significant performance gap between closed-source and open-source models,
particularly in tasks requiring complex reasoning and precise instruction
following. This paper introduces ReasonBridge, a methodology that efficiently
transfers reasoning capabilities from powerful closed-source to open-source
models through a novel hierarchical knowledge distillation framework. We
develop a tailored dataset Reason1K with only 1,000 carefully curated reasoning
traces emphasizing difficulty, diversity, and quality. These traces are
filtered from across multiple domains using a structured multi-criteria
selection algorithm. Our transfer learning approach incorporates: (1) a
hierarchical distillation process capturing both strategic abstraction and
tactical implementation patterns, (2) a **sparse** reasoning-focused adapter
architecture requiring only 0.3% additional trainable parameters, and (3) a
test-time compute scaling mechanism using guided inference interventions.
Comprehensive evaluations demonstrate that ReasonBridge improves reasoning
capabilities in open-source models by up to 23% on benchmark tasks,
significantly narrowing the gap with closed-source models. Notably, the
enhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its
performance on competition-level AIME problems. Our methodology generalizes
effectively across diverse reasoning domains and model architectures,
establishing a sample-efficient approach to reasoning enhancement for
instruction following.


## DOBB-BVH Efficient Ray Traversal by Transforming Wide BVHs into Oriented Bounding Box Trees using Discrete Rotations

>Authors: Michael A. Kern, Alain Galvan, David Oldcorn, Daniel Skinner, Rohan Mehalwal, Leo Reyes Lozano, Matthäus G. Chajdas

>2025-06-28

> http://arxiv.org/abs/2506.22849v1

Oriented bounding box (OBB) bounding volume hierarchies offer a more precise
fit than axis-aligned bounding box hierarchies in scenarios with thin elongated
and arbitrarily rotated geometry, enhancing intersection test performance in
ray tracing. However, determining optimally oriented bounding boxes can be
computationally expensive and have high memory requirements. Recent research
has shown that pre-built hierarchies can be efficiently converted to OBB
hierarchies on the GPU in a bottom-up pass, yielding significant ray tracing
traversal improvements. In this paper, we introduce a novel OBB construction
technique where all internal node children share a consistent OBB transform,
chosen from a fixed set of discrete **quantize**d rotations. This allows for
efficient encoding and reduces the computational complexity of OBB
transformations. We further extend our approach to hierarchies with multiple
children per node by leveraging Discrete Orientation Polytopes (k-DOPs),
demonstrating improvements in traversal performance while limiting the build
time impact for real-time applications. Our method is applied as a
post-processing step, integrating seamlessly into existing hierarchy
construction pipelines. Despite a 12.6% increase in build time, our
experimental results demonstrate an average improvement of 18.5% in primary,
32.4% in secondary rays, and maximum gain of 65% in ray intersection
performance, highlighting its potential for advancing real-time applications.


## Size-Dependent Tensile Behavior of Nanocrystalline HfNbTaTiZr High-Entropy Alloy Roles of Solid-Solution and Short-Range Order

>Authors: Yihan Wu, Gaosheng Yan, Pengfei Yu, Yaohong Suo, Wenshan Yu, Shengping Shen

>2025-06-28

> http://arxiv.org/abs/2506.22822v1

This study investigates the size-dependent mechanical behavior of the
HfNbTaTiZr refractory high-entropy alloy (RHEA) under uniaxial tension, with a
focus on the effects of random solid-solution (RSS) and chemical short-range
order (CSRO). A machine learning framework is developed to accelerate the
parameterization of interatomic force fields (FFs), enabling molecular dynamics
simulations of three nanocrystalline models: (i) a meta-atom (MA) mode
representing the RHEA as a hypothetical sing-element system with averaged
properties, (ii) a quinary RSS model with randomly distributed constituent
atoms, and (iii) a Monte Carlo (MC) model with internal CSRO. The results
reveal that RSS enhances strength, while CSRO reduces flow stress level but
improves strain hardening and failure resistance. A transition from Hall-Petch
(HP) strengthening to inverse Hall-Petch (IHP) softening is observed, with CSRO
suppressing this transition. The underlying plastic mechanisms (i.e.,
dislocation slip, deformation twinning, phase transformation and grain boundary
movements) are analyzed from both nanostructural and energetic perspectives.
Theoretical models are established to describe the size-dependent yield
strength and predict the critical grain size. Additionally, the contributions
of different plastic mechanisms to the overall stress response are separately
quantified. These findings provide new insights into the design and performance
optimization of RHEAs through nanostructural engineering.


## TriADA Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations

>Authors: Stanislav Sedukhin, Yoichi Tomioka, Kazuya Matsumoto, Yuichi Okuyama

>2025-06-28

> http://arxiv.org/abs/2506.22818v1

Multilinear transformations are key in high-performance computing (HPC) and
artificial intelligence (AI) workloads, where data is represented as tensors.
However, their high computational and memory demands, which grow with
dimensionality, often slow down critical tasks. Moreover, scaling computation
by enlarging the number of parallel processing units substantially increases
energy consumption, limiting widespread adoption, especially for **sparse** data,
which is common in HPC and AI applications. This paper introduces the Trilinear
Algorithm and isomorphic to algorithm Device Architecture (TriADA) to address
these challenges with the following innovations: (1) a massively parallel,
low-rank algorithm for computing a family of trilinear (3D) discrete orthogonal
transformations (3D-DXTs), which is a special case of the more general 3-mode
matrix-by-tensor multiplication (3D-GEMT); (2) a new outer-product-based GEMM
kernel with decoupled streaming active memory, specially designed to accelerate
3D-GEMT operation; (3) an isomorphic to the proposed algorithm, fully
distributed 3D network of mesh interconnected processing elements or cells with
a coordinate-free, data-driven local processing activity, which is independent
of problem size; (4) an elastic **sparse** outer-product (ESOP) method that avoids
unnecessary computing and communication operations with zero-valued operands,
thereby enhancing energy efficiency, computational accuracy, and stability.
TriADA is capable of performing a variety of trilinear transformations with
hypercubic arithmetic complexity in a linear number of time-steps. The
massively parallel, scalable, and energy-efficient architecture of TriADA is
ideal for accelerating multilinear tensor operations, which are the most
demanding parts of AI and HPC workloads.


## SPI-BoTER Error Compensation for Industrial Robots via Sparse Attention Masking and Hybrid Loss with Spatial-Physical Information

>Authors: Xuao Hou, Yongquan Jia, Shijin Zhang, Yuqiang Wu

>2025-06-28

> http://arxiv.org/abs/2506.22788v1

The widespread application of industrial robots in fields such as cutting and
welding has imposed increasingly stringent requirements on the trajectory
accuracy of end-effectors. However, current error compensation methods face
several critical challenges, including overly simplified mechanism modeling, a
lack of physical consistency in data-driven approaches, and substantial data
requirements. These issues make it difficult to achieve both high accuracy and
strong generalization simultaneously. To address these challenges, this paper
proposes a Spatial-Physical Informed Attention Residual Network (SPI-BoTER).
This method integrates the kinematic equations of the robotic manipulator with
a Transformer architecture enhanced by **sparse** self-attention masks. A
parameter-adaptive hybrid loss function incorporating spatial and physical
information is employed to iteratively optimize the network during training,
enabling high-precision error compensation under small-sample conditions.
Additionally, inverse joint angle compensation is performed using a gradient
descent-based optimization method. Experimental results on a small-sample
dataset from a UR5 robotic arm (724 samples, with a train:test:validation split
of 8:1:1) demonstrate the superior performance of the proposed method. It
achieves a 3D absolute positioning error of 0.2515 mm with a standard deviation
of 0.15 mm, representing a 35.16\% reduction in error compared to conventional
deep neural network (DNN) methods. Furthermore, the inverse angle compensation
algorithm converges to an accuracy of 0.01 mm within an average of 147
iterations. This study presents a solution that combines physical
interpretability with data adaptability for high-precision control of
industrial robots, offering promising potential for the reliable execution of
precision tasks in intelligent manufacturing.


## Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching

>Authors: Yu Han, Zhiwei Huang, Yanting Zhang, Fangjun Ding, Shen Cai, Rui Fan

>2025-06-28

> http://arxiv.org/abs/2506.22784v1

Point-pixel registration between LiDAR point clouds and camera images is a
fundamental yet challenging task in autonomous driving and robotic perception.
A key difficulty lies in the modality gap between unstructured point clouds and
structured images, especially under **sparse** single-frame LiDAR settings.
Existing methods typically extract features separately from point clouds and
images, then rely on hand-crafted or learned matching strategies. This separate
encoding fails to bridge the modality gap effectively, and more critically,
these methods struggle with the **sparsity** and noise of single-frame LiDAR, often
requiring point cloud accumulation or additional priors to improve reliability.
Inspired by recent progress in detector-free matching paradigms (e.g.
MatchAnything), we revisit the projection-based approach and introduce the
detector-free framework for direct point-pixel matching between LiDAR and
camera views. Specifically, we project the LiDAR intensity map into a 2D view
from the LiDAR perspective and feed it into an attention-based detector-free
matching network, enabling cross-modal correspondence estimation without
relying on multi-frame accumulation. To further enhance matching reliability,
we introduce a repeatability scoring mechanism that acts as a soft visibility
prior. This guides the network to suppress unreliable matches in regions with
low intensity variation, improving robustness under **sparse** input. Extensive
experiments on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks demonstrate that
our method achieves state-of-the-art performance, outperforming prior
approaches on nuScenes (even those relying on accumulated point clouds),
despite using only single-frame LiDAR.


## Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation

>Authors: Sen Fang, Weiyuan Ding, Antonio Mastropaolo, Bowen Xu

>2025-06-28

> http://arxiv.org/abs/2506.22776v1

Quantization has emerged as a mainstream method for compressing Large
Language Models (LLMs), reducing memory requirements and accelerating inference
without architectural modifications. While existing research primarily focuses
on evaluating the effectiveness of **quantize**d LLMs compared to their original
counterparts, the impact on robustness remains largely unexplored.In this
paper, we present the first systematic investigation of how **quantization**
affects the robustness of LLMs in code generation tasks. Through extensive
experiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and
StarCoder) with parameter scales ranging from 350M to 33B, we evaluate
robustness from dual perspectives: adversarial attacks on input prompts and
noise perturbations on model architecture. Our findings challenge conventional
wisdom by demonstrating that **quantize**d LLMs often exhibit superior robustness
compared to their full-precision counterparts, with 51.59% versus 42.86% of our
adversarial experiments showing better resilience in **quantize**d LLMs. Similarly,
our noise perturbation experiments also confirm that LLMs after quantitation
generally withstand higher levels of weight disturbances. These results suggest
that **quantization** not only reduces computational requirements but can actually
enhance LLMs' reliability in code generation tasks, providing valuable insights
for developing more robust and efficient LLM deployment strategies.


## Can We Reliably Predict the Fed's Next Move? A Multi-Modal Approach to U.S. Monetary Policy Forecasting

>Authors: Fiona Xiao Jingyi, Lili Liu

>2025-06-28

> http://arxiv.org/abs/2506.22763v1

Forecasting central bank policy decisions remains a persistent challenge for
investors, financial institutions, and policymakers due to the wide-reaching
impact of monetary actions. In particular, anticipating shifts in the U.S.
federal funds rate is vital for risk management and trading strategies.
Traditional methods relying only on structured macroeconomic indicators often
fall short in capturing the forward-looking cues embedded in central bank
communications.
  This study examines whether predictive accuracy can be enhanced by
integrating structured data with unstructured textual signals from Federal
Reserve communications. We adopt a multi-modal framework, comparing traditional
machine learning models, transformer-based language models, and deep learning
architectures in both unimodal and hybrid settings.
  Our results show that hybrid models consistently outperform unimodal
baselines. The best performance is achieved by combining TF-IDF features of
FOMC texts with economic indicators in an XGBoost classifier, reaching a test
AUC of 0.83. FinBERT-based sentiment features marginally improve ranking but
perform worse in classification, especially under class imbalance. SHAP
analysis reveals that **sparse**, interpretable features align more closely with
policy-relevant signals.
  These findings underscore the importance of integrating textual and
structured signals transparently. For monetary policy forecasting, simpler
hybrid models can offer both accuracy and interpretability, delivering
actionable insights for researchers and decision-makers.


## Prompt Mechanisms in Medical Imaging A Comprehensive Survey

>Authors: Hao Yang, Xinlong Liang, Zhang Li, Yue Sun, Zheyu Hu, Xinghe Xie, Behdad Dashtbozorg, Jincheng Huang, Shiwei Zhu, Luyi Han, Jiong Zhang, Shanshan Wang, Ritse Mann, Qifeng Yu, Tao Tan

>2025-06-28

> http://arxiv.org/abs/2507.01055v1

Deep learning offers transformative potential in medical imaging, yet its
clinical adoption is frequently hampered by challenges such as data scarcity,
distribution shifts, and the need for robust task generalization. Prompt-based
methodologies have emerged as a pivotal strategy to guide deep learning models,
providing flexible, domain-specific adaptations that significantly enhance
model performance and adaptability without extensive retraining. This
systematic review critically examines the burgeoning landscape of prompt
engineering in medical imaging. We dissect diverse prompt modalities, including
textual instructions, visual prompts, and learnable embeddings, and analyze
their integration for core tasks such as image generation, segmentation, and
classification. Our synthesis reveals how these mechanisms improve
task-specific outcomes by enhancing accuracy, robustness, and data efficiency
and reducing reliance on manual feature engineering while fostering greater
model interpretability by making the model's guidance explicit. Despite
substantial advancements, we identify persistent challenges, particularly in
prompt design optimization, data heterogeneity, and ensuring scalability for
clinical deployment. Finally, this review outlines promising future
trajectories, including advanced multimodal prompting and robust clinical
integration, underscoring the critical role of prompt-driven AI in accelerating
the revolution of diagnostics and personalized treatment planning in medicine.


## Beyond Code The Multidimensional Impacts of Large Language Models in Software Development

>Authors: Sardar Bonabi, Sarah Bana, Vijay Gurbaxani, Tingting Nian

>2025-06-28

> http://arxiv.org/abs/2506.22704v2

Large language models (LLMs) are poised to significantly impact software
development, especially in the Open-Source Software (OSS) sector. To understand
this impact, we first outline the mechanisms through which LLMs may influence
OSS through code development, collaborative knowledge transfer, and skill
development. We then empirically examine how LLMs affect OSS developers' work
in these three key areas. Leveraging a natural experiment from a temporary
ChatGPT ban in Italy, we employ a Difference-in-Differences framework with
two-way fixed effects to analyze data from all OSS developers on GitHub in
three similar countries, Italy, France, and Portugal, totaling 88,022 users. We
find that access to ChatGPT increases developer productivity by 6.4%, knowledge
sharing by 9.6%, and skill acquisition by 8.4%. These benefits vary
significantly by user experience level: novice developers primarily experience
productivity gains, whereas more experienced developers benefit more from
improved knowledge sharing and accelerated skill acquisition. In addition, we
find that LLM-assisted learning is highly context-dependent, with the greatest
benefits observed in technically complex, fragmented, or rapidly evolving
contexts. We show that the productivity effects of LLMs extend beyond direct
code generation to include enhanced collaborative learning and knowledge
exchange among developers, dynamics that are essential for gaining a holistic
understanding of LLMs' impact in OSS. Our findings offer critical managerial
implications: strategically deploying LLMs can accelerate novice developers'
onboarding and productivity, empower intermediate developers to foster
knowledge sharing and collaboration, and support rapid skill acquisition,
together enhancing long-term organizational productivity and agility.


## A new sparsity promoting residual transform operator for Lasso regression

>Authors: Yao Xiao, Anne Gelb, Aditya Viswanathan

>2025-06-28

> http://arxiv.org/abs/2506.22689v1

Lasso regression is a widely employed approach within the $\ell_1$
regularization framework used to promote **sparsity** and recover piecewise smooth
signals $f:[a,b) \rightarrow \mathbb{R}$ when the given observations are
obtained from noisy, blurred, and/or incomplete data environments. In choosing
the regularizing **sparsity**-promoting operator, it is assumed that the particular
type of variability of the underlying signal, for example, piecewise constant
or piecewise linear behavior across the entire domain, is both known and fixed.
Such an assumption is problematic in more general cases, e.g.~when a signal
exhibits piecewise oscillatory behavior with varying wavelengths and
magnitudes. To address the limitations of assuming a fixed (and typically low
order) variability when choosing a **sparsity**-promoting operator, this
investigation proposes a novel residual transform operator that can be used
within the Lasso regression formulation. In a nutshell, the idea is that for a
general piecewise smooth signal $f$, it is possible to design two operators
$\mathcal L_1$ and $\mathcal L_2$ such that $\mathcal L_1{\boldsymbol f}
\approx \mathcal L_2{\boldsymbol f}$, where ${\boldsymbol f} \in \mathbb{R}^n$
is a discretized approximation of $f$, but $\mathcal L_1 \not\approx \mathcal
L_2$. The corresponding residual transform operator, $\mathcal L = \mathcal
L_1- \mathcal L_2$, yields a result that (1) effectively reduces the
variability dependent error that occurs when applying either $\mathcal L_1$ or
$\mathcal L_2$ to ${\boldsymbol f}$, a property that holds even when $\mathcal
L_1{\boldsymbol f} \approx \mathcal L_2{\boldsymbol f}$ is not a good
approximation to the true **sparse** domain vector of ${\boldsymbol f}$, and (2)
does not require $\mathcal L_1$ or $\mathcal L_2$ to have prior information
regarding the variability of the underlying signal.


## URSA The Universal Research and Scientific Agent

>Authors: Michael Grosskopf, Russell Bent, Rahul Somasundaram, Isaac Michaud, Arthur Lui, Nathan Debardeleben, Earl Lawrence

>2025-06-27

> http://arxiv.org/abs/2506.22653v1

Large language models (LLMs) have moved far beyond their initial form as
simple chatbots, now carrying out complex reasoning, planning, writing, coding,
and research tasks. These skills overlap significantly with those that human
scientists use day-to-day to solve complex problems that drive the cutting edge
of research. Using LLMs in "agentic" AI has the potential to revolutionize
modern science and remove bottlenecks to progress. In this work, we present
URSA, a scientific agent ecosystem for accelerating research tasks. URSA
consists of a set of modular agents and tools, including coupling to advanced
physics simulation codes, that can be combined to address scientific problems
of varied complexity and impact. This work highlights the architecture of URSA,
as well as examples that highlight the potential of the system.


## Hydrodynamic interactions of low-aspect-ratio oscillating panels in a tip-to-tip formation

>Authors: Yu Pan, Yuanhang Zhu, Elizabeth Westfall, Daniel B. Quinn, Haibo Dong, George V. Lauder

>2025-06-27

> http://arxiv.org/abs/2506.22612v1

The vertical, tip-to-tip arrangement of neighboring caudal fins, common in
densely packed fish schools, has received much less attention than staggered or
side-by-side pairings. We explore this configuration using a canonical system
of two trapezoidal plates (aspect ratio AR = 1.2) that pitch about their
leading edges while heaving harmonically at a Strouhal number St = 0.45 and a
reduced frequency k = 2.09. Direct numerical simulations based on an
immersed-boundary method are conducted over a Reynolds number range of 600 <=
Re <= 1e4, and complementary water-channel experiments extend this range to 1e4
<= Re <= 3e4, thereby validating the computations at higher flow speeds.
Results indicate that when the plates oscillate in phase at a nondimensional
vertical spacing H/c <= 1.0, the cycle-averaged thrust coefficient of each
plate rises by up to 14.5% relative to an isolated plate; the enhancement
decreases monotonically as the spacing increases. Anti-phase motion instead
lowers the time-average power coefficient by up to 6%, with only a modest
thrust penalty, providing an alternative interaction regime. Flow visualization
shows that in-phase kinematics accelerate the stream between the plates,
intensifying the adjacent leading-edge vortices. Downstream, the initially
separate vortex rings merge into a single, larger ring that is strongly
compressed in the spanwise direction; this wake compression correlates with the
measured thrust gain. The interaction mechanism and its quantitative benefits
persist throughout the entire numerical and experimental Reynolds-number sweep,
indicating weak Re-sensitivity within 600 <= Re <= 3e4. These results provide
the first three-dimensional characterization of tip-to-tip flapping-plate
interactions, establish scaling trends with spacing and phase, and offer a
reference data set for reduced-order models of vertically stacked propulsors.


## HyperCLOVA X THINK Technical Report

>Authors: NAVER Cloud HyperCLOVA X Team

>2025-06-27

> http://arxiv.org/abs/2506.22403v2

We introduce HyperCLOVA X THINK, the first reasoning-focused large language
model in the HyperCLOVA X family, pre-trained on roughly $6$ trillion
high-quality Korean, and English tokens, augmented with targeted synthetic
Korean data. It was implemented as a compute-memory-balanced Peri-LN
Transformer scaled with $\mu$P, pre-trained through a three-stage curriculum
that expands the context window to $128$K tokens, and post-trained via
supervised fine-tuning with Reinforcement Learning from Verifiable Rewards
supports both detailed rationale and concise-answer modes. It delivers
competitive performance against similarly sized models on Korea-focused
benchmarks such as KMMLU, CSAT, KoBALT-700, HAERAE-1.0, and KoBigBench, while
preserving robust bilingual consistency and translation quality. In addition, a
vision-augmented variant matches or exceeds GPT-4.1 on the KCSAT STEM
benchmark, all of which are achieved with substantially lower training compute
than existing models of similar sizes. We also present a **pruning** and
distillation technique that will soon be applied to HyperCLOVA X THINK for an
open-source and business-friendly foundation model. Altogether, these
capabilities position HyperCLOVA X THINK as a robust foundation for Korean AI
innovation and a valuable resource for the global research community.


## QuickSilver -- Speeding up LLM Inference through Dynamic Token Halting, KV Skipping, Contextual Token Fusion, and Adaptive Matryoshka Quantization

>Authors: Danush Khanna, Aditya Kumar Guru, Srivarshinee Sridhar, Zidan Ahmed, Rubhav Bahirwani, Meetu Malhotra, Vinija Jain, Aman Chadha, Amitava Das, Kripabandhu Ghosh

>2025-06-27

> http://arxiv.org/abs/2506.22396v1

Inference accounts for the majority of latency and energy consumption in
large language model (LLM) deployments, often exceeding 90% of total cost.
While training-time efficiency has seen extensive progress, runtime
optimization remains a key bottleneck, particularly under autoregressive
decoding. Existing approaches -- such as **pruning**, **quantization**, early exits,
and speculative decoding -- often require retraining, architectural changes, or
disrupt decoding compatibility. We introduce QuickSilver, a modular,
token-level framework that enables semantic adaptivity at inference time
without altering model weights or structure. QuickSilver integrates four
synergistic mechanisms:
  (i) Dynamic Token Halting, which halts computation for tokens with converged
representations; (ii) **KV** Cache Skipping, which selectively suppresses memory
writes to reduce attention overhead; and (iii) Contextual Token Fusion, which
collapses redundant tokens into shared paths to shrink sequence length.
  Unlike speculative decoding or MoE routing, QuickSilver operates entirely on
frozen, dense models and requires no auxiliary networks. Applied to GPT-2 and
Llama-2 across WikiText-103 and C4, QuickSilver achieves up to 39.6% FLOP
reduction with negligible perplexity degradation (<=0.2).


## Towards Distributed Neural Architectures

>Authors: Aditya Cowsik, Tianyu He, Andrey Gromov

>2025-06-27

> http://arxiv.org/abs/2506.22389v1

We introduce and train distributed neural architectures (DNA) in vision and
language domains. DNAs are initialized with a proto-architecture that consists
of (transformer, MLP, attention, etc.) modules and routers. Any token (or
patch) can traverse any series of modules in any order. DNAs are a natural
generalization of the **sparse** methods such as Mixture-of-Experts,
Mixture-of-Depths, parameter sharing, etc. Computation and communication
patterns of DNA modules are learnt end-to-end during training and depend on the
content and context of each token (or patch). These patterns can be shaped by
further requirements added to the optimization objective such as compute/memory
efficiency or load balancing. We empirically show that (i) trained DNAs are
competitive with the dense baselines in both domains and (ii) compute
efficiency/parameter sharing can be learnt from data. Next, we analyze the
emergent connectivity and computation patterns in the trained DNAs. We find
that the paths that tokens take through the models are themselves distributed
according to a power-law. We show that some paths (or, equivalently, groups of
modules) show emergent specialization. Finally, we demonstrate that models
learn to allocate compute and active parameters in an interpretable way.


## Closing the Performance Gap in Biometric Cryptosystems A Deeper Analysis on Unlinkable Fuzzy Vaults

>Authors: Hans Geißner, Christian Rathgeb

>2025-06-27

> http://arxiv.org/abs/2506.22347v1

This paper analyses and addresses the performance gap in the fuzzy
vault-based \ac{BCS}. We identify unstable error correction capabilities, which
are caused by variable feature set sizes and their influence on similarity
thresholds, as a key source of performance degradation. This issue is further
compounded by information loss introduced through feature type transformations.
To address both problems, we propose a novel feature **quantization** method based
on \it{equal frequent intervals}. This method guarantees fixed feature set
sizes and supports training-free adaptation to any number of intervals. The
proposed approach significantly reduces the performance gap introduced by
template protection. Additionally, it integrates seamlessly with existing
systems to minimize the negative effects of feature transformation. Experiments
on state-of-the-art face, fingerprint, and iris recognition systems confirm
that only minimal performance degradation remains, demonstrating the
effectiveness of the method across major biometric modalities.


## Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment

>Authors: Rui Xu, Yunke Wang, Yong Luo, Bo Du

>2025-06-27

> http://arxiv.org/abs/2506.22283v1

Large Vision-Language Models (LVLMs) encode visual inputs as dense sequences
of patch-level tokens to capture fine-grained semantics. These visual tokens
often outnumber their textual counterparts by a large margin, leading to
substantial computational overhead and limiting the scalability of LVLMs in
practice. Previous efforts have explored visual token reduction either prior to
or within the large language models (LLM). However, most in-LLM reduction
approaches rely on text-conditioned interactions, implicitly assuming that
textual tokens can reliably capture the importance of visual tokens. In this
work, we revisit this assumption and reveal causal, semantic, and spatial forms
of cross-modal misalignment. These misalignments undermine the effectiveness of
text-guided visual token reduction. To address this, we introduce VisionDrop, a
training-free, visual-only **pruning** framework that selects informative visual
tokens based on intra-modal (visual-to-visual) attention, without relying on
textual signals. To further suppress redundancy throughout the model hierarchy,
we treat the visual encoder and the LLM as a unified system and design a
progressive **pruning** pipeline. Our method performs dominant token selection and
lightweight contextual merging at multiple stages, enabling fine-grained visual
information to be retained even under aggressive token budgets. Extensive
experiments across diverse benchmarks show that VisionDrop achieves consistent
improvements over existing methods, despite requiring no additional training or
complex modifications. Its simple yet effective design enables efficient
inference while preserving strong performance across tasks.


## Projected Compression Trainable Projection for Efficient Transformer Compression

>Authors: Maciej Stefaniak, Michał Krutul, Jan Małaśnicki, Maciej Pióro, Jakub Krajewski, Sebastian Jaszczur, Marek Cygan, Kamil Adamczewski, Jan Ludziejewski

>2025-06-27

> http://arxiv.org/abs/2506.22255v1

Large language models have steadily increased in size to achieve improved
performance; however, this growth has also led to greater inference time and
computational demands. Consequently, there is rising interest in model size
reduction methods. To address this issue, we propose Projected Compression, a
novel model compression technique, that reduces model weights by utilizing
projection modules. Specifically, we first train additional trainable
projections weights and preserve access to all the original model parameters.
Subsequently, these projections are merged into a lower-dimensional product
matrix, resulting in a reduced-size standard Transformer-based model. Unlike
alternative approaches that require additional computational overhead, our
method matches the base model's per-token computation step in FLOPs.
Experimental results show that Projected Compression outperforms the comparable
hard **pruning** and retraining approach on higher quality models. Moreover, the
performance margin scales well with the number of tokens.


## Exploring Modularity of Agentic Systems for Drug Discovery

>Authors: Laura van Weesep, Samuel Genheden, Ola Engkvist, Jens Sjölund

>2025-06-27

> http://arxiv.org/abs/2506.22189v1

Large-language models (LLMs) and agentic systems present exciting
opportunities to accelerate drug discovery and design. In this study, we
critically examine the modularity of LLM-based agentic systems for drug
discovery, i.e., whether parts of the agentic system such as the LLM are
interchangeable, a topic that has received limited attention in drug discovery
applications. We compare the performance of different large language models
(LLMs) and the effectiveness of tool-calling agents versus code-generating
agents in this domain. Our case study, comparing performance in orchestrating
tools for chemistry and drug discovery using an LLM-as-a-judge score, shows
that Claude-3.5-Sonnet, Claude-3.7-Sonnet and GPT-4o outperform alternative
language models such as Llama-3.1-8B, Llama-3.1-70B, GPT-3.5-Turbo, and
Nova-Micro. Although we confirm that code-generating agents outperform the
tool-calling ones on average, we show that this is highly question and model
dependent. Furthermore, the impact of replacing system prompts is dependent on
the specific question asked and the model used, underscoring that -- even in
this particular domain -- one cannot just replace language models without
considering prompt re-engineering. Our study highlights the necessity of
further research into the modularity of agentic systems to enable the
development of stable and scalable solutions for real-world problems.


## Learning to Solve Multi-Objective Routing Problems on Multigraphs

>Authors: Filip Rydin, Attila Lischka, Jiaming Wu, Morteza Haghir Chehreghani, Balázs Kulcsár

>2025-06-27

> http://arxiv.org/abs/2506.22095v1

Learning-based methods for routing have gained significant attention in
recent years, both in single-objective and multi-objective contexts. However,
the multigraph setting, where multiple paths with distinct attributes can exist
between destinations, has largely been overlooked, despite its high practical
relevancy. In this paper, we introduce two neural approaches to address
multi-objective routing on multigraphs. Our first approach works directly on
the multigraph, by autoregressively selecting edges until a tour is completed.
On the other hand, our second model first prunes the multigraph into a simple
graph and then builds routes. We validate both models experimentally and find
that they demonstrate strong performance across a variety of problems,
including the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing
Problem (CVRP).


## Transformers are Graph Neural Networks

>Authors: Chaitanya K. Joshi

>2025-06-27

> http://arxiv.org/abs/2506.22084v1

We establish connections between the Transformer architecture, originally
introduced for natural language processing, and Graph Neural Networks (GNNs)
for representation learning on graphs. We show how Transformers can be viewed
as message passing GNNs operating on fully connected graphs of tokens, where
the self-attention mechanism capture the relative importance of all tokens
w.r.t. each-other, and positional encodings provide hints about sequential
ordering or structure. Thus, Transformers are expressive set processing
networks that learn relationships among input elements without being
constrained by apriori graphs. Despite this mathematical connection to GNNs,
Transformers are implemented via dense matrix operations that are significantly
more efficient on modern hardware than **sparse** message passing. This leads to
the perspective that Transformers are GNNs currently winning the hardware
lottery.


## Query as Test An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios

>Authors: Shengyue Yao, Runqing Guo, Yangyang Qin, Miangbing Meng, Jipeng Cao, Yilun Lin, Yisheng Lv, Fei-Yue Wang

>2025-06-27

> http://arxiv.org/abs/2506.22068v1

With the deep penetration of Artificial Intelligence (AI) in the
transportation sector, intelligent cockpits, autonomous driving, and
intelligent road networks are developing at an unprecedented pace. However, the
data ecosystems of these three key areas are increasingly fragmented and
incompatible. Especially, existing testing methods rely on data stacking, fail
to cover all edge cases, and lack flexibility. To address this issue, this
paper introduces the concept of "Query as Test" (QaT). This concept shifts the
focus from rigid, prescripted test cases to flexible, on-demand logical queries
against a unified data representation. Specifically, we identify the need for a
fundamental improvement in data storage and representation, leading to our
proposal of "Extensible Scenarios Notations" (ESN). ESN is a novel declarative
data framework based on Answer Set Programming (ASP), which uniformly
represents heterogeneous multimodal data from the cockpit, vehicle, and road as
a collection of logical facts and rules. This approach not only achieves deep
semantic fusion of data, but also brings three core advantages: (1) supports
complex and flexible semantic querying through logical reasoning; (2) provides
natural interpretability for decision-making processes; (3) allows for
on-demand data abstraction through logical rules, enabling fine-grained privacy
protection. We further elaborate on the QaT paradigm, transforming the
functional validation and safety compliance checks of autonomous driving
systems into logical queries against the ESN database, significantly enhancing
the expressiveness and formal rigor of the testing. Finally, we introduce the
concept of "Validation-Driven Development" (VDD), which suggests to guide
developments by logical validation rather than quantitative testing in the era
of Large Language Models, in order to accelerating the iteration and
development process.


## SPTCStencil Unleashing Sparse Tensor Cores for Stencil Computation via Strided Swap

>Authors: Qiqi GU, Chenpeng Wu, Heng Shi, Jianguo Yao

>2025-06-27

> http://arxiv.org/abs/2506.22035v1

Stencil computation, a pivotal numerical method in science and engineering,
iteratively updates grid points using weighted neighbor contributions and
exhibits strong parallelism for multi-core processors. Current optimization
techniques targeting conducting stencil computation on tensor core accelerators
incur substantial overheads due to redundant zero-padding during the
transformation to matrix multiplication. To address this, we introduce a **sparse**
computation paradigm that eliminates inefficiencies by exploiting specialized
hardware units.
  This paper exploits the **sparsity** in these matrices as a feature and presents
SPTCStencil, a high-performance stencil computation system accelerated by
Sparse Tensor Core (SpTCs). SPTCStencil is the first to harness SpTCs for
**acceleration** beyond deep learning domains. First, Our approach generalizes an
efficient transformation of stencil computation into matrix multiplications and
specializes this conversion for SpTC compatibility through a novel
sparsification strategy. Furthermore, SPTCStencil incorporates a
high-performance GPU kernel with systematic optimizations designed to maximize
efficiency on SpTCs. Experimental evaluations demonstrate that SPTCStencil
5.46$\times$ and Tensor Core-based approaches by 2.00$\times$ on average.


## SiPipe Bridging the CPU-GPU Utilization Gap for Efficient Pipeline-Parallel LLM Inference

>Authors: Yongchao He, Bohan Zhao, Zheng Cao

>2025-06-27

> http://arxiv.org/abs/2506.22033v1

As inference workloads for large language models (LLMs) scale to meet growing
user demand, pipeline parallelism (PP) has become a widely adopted strategy for
multi-GPU deployment, particularly in cross-node setups, to improve key-value
(**KV**) cache capacity and inference throughput. However, PP suffers from inherent
inefficiencies caused by three types of execution bubbles-load-imbalance,
intra-stage, and inter-stage-which limit pipeline saturation. We present
SiPipe, a heterogeneous pipeline design that improves throughput by leveraging
underutilized CPU resources to offload auxiliary computation and communication.
SiPipe incorporates three key techniques-CPU sampling, a token-safe execution
model, and structure-aware transmission-to mitigate pipeline bubbles and
improve execution efficiency. Across diverse LLMs, SiPipe achieves up to 2.1
times higher throughput, 43% lower per-token latency, and up to 23% higher
average GPU utilization compared to the state-of-the-art vLLM under the same PP
configuration, demonstrating its generality across LLMs and deployment
scenarios.


## A Survey of LLM Inference Systems

>Authors: James Pan, Guoliang Li

>2025-06-27

> http://arxiv.org/abs/2506.21901v1

The past few years has witnessed specialized large language model (LLM)
inference systems, such as vLLM, SGLang, Mooncake, and DeepFlow, alongside
rapid LLM adoption via services like ChatGPT. Driving these system design
efforts is the unique autoregressive nature of LLM request processing,
motivating new techniques for achieving high performance while preserving high
inference quality over high-volume and high-velocity workloads. While many of
these techniques are discussed across the literature, they have not been
analyzed under the framework of a complete inference system, nor have the
systems themselves been analyzed and compared.
  In this survey, we review these techniques, starting from operators and
algorithms for request processing, then moving on to techniques for model
optimization and execution, including kernel design, batching, and scheduling,
before ending with techniques for memory management, including paged memory,
eviction and offloading techniques, **quantization**, and cache persistence.
Through these discussions, we show that these techniques fundamentally rely on
load prediction, adaptive mechanisms, and cost reduction in order to overcome
the challenges introduced by autoregressive generation and achieve the goals of
the system. We then discuss how these techniques can be combined to form
single-replica and multi-replica inference systems, including disaggregated
inference systems that offer more control over resource allocation and
serverless systems that can be deployed over shared hardware infrastructure. We
end with a discussion of remaining challenges.

