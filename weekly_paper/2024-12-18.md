# 2024-12-18

# Table of Contents
* [GaussTR Foundation Model-Aligned Gaussian Transformer for Self-Supervised 3D Spatial Understanding](#GaussTR-Foundation-Model-Aligned-Gaussian-Transformer-for-Self-Supervised-3D-Spatial-Understanding)
* [Unlocking the Potential of Digital Pathology Novel Baselines for Compression](#Unlocking-the-Potential-of-Digital-Pathology-Novel-Baselines-for-Compression)
* [Efficient Diffusion Transformer Policies with Mixture of Expert Denoisers for Multitask Learning](#Efficient-Diffusion-Transformer-Policies-with-Mixture-of-Expert-Denoisers-for-Multitask-Learning)
* [TimeCHEAT A Channel Harmony Strategy for Irregularly Sampled Multivariate Time Series Analysis](#TimeCHEAT-A-Channel-Harmony-Strategy-for-Irregularly-Sampled-Multivariate-Time-Series-Analysis)
* [A Comparative Study of Pruning Methods in Transformer-based Time Series Forecasting](#A-Comparative-Study-of-Pruning-Methods-in-Transformer-based-Time-Series-Forecasting)
* [Data-Driven Catalyst Design A Machine Learning Approach to Predicting Electrocatalytic Performance in Hydrogen Evolution and Oxygen Evolution Reactions](#Data-Driven-Catalyst-Design-A-Machine-Learning-Approach-to-Predicting-Electrocatalytic-Performance-in-Hydrogen-Evolution-and-Oxygen-Evolution-Reactions)
* [2by2 Weakly-Supervised Learning for Global Action Segmentation](#2by2-Weakly-Supervised-Learning-for-Global-Action-Segmentation)
* [RCTrans Radar-Camera Transformer via Radar Densifier and Sequential Decoder for 3D Object Detection](#RCTrans-Radar-Camera-Transformer-via-Radar-Densifier-and-Sequential-Decoder-for-3D-Object-Detection)
* [Activating Distributed Visual Region within LLMs for Efficient and Effective Vision-Language Training and Inference](#Activating-Distributed-Visual-Region-within-LLMs-for-Efficient-and-Effective-Vision-Language-Training-and-Inference)
* [More Tokens, Lower Precision Towards the Optimal Token-Precision Trade-off in KV Cache Compression](#More-Tokens,-Lower-Precision-Towards-the-Optimal-Token-Precision-Trade-off-in-KV-Cache-Compression)
* [Falcon Faster and Parallel Inference of Large Language Models through Enhanced Semi-Autoregressive Drafting and Custom-Designed Decoding Tree](#Falcon-Faster-and-Parallel-Inference-of-Large-Language-Models-through-Enhanced-Semi-Autoregressive-Drafting-and-Custom-Designed-Decoding-Tree)
* [PO3AD Predicting Point Offsets toward Better 3D Point Cloud Anomaly Detection](#PO3AD-Predicting-Point-Offsets-toward-Better-3D-Point-Cloud-Anomaly-Detection)
* [LLMs are Also Effective Embedding Models An In-depth Overview](#LLMs-are-Also-Effective-Embedding-Models-An-In-depth-Overview)
* [A System for Microserving of LLMs](#A-System-for-Microserving-of-LLMs)
* [Boosting Long-Context Information Seeking via Query-Guided Activation Refilling](#Boosting-Long-Context-Information-Seeking-via-Query-Guided-Activation-Refilling)
* [if-ZKP Intel FPGA-Based Acceleration of Zero Knowledge Proofs](#if-ZKP-Intel-FPGA-Based-Acceleration-of-Zero-Knowledge-Proofs)
* [Numerical Pruning for Efficient Autoregressive Models](#Numerical-Pruning-for-Efficient-Autoregressive-Models)
* [Krony-PT GPT2 compressed with Kronecker Products](#Krony-PT-GPT2-compressed-with-Kronecker-Products)
* [Physics-informed Transformers for Electronic Quantum States](#Physics-informed-Transformers-for-Electronic-Quantum-States)
* [SepLLM Accelerate Large Language Models by Compressing One Segment into One Separator](#SepLLM-Accelerate-Large-Language-Models-by-Compressing-One-Segment-into-One-Separator)
* [LeARN Learnable and Adaptive Representations for Nonlinear Dynamics in System Identification](#LeARN-Learnable-and-Adaptive-Representations-for-Nonlinear-Dynamics-in-System-Identification)
* [SpeechPrune Context-aware Token Pruning for Speech Information Retrieval](#SpeechPrune-Context-aware-Token-Pruning-for-Speech-Information-Retrieval)
* [Multiplex Dirichlet stochastic block model for clustering multidimensional compositional networks](#Multiplex-Dirichlet-stochastic-block-model-for-clustering-multidimensional-compositional-networks)
* [RetroLLM Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation](#RetroLLM-Empowering-Large-Language-Models-to-Retrieve-Fine-grained-Evidence-within-Generation)
* [Harvesting stabilizer entropy and non-locality from a quantum field](#Harvesting-stabilizer-entropy-and-non-locality-from-a-quantum-field)
* [CharacterBench Benchmarking Character Customization of Large Language Models](#CharacterBench-Benchmarking-Character-Customization-of-Large-Language-Models)
* [Transformers Use Causal World Models in Maze-Solving Tasks](#Transformers-Use-Causal-World-Models-in-Maze-Solving-Tasks)
* [A Distributed Collaborative Retrieval Framework Excelling in All Queries and Corpora based on Zero-shot Rank-Oriented Automatic Evaluation](#A-Distributed-Collaborative-Retrieval-Framework-Excelling-in-All-Queries-and-Corpora-based-on-Zero-shot-Rank-Oriented-Automatic-Evaluation)
* [Fast and Slow Gradient Approximation for Binary Neural Network Optimization](#Fast-and-Slow-Gradient-Approximation-for-Binary-Neural-Network-Optimization)
* [CSRAchieving 1 Bit Key-Value Cache via Sparse Representation](#CSRAchieving-1-Bit-Key-Value-Cache-via-Sparse-Representation)
* [AsymRnR Video Diffusion Transformers Acceleration with Asymmetric Reduction and Restoration](#AsymRnR-Video-Diffusion-Transformers-Acceleration-with-Asymmetric-Reduction-and-Restoration)
* [Flex-PE Flexible and SIMD Multi-Precision Processing Element for AI Workloads](#Flex-PE-Flexible-and-SIMD-Multi-Precision-Processing-Element-for-AI-Workloads)
* [Ultra-High-Definition Dynamic Multi-Exposure Image Fusion via Infinite Pixel Learning](#Ultra-High-Definition-Dynamic-Multi-Exposure-Image-Fusion-via-Infinite-Pixel-Learning)
* [QPruner Probabilistic Decision Quantization for Structured Pruning in Large Language Models](#QPruner-Probabilistic-Decision-Quantization-for-Structured-Pruning-in-Large-Language-Models)
* [MeshArt Generating Articulated Meshes with Structure-guided Transformers](#MeshArt-Generating-Articulated-Meshes-with-Structure-guided-Transformers)
* [SFFT-based Homogenization Using Tensor Trains to Enhance FFT-Based Homogenization](#SFFT-based-Homogenization-Using-Tensor-Trains-to-Enhance-FFT-Based-Homogenization)
* [MPQ-DM Mixed Precision Quantization for Extremely Low Bit Diffusion Models](#MPQ-DM-Mixed-Precision-Quantization-for-Extremely-Low-Bit-Diffusion-Models)
* [SP$^2$T Sparse Proxy Attention for Dual-stream Point Transformer](#SP$^2$T-Sparse-Proxy-Attention-for-Dual-stream-Point-Transformer)
* [ON as ALC Active Loop Closing Object Goal Navigation](#ON-as-ALC-Active-Loop-Closing-Object-Goal-Navigation)
* [EditSplat Multi-View Fusion and Attention-Guided Optimization for View-Consistent 3D Scene Editing with 3D Gaussian Splatting](#EditSplat-Multi-View-Fusion-and-Attention-Guided-Optimization-for-View-Consistent-3D-Scene-Editing-with-3D-Gaussian-Splatting)
* [FTP A Fine-grained Token-wise Pruner for Large Language Models via Token Routing](#FTP-A-Fine-grained-Token-wise-Pruner-for-Large-Language-Models-via-Token-Routing)
* [Towards Scientific Discovery with Generative AI Progress, Opportunities, and Challenges](#Towards-Scientific-Discovery-with-Generative-AI-Progress,-Opportunities,-and-Challenges)
* [FinLoRA Finetuning Quantized Financial Large Language Models Using Low-Rank Adaptation](#FinLoRA-Finetuning-Quantized-Financial-Large-Language-Models-Using-Low-Rank-Adaptation)
* [Accelerating Sparse Graph Neural Networks with Tensor Core Optimization](#Accelerating-Sparse-Graph-Neural-Networks-with-Tensor-Core-Optimization)
* [Efficient Whisper on Streaming Speech](#Efficient-Whisper-on-Streaming-Speech)
* [TrimLLM Progressive Layer Dropping for Domain-Specific LLMs](#TrimLLM-Progressive-Layer-Dropping-for-Domain-Specific-LLMs)
* [Latent Reward LLM-Empowered Credit Assignment in Episodic Reinforcement Learning](#Latent-Reward-LLM-Empowered-Credit-Assignment-in-Episodic-Reinforcement-Learning)
* [Multi-Graph Co-Training for Capturing User Intent in Session-based Recommendation](#Multi-Graph-Co-Training-for-Capturing-User-Intent-in-Session-based-Recommendation)
* [Zigzag Diffusion Sampling Diffusion Models Can Self-Improve via Self-Reflection](#Zigzag-Diffusion-Sampling-Diffusion-Models-Can-Self-Improve-via-Self-Reflection)
* [RWKV-edge Deeply Compressed RWKV for Resource-Constrained Devices](#RWKV-edge-Deeply-Compressed-RWKV-for-Resource-Constrained-Devices)
* [Symmetries of a 3D Field-Theoretic Model](#Symmetries-of-a-3D-Field-Theoretic-Model)
* [Boosting ViT-based MRI Reconstruction from the Perspectives of Frequency Modulation, Spatial Purification, and Scale Diversification](#Boosting-ViT-based-MRI-Reconstruction-from-the-Perspectives-of-Frequency-Modulation,-Spatial-Purification,-and-Scale-Diversification)
* [WaveGNN Modeling Irregular Multivariate Time Series for Accurate Predictions](#WaveGNN-Modeling-Irregular-Multivariate-Time-Series-for-Accurate-Predictions)
* [iMoT Inertial Motion Transformer for Inertial Navigation](#iMoT-Inertial-Motion-Transformer-for-Inertial-Navigation)
* [SCBench A KV Cache-Centric Analysis of Long-Context Methods](#SCBench-A-KV-Cache-Centric-Analysis-of-Long-Context-Methods)
* [MST-R Multi-Stage Tuning for Retrieval Systems and Metric Evaluation](#MST-R-Multi-Stage-Tuning-for-Retrieval-Systems-and-Metric-Evaluation)
* [Cultural Evolution of Cooperation among LLM Agents](#Cultural-Evolution-of-Cooperation-among-LLM-Agents)
* [CosyVoice 2 Scalable Streaming Speech Synthesis with Large Language Models](#CosyVoice-2-Scalable-Streaming-Speech-Synthesis-with-Large-Language-Models)
* [Matrix Completion via Residual Spectral Matching](#Matrix-Completion-via-Residual-Spectral-Matching)
* [Static Pruning in Dense Retrieval using Matrix Decomposition](#Static-Pruning-in-Dense-Retrieval-using-Matrix-Decomposition)
* [T-GMSI A transformer-based generative model for spatial interpolation under sparse measurements](#T-GMSI-A-transformer-based-generative-model-for-spatial-interpolation-under-sparse-measurements)
* [Activation Sparsity Opportunities for Compressing General Large Language Models](#Activation-Sparsity-Opportunities-for-Compressing-General-Large-Language-Models)
* [Private Synthetic Data Generation in Small Memory](#Private-Synthetic-Data-Generation-in-Small-Memory)
* [AiEDA Agentic AI Design Framework for Digital ASIC System Design](#AiEDA-Agentic-AI-Design-Framework-for-Digital-ASIC-System-Design)
* [DiP A Scalable, Energy-Efficient Systolic Array for Matrix Multiplication Acceleration](#DiP-A-Scalable,-Energy-Efficient-Systolic-Array-for-Matrix-Multiplication-Acceleration)
* [FreeSplatter Pose-free Gaussian Splatting for Sparse-view 3D Reconstruction](#FreeSplatter-Pose-free-Gaussian-Splatting-for-Sparse-view-3D-Reconstruction)
* [Obfuscated Activations Bypass LLM Latent-Space Defenses](#Obfuscated-Activations-Bypass-LLM-Latent-Space-Defenses)
* [Foundational Large Language Models for Materials Research](#Foundational-Large-Language-Models-for-Materials-Research)
* [Interpolating amplitudes](#Interpolating-amplitudes)
* [From Intention To Implementation Automating Biomedical Research via LLMs](#From-Intention-To-Implementation-Automating-Biomedical-Research-via-LLMs)
* [RTCUDB Building Databases with RT Processors](#RTCUDB-Building-Databases-with-RT-Processors)
* [Physics-Driven Autoregressive State Space Models for Medical Image Reconstruction](#Physics-Driven-Autoregressive-State-Space-Models-for-Medical-Image-Reconstruction)
* [Asymptotics of Harish-Chandra transform and infinitesimal freeness](#Asymptotics-of-Harish-Chandra-transform-and-infinitesimal-freeness)
* [Optimising TinyML with Quantization and Distillation of Transformer and Mamba Models for Indoor Localisation on Edge Devices](#Optimising-TinyML-with-Quantization-and-Distillation-of-Transformer-and-Mamba-Models-for-Indoor-Localisation-on-Edge-Devices)
* [CRVQ Channel-relaxed Vector Quantization for Extreme Compression of LLMs](#CRVQ-Channel-relaxed-Vector-Quantization-for-Extreme-Compression-of-LLMs)
* [Score and Distribution Matching Policy Advanced Accelerated Visuomotor Policies via Matched Distillation](#Score-and-Distribution-Matching-Policy-Advanced-Accelerated-Visuomotor-Policies-via-Matched-Distillation)
* [Generalized Liénard systems with momentum-dependent mass Isochronicity and bound states](#Generalized-Liénard-systems-with-momentum-dependent-mass-Isochronicity-and-bound-states)
* [Forest-of-Thought Scaling Test-Time Compute for Enhancing LLM Reasoning](#Forest-of-Thought-Scaling-Test-Time-Compute-for-Enhancing-LLM-Reasoning)
* [A Symplectic Discretization Based Proximal Point Algorithm for Convex Minimization](#A-Symplectic-Discretization-Based-Proximal-Point-Algorithm-for-Convex-Minimization)
* [Rules for dissipationless topotronics](#Rules-for-dissipationless-topotronics)
* [SEGT A General Spatial Expansion Group Transformer for nuScenes Lidar-based Object Detection Task](#SEGT-A-General-Spatial-Expansion-Group-Transformer-for-nuScenes-Lidar-based-Object-Detection-Task)
* [ZigZagkv Dynamic KV Cache Compression for Long-context Modeling based on Layer Uncertainty](#ZigZagkv-Dynamic-KV-Cache-Compression-for-Long-context-Modeling-based-on-Layer-Uncertainty)
* [RingFormer A Ring-Enhanced Graph Transformer for Organic Solar Cell Property Prediction](#RingFormer-A-Ring-Enhanced-Graph-Transformer-for-Organic-Solar-Cell-Property-Prediction)
* [Lexico Extreme KV Cache Compression via Sparse Coding over Universal Dictionaries](#Lexico-Extreme-KV-Cache-Compression-via-Sparse-Coding-over-Universal-Dictionaries)
* [From Noise to Nuance Advances in Deep Generative Image Models](#From-Noise-to-Nuance-Advances-in-Deep-Generative-Image-Models)
* [The Critical Beta-splitting Random Tree III The exchangeable partition representation and the fringe tree](#The-Critical-Beta-splitting-Random-Tree-III-The-exchangeable-partition-representation-and-the-fringe-tree)
* [Designing flexible hard magnetic materials for zero-magnetic-field operation of the anomalous Nernst effect](#Designing-flexible-hard-magnetic-materials-for-zero-magnetic-field-operation-of-the-anomalous-Nernst-effect)
* [HadaCore Tensor Core Accelerated Hadamard Transform Kernel](#HadaCore-Tensor-Core-Accelerated-Hadamard-Transform-Kernel)
* [Large Concept Models Language Modeling in a Sentence Representation Space](#Large-Concept-Models-Language-Modeling-in-a-Sentence-Representation-Space)
* [GPD-1 Generative Pre-training for Driving](#GPD-1-Generative-Pre-training-for-Driving)
* [Multimodal Latent Language Modeling with Next-Token Diffusion](#Multimodal-Latent-Language-Modeling-with-Next-Token-Diffusion)
* [Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models](#Exploiting-the-Index-Gradients-for-Optimization-Based-Jailbreaking-on-Large-Language-Models)
* [TurboAttention Efficient Attention Approximation For High Throughputs LLMs](#TurboAttention-Efficient-Attention-Approximation-For-High-Throughputs-LLMs)
* [Sparse Signature Coefficient Recovery via Kernels](#Sparse-Signature-Coefficient-Recovery-via-Kernels)
* [EMS Adaptive Evict-then-Merge Strategy for Head-wise KV Cache Compression Based on Global-Local Importance](#EMS-Adaptive-Evict-then-Merge-Strategy-for-Head-wise-KV-Cache-Compression-Based-on-Global-Local-Importance)
* [AltFS Agency-light Feature Selection with Large Language Models in Deep Recommender Systems](#AltFS-Agency-light-Feature-Selection-with-Large-Language-Models-in-Deep-Recommender-Systems)
* [PointCFormer a Relation-based Progressive Feature Extraction Network for Point Cloud Completion](#PointCFormer-a-Relation-based-Progressive-Feature-Extraction-Network-for-Point-Cloud-Completion)
* [SweetTokenizer Semantic-Aware Spatial-Temporal Tokenizer for Compact Visual Discretization](#SweetTokenizer-Semantic-Aware-Spatial-Temporal-Tokenizer-for-Compact-Visual-Discretization)
* [GN-FRGeneralizable Neural Radiance Fields for Flare Removal](#GN-FRGeneralizable-Neural-Radiance-Fields-for-Flare-Removal)
* [Breaking the Bias Recalibrating the Attention of Industrial Anomaly Detection](#Breaking-the-Bias-Recalibrating-the-Attention-of-Industrial-Anomaly-Detection)
* [LatentSpeech Latent Diffusion for Text-To-Speech Generation](#LatentSpeech-Latent-Diffusion-for-Text-To-Speech-Generation)
* [A Deep Semantic Segmentation Network with Semantic and Contextual Refinements](#A-Deep-Semantic-Segmentation-Network-with-Semantic-and-Contextual-Refinements)
* [Static-Dynamic Class-level Perception Consistency in Video Semantic Segmentation](#Static-Dynamic-Class-level-Perception-Consistency-in-Video-Semantic-Segmentation)
* [PAFFA Premeditated Actions For Fast Agents](#PAFFA-Premeditated-Actions-For-Fast-Agents)
* [MOFHEI Model Optimizing Framework for Fast and Efficient Homomorphically Encrypted Neural Network Inference](#MOFHEI-Model-Optimizing-Framework-for-Fast-and-Efficient-Homomorphically-Encrypted-Neural-Network-Inference)
* [GPT-2 Through the Lens of Vector Symbolic Architectures](#GPT-2-Through-the-Lens-of-Vector-Symbolic-Architectures)
* [Low-Rank Correction for Quantized LLMs](#Low-Rank-Correction-for-Quantized-LLMs)
* [From Slow Bidirectional to Fast Causal Video Generators](#From-Slow-Bidirectional-to-Fast-Causal-Video-Generators)
* [STIV Scalable Text and Image Conditioned Video Generation](#STIV-Scalable-Text-and-Image-Conditioned-Video-Generation)
* [ACDiT Interpolating Autoregressive Conditional Modeling and Diffusion Transformer](#ACDiT-Interpolating-Autoregressive-Conditional-Modeling-and-Diffusion-Transformer)
* [Automating Business Intelligence Requirements with Generative AI and Semantic Search](#Automating-Business-Intelligence-Requirements-with-Generative-AI-and-Semantic-Search)
* [Spatio-temporal Latent Representations for the Analysis of Acoustic Scenes in-the-wild](#Spatio-temporal-Latent-Representations-for-the-Analysis-of-Acoustic-Scenes-in-the-wild)
* [PTSBench A Comprehensive Post-Training Sparsity Benchmark Towards Algorithms and Models](#PTSBench-A-Comprehensive-Post-Training-Sparsity-Benchmark-Towards-Algorithms-and-Models)
* [Modeling High-Resolution Spatio-Temporal Wind with Deep Echo State Networks and Stochastic Partial Differential Equations](#Modeling-High-Resolution-Spatio-Temporal-Wind-with-Deep-Echo-State-Networks-and-Stochastic-Partial-Differential-Equations)
* [QuantFormer Learning to Quantize for Neural Activity Forecasting in Mouse Visual Cortex](#QuantFormer-Learning-to-Quantize-for-Neural-Activity-Forecasting-in-Mouse-Visual-Cortex)
* [A Dynamical Systems-Inspired Pruning Strategy for Addressing Oversmoothing in Graph Neural Networks](#A-Dynamical-Systems-Inspired-Pruning-Strategy-for-Addressing-Oversmoothing-in-Graph-Neural-Networks)
* [MAPLE A Framework for Active Preference Learning Guided by Large Language Models](#MAPLE-A-Framework-for-Active-Preference-Learning-Guided-by-Large-Language-Models)
* [Post-Training Statistical Calibration for Higher Activation Sparsity](#Post-Training-Statistical-Calibration-for-Higher-Activation-Sparsity)
* [MoE-CAP Cost-Accuracy-Performance Benchmarking for Mixture-of-Experts Systems](#MoE-CAP-Cost-Accuracy-Performance-Benchmarking-for-Mixture-of-Experts-Systems)
* [Constrained Decoding with Speculative Lookaheads](#Constrained-Decoding-with-Speculative-Lookaheads)
* [Bridging Conversational and Collaborative Signals for Conversational Recommendation](#Bridging-Conversational-and-Collaborative-Signals-for-Conversational-Recommendation)
* [SafeWatch An Efficient Safety-Policy Following Video Guardrail Model with Transparent Explanations](#SafeWatch-An-Efficient-Safety-Policy-Following-Video-Guardrail-Model-with-Transparent-Explanations)
* [Robust Quantum Reservoir Computing for Molecular Property Prediction](#Robust-Quantum-Reservoir-Computing-for-Molecular-Property-Prediction)
* [ONEBench to Test Them All Sample-Level Benchmarking Over Open-Ended Capabilities](#ONEBench-to-Test-Them-All-Sample-Level-Benchmarking-Over-Open-Ended-Capabilities)
* [Terahertz Microscopy Through Complex Media](#Terahertz-Microscopy-Through-Complex-Media)
* [LLM-BIP Structured Pruning for Large Language Models with Block-Wise Forward Importance Propagation](#LLM-BIP-Structured-Pruning-for-Large-Language-Models-with-Block-Wise-Forward-Importance-Propagation)
* [A time-like window into tensionless worldsheets](#A-time-like-window-into-tensionless-worldsheets)
* [A Flexible Template for Edge Generative AI with High-Accuracy Accelerated Softmax & GELU](#A-Flexible-Template-for-Edge-Generative-AI-with-High-Accuracy-Accelerated-Softmax-&-GELU)
* [S$^{2}$FT Efficient, Scalable and Generalizable LLM Fine-tuning by Structured Sparsity](#S$^{2}$FT-Efficient,-Scalable-and-Generalizable-LLM-Fine-tuning-by-Structured-Sparsity)
* [Quantum recharging by shortcut to adiabaticity](#Quantum-recharging-by-shortcut-to-adiabaticity)
* [iLLaVA An Image is Worth Fewer Than 1/3 Input Tokens in Large Multimodal Models](#iLLaVA-An-Image-is-Worth-Fewer-Than-1/3-Input-Tokens-in-Large-Multimodal-Models)
* [Splatter-360 Generalizable 360$^{\circ}$ Gaussian Splatting for Wide-baseline Panoramic Images](#Splatter-360-Generalizable-360$^{\circ}$-Gaussian-Splatting-for-Wide-baseline-Panoramic-Images)
* [Top-r Influential Community Search in Bipartite Graphs](#Top-r-Influential-Community-Search-in-Bipartite-Graphs)
* [SparseAccelerate Efficient Long-Context Inference for Mid-Range GPUs](#SparseAccelerate-Efficient-Long-Context-Inference-for-Mid-Range-GPUs)
* [ASGDiffusion Parallel High-Resolution Generation with Asynchronous Structure Guidance](#ASGDiffusion-Parallel-High-Resolution-Generation-with-Asynchronous-Structure-Guidance)
* [Mixture-of-PageRanks Replacing Long-Context with Real-Time, Sparse GraphRAG](#Mixture-of-PageRanks-Replacing-Long-Context-with-Real-Time,-Sparse-GraphRAG)
* [Taming Sensitive Weights  Noise Perturbation Fine-tuning for Robust LLM Quantization](#Taming-Sensitive-Weights--Noise-Perturbation-Fine-tuning-for-Robust-LLM-Quantization)
* [Language Model as Visual Explainer](#Language-Model-as-Visual-Explainer)
* [Vision Transformer-based Semantic Communications With Importance-Aware Quantization](#Vision-Transformer-based-Semantic-Communications-With-Importance-Aware-Quantization)
* [FlexDiT Dynamic Token Density Control for Diffusion Transformer](#FlexDiT-Dynamic-Token-Density-Control-for-Diffusion-Transformer)
* [Doubly Quantum Mechanics](#Doubly-Quantum-Mechanics)
* [GBR Generative Bundle Refinement for High-fidelity Gaussian Splatting and Meshing](#GBR-Generative-Bundle-Refinement-for-High-fidelity-Gaussian-Splatting-and-Meshing)
* [XKV Personalized KV Cache Memory Reduction for Long-Context LLM Inference](#XKV-Personalized-KV-Cache-Memory-Reduction-for-Long-Context-LLM-Inference)
* [Transcorrelated Theory with Pseudopotentials](#Transcorrelated-Theory-with-Pseudopotentials)
* [[CLS] Token Tells Everything Needed for Training-free Efficient MLLMs](#[CLS]-Token-Tells-Everything-Needed-for-Training-free-Efficient-MLLMs)
* [Mixture of Hidden-Dimensions Transformer](#Mixture-of-Hidden-Dimensions-Transformer)
* [Entropy-Based Sensing Schemes for Energy Efficiency in Massive MTC](#Entropy-Based-Sensing-Schemes-for-Energy-Efficiency-in-Massive-MTC)
* [Strain-engineering spin-valley locking effect in altermagnetic monolayer with multipiezo properties](#Strain-engineering-spin-valley-locking-effect-in-altermagnetic-monolayer-with-multipiezo-properties)
* [UMSPU Universal Multi-Size Phase Unwrapping via Mutual Self-Distillation and Adaptive Boosting Ensemble Segmenters](#UMSPU-Universal-Multi-Size-Phase-Unwrapping-via-Mutual-Self-Distillation-and-Adaptive-Boosting-Ensemble-Segmenters)
* [ULMRec User-centric Large Language Model for Sequential Recommendation](#ULMRec-User-centric-Large-Language-Model-for-Sequential-Recommendation)
* [The BrowserGym Ecosystem for Web Agent Research](#The-BrowserGym-Ecosystem-for-Web-Agent-Research)
* [HiVeGen -- Hierarchical LLM-based Verilog Generation for Scalable Chip Design](#HiVeGen----Hierarchical-LLM-based-Verilog-Generation-for-Scalable-Chip-Design)
* [Sparse autoencoders reveal selective remapping of visual concepts during adaptation](#Sparse-autoencoders-reveal-selective-remapping-of-visual-concepts-during-adaptation)
* [APOLLO SGD-like Memory, AdamW-level Performance](#APOLLO-SGD-like-Memory,-AdamW-level-Performance)
* [Incremental Sentence Processing Mechanisms in Autoregressive Transformer Language Models](#Incremental-Sentence-Processing-Mechanisms-in-Autoregressive-Transformer-Language-Models)
* [A text-to-tabular approach to generate synthetic patient data using LLMs](#A-text-to-tabular-approach-to-generate-synthetic-patient-data-using-LLMs)
* [Learning Hidden Physics and System Parameters with Deep Operator Networks](#Learning-Hidden-Physics-and-System-Parameters-with-Deep-Operator-Networks)
* [Towards the interoperability of low-code platforms](#Towards-the-interoperability-of-low-code-platforms)
* [Flash Communication Reducing Tensor Parallelization Bottleneck for Fast Large Language Model Inference](#Flash-Communication-Reducing-Tensor-Parallelization-Bottleneck-for-Fast-Large-Language-Model-Inference)
* [Continuous Speech Tokens Makes LLMs Robust Multi-Modality Learners](#Continuous-Speech-Tokens-Makes-LLMs-Robust-Multi-Modality-Learners)
* [Dynamics of Aggregation Processes and Electrophysical Properties of Transformer Oil-Based Magnetic Fluids](#Dynamics-of-Aggregation-Processes-and-Electrophysical-Properties-of-Transformer-Oil-Based-Magnetic-Fluids)
* [Adaptive Dropout for Pruning Conformers](#Adaptive-Dropout-for-Pruning-Conformers)
* [Direct Quantized Training of Language Models with Stochastic Rounding](#Direct-Quantized-Training-of-Language-Models-with-Stochastic-Rounding)
* [IterNorm Fast Iterative Normalization](#IterNorm-Fast-Iterative-Normalization)
* [Ltri-LLM Streaming Long Context Inference for LLMs with Training-Free Dynamic Triangular Attention Pattern](#Ltri-LLM-Streaming-Long-Context-Inference-for-LLMs-with-Training-Free-Dynamic-Triangular-Attention-Pattern)


## GaussTR Foundation Model-Aligned Gaussian Transformer for Self-Supervised 3D Spatial Understanding

>Authors: Haoyi Jiang, Liu Liu, Tianheng Cheng, Xinjie Wang, Tianwei Lin, Zhizhong Su, Wenyu Liu, Xinggang Wang

>2024-12-17

> http://arxiv.org/abs/2412.13193v1

3D Semantic Occupancy Prediction is fundamental for spatial understanding as
it provides a comprehensive semantic cognition of surrounding environments.
However, prevalent approaches primarily rely on extensive labeled data and
computationally intensive voxel-based modeling, restricting the scalability and
generalizability of 3D representation learning. In this paper, we introduce
GaussTR, a novel Gaussian Transformer that leverages alignment with foundation
models to advance self-supervised 3D spatial understanding. GaussTR adopts a
Transformer architecture to predict **sparse** sets of 3D Gaussians that represent
scenes in a feed-forward manner. Through aligning rendered Gaussian features
with diverse knowledge from pre-trained foundation models, GaussTR facilitates
the learning of versatile 3D representations and enables open-vocabulary
occupancy prediction without explicit annotations. Empirical evaluations on the
Occ3D-nuScenes dataset showcase GaussTR's state-of-the-art zero-shot
performance, achieving 11.70 mIoU while reducing training duration by
approximately 50%. These experimental results highlight the significant
potential of GaussTR for scalable and holistic 3D spatial understanding, with
promising implications for autonomous driving and embodied agents. Code is
available at https://github.com/hustvl/GaussTR.


## Unlocking the Potential of Digital Pathology Novel Baselines for Compression

>Authors: Maximilian Fischer, Peter Neher, Peter Schüffler, Sebastian Ziegler, Shuhan Xiao, Robin Peretzke, David Clunie, Constantin Ulrich, Michael Baumgartner, Alexander Muckenhuber, Silvia Dias Almeida, Michael Götz, Jens Kleesiek, Marco Nolden, Rickmer Braren, Klaus Maier-Hein

>2024-12-17

> http://arxiv.org/abs/2412.13137v1

Digital pathology offers a groundbreaking opportunity to transform clinical
practice in histopathological image analysis, yet faces a significant hurdle:
the substantial file sizes of pathological Whole Slide Images (WSI). While
current digital pathology solutions rely on lossy JPEG compression to address
this issue, lossy compression can introduce color and texture disparities,
potentially impacting clinical decision-making. While prior research addresses
perceptual image quality and downstream performance independently of each
other, we jointly evaluate compression schemes for perceptual and downstream
task quality on four different datasets. In addition, we collect an initially
uncompressed dataset for an unbiased perceptual evaluation of compression
schemes. Our results show that deep learning models fine-tuned for perceptual
quality outperform conventional compression schemes like JPEG-XL or WebP for
further compression of WSI. However, they exhibit a significant bias towards
the compression artifacts present in the training data and struggle to
generalize across various compression schemes. We introduce a novel evaluation
metric based on feature similarity between original files and compressed files
that aligns very well with the actual downstream performance on the compressed
WSI. Our metric allows for a general and standardized evaluation of lossy
compression schemes and mitigates the requirement to independently assess
different downstream tasks. Our study provides novel insights for the
assessment of lossy compression schemes for WSI and encourages a unified
evaluation of lossy compression schemes to accelerate the clinical uptake of
digital pathology.


## Efficient Diffusion Transformer Policies with Mixture of Expert Denoisers for Multitask Learning

>Authors: Moritz Reuss, Jyothish Pari, Pulkit Agrawal, Rudolf Lioutikov

>2024-12-17

> http://arxiv.org/abs/2412.12953v1

Diffusion Policies have become widely used in Imitation Learning, offering
several appealing properties, such as generating multimodal and discontinuous
behavior. As models are becoming larger to capture more complex capabilities,
their computational demands increase, as shown by recent scaling laws.
Therefore, continuing with the current architectures will present a
computational roadblock. To address this gap, we propose Mixture-of-Denoising
Experts (MoDE) as a novel policy for Imitation Learning. MoDE surpasses current
state-of-the-art Transformer-based Diffusion Policies while enabling
parameter-efficient scaling through **sparse** experts and noise-conditioned
routing, reducing both active parameters by 40% and inference costs by 90% via
expert caching. Our architecture combines this efficient scaling with
noise-conditioned self-attention mechanism, enabling more effective denoising
across different noise levels. MoDE achieves state-of-the-art performance on
134 tasks in four established imitation learning benchmarks (CALVIN and
LIBERO). Notably, by pretraining MoDE on diverse robotics data, we achieve 4.01
on CALVIN ABC and 0.95 on LIBERO-90. It surpasses both CNN-based and
Transformer Diffusion Policies by an average of 57% across 4 benchmarks, while
using 90% fewer FLOPs and fewer active parameters compared to default Diffusion
Transformer architectures. Furthermore, we conduct comprehensive ablations on
MoDE's components, providing insights for designing efficient and scalable
Transformer architectures for Diffusion Policies. Code and demonstrations are
available at https://mbreuss.github.io/MoDE_Diffusion_Policy/.


## TimeCHEAT A Channel Harmony Strategy for Irregularly Sampled Multivariate Time Series Analysis

>Authors: Jiexi Liu, Meng Cao, Songcan Chen

>2024-12-17

> http://arxiv.org/abs/2412.12886v1

Irregularly sampled multivariate time series (ISMTS) are prevalent in
reality. Due to their non-uniform intervals between successive observations and
varying sampling rates among series, the channel-independent (CI) strategy,
which has been demonstrated more desirable for complete multivariate time
series forecasting in recent studies, has failed. This failure can be further
attributed to the sampling **sparsity**, which provides insufficient information
for effective CI learning, thereby reducing its capacity. When we resort to the
channel-dependent (CD) strategy, even higher capacity cannot mitigate the
potential loss of diversity in learning similar embedding patterns across
different channels. We find that existing work considers CI and CD strategies
to be mutually exclusive, primarily because they apply these strategies to the
global channel. However, we hold the view that channel strategies do not
necessarily have to be used globally. Instead, by appropriately applying them
locally and globally, we can create an opportunity to take full advantage of
both strategies. This leads us to introduce the Channel Harmony ISMTS
Transformer (TimeCHEAT), which utilizes the CD locally and the CI globally.
Specifically, we segment the ISMTS into sub-series level patches. Locally, the
CD strategy aggregates information within each patch for time embedding
learning, maximizing the use of relevant observations while reducing long-range
irrelevant interference. Here, we enhance generality by transforming embedding
learning into an edge weight prediction task using bipartite graphs,
eliminating the need for special prior knowledge. Globally, the CI strategy is
applied across patches, allowing the Transformer to learn individualized
attention patterns for each channel. Experimental results indicate our proposed
TimeCHEAT demonstrates competitive SOTA performance across three mainstream
tasks.


## A Comparative Study of Pruning Methods in Transformer-based Time Series Forecasting

>Authors: Nicholas Kiefer, Arvid Weyrauch, Muhammed Öz, Achim Streit, Markus Götz, Charlotte Debus

>2024-12-17

> http://arxiv.org/abs/2412.12883v1

The current landscape in time-series forecasting is dominated by
Transformer-based models. Their high parameter count and corresponding demand
in computational resources pose a challenge to real-world deployment,
especially for commercial and scientific applications with low-power embedded
devices. Pruning is an established approach to reduce neural network parameter
count and save compute. However, the implications and benefits of **pruning**
Transformer-based models for time series forecasting are largely unknown. To
close this gap, we provide a comparative benchmark study by evaluating
unstructured and structured **pruning** on various state-of-the-art multivariate
time series models. We study the effects of these **pruning** strategies on model
predictive performance and computational aspects like model size, operations,
and inference time. Our results show that certain models can be pruned even up
to high **sparsity** levels, outperforming their dense counterpart. However,
fine-tuning pruned models is necessary. Furthermore, we demonstrate that even
with corresponding hardware and software support, structured **pruning** is unable
to provide significant time savings.


## Data-Driven Catalyst Design A Machine Learning Approach to Predicting Electrocatalytic Performance in Hydrogen Evolution and Oxygen Evolution Reactions

>Authors: Vipin K E, Prahallad Padhan

>2024-12-17

> http://arxiv.org/abs/2412.12846v1

The transition to sustainable green hydrogen production demands innovative
electrocatalyst design strategies that can overcome current technological
limitations. This study introduces a comprehensive data-driven approach to
predicting and understanding catalytic performance for Hydrogen Evolution
Reaction (HER) and Oxygen Evolution Reaction (OER) using advanced machine
learning methodologies. By usimg a dataset of 16,226 data points from the
Catalysis-hub database, we developed a novel stacking ensemble model that
integrates Random Forest, XGBoost, and Support Vector Regression to predict
Gibbs free energy of adsorption across diverse bimetallic alloy surfaces. Our
innovative feature engineering strategy combined Matminer-based compositional
analysis, Principal Component Analysis for adsorption site related features,
and correlation screening to generate robust predictive descriptors. The
machine learning model demonstrated exceptional predictive capabilities,
achieving R^2 values of 0.98 for HER and 0.94 for OER, with Mean Absolute Error
values of 0.251 and 0.121, respectively. Shapley Additive Explanations (SHAP)
analysis revealed critical insights into the complex interplay of
compositional, structural, and electronic features governing catalytic
performance. The research provides a powerful computational framework for
accelerating electrocatalyst design, offering unprecedented insights into the
fundamental properties that drive hydrogen evolution and oxygen evolution
reactions. By bridging advanced machine learning techniques with fundamental
electrochemical principles, this study presents a transformative approach to
developing cost-effective, high-performance catalysts for sustainable hydrogen
production.


## 2by2 Weakly-Supervised Learning for Global Action Segmentation

>Authors: Elena Bueno-Benito, Mariella Dimiccoli

>2024-12-17

> http://arxiv.org/abs/2412.12829v1

This paper presents a simple yet effective approach for the poorly
investigated task of global action segmentation, aiming at grouping frames
capturing the same action across videos of different activities. Unlike the
case of videos depicting all the same activity, the temporal order of actions
is not roughly shared among all videos, making the task even more challenging.
We propose to use activity labels to learn, in a weakly-supervised fashion,
action representations suitable for global action segmentation. For this
purpose, we introduce a triadic learning approach for video pairs, to ensure
intra-video action discrimination, as well as inter-video and inter-activity
action association. For the backbone architecture, we use a Siamese network
based on **sparse** transformers that takes as input video pairs and determine
whether they belong to the same activity. The proposed approach is validated on
two challenging benchmark datasets: Breakfast and YouTube Instructions,
outperforming state-of-the-art methods.


## RCTrans Radar-Camera Transformer via Radar Densifier and Sequential Decoder for 3D Object Detection

>Authors: Yiheng Li, Yang Yang, Zhen Lei

>2024-12-17

> http://arxiv.org/abs/2412.12799v1

In radar-camera 3D object detection, the radar point clouds are **sparse** and
noisy, which causes difficulties in fusing camera and radar modalities. To
solve this, we introduce a novel query-based detection method named
Radar-Camera Transformer (RCTrans). Specifically, we first design a Radar Dense
Encoder to enrich the **sparse** valid radar tokens, and then concatenate them with
the image tokens. By doing this, we can fully explore the 3D information of
each interest region and reduce the interference of empty tokens during the
fusing stage. We then design a Pruning Sequential Decoder to predict 3D boxes
based on the obtained tokens and random initialized queries. To alleviate the
effect of elevation ambiguity in radar point clouds, we gradually locate the
position of the object via a sequential fusion structure. It helps to get more
precise and flexible correspondences between tokens and queries. A **pruning**
training strategy is adopted in the decoder, which can save much time during
inference and inhibit queries from losing their distinctiveness. Extensive
experiments on the large-scale nuScenes dataset prove the superiority of our
method, and we also achieve new state-of-the-art radar-camera 3D detection
results. Our implementation is available at https://github.com/liyih/RCTrans.


## Activating Distributed Visual Region within LLMs for Efficient and Effective Vision-Language Training and Inference

>Authors: Siyuan Wang, Dianyi Wang, Chengxing Zhou, Zejun Li, Zhihao Fan, Xuanjing Huang, Zhongyu Wei

>2024-12-17

> http://arxiv.org/abs/2412.12785v1

Large Vision-Language Models (LVLMs) typically learn visual capacity through
visual instruction tuning, involving updates to both a projector and their LLM
backbones. Drawing inspiration from the concept of visual region in the human
brain, we investigate the existence of an analogous \textit{visual region}
within LLMs that functions as a cognitive core, and explore the possibility of
efficient training of LVLMs via selective layers tuning. We use
Bunny-Llama-3-8B-V for detailed experiments and LLaVA-1.5-7B and LLaVA-1.5-13B
for validation across a range of visual and textual tasks. Our findings reveal
that selectively updating 25\% of LLMs layers, when **sparse**ly and uniformly
distributed, can preserve nearly 99\% of visual performance while maintaining
or enhancing textual task results, and also effectively reducing training time.
Based on this targeted training approach, we further propose a novel visual
region-based **pruning** paradigm, removing non-critical layers outside the visual
region, which can achieve minimal performance loss. This study offers an
effective and efficient strategy for LVLM training and inference by activating
a layer-wise visual region within LLMs, which is consistently effective across
different models and parameter scales.


## More Tokens, Lower Precision Towards the Optimal Token-Precision Trade-off in KV Cache Compression

>Authors: Jiebin Zhang, Dawei Zhu, Yifan Song, Wenhao Wu, Chuqiao Kuang, Xiaoguang Li, Lifeng Shang, Qun Liu, Sujian Li

>2024-12-17

> http://arxiv.org/abs/2412.12706v1

As large language models (LLMs) process increasing context windows, the
memory usage of **KV** cache has become a critical bottleneck during inference. The
mainstream **KV** compression methods, including **KV** **pruning** and **KV** **quantization**,
primarily focus on either token or precision dimension and seldom explore the
efficiency of their combination. In this paper, we comprehensively investigate
the token-precision trade-off in **KV** cache compression. Experiments demonstrate
that storing more tokens in the **KV** cache with lower precision, i.e., **quantize**d
**pruning**, can significantly enhance the long-context performance of LLMs.
Furthermore, in-depth analysis regarding token-precision trade-off from a
series of key aspects exhibit that, **quantize**d **pruning** achieves substantial
improvements in retrieval-related tasks and consistently performs well across
varying input lengths. Moreover, **quantize**d **pruning** demonstrates notable
stability across different **KV** **pruning** methods, **quantization** strategies, and
model scales. These findings provide valuable insights into the token-precision
trade-off in **KV** cache compression. We plan to release our code in the near
future.


## Falcon Faster and Parallel Inference of Large Language Models through Enhanced Semi-Autoregressive Drafting and Custom-Designed Decoding Tree

>Authors: Xiangxiang Gao, Weisheng Xie, Yiwei Xiang, Feng Ji

>2024-12-17

> http://arxiv.org/abs/2412.12639v1

Striking an optimal balance between minimal drafting latency and high
speculation accuracy to enhance the inference speed of Large Language Models
remains a significant challenge in speculative decoding. In this paper, we
introduce Falcon, an innovative semi-autoregressive speculative decoding
framework fashioned to augment both the drafter's parallelism and output
quality. Falcon incorporates the Coupled Sequential Glancing Distillation
technique, which fortifies inter-token dependencies within the same block,
leading to increased speculation accuracy. We offer a comprehensive theoretical
analysis to illuminate the underlying mechanisms. Additionally, we introduce a
Custom-Designed Decoding Tree, which permits the drafter to generate multiple
tokens in a single forward pass and accommodates multiple forward passes as
needed, thereby boosting the number of drafted tokens and significantly
improving the overall acceptance rate. Comprehensive evaluations on benchmark
datasets such as MT-Bench, HumanEval, and GSM8K demonstrate Falcon's superior
**acceleration** capabilities. The framework achieves a lossless speedup ratio
ranging from 2.91x to 3.51x when tested on the Vicuna and LLaMA2-Chat model
series. These results outstrip existing speculative decoding methods for LLMs,
including Eagle, Medusa, Lookahead, SPS, and PLD, while maintaining a compact
drafter architecture equivalent to merely two Transformer layers.


## PO3AD Predicting Point Offsets toward Better 3D Point Cloud Anomaly Detection

>Authors: Jianan Ye, Weiguang Zhao, Xi Yang, Guangliang Cheng, Kaizhu Huang

>2024-12-17

> http://arxiv.org/abs/2412.12617v1

Point cloud anomaly detection under the anomaly-free setting poses
significant challenges as it requires accurately capturing the features of 3D
normal data to identify deviations indicative of anomalies. Current efforts
focus on devising reconstruction tasks, such as acquiring normal data
representations by restoring normal samples from altered, pseudo-anomalous
counterparts. Our findings reveal that distributing attention equally across
normal and pseudo-anomalous data tends to dilute the model's focus on anomalous
deviations. The challenge is further compounded by the inherently disordered
and **sparse** nature of 3D point cloud data. In response to those predicaments, we
introduce an innovative approach that emphasizes learning point offsets,
targeting more informative pseudo-abnormal points, thus fostering more
effective distillation of normal data representations. We also have crafted an
augmentation technique that is steered by normal vectors, facilitating the
creation of credible pseudo anomalies that enhance the efficiency of the
training process. Our comprehensive experimental evaluation on the
Anomaly-ShapeNet and Real3D-AD datasets evidences that our proposed method
outperforms existing state-of-the-art approaches, achieving an average
enhancement of 9.0% and 1.4% in the AUC-ROC detection metric across these
datasets, respectively.


## LLMs are Also Effective Embedding Models An In-depth Overview

>Authors: Chongyang Tao, Tao Shen, Shen Gao, Junshuo Zhang, Zhen Li, Zhengwei Tao, Shuai Ma

>2024-12-17

> http://arxiv.org/abs/2412.12591v1

Large language models (LLMs) have revolutionized natural language processing
by achieving state-of-the-art performance across various tasks. Recently, their
effectiveness as embedding models has gained attention, marking a paradigm
shift from traditional encoder-only models like ELMo and BERT to decoder-only,
large-scale LLMs such as GPT, LLaMA, and Mistral. This survey provides an
in-depth overview of this transition, beginning with foundational techniques
before the LLM era, followed by LLM-based embedding models through two main
strategies to derive embeddings from LLMs. 1) Direct prompting: We mainly
discuss the prompt designs and the underlying rationale for deriving
competitive embeddings. 2) Data-centric tuning: We cover extensive aspects that
affect tuning an embedding model, including model architecture, training
objectives, data constructions, etc. Upon the above, we also cover advanced
methods, such as handling longer texts, and multilingual and cross-modal data.
Furthermore, we discuss factors affecting choices of embedding models, such as
performance/efficiency comparisons, dense vs **sparse** embeddings, pooling
strategies, and scaling law. Lastly, the survey highlights the limitations and
challenges in adapting LLMs for embeddings, including cross-task embedding
quality, trade-offs between efficiency and accuracy, low-resource,
long-context, data bias, robustness, etc. This survey serves as a valuable
resource for researchers and practitioners by synthesizing current
advancements, highlighting key challenges, and offering a comprehensive
framework for future work aimed at enhancing the effectiveness and efficiency
of LLMs as embedding models.


## A System for Microserving of LLMs

>Authors: Hongyi Jin, Ruihang Lai, Charlie F. Ruan, Yingcheng Wang, Todd C. Mowry, Xupeng Miao, Zhihao Jia, Tianqi Chen

>2024-12-17

> http://arxiv.org/abs/2412.12488v1

The recent advances in LLMs bring a strong demand for efficient system
support to improve overall serving efficiency. As LLM inference scales towards
multiple GPUs and even multiple compute nodes, various coordination patterns,
such as prefill-decode disaggregation and context migration, arise in serving
systems. Most inference services today expose a coarse-grained request-level
API with a pre-configured coordination strategy, limiting the ability to
customize and dynamically reconfigure the coordination. In this paper, we
propose LLM microserving, a multi-level architecture for structuring and
programming LLM inference services. We introduces simple yet effective
microserving APIs to support fine-grained sub-request level actions. A
programmable router transforms user requests into sub-request calls, enabling
the dynamic reconfiguration of serving patterns. To support diverse execution
patterns, we develop a unified **KV** cache interface that handles various **KV**
compute, transfer, and reuse scenarios. Our evaluation shows that LLM
microserving can be reconfigured to support multiple disaggregation
orchestration strategies in a few lines of Python code while maintaining
state-of-the-art performance for LLM inference tasks. Additionally, it allows
us to explore new strategy variants that reduce up to 47% of job completion
time compared to the existing strategies.


## Boosting Long-Context Information Seeking via Query-Guided Activation Refilling

>Authors: Hongjin Qian, Zheng Liu, Peitian Zhang, Zhicheng Dou, Defu Lian

>2024-12-17

> http://arxiv.org/abs/2412.12486v1

Processing long contexts poses a significant challenge for large language
models (LLMs) due to their inherent context-window limitations and the
computational burden of extensive key-value (**KV**) activations, which severely
impact efficiency. For information-seeking tasks, full context perception is
often unnecessary, as a query's information needs can dynamically range from
localized details to a global perspective, depending on its complexity.
However, existing methods struggle to adapt effectively to these dynamic
information needs.
  In the paper, we propose a method for processing long-context
information-seeking tasks via query-guided Activation Refilling (ACRE). ACRE
constructs a Bi-layer **KV** Cache for long contexts, where the layer-1 (L1) cache
compactly captures global information, and the layer-2 (L2) cache provides
detailed and localized information. ACRE establishes a proxying relationship
between the two caches, allowing the input query to attend to the L1 cache and
dynamically refill it with relevant entries from the L2 cache. This mechanism
integrates global understanding with query-specific local details, thus
improving answer decoding. Experiments on a variety of long-context
information-seeking datasets demonstrate ACRE's effectiveness, achieving
improvements in both performance and efficiency.


## if-ZKP Intel FPGA-Based Acceleration of Zero Knowledge Proofs

>Authors: Shahzad Ahmad Butt, Benjamin Reynolds, Veeraraghavan Ramamurthy, Xiao Xiao, Pohrong Chu, Setareh Sharifian, Sergey Gribok, Bogdan Pasca

>2024-12-17

> http://arxiv.org/abs/2412.12481v1

Zero-Knowledge Proofs (ZKPs) have emerged as an important cryptographic
technique allowing one party (prover) to prove the correctness of a statement
to some other party (verifier) and nothing else. ZKPs give rise to user's
privacy in many applications such as blockchains, digital voting, and machine
learning. Traditionally, ZKPs suffered from poor scalability but recently, a
sub-class of ZKPs known as Zero-knowledge Succinct Non-interactive ARgument of
Knowledges (zk-SNARKs) have addressed this challenge. They are getting
significant attention and are being implemented by many public libraries. In
this paper, we present a novel scalable architecture that is suitable for
accelerating the zk-SNARK prover compute on FPGAs. We focus on the multi-scalar
multiplication (MSM) that accounts for the majority of computation time spent
in zk-SNARK systems. The MSM calculations extensive rely on modular arithmetic
so highly optimized Intel IP Libraries for modular arithmetic are used. The
proposed architecture exploits the parallelism inherent to MSM and is
implemented using the Intel OneAPI framework for FPGAs. Our implementation runs
110x-150x faster compared to reference software library, uses a generic curve
form in Jacobian coordinates and is the first to report FPGA hardware
**acceleration** results for BLS12-381 and BN128 family of elliptic curves.


## Numerical Pruning for Efficient Autoregressive Models

>Authors: Xuan Shen, Zhao Song, Yufa Zhou, Bo Chen, Jing Liu, Ruiyi Zhang, Ryan A. Rossi, Hao Tan, Tong Yu, Xiang Chen, Yufan Zhou, Tong Sun, Pu Zhao, Yanzhi Wang, Jiuxiang Gu

>2024-12-17

> http://arxiv.org/abs/2412.12441v1

Transformers have emerged as the leading architecture in deep learning,
proving to be versatile and highly effective across diverse domains beyond
language and image processing. However, their impressive performance often
incurs high computational costs due to their substantial model size. This paper
focuses on compressing decoder-only transformer-based autoregressive models
through structural weight **pruning** to improve the model efficiency while
preserving performance for both language and image generation tasks.
Specifically, we propose a training-free **pruning** method that calculates a
numerical score with Newton's method for the Attention and MLP modules,
respectively. Besides, we further propose another compensation algorithm to
recover the pruned model for better performance. To verify the effectiveness of
our method, we provide both theoretical support and extensive experiments. Our
experiments show that our method achieves state-of-the-art performance with
reduced memory usage and faster generation speeds on GPUs.


## Krony-PT GPT2 compressed with Kronecker Products

>Authors: M. Ayoub Ben Ayad, Jelena Mitrovic, Michael Granitzer

>2024-12-16

> http://arxiv.org/abs/2412.12351v1

We introduce Krony-PT, a compression technique of GPT2
\citep{radford2019language} based on Kronecker Products. We specifically target
the MLP layers of each transformer layer, and systematically compress the feed
forward layer matrices to various degrees. We introduce a modified Van Loan
decomposition to initialize the new factors, and also introduce a new
**pruning**-based initialization trick. Our method compresses the original 124M
parameter GPT2 to various smaller models, with 80M being the smallest, and 96M
being the largest compressed model. Our 81M model variant outperforms
distilgpt2 on next-token prediction on all standard language modeling datasets,
and shows competitive scores or performs on par with other Kronecker Products
based compressed models of GPT2 that are significantly higher in size.


## Physics-informed Transformers for Electronic Quantum States

>Authors: João Augusto Sobral, Michael Perle, Mathias S. Scheurer

>2024-12-16

> http://arxiv.org/abs/2412.12248v1

Neural-network-based variational quantum states in general, and more recently
autoregressive models in particular, have proven to be powerful tools to
describe complex many-body wave functions. However, their performance crucially
depends on the computational basis chosen and they often lack physical
interpretability. To mitigate these issues, we here propose a modified
variational Monte-Carlo framework which leverages prior physical information to
construct a computational second-**quantize**d basis containing a reference state
that serves as a rough approximation to the true ground state. In this basis, a
Transformer is used to parametrize and autoregressively sample the corrections
to the reference state, giving rise to a more interpretable and computationally
efficient representation of the ground state. We demonstrate this approach
using a non-**sparse** fermionic model featuring a metal-insulator transition and
employing Hartree-Fock and a strong-coupling limit to define physics-informed
bases. We also show that the Transformer's hidden representation captures the
natural energetic order of the different basis states. This work paves the way
for more efficient and interpretable neural quantum-state representations.


## SepLLM Accelerate Large Language Models by Compressing One Segment into One Separator

>Authors: Guoxuan Chen, Han Shi, Jiawei Li, Yihang Gao, Xiaozhe Ren, Yimeng Chen, Xin Jiang, Zhenguo Li, Weiyang Liu, Chao Huang

>2024-12-16

> http://arxiv.org/abs/2412.12094v1

Large Language Models (LLMs) have exhibited exceptional performance across a
spectrum of natural language processing tasks. However, their substantial sizes
pose considerable challenges, particularly in computational demands and
inference speed, due to their quadratic complexity. In this work, we have
identified a key pattern: certain seemingly meaningless special tokens (i.e.,
separators) contribute disproportionately to attention scores compared to
semantically meaningful tokens. This observation suggests that information of
the segments between these separator tokens can be effectively condensed into
the separator tokens themselves without significant information loss. Guided by
this insight, we introduce SepLLM, a plug-and-play framework that accelerates
inference by compressing these segments and eliminating redundant tokens.
Additionally, we implement efficient kernels for training **acceleration**.
Experimental results across training-free, training-from-scratch, and
post-training settings demonstrate SepLLM's effectiveness. Notably, using the
Llama-3-8B backbone, SepLLM achieves over 50% reduction in **KV** cache on the
GSM8K-CoT benchmark while maintaining comparable performance. Furthermore, in
streaming settings, SepLLM effectively processes sequences of up to 4 million
tokens or more while maintaining consistent language modeling capabilities.


## LeARN Learnable and Adaptive Representations for Nonlinear Dynamics in System Identification

>Authors: Arunabh Singh, Joyjit Mukherjee

>2024-12-16

> http://arxiv.org/abs/2412.12036v1

System identification, the process of deriving mathematical models of
dynamical systems from observed input-output data, has undergone a paradigm
shift with the advent of learning-based methods. Addressing the intricate
challenges of data-driven discovery in nonlinear dynamical systems, these
methods have garnered significant attention. Among them, Sparse Identification
of Nonlinear Dynamics (SINDy) has emerged as a transformative approach,
distilling complex dynamical behaviors into interpretable linear combinations
of basis functions. However, SINDy relies on domain-specific expertise to
construct its foundational "library" of basis functions, which limits its
adaptability and universality. In this work, we introduce a nonlinear system
identification framework called LeARN that transcends the need for prior domain
knowledge by learning the library of basis functions directly from data. To
enhance adaptability to evolving system dynamics under varying noise
conditions, we employ a novel meta-learning-based system identification
approach that uses a lightweight deep neural network (DNN) to dynamically
refine these basis functions. This not only captures intricate system behaviors
but also adapts seamlessly to new dynamical regimes. We validate our framework
on the Neural Fly dataset, showcasing its robust adaptation and generalization
capabilities. Despite its simplicity, our LeARN achieves competitive dynamical
error performance compared to SINDy. This work presents a step toward the
autonomous discovery of dynamical systems, paving the way for a future where
machine learning uncovers the governing principles of complex systems without
requiring extensive domain-specific interventions.


## SpeechPrune Context-aware Token Pruning for Speech Information Retrieval

>Authors: Yueqian Lin, Yuzhe Fu, Jingyang Zhang, Yudong Liu, Jianyi Zhang, Jingwei Sun, Hai "Helen" Li, Yiran Chen

>2024-12-16

> http://arxiv.org/abs/2412.12009v1

We introduce Speech Information Retrieval (SIR), a new long-context task for
Speech Large Language Models (Speech LLMs), and present SPIRAL, a 1,012-sample
benchmark testing models' ability to extract critical details from
approximately 90-second spoken inputs. While current Speech LLMs excel at
short-form tasks, they struggle with the computational and representational
demands of longer audio sequences. To address this limitation, we propose
SpeechPrune, a training-free token **pruning** strategy that uses speech-text
similarity and approximated attention scores to efficiently discard irrelevant
tokens. In SPIRAL, SpeechPrune achieves accuracy improvements of 29% and up to
47% over the original model and the random **pruning** model at a **pruning** rate of
20%, respectively. SpeechPrune can maintain network performance even at a
**pruning** level of 80%. This approach highlights the potential of token-level
**pruning** for efficient and scalable long-form speech understanding.


## Multiplex Dirichlet stochastic block model for clustering multidimensional compositional networks

>Authors: Iuliia Promskaia, Adrian O'Hagan, Michael Fop

>2024-12-16

> http://arxiv.org/abs/2412.11971v1

Network data often represent multiple types of relations, which can also
denote exchanged quantities, and are typically encompassed in a weighted
multiplex. Such data frequently exhibit clustering structures, however,
traditional clustering methods are not well-suited for multiplex networks.
Additionally, standard methods treat edge weights in their raw form,
potentially biasing clustering towards a node's total weight capacity rather
than reflecting cluster-related interaction patterns. To address this, we
propose transforming edge weights into a compositional format, enabling the
analysis of connection strengths in relative terms and removing the impact of
nodes' total weights. We introduce a multiplex Dirichlet stochastic block model
designed for multiplex networks with compositional layers. This model accounts
for **sparse** compositional networks and enables joint clustering across different
types of interactions. We validate the model through a simulation study and
apply it to the international export data from the Food and Agriculture
Organization of the United Nations.


## RetroLLM Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation

>Authors: Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yongkang Wu, Zhonghua Li, Qi Ye, Zhicheng Dou

>2024-12-16

> http://arxiv.org/abs/2412.11919v1

Large language models (LLMs) exhibit remarkable generative capabilities but
often suffer from hallucinations. Retrieval-augmented generation (RAG) offers
an effective solution by incorporating external knowledge, but existing methods
still face several limitations: additional deployment costs of separate
retrievers, redundant input tokens from retrieved text chunks, and the lack of
joint optimization of retrieval and generation. To address these issues, we
propose \textbf{RetroLLM}, a unified framework that integrates retrieval and
generation into a single, cohesive process, enabling LLMs to directly generate
fine-grained evidence from the corpus with constrained decoding. Moreover, to
mitigate false **pruning** in the process of constrained evidence generation, we
introduce (1) hierarchical FM-Index constraints, which generate
corpus-constrained clues to identify a subset of relevant documents before
evidence generation, reducing irrelevant decoding space; and (2) a
forward-looking constrained decoding strategy, which considers the relevance of
future sequences to improve evidence accuracy. Extensive experiments on five
open-domain QA datasets demonstrate RetroLLM's superior performance across both
in-domain and out-of-domain tasks. The code is available at
\url{https://github.com/sunnynexus/RetroLLM}.


## Harvesting stabilizer entropy and non-locality from a quantum field

>Authors: S. Cepollaro, S. Cusumano, A. Hamma, G. Lo Giudice, J. Odavic

>2024-12-16

> http://arxiv.org/abs/2412.11918v1

The harvesting of quantum resources from the vacuum state of a quantum field
is a central topic in relativistic quantum information. While several proposals
for the harvesting of entanglement from the quantum vacuum exist, less
attention has been paid to other quantum resources, such as non-stabilizerness,
commonly dubbed magic and quantified by the Stabilizer R\'enyi Entropy (SRE).
In this work, we show how to harvest SRE from the vacuum state of a massless
field, using accelerated Unruh-DeWitt detectors in Minkowski spacetime. In
particular, one can harvest a particular non-local form of SRE that cannot be
erased by local operations. We conclude our work with an analysis of the CHSH
inequalities: one cannot extract a violation from the quantum field unless
these resources are already there.


## CharacterBench Benchmarking Character Customization of Large Language Models

>Authors: Jinfeng Zhou, Yongkang Huang, Bosi Wen, Guanqun Bi, Yuxuan Chen, Pei Ke, Zhuang Chen, Xiyao Xiao, Libiao Peng, Kuntian Tang, Rongsheng Zhang, Le Zhang, Tangjie Lv, Zhipeng Hu, Hongning Wang, Minlie Huang

>2024-12-16

> http://arxiv.org/abs/2412.11912v1

Character-based dialogue (aka role-playing) enables users to freely customize
characters for interaction, which often relies on LLMs, raising the need to
evaluate LLMs' character customization capability. However, existing benchmarks
fail to ensure a robust evaluation as they often only involve a single
character category or evaluate limited dimensions. Moreover, the **sparsity** of
character features in responses makes feature-focused generative evaluation
both ineffective and inefficient. To address these issues, we propose
CharacterBench, the largest bilingual generative benchmark, with 22,859
human-annotated samples covering 3,956 characters from 25 detailed character
categories. We define 11 dimensions of 6 aspects, classified as **sparse** and
dense dimensions based on whether character features evaluated by specific
dimensions manifest in each response. We enable effective and efficient
evaluation by crafting tailored queries for each dimension to induce
characters' responses related to specific dimensions. Further, we develop
CharacterJudge model for cost-effective and stable evaluations. Experiments
show its superiority over SOTA automatic judges (e.g., GPT-4) and our
benchmark's potential to optimize LLMs' character customization. Our repository
is at https://github.com/thu-coai/CharacterBench.


## Transformers Use Causal World Models in Maze-Solving Tasks

>Authors: Alex F. Spies, William Edwards, Michael I. Ivanitskiy, Adrians Skapars, Tilman Räuker, Katsumi Inoue, Alessandra Russo, Murray Shanahan

>2024-12-16

> http://arxiv.org/abs/2412.11867v1

Recent studies in interpretability have explored the inner workings of
transformer models trained on tasks across various domains, often discovering
that these networks naturally develop surprisingly structured representations.
When such representations comprehensively reflect the task domain's structure,
they are commonly referred to as ``World Models'' (WMs). In this work, we
discover such WMs in transformers trained on maze tasks. In particular, by
employing Sparse Autoencoders (SAEs) and analysing attention patterns, we
examine the construction of WMs and demonstrate consistency between the circuit
analysis and the SAE feature-based analysis. We intervene upon the isolated
features to confirm their causal role and, in doing so, find asymmetries
between certain types of interventions. Surprisingly, we find that models are
able to reason with respect to a greater number of active features than they
see during training, even if attempting to specify these in the input token
sequence would lead the model to fail. Futhermore, we observe that varying
positional encodings can alter how WMs are encoded in a model's residual
stream. By analyzing the causal role of these WMs in a toy domain we hope to
make progress toward an understanding of emergent structure in the
representations acquired by Transformers, leading to the development of more
interpretable and controllable AI systems.


## A Distributed Collaborative Retrieval Framework Excelling in All Queries and Corpora based on Zero-shot Rank-Oriented Automatic Evaluation

>Authors: Tian-Yi Che, Xian-Ling Mao, Chun Xu, Cheng-Xin Xin, Heng-Da Xu, Jin-Yu Liu, Heyan Huang

>2024-12-16

> http://arxiv.org/abs/2412.11832v1

Numerous retrieval models, including **sparse**, dense and llm-based methods,
have demonstrated remarkable performance in predicting the relevance between
queries and corpora. However, the preliminary effectiveness analysis
experiments indicate that these models fail to achieve satisfactory performance
on the majority of queries and corpora, revealing their effectiveness
restricted to specific scenarios. Thus, to tackle this problem, we propose a
novel Distributed Collaborative Retrieval Framework (DCRF), outperforming each
single model across all queries and corpora. Specifically, the framework
integrates various retrieval models into a unified system and dynamically
selects the optimal results for each user's query. It can easily aggregate any
retrieval model and expand to any application scenarios, illustrating its
flexibility and scalability.Moreover, to reduce maintenance and training costs,
we design four effective prompting strategies with large language models (LLMs)
to evaluate the quality of ranks without reliance of labeled data. Extensive
experiments demonstrate that proposed framework, combined with 8 efficient
retrieval models, can achieve performance comparable to effective listwise
methods like RankGPT and ListT5, while offering superior efficiency. Besides,
DCRF surpasses all selected retrieval models on the most datasets, indicating
the effectiveness of our prompting strategies on rank-oriented automatic
evaluation.


## Fast and Slow Gradient Approximation for Binary Neural Network Optimization

>Authors: Xinquan Chen, Junqi Gao, Biqing Qi, Dong Li, Yiang Luo, Fangyuan Li, Pengfei Li

>2024-12-16

> http://arxiv.org/abs/2412.11777v1

Binary Neural Networks (BNNs) have garnered significant attention due to
their immense potential for deployment on edge devices. However, the
non-differentiability of the **quantization** function poses a challenge for the
optimization of BNNs, as its derivative cannot be backpropagated. To address
this issue, hypernetwork based methods, which utilize neural networks to learn
the gradients of non-differentiable **quantization** functions, have emerged as a
promising approach due to their adaptive learning capabilities to reduce
estimation errors. However, existing hypernetwork based methods typically rely
solely on current gradient information, neglecting the influence of historical
gradients. This oversight can lead to accumulated gradient errors when
calculating gradient momentum during optimization. To incorporate historical
gradient information, we design a Historical Gradient Storage (HGS) module,
which models the historical gradient sequence to generate the first-order
momentum required for optimization. To further enhance gradient generation in
hypernetworks, we propose a Fast and Slow Gradient Generation (FSG) method.
Additionally, to produce more precise gradients, we introduce Layer Recognition
Embeddings (LRE) into the hypernetwork, facilitating the generation of
layer-specific fine gradients. Extensive comparative experiments on the
CIFAR-10 and CIFAR-100 datasets demonstrate that our method achieves faster
convergence and lower loss values, outperforming existing baselines.Code is
available at http://github.com/two-tiger/FSG .


## CSRAchieving 1 Bit Key-Value Cache via Sparse Representation

>Authors: Hongxuan Zhang, Yao Zhao, Jiaqi Zheng, Chenyi Zhuang, Jinjie Gu, Guihai Chen

>2024-12-16

> http://arxiv.org/abs/2412.11741v1

The emergence of long-context text applications utilizing large language
models (LLMs) has presented significant scalability challenges, particularly in
memory footprint. The linear growth of the Key-Value (**KV**) cache responsible for
storing attention keys and values to minimize redundant computations can lead
to substantial increases in memory consumption, potentially causing models to
fail to serve with limited memory resources. To address this issue, we propose
a novel approach called Cache Sparse Representation (CSR), which converts the
**KV** cache by transforming the dense Key-Value cache tensor into **sparse** indexes
and weights, offering a more memory-efficient representation during LLM
inference. Furthermore, we introduce NeuralDict, a novel neural network-based
method for automatically generating the dictionary used in our **sparse**
representation. Our extensive experiments demonstrate that CSR achieves
performance comparable to state-of-the-art **KV** cache **quantization** algorithms
while maintaining robust functionality in memory-constrained environments.


## AsymRnR Video Diffusion Transformers Acceleration with Asymmetric Reduction and Restoration

>Authors: Wenhao Sun, Rong-Cheng Tu, Jingyi Liao, Zhao Jin, Dacheng Tao

>2024-12-16

> http://arxiv.org/abs/2412.11706v1

Video Diffusion Transformers (DiTs) have demonstrated significant potential
for generating high-fidelity videos but are computationally intensive. Existing
**acceleration** methods include distillation, which requires costly retraining,
and feature caching, which is highly sensitive to network architecture. Recent
token reduction methods are training-free and architecture-agnostic, offering
greater flexibility and wider applicability. However, they enforce the same
sequence length across different components, constraining their **acceleration**
potential. We observe that intra-sequence redundancy in video DiTs varies
across features, blocks, and denoising timesteps. Building on this observation,
we propose Asymmetric Reduction and Restoration (AsymRnR), a training-free
approach to accelerate video DiTs. It offers a flexible and adaptive strategy
that reduces the number of tokens based on their redundancy to enhance both
**acceleration** and generation quality. We further propose matching cache to
facilitate faster processing. Integrated into state-of-the-art video DiTs,
AsymRnR achieves a superior speedup without compromising the quality.


## Flex-PE Flexible and SIMD Multi-Precision Processing Element for AI Workloads

>Authors: Mukul Lokhande, Gopal Raut, Santosh Kumar Vishvakarma

>2024-12-16

> http://arxiv.org/abs/2412.11702v1

The rapid adaptation of data driven AI models, such as deep learning
inference, training, Vision Transformers (ViTs), and other HPC applications,
drives a strong need for runtime precision configurable different non linear
activation functions (AF) hardware support. Existing solutions support diverse
precision or runtime AF reconfigurability but fail to address both
simultaneously. This work proposes a flexible and SIMD multiprecision
processing element (FlexPE), which supports diverse runtime configurable AFs,
including sigmoid, tanh, ReLU and softmax, and MAC operation. The proposed
design achieves an improved throughput of up to 16X FxP4, 8X FxP8, 4X FxP16 and
1X FxP32 in pipeline mode with 100% time multiplexed hardware. This work
proposes an area efficient multiprecision iterative mode in the SIMD systolic
arrays for edge AI use cases. The design delivers superior performance with up
to 62X and 371X reductions in DMA reads for input feature maps and weight
filters in VGG16, with an energy efficiency of 8.42 GOPS / W within the
accuracy loss of 2%. The proposed architecture supports emerging 4-bit
computations for DL inference while enhancing throughput in FxP8/16 modes for
transformers and other HPC applications. The proposed approach enables future
energy-efficient AI accelerators in edge and cloud environments.


## Ultra-High-Definition Dynamic Multi-Exposure Image Fusion via Infinite Pixel Learning

>Authors: Xingchi Chen, Zhuoran Zheng, Xuerui Li, Yuying Chen, Shu Wang, Wenqi Ren

>2024-12-16

> http://arxiv.org/abs/2412.11685v1

With the continuous improvement of device imaging resolution, the popularity
of Ultra-High-Definition (UHD) images is increasing. Unfortunately, existing
methods for fusing multi-exposure images in dynamic scenes are designed for
low-resolution images, which makes them inefficient for generating high-quality
UHD images on a resource-constrained device. To alleviate the limitations of
extremely long-sequence inputs, inspired by the Large Language Model (LLM) for
processing infinitely long texts, we propose a novel learning paradigm to
achieve UHD multi-exposure dynamic scene image fusion on a single
consumer-grade GPU, named Infinite Pixel Learning (IPL). The design of our
approach comes from three key components: The first step is to slice the input
sequences to relieve the pressure generated by the model processing the data
stream; Second, we develop an attention cache technique, which is similar to **KV**
cache for infinite data stream processing; Finally, we design a method for
attention cache compression to alleviate the storage burden of the cache on the
device. In addition, we provide a new UHD benchmark to evaluate the
effectiveness of our method. Extensive experimental results show that our
method maintains high-quality visual performance while fusing UHD dynamic
multi-exposure images in real-time (>40fps) on a single consumer-grade GPU.


## QPruner Probabilistic Decision Quantization for Structured Pruning in Large Language Models

>Authors: Changhai Zhou, Yuhua Zhou, Shijie Han, Qian Qiao, Hongguang Li

>2024-12-16

> http://arxiv.org/abs/2412.11629v1

The rise of large language models (LLMs) has significantly advanced various
natural language processing (NLP) tasks. However, the resource demands of these
models pose substantial challenges. Structured **pruning** is an effective approach
to reducing model size, but it often results in significant accuracy
degradation, necessitating parameter updates to adapt. Unfortunately, such
fine-tuning requires substantial memory, which limits its applicability. To
address these challenges, we introduce **quantization** into the structured **pruning**
framework to reduce memory consumption during both fine-tuning and inference.
However, the combined errors from **pruning** and **quantization** increase the
difficulty of fine-tuning, requiring a more refined **quantization** scheme. To
this end, we propose QPruner, a novel framework that employs structured **pruning**
to reduce model size, followed by a layer-wise mixed-precision **quantization**
scheme. Quantization precisions are assigned to each layer based on their
importance to the target task, and Bayesian optimization is employed to refine
precision allocation strategies, ensuring a balance between model accuracy and
memory efficiency. Extensive experiments on benchmark datasets demonstrate that
QPruner significantly outperforms existing methods in memory savings while
maintaining or improving model performance.


## MeshArt Generating Articulated Meshes with Structure-guided Transformers

>Authors: Daoyi Gao, Yawar Siddiqui, Lei Li, Angela Dai

>2024-12-16

> http://arxiv.org/abs/2412.11596v1

Articulated 3D object generation is fundamental for creating realistic,
functional, and interactable virtual assets which are not simply static. We
introduce MeshArt, a hierarchical transformer-based approach to generate
articulated 3D meshes with clean, compact geometry, reminiscent of
human-crafted 3D models. We approach articulated mesh generation in a
part-by-part fashion across two stages. First, we generate a high-level
articulation-aware object structure; then, based on this structural
information, we synthesize each part's mesh faces. Key to our approach is
modeling both articulation structures and part meshes as sequences of **quantize**d
triangle embeddings, leading to a unified hierarchical framework with
transformers for autoregressive generation. Object part structures are first
generated as their bounding primitives and articulation modes; a second
transformer, guided by these articulation structures, then generates each
part's mesh triangles. To ensure coherency among generated parts, we introduce
structure-guided conditioning that also incorporates local part mesh
connectivity. MeshArt shows significant improvements over state of the art,
with 57.1% improvement in structure coverage and a 209-point improvement in
mesh generation FID.


## SFFT-based Homogenization Using Tensor Trains to Enhance FFT-Based Homogenization

>Authors: Sascha H. Hauck, Matthias Kabel, Mazen Ali, Nicolas R. Gauger

>2024-12-16

> http://arxiv.org/abs/2412.11566v1

Homogenization is a key technique for approximating the macroscopic
properties of materials with microscale heterogeneity. The FFT-based
Homogenization method has gained widespread usage due to its computational
efficiency and accuracy in handling complex microstructures. However, despite
its advantages, the method is limited by speed and memory constraints,
particularly when applied to high-resolution discretizations. These limitations
affect its scalability and efficiency, especially in large-scale simulations or
when dealing with highly detailed microstructures. These challenges arise from
the fundamental reliance on the Fast Fourier Transform, which imposes inherent
restrictions on further advancements. In this paper, we propose a novel
SFFT-based Homogenization algorithm that utilizes a Quantized Tensor Train
variant of the Quantum Fourier Transform. This method is tailored to the
geometry under consideration and offers significant improvements in time
complexity and memory efficiency compared to the traditional FFT-based approach
while remaining executable on classical hardware. The method is applicable only
if a suitable Quantized Tensor Train representation exists for the stiffness
operator associated with the underlying geometry.


## MPQ-DM Mixed Precision Quantization for Extremely Low Bit Diffusion Models

>Authors: Weilun Feng, Haotong Qin, Chuanguang Yang, Zhulin An, Libo Huang, Boyu Diao, Fei Wang, Renshuai Tao, Yongjun Xu, Michele Magno

>2024-12-16

> http://arxiv.org/abs/2412.11549v1

Diffusion models have received wide attention in generation tasks. However,
the expensive computation cost prevents the application of diffusion models in
resource-constrained scenarios. Quantization emerges as a practical solution
that significantly saves storage and computation by reducing the bit-width of
parameters. However, the existing **quantization** methods for diffusion models
still cause severe degradation in performance, especially under extremely low
bit-widths (2-4 bit). The primary decrease in performance comes from the
significant discretization of activation values at low bit **quantization**. Too
few activation candidates are unfriendly for outlier significant weight channel
**quantization**, and the discretized features prevent stable learning over
different time steps of the diffusion model. This paper presents MPQ-DM, a
Mixed-Precision Quantization method for Diffusion Models. The proposed MPQ-DM
mainly relies on two techniques:(1) To mitigate the **quantization** error caused
by outlier severe weight channels, we propose an Outlier-Driven Mixed
Quantization (OMQ) technique that uses $Kurtosis$ to quantify outlier salient
channels and apply optimized intra-layer mixed-precision bit-width allocation
to recover accuracy performance within target efficiency.(2) To robustly learn
representations crossing time steps, we construct a Time-Smoothed Relation
Distillation (TRD) scheme between the **quantize**d diffusion model and its
full-precision counterpart, transferring discrete and continuous latent to a
unified relation space to reduce the representation inconsistency.
Comprehensive experiments demonstrate that MPQ-DM achieves significant accuracy
gains under extremely low bit-widths compared with SOTA **quantization** methods.
MPQ-DM achieves a 58\% FID decrease under W2A4 setting compared with baseline,
while all other methods even collapse.


## SP$^2$T Sparse Proxy Attention for Dual-stream Point Transformer

>Authors: Jiaxu Wan, Hong Zhang, Ziqi He, Qishu Wang, Ding Yuan, Yifan Yang

>2024-12-16

> http://arxiv.org/abs/2412.11540v1

In 3D understanding, point transformers have yielded significant advances in
broadening the receptive field. However, further enhancement of the receptive
field is hindered by the constraints of grouping attention. The proxy-based
model, as a hot topic in image and language feature extraction, uses global or
local proxies to expand the model's receptive field. But global proxy-based
methods fail to precisely determine proxy positions and are not suited for
tasks like segmentation and detection in the point cloud, and exist local
proxy-based methods for image face difficulties in global-local balance, proxy
sampling in various point clouds, and parallel cross-attention computation for
**sparse** association. In this paper, we present SP$^2$T, a local proxy-based dual
stream point transformer, which promotes global receptive field while
maintaining a balance between local and global information. To tackle robust 3D
proxy sampling, we propose a spatial-wise proxy sampling with vertex-based
point proxy associations, ensuring robust point-cloud sampling in many scales
of point cloud. To resolve economical association computation, we introduce
**sparse** proxy attention combined with table-based relative bias, which enables
low-cost and precise interactions between proxy and point features.
Comprehensive experiments across multiple datasets reveal that our model
achieves SOTA performance in downstream tasks. The code has been released in
https://github.com/TerenceWallel/Sparse-Proxy-Point-Transformer .


## ON as ALC Active Loop Closing Object Goal Navigation

>Authors: Daiki Iwata, Kanji Tanaka, Shoya Miyazaki, Kouki Terashima

>2024-12-16

> http://arxiv.org/abs/2412.11523v1

In simultaneous localization and mapping, active loop closing (ALC) is an
active vision problem that aims to visually guide a robot to maximize the
chances of revisiting previously visited points, thereby resetting the drift
errors accumulated in the incrementally built map during travel. However,
current mainstream navigation strategies that leverage such incomplete maps as
workspace prior knowledge often fail in modern long-term autonomy long-distance
travel scenarios where map accumulation errors become significant. To address
these limitations of map-based navigation, this paper is the first to explore
mapless navigation in the embodied AI field, in particular, to utilize
object-goal navigation (commonly abbreviated as ON, ObjNav, or OGN) techniques
that efficiently explore target objects without using such a prior map.
Specifically, in this work, we start from an off-the-shelf mapless ON planner,
extend it to utilize a prior map, and further show that the performance in
long-distance ALC (LD-ALC) can be maximized by minimizing ``ALC loss" and ``ON
loss". This study highlights a simple and effective approach, called ALC-ON
(ALCON), to accelerate the progress of challenging long-distance ALC technology
by leveraging the growing frontier-guided, data-driven, and LLM-guided ON
technologies.


## EditSplat Multi-View Fusion and Attention-Guided Optimization for View-Consistent 3D Scene Editing with 3D Gaussian Splatting

>Authors: Dong In Lee, Hyeongcheol Park, Jiyoung Seo, Eunbyung Park, Hyunje Park, Ha Dam Baek, Shin Sangheon, Sangmin kim, Sangpil Kim

>2024-12-16

> http://arxiv.org/abs/2412.11520v1

Recent advancements in 3D editing have highlighted the potential of
text-driven methods in real-time, user-friendly AR/VR applications. However,
current methods rely on 2D diffusion models without adequately considering
multi-view information, resulting in multi-view inconsistency. While 3D
Gaussian Splatting (3DGS) significantly improves rendering quality and speed,
its 3D editing process encounters difficulties with inefficient optimization,
as pre-trained Gaussians retain excessive source information, hindering
optimization. To address these limitations, we propose \textbf{EditSplat}, a
novel 3D editing framework that integrates Multi-view Fusion Guidance (MFG) and
Attention-Guided Trimming (AGT). Our MFG ensures multi-view consistency by
incorporating essential multi-view information into the diffusion process,
leveraging classifier-free guidance from the text-to-image diffusion model and
the geometric properties of 3DGS. Additionally, our AGT leverages the explicit
representation of 3DGS to selectively prune and optimize 3D Gaussians,
enhancing optimization efficiency and enabling precise, semantically rich local
edits. Through extensive qualitative and quantitative evaluations, EditSplat
achieves superior multi-view consistency and editing quality over existing
methods, significantly enhancing overall efficiency.


## FTP A Fine-grained Token-wise Pruner for Large Language Models via Token Routing

>Authors: Zekai Li, Jintu Zheng, Ji Liu, Han Liu, Haowei Zhu, Zeping Li, Fuwei Yang, Haiduo Huang, Jinzhang Peng, Dong Li, Lu Tian, Emad Barsoum

>2024-12-16

> http://arxiv.org/abs/2412.11494v1

Recently, large language models (LLMs) have demonstrated superior performance
across various tasks by adhering to scaling laws, which significantly increase
model size. However, the huge computation overhead during inference hinders the
deployment in industrial applications. Many works leverage traditional
compression approaches to boost model inference, but these always introduce
additional training costs to restore the performance and the **pruning** results
typically show noticeable performance drops compared to the original model when
aiming for a specific level of **acceleration**. To address these issues, we
propose a fine-grained token-wise **pruning** approach for the LLMs, which presents
a learnable router to adaptively identify the less important tokens and skip
them across model blocks to reduce computational cost during inference. To
construct the router efficiently, we present a search-based **sparsity** scheduler
for **pruning** **sparsity** allocation, a trainable router combined with our proposed
four low-dimensional factors as input and three proposed losses. We conduct
extensive experiments across different benchmarks on different LLMs to
demonstrate the superiority of our method. Our approach achieves
state-of-the-art (SOTA) **pruning** results, surpassing other existing **pruning**
methods. For instance, our method outperforms BlockPruner and ShortGPT by
approximately 10 points on both LLaMA2-7B and Qwen1.5-7B in accuracy retention
at comparable token **sparsity** levels.


## Towards Scientific Discovery with Generative AI Progress, Opportunities, and Challenges

>Authors: Chandan K Reddy, Parshin Shojaee

>2024-12-16

> http://arxiv.org/abs/2412.11427v1

Scientific discovery is a complex cognitive process that has driven human
knowledge and technological progress for centuries. While artificial
intelligence (AI) has made significant advances in automating aspects of
scientific reasoning, simulation, and experimentation, we still lack integrated
AI systems capable of performing autonomous long-term scientific research and
discovery. This paper examines the current state of AI for scientific
discovery, highlighting recent progress in large language models and other AI
techniques applied to scientific tasks. We then outline key challenges and
promising research directions toward developing more comprehensive AI systems
for scientific discovery, including the need for science-focused AI agents,
improved benchmarks and evaluation metrics, multimodal scientific
representations, and unified frameworks combining reasoning, theorem proving,
and data-driven modeling. Addressing these challenges could lead to
transformative AI tools to accelerate progress across disciplines towards
scientific discovery.


## FinLoRA Finetuning Quantized Financial Large Language Models Using Low-Rank Adaptation

>Authors: Dannong Wang, Daniel Kim, Bo Jin, Xingjian Zhao, Tianfan Fu, Steve Yang, Xiao-Yang Liu

>2024-12-16

> http://arxiv.org/abs/2412.11378v1

Finetuned large language models (LLMs) have shown remarkable performance in
financial tasks, such as sentiment analysis and information retrieval. Due to
privacy concerns, finetuning and deploying Financial LLMs (FinLLMs) locally are
crucial for institutions. However, finetuning FinLLMs poses challenges
including GPU memory constraints and long input sequences. In this paper, we
employ **quantize**d low-rank adaptation (QLoRA) to finetune FinLLMs, which
leverage low-rank matrix decomposition and **quantization** techniques to
significantly reduce computational requirements while maintaining high model
performance. We also employ data and pipeline parallelism to enable local
finetuning using cost-effective, widely accessible GPUs. Experiments on
financial datasets demonstrate that our method achieves substantial
improvements in accuracy, GPU memory usage, and time efficiency, underscoring
the potential of lowrank methods for scalable and resource-efficient LLM
finetuning.


## Accelerating Sparse Graph Neural Networks with Tensor Core Optimization

>Authors: Ka Wai Wu

>2024-12-16

> http://arxiv.org/abs/2412.12218v1

Graph neural networks (GNNs) have seen extensive application in domains such
as social networks, bioinformatics, and recommendation systems. However, the
irregularity and **sparsity** of graph data challenge traditional computing
methods, which are insufficient to meet the performance demands of GNNs. Recent
research has explored parallel **acceleration** using CUDA Cores and Tensor Cores,
but significant challenges persist: (1) kernel fusion leads to false high
utilization, failing to treat CUDA and Tensor Cores as independent resources,
and (2) heterogeneous cores have distinct computation preferences, causing
inefficiencies. To address these issues, this paper proposes FTC-GNN, a novel
**acceleration** framework that efficiently utilizes CUDA and Tensor Cores for GNN
computation. FTC-GNN introduces (1) a collaborative design that enables the
parallel utilization of CUDA and Tensor Cores and (2) a **sparse**-to-dense
transformation strategy that assigns dense matrix operations to Tensor Cores
while leveraging CUDA Cores for data management and **sparse** edge processing.
This design optimizes GPU resource utilization and improves computational
efficiency. Experimental results demonstrate the effectiveness of FTC-GNN using
GCN and AGNN models across various datasets. For GCN, FTC-GNN achieves speedups
of 4.90x, 7.10x, and 1.17x compared to DGL, PyG, and TC-GNN, respectively. For
AGNN, it achieves speedups of 5.32x, 2.92x, and 1.02x, establishing its
superiority in accelerating GNN computations.


## Efficient Whisper on Streaming Speech

>Authors: Rongxiang Wang, Zhiming Xu, Felix Xiaozhu Lin

>2024-12-15

> http://arxiv.org/abs/2412.11272v1

Speech foundation models, exemplified by OpenAI's Whisper, have emerged as
leaders in speech understanding thanks to their exceptional accuracy and
adaptability. However, their usage largely focuses on processing pre-recorded
audio, with the efficient handling of streaming speech still in its infancy.
Several core challenges underlie this limitation: (1) These models are trained
for long, fixed-length audio inputs (typically 30 seconds). (2) Encoding such
inputs involves processing up to 1,500 tokens through numerous transformer
layers. (3) Generating outputs requires an irregular and computationally heavy
beam search. Consequently, streaming speech processing on edge devices with
constrained resources is more demanding than many other AI tasks, including
text generation. To address these challenges, we introduce Whisper-T, an
innovative framework combining both model and system-level optimizations: (1)
Hush words, short learnable audio segments appended to inputs, prevent
over-processing and reduce hallucinations in the model. (2) Beam **pruning** aligns
streaming audio buffers over time, leveraging intermediate decoding results to
significantly speed up the process. (3) CPU/GPU pipelining dynamically
distributes resources between encoding and decoding stages, optimizing
performance by adapting to variations in audio input, model characteristics,
and hardware. We evaluate Whisper-T on ARM-based platforms with 4-12 CPU cores
and 10-30 GPU cores, demonstrating latency reductions of 1.6x-4.7x, achieving
per-word delays as low as 0.5 seconds with minimal accuracy loss. Additionally,
on a MacBook Air, Whisper-T maintains approximately 1-second latency per word
while consuming just 7 Watts of total system power.


## TrimLLM Progressive Layer Dropping for Domain-Specific LLMs

>Authors: Lanxiang Hu, Tajana Rosing, Hao Zhang

>2024-12-15

> http://arxiv.org/abs/2412.11242v1

Specializing large language models (LLMs) for local deployment in
domain-specific use cases is necessary for strong performance while meeting
latency and privacy constraints. However, conventional task-specific adaptation
approaches do not show simultaneous memory saving and inference speedup at
deployment time. Practical compression techniques like **quantization** and **pruning**
require dedicated hardware or kernel support to achieve measured inference
speedup. We develop TrimLLM based on the layer-wise specialization phenomenon
we empirically observed and verified on contemporary LLMs. TrimLLM reduces the
depth of LLMs via progressive layer dropping. We show it retains LLMs' capacity
in specific domains and achieves inference speedup irrespective of hardware and
deep learning frameworks. We evaluated TrimLLM on LLMs of various sizes for
inference; models adapted on medical, legal, and financial datasets all
demonstrate $2.1-5.7\times$ inference speedup on consumer GPUs and up to
$3.1\times$ speedup on A100 when compared to state-of-the-art model compression
algorithms, with no loss in accuracy at 50$\sim$60\% model compression ratio.


## Latent Reward LLM-Empowered Credit Assignment in Episodic Reinforcement Learning

>Authors: Yun Qu, Yuhang Jiang, Boyuan Wang, Yixiu Mao, Cheems Wang, Chang Liu, Xiangyang Ji

>2024-12-15

> http://arxiv.org/abs/2412.11120v1

Reinforcement learning (RL) often encounters delayed and **sparse** feedback in
real-world applications, even with only episodic rewards. Previous approaches
have made some progress in reward redistribution for credit assignment but
still face challenges, including training difficulties due to redundancy and
ambiguous attributions stemming from overlooking the multifaceted nature of
mission performance evaluation. Hopefully, Large Language Model (LLM)
encompasses fruitful decision-making knowledge and provides a plausible tool
for reward redistribution. Even so, deploying LLM in this case is non-trivial
due to the misalignment between linguistic knowledge and the symbolic form
requirement, together with inherent randomness and hallucinations in inference.
To tackle these issues, we introduce LaRe, a novel LLM-empowered symbolic-based
decision-making framework, to improve credit assignment. Key to LaRe is the
concept of the Latent Reward, which works as a multi-dimensional performance
evaluation, enabling more interpretable goal attainment from various
perspectives and facilitating more effective reward redistribution. We examine
that semantically generated code from LLM can bridge linguistic knowledge and
symbolic latent rewards, as it is executable for symbolic objects. Meanwhile,
we design latent reward self-verification to increase the stability and
reliability of LLM inference. Theoretically, reward-irrelevant redundancy
elimination in the latent reward benefits RL performance from more accurate
reward estimation. Extensive experimental results witness that LaRe (i)
achieves superior temporal credit assignment to SOTA methods, (ii) excels in
allocating contributions among multiple agents, and (iii) outperforms policies
trained with ground truth rewards for certain tasks.


## Multi-Graph Co-Training for Capturing User Intent in Session-based Recommendation

>Authors: Zhe Yang, Tiantian Liang

>2024-12-15

> http://arxiv.org/abs/2412.11105v1

Session-based recommendation focuses on predicting the next item a user will
interact with based on sequences of anonymous user sessions. A significant
challenge in this field is data **sparsity** due to the typically short-term
interactions. Most existing methods rely heavily on users' current
interactions, overlooking the wealth of auxiliary information available. To
address this, we propose a novel model, the Multi-Graph Co-Training model
(MGCOT), which leverages not only the current session graph but also similar
session graphs and a global item relation graph. This approach allows for a
more comprehensive exploration of intrinsic relationships and better captures
user intent from multiple views, enabling session representations to complement
each other. Additionally, MGCOT employs multi-head attention mechanisms to
effectively capture relevant session intent and uses contrastive learning to
form accurate and robust session representations. Extensive experiments on
three datasets demonstrate that MGCOT significantly enhances the performance of
session-based recommendations, particularly on the Diginetica dataset,
achieving improvements up to 2.00% in P@20 and 10.70% in MRR@20. Resources have
been made publicly available in our GitHub repository
https://github.com/liang-tian-tian/MGCOT.


## Zigzag Diffusion Sampling Diffusion Models Can Self-Improve via Self-Reflection

>Authors: Lichen Bai, Shitong Shao, Zikai Zhou, Zipeng Qi, Zhiqiang Xu, Haoyi Xiong, Zeke Xie

>2024-12-14

> http://arxiv.org/abs/2412.10891v2

Diffusion models, the most popular generative paradigm so far, can inject
conditional information into the generation path to guide the latent towards
desired directions. However, existing text-to-image diffusion models often fail
to maintain high image quality and high prompt-image alignment for those
challenging prompts. To mitigate this issue and enhance existing pretrained
diffusion models, we mainly made three contributions in this paper. First, we
propose diffusion self-reflection that alternately performs denoising and
inversion and demonstrate that such diffusion self-reflection can leverage the
guidance gap between denoising and inversion to capture prompt-related semantic
information with theoretical and empirical evidence. Second, motivated by
theoretical analysis, we derive Zigzag Diffusion Sampling (Z-Sampling), a novel
self-reflection-based diffusion sampling method that leverages the guidance gap
between denosing and inversion to accumulate semantic information step by step
along the sampling path, leading to improved sampling results. Moreover, as a
plug-and-play method, Z-Sampling can be generally applied to various diffusion
models (e.g., accelerated ones and Transformer-based ones) with very limited
coding and computational costs. Third, our extensive experiments demonstrate
that Z-Sampling can generally and significantly enhance generation quality
across various benchmark datasets, diffusion models, and performance evaluation
metrics. For example, DreamShaper with Z-Sampling can self-improve with the
HPSv2 winning rate up to 94% over the original results. Moreover, Z-Sampling
can further enhance existing diffusion models combined with other orthogonal
methods, including Diffusion-DPO.


## RWKV-edge Deeply Compressed RWKV for Resource-Constrained Devices

>Authors: Wonkyo Choe, Yangfeng Ji, Felix Lin

>2024-12-14

> http://arxiv.org/abs/2412.10856v1

To deploy LLMs on resource-contained platforms such as mobile robotics and
wearables, non-transformers LLMs have achieved major breakthroughs. Recently, a
novel RNN-based LLM family, Repentance Weighted Key Value (RW**KV**) models have
shown promising results in text generation on resource-constrained devices
thanks to their computational efficiency. However, these models remain too
large to be deployed on embedded devices due to their high parameter count. In
this paper, we propose an efficient suite of compression techniques, tailored
to the RW**KV** architecture. These techniques include low-rank approximation,
**sparsity** predictors, and clustering head, designed to align with the model
size. Our methods compress the RW**KV** models by 4.95--3.8x with only 2.95pp loss
in accuracy.


## Symmetries of a 3D Field-Theoretic Model

>Authors: R. Kumar, R. P. Malik

>2024-12-14

> http://arxiv.org/abs/2412.10852v1

We discuss the discrete as well as the continuous symmetry transformations
for a three $(2+1)$-dimensional $(3D)$ combined system of the free Abelian
1-form and 2-form gauge theories within the framework of
Becchi-Rouet-Stora-Tyutin (BRST) formalism and establish their relevance in the
context of the algebraic structures that are obeyed by the de Rham
cohomological operators of differential geometry. In fact, our present
field-theoretic system respects six continuous symmetry transformations and a
couple of very useful discrete duality symmetry transformations. Out of the
above six continuous symmetry transformations four are off-shell nilpotent
(i.e. fermionic) in nature and two are bosonic. The algebraic structures,
obeyed by the symmetry operators, are reminiscent of the algebra satisfied by
the de Rham cohomological operators. Hence, our present $3D$ field-theoretic
system provides a perfect example for Hodge theory where there is convergence
of ideas from the physical aspects of the BRST formalism and mathematical
ingredients that are connected with the cohomological operators of differential
geometry at the algebraic level. One of the highlights of our present
investigation is the appearance of a pseudo-scalar field in our theory (on the
symmetry ground alone) which carries the negative kinetic term. Thus, it is one
of the possible candidates for the ``phantom" fields of the cyclic, bouncing
and self-accelerated cosmological models of the Universe.


## Boosting ViT-based MRI Reconstruction from the Perspectives of Frequency Modulation, Spatial Purification, and Scale Diversification

>Authors: Yucong Meng, Zhiwei Yang, Yonghong Shi, Zhijian Song

>2024-12-14

> http://arxiv.org/abs/2412.10776v1

The accelerated MRI reconstruction process presents a challenging ill-posed
inverse problem due to the extensive under-sampling in k-space. Recently,
Vision Transformers (ViTs) have become the mainstream for this task,
demonstrating substantial performance improvements. However, there are still
three significant issues remain unaddressed: (1) ViTs struggle to capture
high-frequency components of images, limiting their ability to detect local
textures and edge information, thereby impeding MRI restoration; (2) Previous
methods calculate multi-head self-attention (MSA) among both related and
unrelated tokens in content, introducing noise and significantly increasing
computational burden; (3) The naive feed-forward network in ViTs cannot model
the multi-scale information that is important for image restoration. In this
paper, we propose FPS-Former, a powerful ViT-based framework, to address these
issues from the perspectives of frequency modulation, spatial purification, and
scale diversification. Specifically, for issue (1), we introduce a frequency
modulation attention module to enhance the self-attention map by adaptively
re-calibrating the frequency information in a Laplacian pyramid. For issue (2),
we customize a spatial purification attention module to capture interactions
among closely related tokens, thereby reducing redundant or irrelevant feature
representations. For issue (3), we propose an efficient feed-forward network
based on a hybrid-scale fusion strategy. Comprehensive experiments conducted on
three public datasets show that our FPS-Former outperforms state-of-the-art
methods while requiring lower computational costs.


## WaveGNN Modeling Irregular Multivariate Time Series for Accurate Predictions

>Authors: Arash Hajisafi, Maria Despoina Siampou, Bita Azarijoo, Cyrus Shahabi

>2024-12-14

> http://arxiv.org/abs/2412.10621v1

Accurately modeling and analyzing time series data is crucial for downstream
applications across various fields, including healthcare, finance, astronomy,
and epidemiology. However, real-world time series often exhibit irregularities
such as misaligned timestamps, missing entries, and variable sampling rates,
complicating their analysis. Existing approaches often rely on imputation,
which can introduce biases. A few approaches that directly model irregularity
tend to focus exclusively on either capturing intra-series patterns or
inter-series relationships, missing the benefits of integrating both. To this
end, we present WaveGNN, a novel framework designed to directly (i.e., no
imputation) embed irregularly sampled multivariate time series data for
accurate predictions. WaveGNN utilizes a Transformer-based encoder to capture
intra-series patterns by directly encoding the temporal dynamics of each time
series. To capture inter-series relationships, WaveGNN uses a dynamic graph
neural network model, where each node represents a sensor, and the edges
capture the long- and short-term relationships between them. Our experimental
results on real-world healthcare datasets demonstrate that WaveGNN consistently
outperforms existing state-of-the-art methods, with an average relative
improvement of 14.7% in F1-score when compared to the second-best baseline in
cases with extreme **sparsity**. Our ablation studies reveal that both intra-series
and inter-series modeling significantly contribute to this notable improvement.


## iMoT Inertial Motion Transformer for Inertial Navigation

>Authors: Son Minh Nguyen, Linh Duy Tran, Duc Viet Le, Paul J. M Havinga

>2024-12-13

> http://arxiv.org/abs/2412.12190v1

We propose iMoT, an innovative Transformer-based inertial odometry method
that retrieves cross-modal information from motion and rotation modalities for
accurate positional estimation. Unlike prior work, during the encoding of the
motion context, we introduce Progressive Series Decoupler at the beginning of
each encoder layer to stand out critical motion events inherent in **acceleration**
and angular velocity signals. To better aggregate cross-modal interactions, we
present Adaptive Positional Encoding, which dynamically modifies positional
embeddings for temporal discrepancies between different modalities. During
decoding, we introduce a small set of learnable query motion particles as
priors to model motion uncertainties within velocity segments. Each query
motion particle is intended to draw cross-modal features dedicated to a
specific motion mode, all taken together allowing the model to refine its
understanding of motion dynamics effectively. Lastly, we design a dynamic
scoring mechanism to stabilize iMoT's optimization by considering all aligned
motion particles at the final decoding step, ensuring robust and accurate
velocity segment estimation. Extensive evaluations on various inertial datasets
demonstrate that iMoT significantly outperforms state-of-the-art methods in
delivering superior robustness and accuracy in trajectory reconstruction.


## SCBench A KV Cache-Centric Analysis of Long-Context Methods

>Authors: Yucheng Li, Huiqiang Jiang, Qianhui Wu, Xufang Luo, Surin Ahn, Chengruidong Zhang, Amir H. Abdi, Dongsheng Li, Jianfeng Gao, Yuqing Yang, Lili Qiu

>2024-12-13

> http://arxiv.org/abs/2412.10319v1

Long-context LLMs have enabled numerous downstream applications but also
introduced significant challenges related to computational and memory
efficiency. To address these challenges, optimizations for long-context
inference have been developed, centered around the **KV** cache. However, existing
benchmarks often evaluate in single-request, neglecting the full lifecycle of
the **KV** cache in real-world use. This oversight is particularly critical, as **KV**
cache reuse has become widely adopted in LLMs inference frameworks, such as
vLLM and SGLang, as well as by LLM providers, including OpenAI, Microsoft,
Google, and Anthropic. To address this gap, we introduce
SCBench(SharedContextBench), a comprehensive benchmark for evaluating
long-context methods from a **KV** cachecentric perspective: 1) **KV** cache
generation, 2) **KV** cache compression, 3) **KV** cache retrieval, 4) **KV** cache
loading. Specifically, SCBench uses test examples with shared context, ranging
12 tasks with two shared context modes, covering four categories of
long-context capabilities: string retrieval, semantic retrieval, global
information, and multi-task. With it, we provide an extensive **KV** cache-centric
analysis of eight categories long-context solutions, including Gated Linear
RNNs, Mamba-Attention hybrids, and efficient methods such as **sparse** attention,
**KV** cache dropping, **quantization**, retrieval, loading, and prompt compression.
The evaluation is conducted on 8 long-context LLMs. Our findings show that
sub-O(n) memory methods suffer in multi-turn scenarios, while **sparse** encoding
with O(n) memory and sub-O(n^2) pre-filling computation perform robustly.
Dynamic **sparsity** yields more expressive **KV** caches than static patterns, and
layer-level **sparsity** in hybrid architectures reduces memory usage with strong
performance. Additionally, we identify attention distribution shift issues in
long-generation scenarios. https://aka.ms/SCBench.


## MST-R Multi-Stage Tuning for Retrieval Systems and Metric Evaluation

>Authors: Yash Malviya, Karan Dhingra, Maneesh Singh

>2024-12-13

> http://arxiv.org/abs/2412.10313v1

Regulatory documents are rich in nuanced terminology and specialized
semantics. FRAG systems: Frozen retrieval-augmented generators utilizing
pre-trained (or, frozen) components face consequent challenges with both
retriever and answering performance. We present a system that adapts the
retriever performance to the target domain using a multi-stage tuning (MST)
strategy. Our retrieval approach, called MST-R (a) first fine-tunes encoders
used in vector stores using hard negative mining, (b) then uses a hybrid
retriever, combining **sparse** and dense retrievers using reciprocal rank fusion,
and then (c) adapts the cross-attention encoder by fine-tuning only the top-k
retrieved results. We benchmark the system performance on the dataset released
for the RIRAG challenge (as part of the RegNLP workshop at COLING 2025). We
achieve significant performance gains obtaining a top rank on the RegNLP
challenge leaderboard. We also show that a trivial answering approach games the
RePASs metric outscoring all baselines and a pre-trained Llama model. Analyzing
this anomaly, we present important takeaways for future research.


## Cultural Evolution of Cooperation among LLM Agents

>Authors: Aron Vallinder, Edward Hughes

>2024-12-13

> http://arxiv.org/abs/2412.10270v1

Large language models (LLMs) provide a compelling foundation for building
generally-capable AI agents. These agents may soon be deployed at scale in the
real world, representing the interests of individual humans (e.g., AI
assistants) or groups of humans (e.g., AI-accelerated corporations). At
present, relatively little is known about the dynamics of multiple LLM agents
interacting over many generations of iterative deployment. In this paper, we
examine whether a "society" of LLM agents can learn mutually beneficial social
norms in the face of incentives to defect, a distinctive feature of human
sociality that is arguably crucial to the success of civilization. In
particular, we study the evolution of indirect reciprocity across generations
of LLM agents playing a classic iterated Donor Game in which agents can observe
the recent behavior of their peers. We find that the evolution of cooperation
differs markedly across base models, with societies of Claude 3.5 Sonnet agents
achieving significantly higher average scores than Gemini 1.5 Flash, which, in
turn, outperforms GPT-4o. Further, Claude 3.5 Sonnet can make use of an
additional mechanism for costly punishment to achieve yet higher scores, while
Gemini 1.5 Flash and GPT-4o fail to do so. For each model class, we also
observe variation in emergent behavior across random seeds, suggesting an
understudied sensitive dependence on initial conditions. We suggest that our
evaluation regime could inspire an inexpensive and informative new class of LLM
benchmarks, focussed on the implications of LLM agent deployment for the
cooperative infrastructure of society.


## CosyVoice 2 Scalable Streaming Speech Synthesis with Large Language Models

>Authors: Zhihao Du, Yuxuan Wang, Qian Chen, Xian Shi, Xiang Lv, Tianyu Zhao, Zhifu Gao, Yexin Yang, Changfeng Gao, Hui Wang, Fan Yu, Huadai Liu, Zhengyan Sheng, Yue Gu, Chong Deng, Wen Wang, Shiliang Zhang, Zhijie Yan, Jingren Zhou

>2024-12-13

> http://arxiv.org/abs/2412.10117v1

In our previous work, we introduced CosyVoice, a multilingual speech
synthesis model based on supervised discrete speech tokens. By employing
progressive semantic decoding with two popular generative models, language
models (LMs) and Flow Matching, CosyVoice demonstrated high prosody
naturalness, content consistency, and speaker similarity in speech in-context
learning. Recently, significant progress has been made in multi-modal large
language models (LLMs), where the response latency and real-time factor of
speech synthesis play a crucial role in the interactive experience. Therefore,
in this report, we present an improved streaming speech synthesis model,
CosyVoice 2, which incorporates comprehensive and systematic optimizations.
Specifically, we introduce finite-scalar **quantization** to improve the codebook
utilization of speech tokens. For the text-speech LM, we streamline the model
architecture to allow direct use of a pre-trained LLM as the backbone. In
addition, we develop a chunk-aware causal flow matching model to support
various synthesis scenarios, enabling both streaming and non-streaming
synthesis within a single model. By training on a large-scale multilingual
dataset, CosyVoice 2 achieves human-parity naturalness, minimal response
latency, and virtually lossless synthesis quality in the streaming mode. We
invite readers to listen to the demos at
https://funaudiollm.github.io/cosyvoice2.


## Matrix Completion via Residual Spectral Matching

>Authors: Ziyuan Chen, Fang Yao

>2024-12-13

> http://arxiv.org/abs/2412.10005v2

Noisy matrix completion has attracted significant attention due to its
applications in recommendation systems, signal processing and image
restoration. Most existing works rely on (weighted) least squares methods under
various low-rank constraints. However, minimizing the sum of squared residuals
is not always efficient, as it may ignore the potential structural information
in the residuals. In this study, we propose a novel residual spectral matching
criterion that incorporates not only the numerical but also locational
information of residuals. This criterion is the first in noisy matrix
completion to adopt the perspective of low-rank perturbation of random matrices
and exploit the spectral properties of **sparse** random matrices. We derive
optimal statistical properties by analyzing the spectral properties of **sparse**
random matrices and bounding the effects of low-rank perturbations and partial
observations. Additionally, we propose algorithms that efficiently approximate
solutions by constructing easily computable pseudo-gradients. The iterative
process of the proposed algorithms ensures convergence at a rate consistent
with the optimal statistical error bound. Our method and algorithms demonstrate
improved numerical performance in both simulated and real data examples,
particularly in environments with high noise levels.


## Static Pruning in Dense Retrieval using Matrix Decomposition

>Authors: Federico Siciliano, Francesca Pezzuti, Nicola Tonellotto, Fabrizio Silvestri

>2024-12-13

> http://arxiv.org/abs/2412.09983v1

In the era of dense retrieval, document indexing and retrieval is largely
based on encoding models that transform text documents into embeddings. The
efficiency of retrieval is directly proportional to the number of documents and
the size of the embeddings. Recent studies have shown that it is possible to
reduce embedding size without sacrificing - and in some cases improving - the
retrieval effectiveness. However, the methods introduced by these studies are
query-dependent, so they can't be applied offline and require additional
computations during query processing, thus negatively impacting the retrieval
efficiency. In this paper, we present a novel static **pruning** method for
reducing the dimensionality of embeddings using Principal Components Analysis.
This approach is query-independent and can be executed offline, leading to a
significant boost in dense retrieval efficiency with a negligible impact on the
system effectiveness. Our experiments show that our proposed method reduces the
dimensionality of document representations by over 50% with up to a 5%
reduction in NDCG@10, for different dense retrieval models.


## T-GMSI A transformer-based generative model for spatial interpolation under sparse measurements

>Authors: Xiangxi Tian, Jie Shan

>2024-12-13

> http://arxiv.org/abs/2412.09886v1

Generating continuous environmental models from **sparse**ly sampled data is a
critical challenge in spatial modeling, particularly for topography.
Traditional spatial interpolation methods often struggle with handling **sparse**
measurements. To address this, we propose a Transformer-based Generative Model
for Spatial Interpolation (T-GMSI) using a vision transformer (ViT)
architecture for digital elevation model (DEM) generation under **sparse**
conditions. T-GMSI replaces traditional convolution-based methods with ViT for
feature extraction and DEM interpolation while incorporating a terrain
feature-aware loss function for enhanced accuracy. T-GMSI excels in producing
high-quality elevation surfaces from datasets with over 70% **sparsity** and
demonstrates strong transferability across diverse landscapes without
fine-tuning. Its performance is validated through extensive experiments,
outperforming traditional methods such as ordinary Kriging (OK) and natural
neighbor (NN) and a conditional generative adversarial network (CGAN)-based
model (CEDGAN). Compared to OK and NN, T-GMSI reduces root mean square error
(RMSE) by 40% and 25% on airborne lidar data and by 23% and 10% on spaceborne
lidar data. Against CEDGAN, T-GMSI achieves a 20% RMSE improvement on provided
DEM data, requiring no fine-tuning. The ability of model on generalizing to
large, unseen terrains underscores its transferability and potential
applicability beyond topographic modeling. This research establishes T-GMSI as
a state-of-the-art solution for spatial interpolation on **sparse** datasets and
highlights its broader utility for other **sparse** data interpolation challenges.


## Activation Sparsity Opportunities for Compressing General Large Language Models

>Authors: Nobel Dhar, Bobin Deng, Md Romyull Islam, Kazi Fahim Ahmad Nasif, Liang Zhao, Kun Suo

>2024-12-13

> http://arxiv.org/abs/2412.12178v1

Deploying local AI models, such as Large Language Models (LLMs), to edge
devices can substantially enhance devices' independent capabilities, alleviate
the server's burden, and lower the response time. Owing to these tremendous
potentials, many big tech companies have released several lightweight Small
Language Models (SLMs) to bridge this gap. However, we still have huge
motivations to deploy more powerful (LLMs) AI models on edge devices and
enhance their smartness level. Unlike the conventional approaches for AI model
compression, we investigate activation **sparsity**. The activation **sparsity** method
is orthogonal and combinable with existing techniques to maximize compression
rate while maintaining great accuracy. LLMs' Feed-Forward Network (FFN)
components, which typically comprise a large proportion of parameters (around
3/2), ensure that our FFN optimizations would have a better chance of achieving
effective compression. Moreover, our findings are beneficial to general LLMs
and are not restricted to ReLU-based models. This work systematically
investigates the tradeoff between enforcing activation **sparsity** and perplexity
(accuracy) on state-of-the-art LLMs. Our empirical analysis demonstrates that
we can obtain around 50% of main memory and computing reductions for critical
FFN components with negligible accuracy degradation. This extra 50% **sparsity**
does not naturally exist in the current LLMs, which require tuning LLMs'
activation outputs by injecting zero-enforcing thresholds. To obtain the
benefits of activation **sparsity**, we provide a guideline for the system
architect for LLM prediction and prefetching. The success prediction allows the
system to prefetch the necessary weights while omitting the inactive ones and
their successors, therefore lowering cache and memory pollution and reducing
LLM execution time on resource-constrained edge devices.


## Private Synthetic Data Generation in Small Memory

>Authors: Rayne Holland, Seyit Camtepe, Chandra Thapa, Jason Xue

>2024-12-12

> http://arxiv.org/abs/2412.09756v1

Protecting sensitive information on data streams is a critical challenge for
modern systems. Current approaches to privacy in data streams follow two
strategies. The first transforms the stream into a private sequence, enabling
the use of non-private analyses but incurring high memory costs. The second
uses compact data structures to create private summaries but restricts
flexibility to predefined queries.
  To address these limitations, we propose $\textsf{PrivHP}$, a lightweight
synthetic data generator that ensures differential privacy while being
resource-efficient. $\textsf{PrivHP}$ generates private synthetic data that
preserves the input stream's distribution, allowing flexible downstream
analyses without additional privacy costs. It leverages a hierarchical
decomposition of the domain, **pruning** low-frequency subdomains while preserving
high-frequency ones in a privacy-preserving manner. To achieve memory
efficiency in streaming contexts, $\textsf{PrivHP}$ uses private sketches to
estimate subdomain frequencies without accessing the full dataset.
  $\textsf{PrivHP}$ is parameterized by a privacy budget $\varepsilon$, a
**pruning** parameter $k$ and the sketch width $w$. It can process a dataset of
size $n$ in $\mathcal{O}((w+k)\log (\varepsilon n))$ space, $\mathcal{O}(\log
(\varepsilon n))$ update time, and outputs a private synthetic data generator
in $\mathcal{O}(k\log k\log (\varepsilon n))$ time. Prior methods require
$\Omega(n)$ space and construction time. Our evaluation uses the expected
1-Wasserstein distance between the sampler and the empirical distribution.
Compared to state-of-the-art methods, we demonstrate that the additional cost
in utility is inversely proportional to $k$ and $w$. This represents the first
meaningful trade-off between performance and utility for private synthetic data
generation.


## AiEDA Agentic AI Design Framework for Digital ASIC System Design

>Authors: Aditya Patra, Saroj Rout, Arun Ravindran

>2024-12-12

> http://arxiv.org/abs/2412.09745v1

The paper addresses advancements in Generative Artificial Intelligence
(GenAI) and digital chip design, highlighting the integration of Large Language
Models (LLMs) in automating hardware description and design. LLMs, known for
generating human-like content, are now being explored for creating hardware
description languages (HDLs) like Verilog from natural language inputs. This
approach aims to enhance productivity and reduce costs in VLSI system design.
The study introduces "AiEDA", a proposed agentic design flow framework for
digital ASIC systems, leveraging autonomous AI agents to manage complex design
tasks. AiEDA is designed to streamline the transition from conceptual design to
GDSII layout using an open-source toolchain. The framework is demonstrated
through the design of an ultra-low-power digital ASIC for KeyWord Spotting
(KWS). The use of agentic AI workflows promises to improve design efficiency by
automating the integration of multiple design tools, thereby accelerating the
development process and addressing the complexities of hardware design.


## DiP A Scalable, Energy-Efficient Systolic Array for Matrix Multiplication Acceleration

>Authors: Ahmed J. Abdelmaksoud, Shady Agwa, Themis Prodromakis

>2024-12-12

> http://arxiv.org/abs/2412.09709v1

Transformers are gaining increasing attention across different application
domains due to their outstanding accuracy. However, these data-intensive models
add significant performance demands to the existing computing architectures.
Systolic arrays are spatial architectures that have been adopted by commercial
AI computing platforms (like Google TPUs), due to their energy-efficient
approach of data-reusability. However, these spatial architectures face a
penalty in throughput and energy efficiency due to the need for input and
output synchronization using First-In-First-Out (FIFO) buffers. This paper
proposes a novel scalable systolic-array architecture featuring Diagonal-Input
and Permutated weight-stationary (DiP) dataflow for the **acceleration** of matrix
multiplication. The proposed architecture eliminates the synchronization FIFOs
required by state-of-the-art weight stationary systolic arrays. Aside from the
area, power, and energy savings achieved by eliminating these FIFOs, DiP
architecture maximizes the computational resources (PEs) utilization. Thus, it
outperforms the weight-stationary counterparts in terms of throughput by up to
50%. A comprehensive hardware design space exploration is demonstrated using
commercial 22nm technology, highlighting the scalability advantages of DiP over
the conventional approach across various dimensions where DiP offers
improvement of energy efficiency per area up to 2.02x. Furthermore, DiP is
evaluated using various transformer workloads from widely-used models,
consistently outperforming TPU-like architectures, achieving energy
improvements of up to 1.81x and latency improvements of up to 1.49x across a
range of transformer workloads. At a 64x64 size with 4096 PEs, DiP achieves a
peak performance of 8.2 TOPS with energy efficiency 9.55 TOPS/W.


## FreeSplatter Pose-free Gaussian Splatting for Sparse-view 3D Reconstruction

>Authors: Jiale Xu, Shenghua Gao, Ying Shan

>2024-12-12

> http://arxiv.org/abs/2412.09573v1

Existing **sparse**-view reconstruction models heavily rely on accurate known
camera poses. However, deriving camera extrinsics and intrinsics from
**sparse**-view images presents significant challenges. In this work, we present
FreeSplatter, a highly scalable, feed-forward reconstruction framework capable
of generating high-quality 3D Gaussians from uncalibrated **sparse**-view images
and recovering their camera parameters in mere seconds. FreeSplatter is built
upon a streamlined transformer architecture, comprising sequential
self-attention blocks that facilitate information exchange among multi-view
image tokens and decode them into pixel-wise 3D Gaussian primitives. The
predicted Gaussian primitives are situated in a unified reference frame,
allowing for high-fidelity 3D modeling and instant camera parameter estimation
using off-the-shelf solvers. To cater to both object-centric and scene-level
reconstruction, we train two model variants of FreeSplatter on extensive
datasets. In both scenarios, FreeSplatter outperforms state-of-the-art
baselines in terms of reconstruction quality and pose estimation accuracy.
Furthermore, we showcase FreeSplatter's potential in enhancing the productivity
of downstream applications, such as text/image-to-3D content creation.


## Obfuscated Activations Bypass LLM Latent-Space Defenses

>Authors: Luke Bailey, Alex Serrano, Abhay Sheshadri, Mikhail Seleznyov, Jordan Taylor, Erik Jenner, Jacob Hilton, Stephen Casper, Carlos Guestrin, Scott Emmons

>2024-12-12

> http://arxiv.org/abs/2412.09565v1

Recent latent-space monitoring techniques have shown promise as defenses
against LLM attacks. These defenses act as scanners that seek to detect harmful
activations before they lead to undesirable actions. This prompts the question:
Can models execute harmful behavior via inconspicuous latent states? Here, we
study such obfuscated activations. We show that state-of-the-art latent-space
defenses -- including **sparse** autoencoders, representation probing, and latent
OOD detection -- are all vulnerable to obfuscated activations. For example,
against probes trained to classify harmfulness, our attacks can often reduce
recall from 100% to 0% while retaining a 90% jailbreaking rate. However,
obfuscation has limits: we find that on a complex task (writing SQL code),
obfuscation reduces model performance. Together, our results demonstrate that
neural activations are highly malleable: we can reshape activation patterns in
a variety of ways, often while preserving a network's behavior. This poses a
fundamental challenge to latent-space defenses.


## Foundational Large Language Models for Materials Research

>Authors: Vaibhav Mishra, Somaditya Singh, Dhruv Ahlawat, Mohd Zaki, Vaibhav Bihani, Hargun Singh Grover, Biswajit Mishra, Santiago Miret, Mausam, N. M. Anoop Krishnan

>2024-12-12

> http://arxiv.org/abs/2412.09560v1

Materials discovery and development are critical for addressing global
challenges. Yet, the exponential growth in materials science literature
comprising vast amounts of textual data has created significant bottlenecks in
knowledge extraction, synthesis, and scientific reasoning. Large Language
Models (LLMs) offer unprecedented opportunities to accelerate materials
research through automated analysis and prediction. Still, their effective
deployment requires domain-specific adaptation for understanding and solving
domain-relevant tasks. Here, we present LLaMat, a family of foundational models
for materials science developed through continued pretraining of LLaMA models
on an extensive corpus of materials literature and crystallographic data.
Through systematic evaluation, we demonstrate that LLaMat excels in
materials-specific NLP and structured information extraction while maintaining
general linguistic capabilities. The specialized LLaMat-CIF variant
demonstrates unprecedented capabilities in crystal structure generation,
predicting stable crystals with high coverage across the periodic table.
Intriguingly, despite LLaMA-3's superior performance in comparison to LLaMA-2,
we observe that LLaMat-2 demonstrates unexpectedly enhanced domain-specific
performance across diverse materials science tasks, including structured
information extraction from text and tables, more particularly in crystal
structure generation, a potential adaptation rigidity in overtrained LLMs.
Altogether, the present work demonstrates the effectiveness of domain
adaptation towards developing practically deployable LLM copilots for materials
research. Beyond materials science, our findings reveal important
considerations for domain adaptation of LLMs, such as model selection, training
methodology, and domain-specific performance, which may influence the
development of specialized scientific AI systems.


## Interpolating amplitudes

>Authors: Víctor Bresó, Gudrun Heinrich, Vitaly Magerya, Anton Olsson

>2024-12-12

> http://arxiv.org/abs/2412.09534v1

While the calculation of scattering amplitudes at higher orders in
perturbation theory has reached a high degree of maturity, their usage to
produce physical predictions within Monte Carlo programs is often hampered by
the slow evaluation of the multi-loop amplitudes, especially so for amplitudes
calculated numerically. As a remedy, interpolation frameworks have been
successfully used in lower dimensions, but for higher-dimensional problems,
such as the five dimensions of a 2 -> 3 phase space, efficient and reliable
solutions are **sparse**.
  This work aims to fill this gap by reviewing state-of-the-art interpolation
methods, and by assessing their performance for concrete examples drawn from
particle physics. Specifically, we investigate interpolation methods based on
polynomials, splines, spatially adaptive **sparse** grids, and neural networks
(multilayer perceptron and Lorentz-Equivariant Geometric Algebra Transformer).
Our additional aim is to motivate further studies of the interpolation of
scattering amplitudes among both physicists and mathematicians.


## From Intention To Implementation Automating Biomedical Research via LLMs

>Authors: Yi Luo, Linghang Shi, Yihao Li, Aobo Zhuang, Yeyun Gong, Ling Liu, Lin Chen

>2024-12-12

> http://arxiv.org/abs/2412.09429v1

Conventional biomedical research is increasingly labor-intensive due to the
exponential growth of scientific literature and datasets. Artificial
intelligence (AI), particularly Large Language Models (LLMs), has the potential
to revolutionize this process by automating various steps. Still, significant
challenges remain, including the need for multidisciplinary expertise,
logicality of experimental design, and performance measurements. This paper
introduces BioResearcher, the first end-to-end automated system designed to
streamline the entire biomedical research process involving dry lab
experiments. BioResearcher employs a modular multi-agent architecture,
integrating specialized agents for search, literature processing, experimental
design, and programming. By decomposing complex tasks into logically related
sub-tasks and utilizing a hierarchical learning approach, BioResearcher
effectively addresses the challenges of multidisciplinary requirements and
logical complexity. Furthermore, BioResearcher incorporates an LLM-based
reviewer for in-process quality control and introduces novel evaluation metrics
to assess the quality and automation of experimental protocols. BioResearcher
successfully achieves an average execution success rate of 63.07% across eight
previously unmet research objectives. The generated protocols averagely
outperform typical agent systems by 22.0% on five quality metrics. The system
demonstrates significant potential to reduce researchers' workloads and
accelerate biomedical discoveries, paving the way for future innovations in
automated research systems.


## RTCUDB Building Databases with RT Processors

>Authors: Xuri Shi, Kai Zhang, X. Sean Wang, Xiaodong Zhang, Rubao Lee

>2024-12-12

> http://arxiv.org/abs/2412.09337v2

A spectrum of new hardware has been studied to accelerate database systems in
the past decade. Specifically, CUDA cores are known to benefit from the fast
development of GPUs and make notable performance improvements. The
state-of-the-art GPU-based implementation, i.e., Crystal, can achieve up to 61
times higher performance than CPU-based implementations. However, experiments
show that the approach has already saturated almost all GPU memory bandwidth,
which means there is little room left for further performance improvements. We
introduce RTCUDB, the first query engine that leverages ray tracing (RT) cores
in GPUs to accelerate database query processing. RTCUDB efficiently transforms
the evaluation of a query into a ray-tracing job in a three-dimensional space.
By dramatically reducing the amount of accessed data and optimizing the data
access pattern with the ray tracing mechanism, the performance of RTCUDB is no
longer limited by the memory bandwidth as in CUDA-based implementations.
Experimental results show that RTCUDB outperforms the state-of-the-art
GPU-based query engine by up to 18.3 times while the memory bandwidth usage
drops to only 36.7% on average.


## Physics-Driven Autoregressive State Space Models for Medical Image Reconstruction

>Authors: Bilal Kabas, Fuat Arslan, Valiyeh A. Nezhad, Saban Ozturk, Emine U. Saritas, Tolga Çukur

>2024-12-12

> http://arxiv.org/abs/2412.09331v1

Medical image reconstruction from undersampled acquisitions is an ill-posed
problem that involves inversion of the imaging operator linking measurement and
image domains. In recent years, physics-driven (PD) models have gained
prominence in learning-based reconstruction given their enhanced balance
between efficiency and performance. For reconstruction, PD models cascade
data-consistency modules that enforce fidelity to acquired data based on the
imaging operator, with network modules that process feature maps to alleviate
image artifacts due to undersampling. Success in artifact suppression
inevitably depends on the ability of the network modules to tease apart
artifacts from underlying tissue structures, both of which can manifest
contextual relations over broad spatial scales. Convolutional modules that
excel at capturing local correlations are relatively insensitive to non-local
context. While transformers promise elevated sensitivity to non-local context,
practical implementations often suffer from a suboptimal trade-off between
local and non-local sensitivity due to intrinsic model complexity. Here, we
introduce a novel physics-driven autoregressive state space model (MambaRoll)
for enhanced fidelity in medical image reconstruction. In each cascade of an
unrolled architecture, MambaRoll employs an autoregressive framework based on
physics-driven state space modules (PSSM), where PSSMs efficiently aggregate
contextual features at a given spatial scale while maintaining fidelity to
acquired data, and autoregressive prediction of next-scale feature maps from
earlier spatial scales enhance capture of multi-scale contextual features.
Demonstrations on accelerated MRI and **sparse**-view CT reconstructions indicate
that MambaRoll outperforms state-of-the-art PD methods based on convolutional,
transformer and conventional SSM modules.


## Asymptotics of Harish-Chandra transform and infinitesimal freeness

>Authors: Alexey Bufetov, Panagiotis Zografos

>2024-12-12

> http://arxiv.org/abs/2412.09290v1

In the last ten years a technique of Schur generating functions and
Harish-Chandra transforms was developed for the study of the asymptotic
behavior of discrete particle systems and random matrices. In the current paper
we extend this toolbox in several directions. We establish general results
which allow to access not only the Law of Large Numbers, but also next terms of
the asymptotic expansion of averaged empirical measures. In particular, this
allows to obtain an analog of a discrete Baik-Ben Arous-Peche phase transition.
A connection with infinitesimal free probability is shown and a **quantize**d
version of infinitesimal free probability is introduced. Also, we establish the
Law of Large Numbers for several new regimes of growth of a Harish-Chandra
transform.


## Optimising TinyML with Quantization and Distillation of Transformer and Mamba Models for Indoor Localisation on Edge Devices

>Authors: Thanaphon Suwannaphong, Ferdian Jovan, Ian Craddock, Ryan McConville

>2024-12-12

> http://arxiv.org/abs/2412.09289v1

This paper proposes small and efficient machine learning models (TinyML) for
resource-constrained edge devices, specifically for on-device indoor
localisation. Typical approaches for indoor localisation rely on centralised
remote processing of data transmitted from lower powered devices such as
wearables. However, there are several benefits for moving this to the edge
device itself, including increased battery life, enhanced privacy, reduced
latency and lowered operational costs, all of which are key for common
applications such as health monitoring. The work focuses on model compression
techniques, including **quantization** and knowledge distillation, to significantly
reduce the model size while maintaining high predictive performance. We base
our work on a large state-of-the-art transformer-based model and seek to deploy
it within low-power MCUs. We also propose a state-space-based architecture
using Mamba as a more compact alternative to the transformer. Our results show
that the **quantize**d transformer model performs well within a 64 KB RAM
constraint, achieving an effective balance between model size and localisation
precision. Additionally, the compact Mamba model has strong performance under
even tighter constraints, such as a 32 KB of RAM, without the need for model
compression, making it a viable option for more resource-limited environments.
We demonstrate that, through our framework, it is feasible to deploy advanced
indoor localisation models onto low-power MCUs with restricted memory
limitations. The application of these TinyML models in healthcare has the
potential to revolutionize patient monitoring by providing accurate, real-time
location data while minimizing power consumption, increasing data privacy,
improving latency and reducing infrastructure costs.


## CRVQ Channel-relaxed Vector Quantization for Extreme Compression of LLMs

>Authors: Yuzhuang Xu, Shiyu Ji, Qingfu Zhu, Wanxiang Che

>2024-12-12

> http://arxiv.org/abs/2412.09282v1

Powerful large language models (LLMs) are increasingly expected to be
deployed with lower computational costs, enabling their capabilities on
resource-constrained devices. Post-training **quantization** (PTQ) has emerged as a
star approach to achieve this ambition, with best methods compressing weights
to less than 2 bit on average. In this paper, we propose Channel-Relaxed Vector
Quantization (CRVQ), a novel technique that significantly improves the
performance of PTQ baselines at the cost of only minimal additional bits. This
state-of-the-art extreme compression method achieves its results through two
key innovations: (1) carefully selecting and reordering a very small subset of
critical weight channels, and (2) leveraging multiple codebooks to relax the
constraint of critical channels. With our method, we demonstrate a 38.9%
improvement over the current strongest sub-2-bit PTQ baseline, enabling nearer
lossless 1-bit compression. Furthermore, our approach offers flexible
customization of **quantization** bit-width and performance, providing a wider
range of deployment options for diverse hardware platforms.


## Score and Distribution Matching Policy Advanced Accelerated Visuomotor Policies via Matched Distillation

>Authors: Bofang Jia, Pengxiang Ding, Can Cui, Mingyang Sun, Pengfang Qian, Siteng Huang, Zhaoxin Fan, Donglin Wang

>2024-12-12

> http://arxiv.org/abs/2412.09265v3

Visual-motor policy learning has advanced with architectures like
diffusion-based policies, known for modeling complex robotic trajectories.
However, their prolonged inference times hinder high-frequency control tasks
requiring real-time feedback. While consistency distillation (CD) accelerates
inference, it introduces errors that compromise action quality. To address
these limitations, we propose the Score and Distribution Matching Policy (SDM
Policy), which transforms diffusion-based policies into single-step generators
through a two-stage optimization process: score matching ensures alignment with
true action distributions, and distribution matching minimizes KL divergence
for consistency. A dual-teacher mechanism integrates a frozen teacher for
stability and an unfrozen teacher for adversarial training, enhancing
robustness and alignment with target distributions. Evaluated on a 57-task
simulation benchmark, SDM Policy achieves a 6x inference speedup while having
state-of-the-art action quality, providing an efficient and reliable framework
for high-frequency robotic tasks.


## Generalized Liénard systems with momentum-dependent mass Isochronicity and bound states

>Authors: Bijan Bagchi, A. Ghose-Choudhury, Aritra Ghosh, Partha Guha

>2024-12-12

> http://arxiv.org/abs/2412.09100v1

In this paper, we explore some classical and quantum aspects of the nonlinear
Li\'enard equation $\ddot{x} + k x \dot{x} + \omega^2 x + (k^2/9) x^3 = 0$,
where $x=x(t)$ is a real variable and $k, \omega \in \mathbb{R}$. We
demonstrate that such an equation could be derived from an equation of the
Levinson-Smith kind which is of the form $\ddot{z} + J(z) \dot{z}^2 + F(z)
\dot{z} + G(z) = 0$, where $z=z(t)$ is a real variable and $\{J(z), F(z),
G(z)\}$ are suitable functions to be specified. It can further be mapped to the
harmonic oscillator by making use of a nonlocal transformation, establishing
its isochronicity. Computations employing the Jacobi last multiplier reveal
that the system exhibits a bi-Hamiltonian character, i.e., there are two
distinct types of Hamiltonians describing the system. For each of these, we
perform a canonical **quantization** in the momentum representation and explore the
possibility of bound states. While one of the Hamiltonians is seen to exhibit
an equispaced spectrum with an infinite tower of states, the other one exhibits
branching but can be solved exactly for certain choices of the parameters.


## Forest-of-Thought Scaling Test-Time Compute for Enhancing LLM Reasoning

>Authors: Zhenni Bi, Kai Han, Chuanjian Liu, Yehui Tang, Yunhe Wang

>2024-12-12

> http://arxiv.org/abs/2412.09078v1

Large Language Models (LLMs) have shown remarkable abilities across various
language tasks, but solving complex reasoning problems remains a challenge.
While existing methods like Chain-of-Thought (CoT) and Tree-of-Thought (ToT)
enhance reasoning by decomposing problems or structuring prompts, they
typically perform a single pass of reasoning and may fail to revisit flawed
paths, compromising accuracy. To address this, we propose a novel reasoning
framework called Forest-of-Thought (FoT), which integrates multiple reasoning
trees to leverage collective decision-making for solving complex logical
problems. FoT utilizes **sparse** activation strategies to select the most relevant
reasoning paths, improving both efficiency and accuracy. Additionally, we
introduce a dynamic self-correction strategy that enables real-time error
correction and learning from past mistakes, as well as consensus-guided
decision making strategies to optimize correctness and computational resources.
Experimental results demonstrate that the FoT framework, combined with these
strategies, significantly enhances the reasoning capabilities of LLMs, enabling
them to solve complex tasks with greater precision and efficiency.


## A Symplectic Discretization Based Proximal Point Algorithm for Convex Minimization

>Authors: Ya-xiang Yuan, Yi Zhang

>2024-12-12

> http://arxiv.org/abs/2412.09077v1

The proximal point algorithm plays a central role in non-smooth convex
programming. The Augmented Lagrangian Method, one of the most famous
optimization algorithms, has been found to be closely related to the proximal
point algorithm. Due to its importance, accelerated variants of the proximal
point algorithm have received considerable attention. In this paper, we first
study an Ordinary Differential Equation (ODE) system, which provides valuable
insights into proving the convergence rate of the desired algorithm. Using the
Lyapunov function technique, we establish the convergence rate of the ODE
system. Next, we apply the Symplectic Euler Method to discretize the ODE system
to derive a new proximal point algorithm, called the Symplectic Proximal Point
Algorithm (SPPA). By utilizing the proof techniques developed for the ODE
system, we demonstrate the convergence rate of the SPPA. Additionally, it is
shown that existing accelerated proximal point algorithm can be considered a
special case of the SPPA in a specific manner. Furthermore, under several
additional assumptions, we prove that the SPPA exhibits a finer convergence
rate.


## Rules for dissipationless topotronics

>Authors: Qing Yan, Hailong Li, Hua Jiang, Qing-Feng Sun, X. C. Xie

>2024-12-12

> http://arxiv.org/abs/2412.09076v1

Topological systems hosting gapless boundary states have attracted huge
attention as promising components for next-generation information processing,
attributed to their capacity for dissipationless electronics. Nevertheless,
recent theoretical and experimental inquiries have revealed the emergence of
energy dissipation in precisely **quantize**d electrical transport. Here, we
present a criterion for the realization of truly no-dissipation design,
characterized as $N_{in}=N_{tunl}+N_{bs}$, where $N_{in}$, $N_{tunl}$, and
$N_{bs}$ represent the number of modes participating in injecting, tunneling,
and backscattering processes, respectively. The key lies in matching the number
of injecting, tunneling and backscattering modes, ensuring the equilibrium
among all engaged modes inside the device. Among all the topological materials,
we advocate for the indispensability of Chern insulators exhibiting higher
Chern numbers to achieve functional devices and uphold the no-dissipation rule
simultaneously. Furthermore, we design the topological current divider and
collector, evading dissipation upon fulfilling the established criterion. Our
work paves the path for developing the prospective topotronics.


## SEGT A General Spatial Expansion Group Transformer for nuScenes Lidar-based Object Detection Task

>Authors: Cheng Mei, Hao He, Yahui Liu, Zhenhua Guo

>2024-12-12

> http://arxiv.org/abs/2412.09658v1

In the technical report, we present a novel transformer-based framework for
nuScenes lidar-based object detection task, termed Spatial Expansion Group
Transformer (SEGT). To efficiently handle the irregular and **sparse** nature of
point cloud, we propose migrating the voxels into distinct specialized ordered
fields with the general spatial expansion strategies, and employ group
attention mechanisms to extract the exclusive feature maps within each field.
Subsequently, we integrate the feature representations across different ordered
fields by alternately applying diverse expansion strategies, thereby enhancing
the model's ability to capture comprehensive spatial information. The method
was evaluated on the nuScenes lidar-based object detection test dataset,
achieving an NDS score of 73.5 without Test-Time Augmentation (TTA) and 74.2
with TTA, demonstrating the effectiveness of the proposed method.


## ZigZagkv Dynamic KV Cache Compression for Long-context Modeling based on Layer Uncertainty

>Authors: Meizhi Zhong, Xikai Liu, Chen Zhang, Yikun Lei, Yan Gao, Yao Hu, Kehai Chen, Min Zhang

>2024-12-12

> http://arxiv.org/abs/2412.09036v1

Large Language models (LLMs) have become a research hotspot. To accelerate
the inference of LLMs, storing computed caches in memory has become the
standard technique. However, as the inference length increases, growing **KV**
caches might lead to out-of-memory issues. Many existing methods address this
issue through **KV** cache compression, primarily by preserving key tokens
throughout all layers to reduce information loss. Most of them allocate a
uniform budget size for each layer to retain. However, we observe that the
minimum budget sizes needed to retain essential information vary across layers
and models based on the perspectives of attention and hidden state output.
Building on this observation, this paper proposes a simple yet effective **KV**
cache compression method that leverages layer uncertainty to allocate budget
size for each layer. Experimental results show that the proposed method can
reduce memory usage of the **KV** caches to only $\sim$20\% when compared to Full
**KV** inference while achieving nearly lossless performance.


## RingFormer A Ring-Enhanced Graph Transformer for Organic Solar Cell Property Prediction

>Authors: Zhihao Ding, Ting Zhang, Yiran Li, Jieming Shi, Chen Jason Zhang

>2024-12-12

> http://arxiv.org/abs/2412.09030v1

Organic Solar Cells (OSCs) are a promising technology for sustainable energy
production. However, the identification of molecules with desired OSC
properties typically involves laborious experimental research. To accelerate
progress in the field, it is crucial to develop machine learning models capable
of accurately predicting the properties of OSC molecules. While graph
representation learning has demonstrated success in molecular property
prediction, it remains underexplored for OSC-specific tasks. Existing methods
fail to capture the unique structural features of OSC molecules, particularly
the intricate ring systems that critically influence OSC properties, leading to
suboptimal performance. To fill the gap, we present RingFormer, a novel graph
transformer framework specially designed to capture both atom and ring level
structural patterns in OSC molecules. RingFormer constructs a hierarchical
graph that integrates atomic and ring structures and employs a combination of
local message passing and global attention mechanisms to generate expressive
graph representations for accurate OSC property prediction. We evaluate
RingFormer's effectiveness on five curated OSC molecule datasets through
extensive experiments. The results demonstrate that RingFormer consistently
outperforms existing methods, achieving a 22.77% relative improvement over the
nearest competitor on the CEPDB dataset.


## Lexico Extreme KV Cache Compression via Sparse Coding over Universal Dictionaries

>Authors: Junhyuck Kim, Jongho Park, Jaewoong Cho, Dimitris Papailiopoulos

>2024-12-12

> http://arxiv.org/abs/2412.08890v1

We introduce Lexico, a novel **KV** cache compression method that leverages
**sparse** coding with a universal dictionary. Our key finding is that key-value
cache in modern LLMs can be accurately approximated using **sparse** linear
combination from a small, input-agnostic dictionary of ~4k atoms, enabling
efficient compression across different input prompts, tasks and models. Using
orthogonal matching pursuit for **sparse** approximation, Lexico achieves flexible
compression ratios through direct **sparsity** control. On GSM8K, across multiple
model families (Mistral, Llama 3, Qwen2.5), Lexico maintains 90-95% of the
original performance while using only 15-25% of the full **KV**-cache memory,
outperforming both **quantization** and token eviction methods. Notably, Lexico
remains effective in low memory regimes where 2-bit **quantization** fails,
achieving up to 1.7x better compression on LongBench and GSM8K while
maintaining high accuracy.


## From Noise to Nuance Advances in Deep Generative Image Models

>Authors: Benji Peng, Chia Xin Liang, Ziqian Bi, Ming Liu, Yichao Zhang, Tianyang Wang, Keyu Chen, Xinyuan Song, Pohsun Feng

>2024-12-12

> http://arxiv.org/abs/2412.09656v1

Deep learning-based image generation has undergone a paradigm shift since
2021, marked by fundamental architectural breakthroughs and computational
innovations. Through reviewing architectural innovations and empirical results,
this paper analyzes the transition from traditional generative methods to
advanced architectures, with focus on compute-efficient diffusion models and
vision transformer architectures. We examine how recent developments in Stable
Diffusion, DALL-E, and consistency models have redefined the capabilities and
performance boundaries of image synthesis, while addressing persistent
challenges in efficiency and quality. Our analysis focuses on the evolution of
latent space representations, cross-attention mechanisms, and
parameter-efficient training methodologies that enable accelerated inference
under resource constraints. While more efficient training methods enable faster
inference, advanced control mechanisms like ControlNet and regional attention
systems have simultaneously improved generation precision and content
customization. We investigate how enhanced multi-modal understanding and
zero-shot generation capabilities are reshaping practical applications across
industries. Our analysis demonstrates that despite remarkable advances in
generation quality and computational efficiency, critical challenges remain in
developing resource-conscious architectures and interpretable generation
systems for industrial applications. The paper concludes by mapping promising
research directions, including neural architecture optimization and explainable
generation frameworks.


## The Critical Beta-splitting Random Tree III The exchangeable partition representation and the fringe tree

>Authors: David J. Aldous, Svante Janson

>2024-12-12

> http://arxiv.org/abs/2412.09655v1

In the critical beta-splitting model of a random $n$-leaf rooted tree, clades
are recursively split into sub-clades, and a clade of $m$ leaves is split into
sub-clades containing $i$ and $m-i$ leaves with probabilities $\propto
1/(i(m-i))$. Study of structure theory and explicit quantitative aspects of the
model is an active research topic. It turns out that many results have several
different proofs, and detailed studies of analytic proofs are given elsdewhere
(via analysis of recursions and via Mellin transforms). This article describes
two core probabilistic methods for studying $n \to \infty$ asymptotics of the
basic finite-$n$-leaf models.
  (i) There is a canonical embedding into a continuous-time model, that is a
random tree CTCS(n) on $n$ leaves with real-valued edge lengths, and this model
turns out to be more convenient to study. The family (CTCS(n), $n \ge 2)$ is
consistent under a ``delete random leaf and prune" operation. That leads to an
explicit inductive construction (the {\em growth algorithm}) of (CTCS(n), $n
\ge 2)$ as $n$ increases, and then to a limit structure CTCS$(\infty)$ which
can be formalized via exchangeable partitions, in some ways analogous to the
Brownian continuum random tree.
  (ii) There is an explicit description of the limit fringe distribution
relative to a random leaf, whose graphical representation is essentially the
format of the cladogram representation of biological phylogenies.


## Designing flexible hard magnetic materials for zero-magnetic-field operation of the anomalous Nernst effect

>Authors: Sang J. Park, Rajkumar Modak, Ravi Gautam, Abdulkareem Alasli, Takamasa Hirai, Fuyuki Ando, Hosei Nagano, Hossein Sepehri-Amin, Ken-ichi Uchida

>2024-12-12

> http://arxiv.org/abs/2412.08853v1

The global shift towards a carbon-neutral society has accelerated the demand
for green energy, driving research into efficient technologies for harvesting
energy from low-grade waste heat. Recently, transverse thermoelectrics based on
the anomalous Nernst effect (ANE) has gained attention due to their simple
device structure, scalability, and manufacturing-friendly nature. While
topological single crystals and epitaxial films have been focused for enhancing
the ANE-driven thermoelectric performance, further improvements in material
design are necessary for practical applications. Here, we report an
easy-to-implement strategy for designing mechanically flexible and magnetically
hard transverse thermoelectric materials by creating amorphous-crystalline
heterogeneous composites. We fabricated and optimized the heterogeneous
composites through controlled heat treatment, achieving significant
enhancements in the coercivity and anomalous Nernst coefficient, while
maintaining flexibility. Additionally, using the developed material, we
constructed a single-material-based coiled device and demonstrated the
zero-field operation of the ANE-based energy harvesting from curved heat
sources. These results validate the feasibility of using the ANE-based flexible
materials for energy harvesting applications.


## HadaCore Tensor Core Accelerated Hadamard Transform Kernel

>Authors: Krish Agarwal, Rishi Astra, Adnan Hoque, Mudhakar Srivatsa, Raghu Ganti, Less Wright, Sijia Chen

>2024-12-12

> http://arxiv.org/abs/2412.08832v1

We present HadaCore, a modified Fast Walsh-Hadamard Transform (FWHT)
algorithm optimized for the Tensor Cores present in modern GPU hardware.
HadaCore follows the recursive structure of the original FWHT algorithm,
achieving the same asymptotic runtime complexity but leveraging a
hardware-aware work decomposition that benefits from Tensor Core **acceleration**.
This reduces bottlenecks from compute and data exchange. On Nvidia A100 and
H100 GPUs, HadaCore achieves speedups of 1.1-1.4x and 1.0-1.3x, with a peak
gain of 3.5x and 3.6x respectively, when compared to the existing
state-of-the-art implementation of the original algorithm. We also show that
when using FP16 or BF16, our implementation is numerically accurate, enabling
comparable accuracy on MMLU benchmarks when used in an end-to-end Llama3
inference run with **quantize**d (FP8) attention.


## Large Concept Models Language Modeling in a Sentence Representation Space

>Authors: LCM team, Loïc Barrault, Paul-Ambroise Duquenne, Maha Elbayad, Artyom Kozhevnikov, Belen Alastruey, Pierre Andrews, Mariano Coria, Guillaume Couairon, Marta R. Costa-jussà, David Dale, Hady Elsahar, Kevin Heffernan, João Maria Janeiro, Tuan Tran, Christophe Ropers, Eduardo Sánchez, Robin San Roman, Alexandre Mourachko, Safiyyah Saleem, Holger Schwenk

>2024-12-11

> http://arxiv.org/abs/2412.08821v2

LLMs have revolutionized the field of artificial intelligence and have
emerged as the de-facto tool for many tasks. The current established technology
of LLMs is to process input and generate output at the token level. This is in
sharp contrast to humans who operate at multiple levels of abstraction, well
beyond single words, to analyze information and to generate creative content.
In this paper, we present an attempt at an architecture which operates on an
explicit higher-level semantic representation, which we name a concept.
Concepts are language- and modality-agnostic and represent a higher level idea
or action in a flow. Hence, we build a "Large Concept Model". In this study, as
proof of feasibility, we assume that a concept corresponds to a sentence, and
use an existing sentence embedding space, SONAR, which supports up to 200
languages in both text and speech modalities.
  The Large Concept Model is trained to perform autoregressive sentence
prediction in an embedding space. We explore multiple approaches, namely MSE
regression, variants of diffusion-based generation, and models operating in a
**quantize**d SONAR space. These explorations are performed using 1.6B parameter
models and training data in the order of 1.3T tokens. We then scale one
architecture to a model size of 7B parameters and training data of about 2.7T
tokens. We perform an experimental evaluation on several generative tasks,
namely summarization and a new task of summary expansion. Finally, we show that
our model exhibits impressive zero-shot generalization performance to many
languages, outperforming existing LLMs of the same size. The training code of
our models is freely available.


## GPD-1 Generative Pre-training for Driving

>Authors: Zixun Xie, Sicheng Zuo, Wenzhao Zheng, Yunpeng Zhang, Dalong Du, Jie Zhou, Jiwen Lu, Shanghang Zhang

>2024-12-11

> http://arxiv.org/abs/2412.08643v1

Modeling the evolutions of driving scenarios is important for the evaluation
and decision-making of autonomous driving systems. Most existing methods focus
on one aspect of scene evolution such as map generation, motion prediction, and
trajectory planning. In this paper, we propose a unified Generative
Pre-training for Driving (GPD-1) model to accomplish all these tasks altogether
without additional fine-tuning. We represent each scene with ego, agent, and
map tokens and formulate autonomous driving as a unified token generation
problem. We adopt the autoregressive transformer architecture and use a
scene-level attention mask to enable intra-scene bi-directional interactions.
For the ego and agent tokens, we propose a hierarchical positional tokenizer to
effectively encode both 2D positions and headings. For the map tokens, we train
a map vector-**quantize**d autoencoder to efficiently compress ego-centric semantic
maps into discrete tokens. We pre-train our GPD-1 on the large-scale nuPlan
dataset and conduct extensive experiments to evaluate its effectiveness. With
different prompts, our GPD-1 successfully generalizes to various tasks without
finetuning, including scene generation, traffic simulation, closed-loop
simulation, map prediction, and motion planning. Code:
https://github.com/wzzheng/GPD.


## Multimodal Latent Language Modeling with Next-Token Diffusion

>Authors: Yutao Sun, Hangbo Bao, Wenhui Wang, Zhiliang Peng, Li Dong, Shaohan Huang, Jianyong Wang, Furu Wei

>2024-12-11

> http://arxiv.org/abs/2412.08635v1

Multimodal generative models require a unified approach to handle both
discrete data (e.g., text and code) and continuous data (e.g., image, audio,
video). In this work, we propose Latent Language Modeling (LatentLM), which
seamlessly integrates continuous and discrete data using causal Transformers.
Specifically, we employ a variational autoencoder (VAE) to represent continuous
data as latent vectors and introduce next-token diffusion for autoregressive
generation of these vectors. Additionally, we develop $\sigma$-VAE to address
the challenges of variance collapse, which is crucial for autoregressive
modeling. Extensive experiments demonstrate the effectiveness of LatentLM
across various modalities. In image generation, LatentLM surpasses Diffusion
Transformers in both performance and scalability. When integrated into
multimodal large language models, LatentLM provides a general-purpose interface
that unifies multimodal generation and understanding. Experimental results show
that LatentLM achieves favorable performance compared to Transfusion and vector
**quantize**d models in the setting of scaling up training tokens. In
text-to-speech synthesis, LatentLM outperforms the state-of-the-art VALL-E 2
model in speaker similarity and robustness, while requiring 10x fewer decoding
steps. The results establish LatentLM as a highly effective and scalable
approach to advance large multimodal models.


## Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models

>Authors: Jiahui Li, Yongchang Hao, Haoyu Xu, Xing Wang, Yu Hong

>2024-12-11

> http://arxiv.org/abs/2412.08615v2

Despite the advancements in training Large Language Models (LLMs) with
alignment techniques to enhance the safety of generated content, these models
remain susceptible to jailbreak, an adversarial attack method that exposes
security vulnerabilities in LLMs. Notably, the Greedy Coordinate Gradient (GCG)
method has demonstrated the ability to automatically generate adversarial
suffixes that jailbreak state-of-the-art LLMs. However, the optimization
process involved in GCG is highly time-consuming, rendering the jailbreaking
pipeline inefficient. In this paper, we investigate the process of GCG and
identify an issue of Indirect Effect, the key bottleneck of the GCG
optimization. To this end, we propose the Model Attack Gradient Index GCG
(MAGIC), that addresses the Indirect Effect by exploiting the gradient
information of the suffix tokens, thereby accelerating the procedure by having
less computation and fewer iterations. Our experiments on AdvBench show that
MAGIC achieves up to a 1.5x speedup, while maintaining Attack Success Rates
(ASR) on par or even higher than other baselines. Our MAGIC achieved an ASR of
74% on the Llama-2 and an ASR of 54% when conducting transfer attacks on
GPT-3.5. Code is available at https://github.com/jiah-li/magic.


## TurboAttention Efficient Attention Approximation For High Throughputs LLMs

>Authors: Hao Kang, Srikant Bharadwaj, James Hensman, Tushar Krishna, Victor Ruhle, Saravan Rajmohan

>2024-12-11

> http://arxiv.org/abs/2412.08585v3

Large language model (LLM) inference demands significant amount of
computation and memory, especially in the key attention mechanism. While
techniques, such as **quantization** and **acceleration** algorithms, like
FlashAttention, have improved efficiency of the overall inference, they address
different aspects of the problem: **quantization** focuses on weight-activation
operations, while FlashAttention improves execution but requires high-precision
formats. Recent Key-value (**KV**) cache **quantization** reduces memory bandwidth but
still needs floating-point de**quantization** for attention operation.
  We present TurboAttention, a comprehensive approach to enable **quantize**d
execution of attention that simultaneously addresses both memory and
computational efficiency. Our solution introduces two key innovations: FlashQ,
a headwise attention **quantization** technique that enables both compression of **KV**
cache and **quantize**d execution of activation-activation multiplication, and
Sparsity-based Softmax Approximation (SAS), which eliminates the need for
de**quantization** to FP32 during exponentiation operation in attention.
Experimental results demonstrate that TurboAttention achieves 1.2-1.8x speedup
in attention, reduces the **KV** cache size by over 4.4x, and enables up to 2.37x
maximum throughput over the FP16 baseline while outperforming state-of-the-art
**quantization** and compression techniques across various datasets and models.


## Sparse Signature Coefficient Recovery via Kernels

>Authors: Daniil Shmelev, Cristopher Salvi

>2024-12-11

> http://arxiv.org/abs/2412.08579v2

Central to rough path theory is the signature transform of a path, an
infinite series of tensors given by the iterated integrals of the underlying
path. The signature poses an effective way to capture sequentially ordered
information, thanks both to its rich analytic and algebraic properties as well
as its universality when used as a basis to approximate functions on path
space. Whilst a truncated version of the signature can be efficiently computed
using Chen's identity, there is a lack of efficient methods for computing a
**sparse** collection of iterated integrals contained in high levels of the
signature. We address this problem by leveraging signature kernels, defined as
the inner product of two signatures, and computable efficiently by means of
PDE-based methods. By forming a filter in signature space with which to take
kernels, one can effectively isolate specific groups of signature coefficients
and, in particular, a singular coefficient at any depth of the transform. We
show that such a filter can be expressed as a linear combination of suitable
signature transforms and demonstrate empirically the effectiveness of our
approach. To conclude, we give an example use case for **sparse** collections of
signature coefficients based on the construction of N-step Euler schemes for
**sparse** CDEs.


## EMS Adaptive Evict-then-Merge Strategy for Head-wise KV Cache Compression Based on Global-Local Importance

>Authors: Yingxin Li, Ye Li, Yuan Meng, Xinzhu Ma, Zihan Geng, Shutao Xia, Zhi Wang

>2024-12-11

> http://arxiv.org/abs/2412.08521v1

As large language models (LLMs) continue to advance, the demand for higher
quality and faster processing of long contexts across various applications is
growing. **KV** cache is widely adopted as it stores previously generated key and
value tokens, effectively reducing redundant computations during inference.
However, as memory overhead becomes a significant concern, efficient
compression of **KV** cache has gained increasing attention. Most existing methods
perform compression from two perspectives: identifying important tokens and
designing compression strategies. However, these approaches often produce
biased distributions of important tokens due to the influence of accumulated
attention scores or positional encoding. Furthermore, they overlook the
**sparsity** and redundancy across different heads, which leads to difficulties in
preserving the most effective information at the head level. To this end, we
propose EMS to overcome these limitations, while achieving better **KV** cache
compression under extreme compression ratios. Specifically, we introduce a
Global-Local score that combines accumulated attention scores from both global
and local **KV** tokens to better identify the token importance. For the
compression strategy, we design an adaptive and unified Evict-then-Merge
framework that accounts for the **sparsity** and redundancy of **KV** tokens across
different heads. Additionally, we implement the head-wise parallel compression
through a zero-class mechanism to enhance efficiency. Extensive experiments
demonstrate our SOTA performance even under extreme compression ratios. EMS
consistently achieves the lowest perplexity, improves scores by over 1.28
points across four LLMs on LongBench under a 256 cache budget, and preserves
95% retrieval accuracy with a cache budget less than 2% of the context length
in the Needle-in-a-Haystack task.


## AltFS Agency-light Feature Selection with Large Language Models in Deep Recommender Systems

>Authors: Pengyue Jia, Zhaocheng Du, Yichao Wang, Xiangyu Zhao, Xiaopeng Li, Yuhao Wang, Qidong Liu, Huifeng Guo, Ruiming Tang

>2024-12-11

> http://arxiv.org/abs/2412.08516v1

Feature selection is crucial in recommender systems for improving model
efficiency and predictive performance. Traditional methods rely on agency
models, such as decision trees or neural networks, to estimate feature
importance. However, this approach is inherently limited, as the agency models
may fail to learn effectively in all scenarios due to suboptimal training
conditions (e.g., feature collinearity, high-dimensional **sparsity**, and data
insufficiency). In this paper, we propose AltFS, an Agency-light Feature
Selection method for deep recommender systems. AltFS integrates semantic
reasoning from Large Language Models (LLMs) with task-specific learning from
agency models. Initially, LLMs will generate a semantic ranking of feature
importance, which is then refined by an agency model, combining world knowledge
with task-specific insights. Extensive experiments on three public datasets
from real-world recommender platforms demonstrate the effectiveness of AltFS.
Our code is publicly available for reproducibility.


## PointCFormer a Relation-based Progressive Feature Extraction Network for Point Cloud Completion

>Authors: Yi Zhong, Weize Quan, Dong-ming Yan, Jie Jiang, Yingmei Wei

>2024-12-11

> http://arxiv.org/abs/2412.08421v2

Point cloud completion aims to reconstruct the complete 3D shape from
incomplete point clouds, and it is crucial for tasks such as 3D object
detection and segmentation. Despite the continuous advances in point cloud
analysis techniques, feature extraction methods are still confronted with
apparent limitations. The **sparse** sampling of point clouds, used as inputs in
most methods, often results in a certain loss of global structure information.
Meanwhile, traditional local feature extraction methods usually struggle to
capture the intricate geometric details. To overcome these drawbacks, we
introduce PointCFormer, a transformer framework optimized for robust global
retention and precise local detail capture in point cloud completion. This
framework embraces several key advantages. First, we propose a relation-based
local feature extraction method to perceive local delicate geometry
characteristics. This approach establishes a fine-grained relationship metric
between the target point and its k-nearest neighbors, quantifying each
neighboring point's contribution to the target point's local features.
Secondly, we introduce a progressive feature extractor that integrates our
local feature perception method with self-attention. Starting with a denser
sampling of points as input, it iteratively queries long-distance global
dependencies and local neighborhood relationships. This extractor maintains
enhanced global structure and refined local details, without generating
substantial computational overhead. Additionally, we develop a correction
module after generating point proxies in the latent space to reintroduce denser
information from the input points, enhancing the representation capability of
the point proxies. PointCFormer demonstrates state-of-the-art performance on
several widely used benchmarks. Our code is available at
https://github.com/Zyyyyy0926/PointCFormer_Plus_Pytorch.


## SweetTokenizer Semantic-Aware Spatial-Temporal Tokenizer for Compact Visual Discretization

>Authors: Zhentao Tan, Ben Xue, Jian Jia, Junhao Wang, Wencai Ye, Shaoyun Shi, Mingjie Sun, Wenjin Wu, Quan Chen, Peng Jiang

>2024-12-11

> http://arxiv.org/abs/2412.10443v2

This paper presents the \textbf{S}emantic-a\textbf{W}ar\textbf{E}
spatial-t\textbf{E}mporal \textbf{T}okenizer (SweetTokenizer), a compact yet
effective discretization approach for vision data. Our goal is to boost
tokenizers' compression ratio while maintaining reconstruction fidelity in the
VQ-VAE paradigm. Firstly, to obtain compact latent representations, we decouple
images or videos into spatial-temporal dimensions, translating visual
information into learnable querying spatial and temporal tokens through a
\textbf{C}ross-attention \textbf{Q}uery \textbf{A}uto\textbf{E}ncoder (CQAE).
Secondly, to complement visual information during compression, we **quantize**
these tokens via a specialized codebook derived from off-the-shelf LLM
embeddings to leverage the rich semantics from language modality. Finally, to
enhance training stability and convergence, we also introduce a curriculum
learning strategy, which proves critical for effective discrete visual
representation learning. SweetTokenizer achieves comparable video
reconstruction fidelity with only \textbf{25\%} of the tokens used in previous
state-of-the-art video tokenizers, and boost video generation results by
\textbf{32.9\%} w.r.t gFVD. When using the same token number, we significantly
improves video and image reconstruction results by \textbf{57.1\%} w.r.t rFVD
on UCF-101 and \textbf{37.2\%} w.r.t rFID on ImageNet-1K. Additionally, the
compressed tokens are imbued with semantic information, enabling few-shot
recognition capabilities powered by LLMs in downstream applications.


## GN-FRGeneralizable Neural Radiance Fields for Flare Removal

>Authors: Gopi Raju Matta, Rahul Siddartha, Rongali Simhachala Venkata Girish, Sumit Sharma, Kaushik Mitra

>2024-12-11

> http://arxiv.org/abs/2412.08200v1

Flare, an optical phenomenon resulting from unwanted scattering and
reflections within a lens system, presents a significant challenge in imaging.
The diverse patterns of flares, such as halos, streaks, color bleeding, and
haze, complicate the flare removal process. Existing traditional and
learning-based methods have exhibited limited efficacy due to their reliance on
single-image approaches, where flare removal is highly ill-posed. We address
this by framing flare removal as a multi-view image problem, taking advantage
of the view-dependent nature of flare artifacts. This approach leverages
information from neighboring views to recover details obscured by flare in
individual images. Our proposed framework, GN-FR (Generalizable Neural Radiance
Fields for Flare Removal), can render flare-free views from a **sparse** set of
input images affected by lens flare and generalizes across different scenes in
an unsupervised manner. GN-FR incorporates several modules within the
Generalizable NeRF Transformer (GNT) framework: Flare-occupancy Mask Generation
(FMG), View Sampler (VS), and Point Sampler (PS). To overcome the
impracticality of capturing both flare-corrupted and flare-free data, we
introduce a masking loss function that utilizes mask information in an
unsupervised setting. Additionally, we present a 3D multi-view flare dataset,
comprising 17 real flare scenes with 782 images, 80 real flare patterns, and
their corresponding annotated flare-occupancy masks. To our knowledge, this is
the first work to address flare removal within a Neural Radiance Fields (NeRF)
framework.


## Breaking the Bias Recalibrating the Attention of Industrial Anomaly Detection

>Authors: Xin Chen, Liujuan Cao, Shengchuan Zhang, Xiewu Zheng, Yan Zhang

>2024-12-11

> http://arxiv.org/abs/2412.08189v1

Due to the scarcity and unpredictable nature of defect samples, industrial
anomaly detection (IAD) predominantly employs unsupervised learning. However,
all unsupervised IAD methods face a common challenge: the inherent bias in
normal samples, which causes models to focus on variable regions while
overlooking potential defects in invariant areas. To effectively overcome this,
it is essential to decompose and recalibrate attention, guiding the model to
suppress irrelevant variations and concentrate on subtle, defect-susceptible
areas. In this paper, we propose Recalibrating Attention of Industrial Anomaly
Detection (RAAD), a framework that systematically decomposes and recalibrates
attention maps. RAAD employs a two-stage process: first, it reduces attention
bias through **quantization**, and second, it fine-tunes defect-prone regions for
improved sensitivity. Central to this framework is Hierarchical Quantization
Scoring (HQS), which dynamically allocates bit-widths across layers based on
their anomaly detection contributions. HQS dynamically adjusts bit-widths based
on the hierarchical nature of attention maps, compressing lower layers that
produce coarse and noisy attention while preserving deeper layers with sharper,
defect-focused attention. This approach optimizes both computational efficiency
and the model' s sensitivity to anomalies. We validate the effectiveness of
RAAD on 32 datasets using a single 3090ti. Experiments demonstrate that RAAD,
balances the complexity and expressive power of the model, enhancing its
anomaly detection capability.


## LatentSpeech Latent Diffusion for Text-To-Speech Generation

>Authors: Haowei Lou, Helen Paik, Pari Delir Haghighi, Wen Hu, Lina Yao

>2024-12-11

> http://arxiv.org/abs/2412.08117v1

Diffusion-based Generative AI gains significant attention for its superior
performance over other generative techniques like Generative Adversarial
Networks and Variational Autoencoders. While it has achieved notable
advancements in fields such as computer vision and natural language processing,
their application in speech generation remains under-explored. Mainstream
Text-to-Speech systems primarily map outputs to Mel-Spectrograms in the
spectral space, leading to high computational loads due to the **sparsity** of
MelSpecs. To address these limitations, we propose LatentSpeech, a novel TTS
generation approach utilizing latent diffusion models. By using latent
embeddings as the intermediate representation, LatentSpeech reduces the target
dimension to 5% of what is required for MelSpecs, simplifying the processing
for the TTS encoder and vocoder and enabling efficient high-quality speech
generation. This study marks the first integration of latent diffusion models
in TTS, enhancing the accuracy and naturalness of generated speech.
Experimental results on benchmark datasets demonstrate that LatentSpeech
achieves a 25% improvement in Word Error Rate and a 24% improvement in Mel
Cepstral Distortion compared to existing models, with further improvements
rising to 49.5% and 26%, respectively, with additional training data. These
findings highlight the potential of LatentSpeech to advance the
state-of-the-art in TTS technology


## A Deep Semantic Segmentation Network with Semantic and Contextual Refinements

>Authors: Zhiyan Wang, Deyin Liu, Lin Yuanbo Wu, Song Wang, Xin Guo, Lin Qi

>2024-12-11

> http://arxiv.org/abs/2412.08671v1

Semantic segmentation is a fundamental task in multimedia processing, which
can be used for analyzing, understanding, editing contents of images and
videos, among others. To accelerate the analysis of multimedia data, existing
segmentation researches tend to extract semantic information by progressively
reducing the spatial resolutions of feature maps. However, this approach
introduces a misalignment problem when restoring the resolution of high-level
feature maps. In this paper, we design a Semantic Refinement Module (SRM) to
address this issue within the segmentation network. Specifically, SRM is
designed to learn a transformation offset for each pixel in the upsampled
feature maps, guided by high-resolution feature maps and neighboring offsets.
By applying these offsets to the upsampled feature maps, SRM enhances the
semantic representation of the segmentation network, particularly for pixels
around object boundaries. Furthermore, a Contextual Refinement Module (CRM) is
presented to capture global context information across both spatial and channel
dimensions. To balance dimensions between channel and space, we aggregate the
semantic maps from all four stages of the backbone to enrich channel context
information. The efficacy of these proposed modules is validated on three
widely used datasets-Cityscapes, Bdd100K, and ADE20K-demonstrating superior
performance compared to state-of-the-art methods. Additionally, this paper
extends these modules to a lightweight segmentation network, achieving an mIoU
of 82.5% on the Cityscapes validation set with only 137.9 GFLOPs.


## Static-Dynamic Class-level Perception Consistency in Video Semantic Segmentation

>Authors: Zhigang Cen, Ningyan Guo, Wenjing Xu, Zhiyong Feng, Danlan Huang

>2024-12-11

> http://arxiv.org/abs/2412.08034v1

Video semantic segmentation(VSS) has been widely employed in lots of fields,
such as simultaneous localization and mapping, autonomous driving and
surveillance. Its core challenge is how to leverage temporal information to
achieve better segmentation. Previous efforts have primarily focused on
pixel-level static-dynamic contexts matching, utilizing techniques such as
optical flow and attention mechanisms. Instead, this paper rethinks
static-dynamic contexts at the class level and proposes a novel static-dynamic
class-level perceptual consistency (SD-CPC) framework. In this framework, we
propose multivariate class prototype with contrastive learning and a
static-dynamic semantic alignment module. The former provides class-level
constraints for the model, obtaining personalized inter-class features and
diversified intra-class features. The latter first establishes intra-frame
spatial multi-scale and multi-level correlations to achieve static semantic
alignment. Then, based on cross-frame static perceptual differences, it
performs two-stage cross-frame selective aggregation to achieve dynamic
semantic alignment. Meanwhile, we propose a window-based attention map
calculation method that leverages the **sparsity** of attention points during
cross-frame aggregation to reduce computation cost. Extensive experiments on
VSPW and Cityscapes datasets show that the proposed approach outperforms
state-of-the-art methods. Our implementation will be open-sourced on GitHub.


## PAFFA Premeditated Actions For Fast Agents

>Authors: Shambhavi Krishna, Zheng Chen, Vaibhav Kumar, Xiaojiang Huang, Yingjie Li, Fan Yang, Xiang Li

>2024-12-10

> http://arxiv.org/abs/2412.07958v1

Modern AI assistants have made significant progress in natural language
understanding and API/tool integration, with emerging efforts to incorporate
diverse interfaces (such as Web interfaces) for enhanced scalability and
functionality. However, current approaches that heavily rely on repeated
LLM-driven HTML parsing are computationally expensive and error-prone,
particularly when handling dynamic web interfaces and multi-step tasks. To
overcome these challenges, we introduce PAFFA (Premeditated Actions For Fast
Agents), a framework designed to enhance web interaction capabilities through
an Action API Library of reusable, verified browser interaction functions. By
pre-computing interaction patterns and employing two core methodologies -
"Dist-Map" for task-agnostic element distillation and "Unravel" for incremental
page-wise exploration - PAFFA reduces inference calls by 87% while maintaining
robust performance even as website structures evolve. This framework
accelerates multi-page task execution and offers a scalable solution to advance
autonomous web agent research.


## MOFHEI Model Optimizing Framework for Fast and Efficient Homomorphically Encrypted Neural Network Inference

>Authors: Parsa Ghazvinian, Robert Podschwadt, Prajwal Panzade, Mohammad H. Rafiei, Daniel Takabi

>2024-12-10

> http://arxiv.org/abs/2412.07954v1

Due to the extensive application of machine learning (ML) in a wide range of
fields and the necessity of data privacy, privacy-preserving machine learning
(PPML) solutions have recently gained significant traction. One group of
approaches relies on Homomorphic Encryption (HE), which enables us to perform
ML tasks over encrypted data. However, even with state-of-the-art HE schemes,
HE operations are still significantly slower compared to their plaintext
counterparts and require a considerable amount of memory. Therefore, we propose
MOFHEI, a framework that optimizes the model to make HE-based neural network
inference, referred to as private inference (PI), fast and efficient. First,
our proposed learning-based method automatically transforms a pre-trained ML
model into its compatible version with HE operations, called the HE-friendly
version. Then, our iterative block **pruning** method prunes the model's parameters
in configurable block shapes in alignment with the data packing method. This
allows us to drop a significant number of costly HE operations, thereby
reducing the latency and memory consumption while maintaining the model's
performance. We evaluate our framework through extensive experiments on
different models using various datasets. Our method achieves up to 98% **pruning**
ratio on LeNet, eliminating up to 93% of the required HE operations for
performing PI, reducing latency and the required memory by factors of 9.63 and
4.04, respectively, with negligible accuracy loss.


## GPT-2 Through the Lens of Vector Symbolic Architectures

>Authors: Johannes Knittel, Tushaar Gangavarapu, Hendrik Strobelt, Hanspeter Pfister

>2024-12-10

> http://arxiv.org/abs/2412.07947v1

Understanding the general priniciples behind transformer models remains a
complex endeavor. Experiments with probing and disentangling features using
**sparse** autoencoders (SAE) suggest that these models might manage linear
features embedded as directions in the residual stream. This paper explores the
resemblance between decoder-only transformer architecture and vector symbolic
architectures (VSA) and presents experiments indicating that GPT-2 uses
mechanisms involving nearly orthogonal vector bundling and binding operations
similar to VSA for computation and communication between layers. It further
shows that these principles help explain a significant portion of the actual
neural weights.


## Low-Rank Correction for Quantized LLMs

>Authors: Meyer Scetbon, James Hensman

>2024-12-10

> http://arxiv.org/abs/2412.07902v1

We consider the problem of model compression for Large Language Models (LLMs)
at post-training time, where the task is to compress a well-trained model using
only a small set of calibration input data. In this work, we introduce a new
low-rank approach to correct for **quantization** errors of \emph{activations} in
LLMs: we propose to add low-rank weight matrices in full precision that act on
the \emph{un**quantize**d} activations. We then solve a joint optimization problem
over the **quantize**d representation of the weights and additional low-rank weight
matrices to **quantize** both weights and activations. We focus on the case of
4-bit weight-and-activation **quantization** (W4A4). Using ranks equivalent to 10\%
of the original weight matrix size, our approach reduces the accuracy gap with
the original model by more than 50\%. Using ranks equivalent to 30\% of the
original weight matrix, the accuracy gap is closed completely. We demonstrate
our results on four recent LLMs, namely Llama-2, Llama-3, Phi-3 and Mixtral
models.


## From Slow Bidirectional to Fast Causal Video Generators

>Authors: Tianwei Yin, Qiang Zhang, Richard Zhang, William T. Freeman, Fredo Durand, Eli Shechtman, Xun Huang

>2024-12-10

> http://arxiv.org/abs/2412.07772v1

Current video diffusion models achieve impressive generation quality but
struggle in interactive applications due to bidirectional attention
dependencies. The generation of a single frame requires the model to process
the entire sequence, including the future. We address this limitation by
adapting a pretrained bidirectional diffusion transformer to a causal
transformer that generates frames on-the-fly. To further reduce latency, we
extend distribution matching distillation (DMD) to videos, distilling 50-step
diffusion model into a 4-step generator. To enable stable and high-quality
distillation, we introduce a student initialization scheme based on teacher's
ODE trajectories, as well as an asymmetric distillation strategy that
supervises a causal student model with a bidirectional teacher. This approach
effectively mitigates error accumulation in autoregressive generation, allowing
long-duration video synthesis despite training on short clips. Our model
supports fast streaming generation of high quality videos at 9.4 FPS on a
single GPU thanks to **KV** caching. Our approach also enables streaming
video-to-video translation, image-to-video, and dynamic prompting in a
zero-shot manner. We will release the code based on an open-source model in the
future.


## STIV Scalable Text and Image Conditioned Video Generation

>Authors: Zongyu Lin, Wei Liu, Chen Chen, Jiasen Lu, Wenze Hu, Tsu-Jui Fu, Jesse Allardice, Zhengfeng Lai, Liangchen Song, Bowen Zhang, Cha Chen, Yiran Fei, Yifan Jiang, Lezhi Li, Yizhou Sun, Kai-Wei Chang, Yinfei Yang

>2024-12-10

> http://arxiv.org/abs/2412.07730v1

The field of video generation has made remarkable advancements, yet there
remains a pressing need for a clear, systematic recipe that can guide the
development of robust and scalable models. In this work, we present a
comprehensive study that systematically explores the interplay of model
architectures, training recipes, and data curation strategies, culminating in a
simple and scalable text-image-conditioned video generation method, named STIV.
Our framework integrates image condition into a Diffusion Transformer (DiT)
through frame replacement, while incorporating text conditioning via a joint
image-text conditional classifier-free guidance. This design enables STIV to
perform both text-to-video (T2V) and text-image-to-video (TI2V) tasks
simultaneously. Additionally, STIV can be easily extended to various
applications, such as video prediction, frame interpolation, multi-view
generation, and long video generation, etc. With comprehensive ablation studies
on T2I, T2V, and TI2V, STIV demonstrate strong performance, despite its simple
design. An 8.7B model with 512 resolution achieves 83.1 on VBench T2V,
surpassing both leading open and closed-source models like CogVideoX-5B, Pika,
Kling, and Gen-3. The same-sized model also achieves a state-of-the-art result
of 90.1 on VBench I2V task at 512 resolution. By providing a transparent and
extensible recipe for building cutting-edge video generation models, we aim to
empower future research and accelerate progress toward more versatile and
reliable video generation solutions.


## ACDiT Interpolating Autoregressive Conditional Modeling and Diffusion Transformer

>Authors: Jinyi Hu, Shengding Hu, Yuxuan Song, Yufei Huang, Mingxuan Wang, Hao Zhou, Zhiyuan Liu, Wei-Ying Ma, Maosong Sun

>2024-12-10

> http://arxiv.org/abs/2412.07720v1

The recent surge of interest in comprehensive multimodal models has
necessitated the unification of diverse modalities. However, the unification
suffers from disparate methodologies. Continuous visual generation necessitates
the full-sequence diffusion-based approach, despite its divergence from the
autoregressive modeling in the text domain. We posit that autoregressive
modeling, i.e., predicting the future based on past deterministic experience,
remains crucial in developing both a visual generation model and a potential
unified multimodal model. In this paper, we explore an interpolation between
the autoregressive modeling and full-parameters diffusion to model visual
information. At its core, we present ACDiT, an Autoregressive blockwise
Conditional Diffusion Transformer, where the block size of diffusion, i.e., the
size of autoregressive units, can be flexibly adjusted to interpolate between
token-wise autoregression and full-sequence diffusion. ACDiT is easy to
implement, as simple as creating a Skip-Causal Attention Mask (SCAM) during
training. During inference, the process iterates between diffusion denoising
and autoregressive decoding that can make full use of **KV**-Cache. We verify the
effectiveness of ACDiT on image and video generation tasks. We also demonstrate
that benefitted from autoregressive modeling, ACDiT can be seamlessly used in
visual understanding tasks despite being trained on the diffusion objective.
The analysis of the trade-off between autoregressive modeling and diffusion
demonstrates the potential of ACDiT to be used in long-horizon visual
generation tasks. These strengths make it promising as the backbone of future
unified models.


## Automating Business Intelligence Requirements with Generative AI and Semantic Search

>Authors: Nimrod Busany, Ethan Hadar, Hananel Hadad, Gil Rosenblum, Zofia Maszlanka, Okhaide Akhigbe, Daniel Amyot

>2024-12-10

> http://arxiv.org/abs/2412.07668v1

Eliciting requirements for Business Intelligence (BI) systems remains a
significant challenge, particularly in changing business environments. This
paper introduces a novel AI-driven system, called AutoBIR, that leverages
semantic search and Large Language Models (LLMs) to automate and accelerate the
specification of BI requirements. The system facilitates intuitive interaction
with stakeholders through a conversational interface, translating user inputs
into prototype analytic code, descriptions, and data dependencies.
Additionally, AutoBIR produces detailed test-case reports, optionally enhanced
with visual aids, streamlining the requirement elicitation process. By
incorporating user feedback, the system refines BI reporting and system design,
demonstrating practical applications for expediting data-driven
decision-making. This paper explores the broader potential of generative AI in
transforming BI development, illustrating its role in enhancing data
engineering practice for large-scale, evolving systems.


## Spatio-temporal Latent Representations for the Analysis of Acoustic Scenes in-the-wild

>Authors: Claudia Montero-Ramírez, Esther Rituerto-González, Carmen Peláez-Moreno

>2024-12-10

> http://arxiv.org/abs/2412.07648v1

In the field of acoustic scene analysis, this paper presents a novel approach
to find spatio-temporal latent representations from in-the-wild audio data. By
using WE-LIVE, an in-house collected dataset that includes audio recordings in
diverse real-world environments together with **sparse** GPS coordinates,
self-annotated emotional and situational labels, we tackle the challenging task
of associating each audio segment with its corresponding location as a pretext
task, with the final aim of acoustically detecting violent (anomalous)
contexts, left as further work. By generating acoustic embeddings and using the
self-supervised learning paradigm, we aim to use the model-generated latent
space to acoustically characterize the spatio-temporal context. We use YAMNet,
an acoustic events classifier trained in AudioSet to temporally locate and
identify acoustic events in WE-LIVE. In order to transform the discrete
acoustic events into embeddings, we compare the information-retrieval-based
TF-IDF algorithm and Node2Vec as an analogy to Natural Language Processing
techniques. A VAE is then trained to provide a further adapted latent space.
The analysis was carried out by measuring the cosine distance and visualizing
data distribution via t-Distributed Stochastic Neighbor Embedding, revealing
distinct acoustic scenes. Specifically, we discern variations between indoor
and subway environments. Notably, these distinctions emerge within the latent
space of the VAE, a stark contrast to the random distribution of data points
before encoding. In summary, our research contributes a pioneering approach for
extracting spatio-temporal latent representations from in-the-wild audio data.


## PTSBench A Comprehensive Post-Training Sparsity Benchmark Towards Algorithms and Models

>Authors: Zining Wnag, Jinyang Guo, Ruihao Gong, Yang Yong, Aishan Liu, Yushi Huang, Jiaheng Liu, Xianglong Liu

>2024-12-10

> http://arxiv.org/abs/2412.07268v1

With the increased attention to model efficiency, post-training **sparsity**
(PTS) has become more and more prevalent because of its effectiveness and
efficiency. However, there remain questions on better practice of PTS
algorithms and the sparsification ability of models, which hinders the further
development of this area. Therefore, a benchmark to comprehensively investigate
the issues above is urgently needed. In this paper, we propose the first
comprehensive post-training **sparsity** benchmark called PTSBench towards
algorithms and models. We benchmark 10+ PTS general-pluggable fine-grained
techniques on 3 typical tasks using over 40 off-the-shelf model architectures.
Through extensive experiments and analyses, we obtain valuable conclusions and
provide several insights from both algorithms and model aspects. Our PTSBench
can provide (1) new observations for a better understanding of the PTS
algorithms, (2) in-depth and comprehensive evaluations for the sparsification
ability of models, and (3) a well-structured and easy-integrate open-source
framework. We hope this work will provide illuminating conclusions and advice
for future studies of post-training **sparsity** methods and
sparsification-friendly model design. The code for our PTSBench is released at
\href{https://github.com/ModelTC/msbench}{https://github.com/ModelTC/msbench}.


## Modeling High-Resolution Spatio-Temporal Wind with Deep Echo State Networks and Stochastic Partial Differential Equations

>Authors: Kesen Wang, Minwoo Kim, Stefano Castruccio, Marc G. Genton

>2024-12-10

> http://arxiv.org/abs/2412.07265v1

In the past decades, clean and renewable energy has gained increasing
attention due to a global effort on carbon footprint reduction. In particular,
Saudi Arabia is gradually shifting its energy portfolio from an exclusive use
of oil to a reliance on renewable energy, and, in particular, wind. Modeling
wind for assessing potential energy output in a country as large,
geographically diverse and understudied as Saudi Arabia is a challenge which
implies highly non-linear dynamic structures in both space and time. To address
this, we propose a spatio-temporal model whose spatial information is first
reduced via an energy distance-based approach and then its dynamical behavior
is informed by a **sparse** and stochastic recurrent neural network (Echo State
Network). Finally, the full spatial data is reconstructed by means of a
non-stationary stochastic partial differential equation-based approach. Our
model can capture the fine scale wind structure and produce more accurate
forecasts of both wind speed and energy in lead times of interest for energy
grid management and save annually as much as one million dollar against the
closest competitive model.


## QuantFormer Learning to Quantize for Neural Activity Forecasting in Mouse Visual Cortex

>Authors: Salvatore Calcagno, Isaak Kavasidis, Simone Palazzo, Marco Brondi, Luca Sità, Giacomo Turri, Daniela Giordano, Vladimir R. Kostic, Tommaso Fellin, Massimiliano Pontil, Concetto Spampinato

>2024-12-10

> http://arxiv.org/abs/2412.07264v1

Understanding complex animal behaviors hinges on deciphering the neural
activity patterns within brain circuits, making the ability to forecast neural
activity crucial for developing predictive models of brain dynamics. This
capability holds immense value for neuroscience, particularly in applications
such as real-time optogenetic interventions. While traditional encoding and
decoding methods have been used to map external variables to neural activity
and vice versa, they focus on interpreting past data. In contrast, neural
forecasting aims to predict future neural activity, presenting a unique and
challenging task due to the spatiotemporal **sparsity** and complex dependencies of
neural signals. Existing transformer-based forecasting methods, while effective
in many domains, struggle to capture the distinctiveness of neural signals
characterized by spatiotemporal **sparsity** and intricate dependencies. To address
this challenge, we here introduce QuantFormer, a transformer-based model
specifically designed for forecasting neural activity from two-photon calcium
imaging data. Unlike conventional regression-based approaches,
QuantFormerreframes the forecasting task as a classification problem via
dynamic signal **quantization**, enabling more effective learning of **sparse** neural
activation patterns. Additionally, QuantFormer tackles the challenge of
analyzing multivariate signals from an arbitrary number of neurons by
incorporating neuron-specific tokens, allowing scalability across diverse
neuronal populations. Trained with unsupervised **quantization** on the Allen
dataset, QuantFormer sets a new benchmark in forecasting mouse visual cortex
activity. It demonstrates robust performance and generalization across various
stimuli and individuals, paving the way for a foundational model in neural
signal prediction.


## A Dynamical Systems-Inspired Pruning Strategy for Addressing Oversmoothing in Graph Neural Networks

>Authors: Biswadeep Chakraborty, Harshit Kumar, Saibal Mukhopadhyay

>2024-12-10

> http://arxiv.org/abs/2412.07243v1

Oversmoothing in Graph Neural Networks (GNNs) poses a significant challenge
as network depth increases, leading to homogenized node representations and a
loss of expressiveness. In this work, we approach the oversmoothing problem
from a dynamical systems perspective, providing a deeper understanding of the
stability and convergence behavior of GNNs. Leveraging insights from dynamical
systems theory, we identify the root causes of oversmoothing and propose
\textbf{\textit{DYNAMO-GAT}}. This approach utilizes noise-driven covariance
analysis and Anti-Hebbian principles to selectively prune redundant attention
weights, dynamically adjusting the network's behavior to maintain node feature
diversity and stability. Our theoretical analysis reveals how DYNAMO-GAT
disrupts the convergence to oversmoothed states, while experimental results on
benchmark datasets demonstrate its superior performance and efficiency compared
to traditional and state-of-the-art methods. DYNAMO-GAT not only advances the
theoretical understanding of oversmoothing through the lens of dynamical
systems but also provides a practical and effective solution for improving the
stability and expressiveness of deep GNNs.


## MAPLE A Framework for Active Preference Learning Guided by Large Language Models

>Authors: Saaduddin Mahmud, Mason Nakamura, Shlomo Zilberstein

>2024-12-10

> http://arxiv.org/abs/2412.07207v1

The advent of large language models (LLMs) has sparked significant interest
in using natural language for preference learning. However, existing methods
often suffer from high computational burdens, taxing human supervision, and
lack of interpretability. To address these issues, we introduce MAPLE, a
framework for large language model-guided Bayesian active preference learning.
MAPLE leverages LLMs to model the distribution over preference functions,
conditioning it on both natural language feedback and conventional preference
learning feedback, such as pairwise trajectory rankings. MAPLE also employs
active learning to systematically reduce uncertainty in this distribution and
incorporates a language-conditioned active query selection mechanism to
identify informative and easy-to-answer queries, thus reducing human burden. We
evaluate MAPLE's sample efficiency and preference inference quality across two
benchmarks, including a real-world vehicle route planning benchmark using
OpenStreetMap data. Our results demonstrate that MAPLE accelerates the learning
process and effectively improves humans' ability to answer queries.


## Post-Training Statistical Calibration for Higher Activation Sparsity

>Authors: Vui Seng Chua, Yujie Pan, Nilesh Jain

>2024-12-10

> http://arxiv.org/abs/2412.07174v1

We present Statistical Calibrated Activation Pruning (SCAP), a post-training
activation **pruning** framework that (1) generalizes sparsification by input
activations of Fully-Connected layers for generic and flexible application
across Transformers, and (2) features a simple Mode-Centering technique to
pre-calibrate activation distributions for maximizing post-training **sparsity**.
Our results demonstrate robust Pareto efficiency compared to prior methods,
translating to a 1.5x additional LLM decoding speedup against CATS at iso model
quality. SCAP effectiveness is empirically verified across a wide range of
models, including recent Transformer Decoders, MoE, Mamba2, Encoding
Transformer, and pre-**quantize**d models, highlighting its practicality and
scalability. The code is available at: https://github.com/IntelLabs/SCAP.


## MoE-CAP Cost-Accuracy-Performance Benchmarking for Mixture-of-Experts Systems

>Authors: Yao Fu, Yinsicheng Jiang, Yeqi Huang, Ping Nie, Zhan Lu, Leyang Xue, Congjie He, Man-Kit Sit, Jilong Xue, Li Dong, Ziming Miao, Kai Zou, Edoardo Ponti, Luo Mai

>2024-12-10

> http://arxiv.org/abs/2412.07067v1

The **sparse** Mixture-of-Experts (MoE) architecture is increasingly favored for
scaling Large Language Models (LLMs) efficiently; however, MoE systems rely on
heterogeneous compute and memory resources. These factors collectively
influence the system's Cost, Accuracy, and Performance (CAP), creating a
challenging trade-off. Current benchmarks often fail to provide precise
estimates of these effects, complicating practical considerations for deploying
MoE systems. To bridge this gap, we introduce MoE-CAP, a benchmark specifically
designed to evaluate MoE systems. Our findings highlight the difficulty of
achieving an optimal balance of cost, accuracy, and performance with existing
hardware capabilities. MoE systems often necessitate compromises on one factor
to optimize the other two, a dynamic we term the MoE-CAP trade-off. To identify
the best trade-off, we propose novel performance evaluation metrics - Sparse
Memory Bandwidth Utilization (S-MBU) and Sparse Model FLOPS Utilization (S-MFU)
- and develop cost models that account for the heterogeneous compute and memory
hardware integral to MoE systems. This benchmark is publicly available on
HuggingFace:
https://huggingface.co/spaces/**sparse**-generative-ai/open-moe-llm-leaderboard.


## Constrained Decoding with Speculative Lookaheads

>Authors: Nishanth Nakshatri, Shamik Roy, Rajarshi Das, Suthee Chaidaroon, Leonid Boytsov, Rashmi Gangadharaiah

>2024-12-09

> http://arxiv.org/abs/2412.10418v1

Constrained decoding with lookahead heuristics (CDLH) is a highly effective
method for aligning LLM generations to human preferences. However, the
extensive lookahead roll-out operations for each generated token makes CDLH
prohibitively expensive, resulting in low adoption in practice. In contrast,
common decoding strategies such as greedy decoding are extremely efficient, but
achieve very low constraint satisfaction. We propose constrained decoding with
speculative lookaheads (CDSL), a technique that significantly improves upon the
inference efficiency of CDLH without experiencing the drastic performance
reduction seen with greedy decoding. CDSL is motivated by the recently proposed
idea of speculative decoding that uses a much smaller draft LLM for generation
and a larger target LLM for verification. In CDSL, the draft model is used to
generate lookaheads which is verified by a combination of target LLM and
task-specific reward functions. This process accelerates decoding by reducing
the computational burden while maintaining strong performance. We evaluate CDSL
in two constraint decoding tasks with three LLM families and achieve 2.2x to
12.15x speedup over CDLH without significant performance reduction.


## Bridging Conversational and Collaborative Signals for Conversational Recommendation

>Authors: Ahmad Bin Rabiah, Nafis Sadeq, Julian McAuley

>2024-12-09

> http://arxiv.org/abs/2412.06949v1

Conversational recommendation systems (CRS) leverage contextual information
from conversations to generate recommendations but often struggle due to a lack
of collaborative filtering (CF) signals, which capture user-item interaction
patterns essential for accurate recommendations. We introduce Reddit-ML32M, a
dataset that links reddit conversations with interactions on MovieLens 32M, to
enrich item representations by leveraging collaborative knowledge and
addressing interaction **sparsity** in conversational datasets. We propose an
LLM-based framework that uses Reddit-ML32M to align LLM-generated
recommendations with CF embeddings, refining rankings for better performance.
We evaluate our framework against three sets of baselines: CF-based
recommenders using only interactions from CRS tasks, traditional CRS models,
and LLM-based methods relying on conversational context without item
representations. Our approach achieves consistent improvements, including a
12.32% increase in Hit Rate and a 9.9% improvement in NDCG, outperforming the
best-performing baseline that relies on conversational context but lacks
collaborative item representations.


## SafeWatch An Efficient Safety-Policy Following Video Guardrail Model with Transparent Explanations

>Authors: Zhaorun Chen, Francesco Pinto, Minzhou Pan, Bo Li

>2024-12-09

> http://arxiv.org/abs/2412.06878v1

With the rise of generative AI and rapid growth of high-quality video
generation, video guardrails have become more crucial than ever to ensure
safety and security across platforms. Current video guardrails, however, are
either overly simplistic, relying on pure classification models trained on
simple policies with limited unsafe categories, which lack detailed
explanations, or prompting multimodal large language models (MLLMs) with long
safety guidelines, which are inefficient and impractical for guardrailing
real-world content. To bridge this gap, we propose SafeWatch, an efficient
MLLM-based video guardrail model designed to follow customized safety policies
and provide multi-label video guardrail outputs with content-specific
explanations in a zero-shot manner. In particular, unlike traditional
MLLM-based guardrails that encode all safety policies autoregressively, causing
inefficiency and bias, SafeWatch uniquely encodes each policy chunk in parallel
and eliminates their position bias such that all policies are attended
simultaneously with equal importance. In addition, to improve efficiency and
accuracy, SafeWatch incorporates a policy-aware visual token **pruning** algorithm
that adaptively selects the most relevant video tokens for each policy,
discarding noisy or irrelevant information. This allows for more focused,
policy-compliant guardrail with significantly reduced computational overhead.
Considering the limitations of existing video guardrail benchmarks, we propose
SafeWatch-Bench, a large-scale video guardrail benchmark comprising over 2M
videos spanning six safety categories which covers over 30 tasks to ensure a
comprehensive coverage of all potential safety scenarios. SafeWatch outperforms
SOTA by 28.2% on SafeWatch-Bench, 13.6% on benchmarks, cuts costs by 10%, and
delivers top-tier explanations validated by LLM and human reviews.


## Robust Quantum Reservoir Computing for Molecular Property Prediction

>Authors: Daniel Beaulieu, Milan Kornjaca, Zoran Krunic, Michael Stivaktakis, Thomas Ehmer, Sheng-Tao Wang, Anh Pham

>2024-12-09

> http://arxiv.org/abs/2412.06758v1

Machine learning has been increasingly utilized in the field of biomedical
research to accelerate the drug discovery process. In recent years, the
emergence of quantum computing has been followed by extensive exploration of
quantum machine learning algorithms. Quantum variational machine learning
algorithms are currently the most prevalent but face issues with trainability
due to vanishing gradients. An emerging alternative is the quantum reservoir
computing (QRC) approach, in which the quantum algorithm does not require
gradient evaluation on quantum hardware. Motivated by the potential advantages
of the QRC method, we apply it to predict the biological activity of potential
drug molecules based on molecular descriptors. We observe more robust QRC
performance as the size of the dataset decreases, compared to standard
classical models, a quality of potential interest for pharmaceutical datasets
of limited size. In addition, we leverage the uniform manifold approximation
and projection technique to analyze structural changes as classical features
are transformed through quantum dynamics and find that quantum reservoir
embeddings appear to be more interpretable in lower dimensions.


## ONEBench to Test Them All Sample-Level Benchmarking Over Open-Ended Capabilities

>Authors: Adhiraj Ghosh, Sebastian Dziadzio, Ameya Prabhu, Vishaal Udandarao, Samuel Albanie, Matthias Bethge

>2024-12-09

> http://arxiv.org/abs/2412.06745v1

Traditional fixed test sets fall short in evaluating open-ended capabilities
of foundation models. To address this, we propose ONEBench(OpeN-Ended
Benchmarking), a new testing paradigm that consolidates individual evaluation
datasets into a unified, ever-expanding sample pool. ONEBench allows users to
generate custom, open-ended evaluation benchmarks from this pool, corresponding
to specific capabilities of interest. By aggregating samples across test sets,
ONEBench enables the assessment of diverse capabilities beyond those covered by
the original test sets, while mitigating overfitting and dataset bias. Most
importantly, it frames model evaluation as a collective process of selecting
and aggregating sample-level tests.
  The shift from task-specific benchmarks to ONEBench introduces two
challenges: (1)heterogeneity and (2)incompleteness. Heterogeneity refers to the
aggregation over diverse metrics, while incompleteness describes comparing
models evaluated on different data subsets. To address these challenges, we
explore algorithms to aggregate **sparse** measurements into reliable model scores.
Our aggregation algorithm ensures identifiability(asymptotically recovering
ground-truth scores) and rapid convergence, enabling accurate model ranking
with less data. On homogenous datasets, we show our aggregation algorithm
provides rankings that highly correlate with those produced by average scores.
We also demonstrate robustness to ~95% of measurements missing, reducing
evaluation cost by up to 20x with little-to-no change in model rankings. We
introduce ONEBench-LLM for language models and ONEBench-LMM for vision-language
models, unifying evaluations across these domains. Overall, we present a
technique for open-ended evaluation, which can aggregate over incomplete,
heterogeneous sample-level measurements to continually grow a benchmark
alongside the rapidly developing foundation models.


## Terahertz Microscopy Through Complex Media

>Authors: Vivek Kumar, Vittorio Cecconi, Antonio Cutrona, Luke Peters, Luana Olivieri, Juan S. Totero Gongora, Alessia Pasquazi, Marco Peccianti

>2024-12-09

> http://arxiv.org/abs/2412.06427v2

Manipulating broadband fields in scattering media is a modern challenge
across photonics and other wave domains. Recent studies have shown that complex
propagation in scattering media can be harnessed to manipulate broadband light
wave packets in space-time for focusing, imaging, and computing applications.
Interestingly, while many proposed methodologies operate on intensity-based
assessment of scattered fields, often in the spectral domain, from a pure
transmission-function perspective, scattering operates as a linear field-level
combinatory process, i.e., the superposition of transformation of unit
excitations. As a result, we recently demonstrated that gaining experimental
access to instantaneous scattered fields, as available through time-domain
spectroscopy in the terahertz spectral range, in conjunction with **sparse** light
excitation typical of ghost imaging, provides a key advantage in enabling the
functionalisation of scattering, exposing a novel modelling paradigm. In this
paper, we provide experimental proof of reconstructing 1-dimensional object
features through a scattering medium using a fully broadband time-domain
terahertz approach.


## LLM-BIP Structured Pruning for Large Language Models with Block-Wise Forward Importance Propagation

>Authors: Haihang Wu

>2024-12-09

> http://arxiv.org/abs/2412.06419v1

Large language models (LLMs) have demonstrated remarkable performance across
various language tasks, but their widespread deployment is impeded by their
large size and high computational costs. Structural **pruning** is a prevailing
technique used to introduce **sparsity** into pre-trained models and facilitate
direct hardware **acceleration** during inference by removing redundant connections
(structurally-grouped parameters), such as channels and attention heads.
Existing structural **pruning** approaches often employ either global or layer-wise
**pruning** criteria; however, they are hindered by ineffectiveness stemming from
inaccurate evaluation of connection importance. Global **pruning** methods
typically assess component importance using near-zero and unreliable gradients,
while layer-wise **pruning** approaches encounter significant **pruning** error
accumulation issues. To this end, we propose a more accurate **pruning** metric
based on the block-wise importance score propagation, termed LLM-BIP.
Specifically, LLM-BIP precisely evaluates connection importance by gauging its
influence on the respective transformer block output, which can be efficiently
approximated in a single forward pass through an upper bound derived from the
assumption of Lipschitz continuity. We evaluate the proposed method using
LLaMA-7B, Vicuna-7B, and LLaMA-13B across common zero-shot tasks. The results
demonstrate that our approach achieves an average of 3.26% increase in accuracy
for common reasoning tasks compared to previous best baselines. It also reduces
perplexity by 14.09 and 68.76 on average for the WikiText2 dataset and PTB
dataset, respectively.


## A time-like window into tensionless worldsheets

>Authors: Sudip Karan, Bibhas Ranjan Majhi

>2024-12-09

> http://arxiv.org/abs/2412.06387v1

Rindler worldsheets are known to acquire a Carrollian structure at infinite
**acceleration**, marking their tensionless limit. This work extends the same
paradigm to time-evolving worldsheets in the background target spacetime
spanning the Kasner wedges. Specifically, we demonstrate that approaching the
null horizons of the Kasner worldsheet induces a Carrollian structure,
necessitating an infinite limit on the time-evolution parameter. We further
examine how the associated Bogoliubov transformations on the usual tensile
Kasner worldsheets -- encompassing quantum modes, vacuum states, and
oscillators -- provide insights into their yet-unexplored tensionless regime.
Intriguingly, phenomena such as null string complementarity (i.e., the
emergence of open string physics from closed strings) and Hagedorn physics
naturally arise in the quantum vacuum of tensionless worldsheets. These
findings validate that time-like entanglement in Kasner worldsheets is not
merely analogous to, but exactly equivalent to, space-like entanglement in
Rindler worldsheets, viewed in distinct causally-disconnected regions.


## A Flexible Template for Edge Generative AI with High-Accuracy Accelerated Softmax & GELU

>Authors: Andrea Belano, Yvan Tortorella, Angelo Garofalo, Luca Benini, Davide Rossi, Francesco Conti

>2024-12-09

> http://arxiv.org/abs/2412.06321v1

Transformer-based generative Artificial Intelligence (GenAI) models achieve
remarkable results in a wide range of fields, including natural language
processing, computer vision, and audio processing. However, this comes at the
cost of increased complexity and the need of sophisticated non-linearities such
as softmax and GELU. Even if Transformers are computationally dominated by
matrix multiplications (MatMul), these non-linearities can become a performance
bottleneck, especially if dedicated hardware is used to accelerate MatMul
operators. In this work, we introduce a GenAI BFloat16 Transformer **acceleration**
template based on a heterogeneous tightly-coupled cluster containing 256KiB of
shared SRAM, 8 general-purpose RISC-V cores, a 24x8 systolic array MatMul
accelerator, and a novel accelerator for Transformer softmax and GELU
non-linearities: SoftEx. SoftEx introduces an approximate exponentiation
algorithm balancing efficiency (121x speedup over glibc's implementation) with
accuracy (mean relative error of 0.14%). In 12nm technology, SoftEx occupies
0.039 mm$^2$, only 3.22% of the cluster, which achieves an operating frequency
of 1.12 GHz. Compared to optimized software running on the RISC-V cores, SoftEx
achieves significant improvements, accelerating softmax and GELU computations
by up to 10.8x and 5.11x, respectively, while reducing their energy consumption
by up to 10.8x and 5.29x. These enhancements translate into a 1.58x increase in
throughput (310 GOPS at 0.8V) and a 1.42x improvement in energy efficiency
(1.34 TOPS/W at 0.55V) on end-to-end ViT inference workloads.


## S$^{2}$FT Efficient, Scalable and Generalizable LLM Fine-tuning by Structured Sparsity

>Authors: Xinyu Yang, Jixuan Leng, Geyang Guo, Jiawei Zhao, Ryumei Nakada, Linjun Zhang, Huaxiu Yao, Beidi Chen

>2024-12-09

> http://arxiv.org/abs/2412.06289v2

Current PEFT methods for LLMs can achieve either high quality, efficient
training, or scalable serving, but not all three simultaneously. To address
this limitation, we investigate **sparse** fine-tuning and observe a remarkable
improvement in generalization ability. Utilizing this key insight, we propose a
family of Structured Sparse Fine-Tuning (S$^{2}$FT) methods for LLMs, which
concurrently achieve state-of-the-art fine-tuning performance, training
efficiency, and inference scalability. S$^{2}$FT accomplishes this by
"selecting **sparse**ly and computing densely". It selects a few heads and channels
in the MHA and FFN modules for each Transformer block, respectively. Next, it
co-permutes weight matrices on both sides of the coupled structures in LLMs to
connect the selected components in each layer into a dense submatrix. Finally,
S$^{2}$FT performs in-place gradient updates on all submatrices. Through
theoretical analysis and empirical results, our method prevents overfitting and
forgetting, delivers SOTA performance on both commonsense and arithmetic
reasoning with 4.6% and 1.3% average improvements compared to LoRA, and
surpasses full FT by 11.5% when generalizing to various domains after
instruction tuning. Using our partial backpropagation algorithm, S$^{2}$FT
saves training memory up to 3$\times$ and improves latency by 1.5-2.7$\times$
compared to full FT, while delivering an average 10% improvement over LoRA on
both metrics. We further demonstrate that the weight updates in S$^{2}$FT can
be decoupled into adapters, enabling effective fusion, fast switch, and
efficient parallelism for serving multiple fine-tuned models.


## Quantum recharging by shortcut to adiabaticity

>Authors: Shi-fan Qi, Jun Jing

>2024-12-09

> http://arxiv.org/abs/2412.06266v1

Quantum battery concerns about population redistribution and energy dispatch
over controllable quantum systems. Under unitary transformation, ergotropy
rather than energy plays an essential role in describing the accumulated useful
work. Thus, the charging and recharging of quantum batteries are distinct from
the electric-energy input and reuse of classical batteries. In this work, we
focus on recharging a three-level quantum battery that has been exhausted under
self-discharging and work extraction. We find that the quantum battery cannot
be fully refreshed with the maximum ergotropy only by the driving pulses for
unitary charging. For an efficient refreshment of the quantum battery, we
propose a fast and stable recharging protocol based on postselection and
shortcut to adiabaticity. More than accelerating the adiabatic passage for
charging, the protocol can eliminate unextractable energy and is robust against
driving errors and environmental decoherence. Our protocol is energy-saving and
experimental-feasible, even in systems with the forbidden transition.


## iLLaVA An Image is Worth Fewer Than 1/3 Input Tokens in Large Multimodal Models

>Authors: Lianyu Hu, Fanhua Shang, Liang Wan, Wei Feng

>2024-12-09

> http://arxiv.org/abs/2412.06263v1

In this paper, we introduce iLLaVA, a simple method that can be seamlessly
deployed upon current Large Vision-Language Models (LVLMs) to greatly increase
the throughput with nearly lossless model performance, without a further
requirement to train. iLLaVA achieves this by finding and gradually merging the
redundant tokens with an accurate and fast algorithm, which can merge hundreds
of tokens within only one step. While some previous methods have explored
directly **pruning** or merging tokens in the inference stage to accelerate models,
our method excels in both performance and throughput by two key designs. First,
while most previous methods only try to save the computations of Large Language
Models (LLMs), our method accelerates the forward pass of both image encoders
and LLMs in LVLMs, which both occupy a significant part of time during
inference. Second, our method recycles the beneficial information from the
pruned tokens into existing tokens, which avoids directly dropping context
tokens like previous methods to cause performance loss. iLLaVA can nearly
2$\times$ the throughput, and reduce the memory costs by half with only a 0.2\%
- 0.5\% performance drop across models of different scales including 7B, 13B
and 34B. On tasks across different domains including single-image, multi-images
and videos, iLLaVA demonstrates strong generalizability with consistently
promising efficiency. We finally offer abundant visualizations to show the
merging processes of iLLaVA in each step, which show insights into the
distribution of computing resources in LVLMs. Code is available at
https://github.com/hulianyuyy/iLLaVA.


## Splatter-360 Generalizable 360$^{\circ}$ Gaussian Splatting for Wide-baseline Panoramic Images

>Authors: Zheng Chen, Chenming Wu, Zhelun Shen, Chen Zhao, Weicai Ye, Haocheng Feng, Errui Ding, Song-Hai Zhang

>2024-12-09

> http://arxiv.org/abs/2412.06250v1

Wide-baseline panoramic images are frequently used in applications like VR
and simulations to minimize capturing labor costs and storage needs. However,
synthesizing novel views from these panoramic images in real time remains a
significant challenge, especially due to panoramic imagery's high resolution
and inherent distortions. Although existing 3D Gaussian splatting (3DGS)
methods can produce photo-realistic views under narrow baselines, they often
overfit the training views when dealing with wide-baseline panoramic images due
to the difficulty in learning precise geometry from **sparse** 360$^{\circ}$ views.
This paper presents \textit{Splatter-360}, a novel end-to-end generalizable
3DGS framework designed to handle wide-baseline panoramic images. Unlike
previous approaches, \textit{Splatter-360} performs multi-view matching
directly in the spherical domain by constructing a spherical cost volume
through a spherical sweep algorithm, enhancing the network's depth perception
and geometry estimation. Additionally, we introduce a 3D-aware bi-projection
encoder to mitigate the distortions inherent in panoramic images and integrate
cross-view attention to improve feature interactions across multiple
viewpoints. This enables robust 3D-aware feature representations and real-time
rendering capabilities. Experimental results on the HM3D~\cite{hm3d} and
Replica~\cite{replica} demonstrate that \textit{Splatter-360} significantly
outperforms state-of-the-art NeRF and 3DGS methods (e.g., PanoGRF, MVSplat,
DepthSplat, and HiSplat) in both synthesis quality and generalization
performance for wide-baseline panoramic images. Code and trained models are
available at \url{https://3d-aigc.github.io/Splatter-360/}.


## Top-r Influential Community Search in Bipartite Graphs

>Authors: Yanxin Zhang, Zhengyu Hua, Long Yuan

>2024-12-09

> http://arxiv.org/abs/2412.06216v2

Community search over bipartite graphs is a fundamental problem, and finding
influential communities has attracted significant attention. However, all
existing studies have used the minimum weight of vertices as the influence of
communities. This leads to an inaccurate assessment of real influence in graphs
where there are only a few vertices with low weights. In this paper, we propose
a new cohesive subgraph model named ($\alpha$,$\beta$)-influential community
that considers the average weight of vertices from two layers on bipartite
graphs, thereby providing a more comprehensive reflection of community
influence. Based on this community model, we present a recursive algorithm that
traverses the entire bipartite graph to find top-$r$
($\alpha$,$\beta$)-influential communities. To further expedite the search for
influential communities, we propose a slim tree structure to reduce the search
width and introduce several effective upper bounds to reduce the search depth.
Since we have proven that this problem is NP-hard, using exact algorithms to
find top-$r$ ($\alpha$,$\beta$)-communities accurately is very time-consuming.
Therefore, we propose an approximate algorithm using a greedy approach to find
top-$r$ ($\alpha$,$\beta$)-communities as quickly as possible. It only takes
$O((n+m)+m\log_{}{n})$ time. Additionally, we introduce a new **pruning** algorithm
to improve the efficiency of the search. Extensive experiments on 10 real-world
graphs validate both the effectiveness and the efficiency of our algorithms.


## SparseAccelerate Efficient Long-Context Inference for Mid-Range GPUs

>Authors: James Vo

>2024-12-09

> http://arxiv.org/abs/2412.06198v1

As Large Language Models (LLMs) scale to longer context windows, the
computational cost of attention mechanisms, which traditionally grows
quadratically with input length, presents a critical challenge for real-time
and memory-constrained deployments. Existing **sparse** attention techniques have
sought to reduce this complexity, but they often incur significant overhead or
compromise accuracy, making them less practical for large contexts on mid-range
hardware. In this paper, we introduce SparseAccelerate, a dynamic **sparse**
attention method that adapts its **sparsity** patterns based on input
characteristics, effectively flattening the attention complexity curve. Our
approach is effective for input lengths starting at 16K tokens and scales
efficiently up to 128K tokens on dual NVIDIA A5000 GPUs (24GB each).
Experimental results show that SparseAccelerate achieves up to a 1.04x
reduction in Time-To-First-Token (TTFT) latency at 32K tokens, while also
providing substantial memory savings. These improvements yield practical gains
for memory-intensive applications and long-context tasks that were previously
infeasible with standard attention. Beyond latency reductions, SparseAccelerate
fundamentally shifts the scaling trend, demonstrating the smallest TTFT growth
gradient relative to context length among competing methods. Ongoing
evaluations on diverse benchmarks confirm its scalability, positioning
SparseAccelerate as a critical advancement toward efficient, real-time, and
large-context LLM inference on accessible hardware.


## ASGDiffusion Parallel High-Resolution Generation with Asynchronous Structure Guidance

>Authors: Yuming Li, Peidong Jia, Daiwei Hong, Yueru Jia, Qi She, Rui Zhao, Ming Lu, Shanghang Zhang

>2024-12-09

> http://arxiv.org/abs/2412.06163v1

Training-free high-resolution (HR) image generation has garnered significant
attention due to the high costs of training large diffusion models. Most
existing methods begin by reconstructing the overall structure and then proceed
to refine the local details. Despite their advancements, they still face issues
with repetitive patterns in HR image generation. Besides, HR generation with
diffusion models incurs significant computational costs. Thus, parallel
generation is essential for interactive applications. To solve the above
limitations, we introduce a novel method named ASGDiffusion for parallel HR
generation with Asynchronous Structure Guidance (ASG) using pre-trained
diffusion models. To solve the pattern repetition problem of HR image
generation, ASGDiffusion leverages the low-resolution (LR) noise weighted by
the attention mask as the structure guidance for the denoising step to ensure
semantic consistency. The proposed structure guidance can significantly
alleviate the pattern repetition problem. To enable parallel generation, we
further propose a parallelism strategy, which calculates the patch noises and
structure guidance asynchronously. By leveraging multi-GPU parallel
**acceleration**, we significantly accelerate generation speed and reduce memory
usage per GPU. Extensive experiments demonstrate that our method effectively
and efficiently addresses common issues like pattern repetition and achieves
state-of-the-art HR generation.


## Mixture-of-PageRanks Replacing Long-Context with Real-Time, Sparse GraphRAG

>Authors: Nicholas Alonso, Beren Millidge

>2024-12-08

> http://arxiv.org/abs/2412.06078v1

Recent advances have extended the context window of frontier LLMs
dramatically, from a few thousand tokens up to millions, enabling entire books
and codebases to fit into context. However, the compute costs of inferencing
long-context LLMs are massive and often prohibitive in practice. RAG offers an
efficient and effective alternative: retrieve and process only the subset of
the context most important for the current task. Although promising, recent
work applying RAG to long-context tasks has two core limitations: 1) there has
been little focus on making the RAG pipeline compute efficient, and 2) such
works only test on simple QA tasks, and their performance on more challenging
tasks is unclear. To address this, we develop an algorithm based on PageRank, a
graph-based retrieval algorithm, which we call mixture-of-PageRanks (MixPR).
MixPR uses a mixture of PageRank-based graph-retrieval algorithms implemented
using **sparse** matrices for efficent, cheap retrieval that can deal with a
variety of complex tasks. Our MixPR retriever achieves state-of-the-art results
across a wide range of long-context benchmark tasks, outperforming both
existing RAG methods, specialized retrieval architectures, and long-context
LLMs despite being far more compute efficient. Due to using **sparse** embeddings,
our retriever is extremely compute efficient, capable of embedding and
retrieving millions of tokens within a few seconds and runs entirely on CPU.


## Taming Sensitive Weights  Noise Perturbation Fine-tuning for Robust LLM Quantization

>Authors: Dongwei Wang, Huanrui Yang

>2024-12-08

> http://arxiv.org/abs/2412.06858v1

Quantization is a critical step to enable efficient LLM serving under limited
resource. However, previous research observes that certain weights in the LLM,
known as outliers, are significantly sensitive to **quantization** noises. Existing
**quantization** methods leave these outliers as floating points or higher
precisions to retain performance, posting challenges on the efficient hardware
deployment of the mixed-precision model. This work investigates an alternative
way to tame the sensitive weights' impact on the **quantization** error, by
reducing the loss Hessian trace with respect to outliers through an efficient
fine-tuning process. We propose Noise Perturbation Fine-tuning (NPFT), which
identifies outlier weights and add random weight perturbations on the outliers
as the model going through a PEFT optimization. NPFT tames the sensitivity of
outlier weights so that the **quantize**d model performance can be improved without
special treatment to the outliers. When applied to OPT and LLaMA models, our
NPFT method achieves stable performance improvements for both uniform and
non-uniform **quantize**rs, while also offering better inference efficiency.
Notably, the simplest RTN can achieve performance on par with GPTQ using our
NPFT on LLaMA2-7B-4bits benchmark.


## Language Model as Visual Explainer

>Authors: Xingyi Yang, Xinchao Wang

>2024-12-08

> http://arxiv.org/abs/2412.07802v1

In this paper, we present Language Model as Visual Explainer LVX, a
systematic approach for interpreting the internal workings of vision models
using a tree-structured linguistic explanation, without the need for model
training. Central to our strategy is the collaboration between vision models
and LLM to craft explanations. On one hand, the LLM is harnessed to delineate
hierarchical visual attributes, while concurrently, a text-to-image API
retrieves images that are most aligned with these textual concepts. By mapping
the collected texts and images to the vision model's embedding space, we
construct a hierarchy-structured visual embedding tree. This tree is
dynamically pruned and grown by querying the LLM using language templates,
tailoring the explanation to the model. Such a scheme allows us to seamlessly
incorporate new attributes while eliminating undesired concepts based on the
model's representations. When applied to testing samples, our method provides
human-understandable explanations in the form of attribute-laden trees. Beyond
explanation, we retrained the vision model by calibrating it on the generated
concept hierarchy, allowing the model to incorporate the refined knowledge of
visual attributes. To access the effectiveness of our approach, we introduce
new benchmarks and conduct rigorous evaluations, demonstrating its
plausibility, faithfulness, and stability.


## Vision Transformer-based Semantic Communications With Importance-Aware Quantization

>Authors: Joohyuk Park, Yongjeong Oh, Yongjune Kim, Yo-Seb Jeon

>2024-12-08

> http://arxiv.org/abs/2412.06038v1

Semantic communications provide significant performance gains over
traditional communications by transmitting task-relevant semantic features
through wireless channels. However, most existing studies rely on end-to-end
(E2E) training of neural-type encoders and decoders to ensure effective
transmission of these semantic features. To enable semantic communications
without relying on E2E training, this paper presents a vision transformer
(ViT)-based semantic communication system with importance-aware **quantization**
(IAQ) for wireless image transmission. The core idea of the presented system is
to leverage the attention scores of a pretrained ViT model to quantify the
importance levels of image patches. Based on this idea, our IAQ framework
assigns different **quantization** bits to image patches based on their importance
levels. This is achieved by formulating a weighted **quantization** error
minimization problem, where the weight is set to be an increasing function of
the attention score. Then, an optimal incremental allocation method and a
low-complexity water-filling method are devised to solve the formulated
problem. Our framework is further extended for realistic digital communication
systems by modifying the bit allocation problem and the corresponding
allocation methods based on an equivalent binary symmetric channel (BSC) model.
Simulations on single-view and multi-view image classification tasks show that
our IAQ framework outperforms conventional image compression methods in both
error-free and realistic communication scenarios.


## FlexDiT Dynamic Token Density Control for Diffusion Transformer

>Authors: Shuning Chang, Pichao Wang, Jiasheng Tang, Yi Yang

>2024-12-08

> http://arxiv.org/abs/2412.06028v1

Diffusion Transformers (DiT) deliver impressive generative performance but
face prohibitive computational demands due to both the quadratic complexity of
token-based self-attention and the need for extensive sampling steps. While
recent research has focused on accelerating sampling, the structural
inefficiencies of DiT remain underexplored. We propose FlexDiT, a framework
that dynamically adapts token density across both spatial and temporal
dimensions to achieve computational efficiency without compromising generation
quality. Spatially, FlexDiT employs a three-segment architecture that allocates
token density based on feature requirements at each layer: Poolingformer in the
bottom layers for efficient global feature extraction, Sparse-Dense Token
Modules (SDTM) in the middle layers to balance global context with local
detail, and dense tokens in the top layers to refine high-frequency details.
Temporally, FlexDiT dynamically modulates token density across denoising
stages, progressively increasing token count as finer details emerge in later
timesteps. This synergy between FlexDiT's spatially adaptive architecture and
its temporal **pruning** strategy enables a unified framework that balances
efficiency and fidelity throughout the generation process. Our experiments
demonstrate FlexDiT's effectiveness, achieving a 55% reduction in FLOPs and a
175% improvement in inference speed on DiT-XL with only a 0.09 increase in FID
score on 512$\times$512 ImageNet images, a 56% reduction in FLOPs across video
generation datasets including FaceForensics, SkyTimelapse, UCF101, and
Taichi-HD, and a 69% improvement in inference speed on PixArt-$\alpha$ on
text-to-image generation task with a 0.24 FID score decrease. FlexDiT provides
a scalable solution for high-quality diffusion-based generation compatible with
further sampling optimization techniques.


## Doubly Quantum Mechanics

>Authors: Vittorio D'Esposito, Giuseppe Fabiano, Domenico Frattulillo, Flavio Mercati

>2024-12-08

> http://arxiv.org/abs/2412.05997v1

Motivated by the expectation that relativistic symmetries might acquire
quantum features in Quantum Gravity, we take the first steps towards a theory
of ''Doubly'' Quantum Mechanics, a modification of Quantum Mechanics in which
the geometrical configurations of physical systems, measurement apparata, and
reference frame transformations are themselves **quantize**d and described by
''geometry'' states in a Hilbert space. We develop the formalism for
spin-$\frac{1}{2}$ measurements by promoting the group of spatial rotations
$SU(2)$ to the quantum group $SU_q(2)$ and generalizing the axioms of Quantum
Theory in a covariant way. As a consequence of our axioms, the notion of
probability becomes a self-adjoint operator acting on the Hilbert space of
geometry states, hence acquiring novel non-classical features. After
introducing a suitable class of semi-classical geometry states, which describe
near-to-classical geometrical configurations of physical systems, we find that
probability measurements are affected, in these configurations, by intrinsic
uncertainties stemming from the quantum properties of $SU_q(2)$. This feature
translates into an unavoidable fuzziness for observers attempting to align
their reference frames by exchanging qubits, even when the number of exchanged
qubits approaches infinity, contrary to the standard $SU(2)$ case.


## GBR Generative Bundle Refinement for High-fidelity Gaussian Splatting and Meshing

>Authors: Jianing Zhang, Yuchao Zheng, Ziwei Li, Qionghai Dai, Xiaoyun Yuan

>2024-12-08

> http://arxiv.org/abs/2412.05908v1

Gaussian splatting has gained attention for its efficient representation and
rendering of 3D scenes using continuous Gaussian primitives. However, it
struggles with **sparse**-view inputs due to limited geometric and photometric
information, causing ambiguities in depth, shape, and texture.
  we propose GBR: Generative Bundle Refinement, a method for high-fidelity
Gaussian splatting and meshing using only 4-6 input views. GBR integrates a
neural bundle adjustment module to enhance geometry accuracy and a generative
depth refinement module to improve geometry fidelity. More specifically, the
neural bundle adjustment module integrates a foundation network to produce
initial 3D point maps and point matches from unposed images, followed by bundle
adjustment optimization to improve multiview consistency and point cloud
accuracy. The generative depth refinement module employs a diffusion-based
strategy to enhance geometric details and fidelity while preserving the scale.
Finally, for Gaussian splatting optimization, we propose a multimodal loss
function incorporating depth and normal consistency, geometric regularization,
and pseudo-view supervision, providing robust guidance under **sparse**-view
conditions. Experiments on widely used datasets show that GBR significantly
outperforms existing methods under **sparse**-view inputs. Additionally, GBR
demonstrates the ability to reconstruct and render large-scale real-world
scenes, such as the Pavilion of Prince Teng and the Great Wall, with remarkable
details using only 6 views.


## XKV Personalized KV Cache Memory Reduction for Long-Context LLM Inference

>Authors: Weizhuo Li, Zhigang Wang, Yu Gu, Ge Yu

>2024-12-08

> http://arxiv.org/abs/2412.05896v1

Recently the generative Large Language Model (LLM) has achieved remarkable
success in numerous applications. Notably its inference generates output tokens
one-by-one, leading to many redundant computations. The widely-used **KV**-Cache
framework makes a compromise between time and space complexities. However,
caching data generates the increasingly growing memory demand, that can quickly
exhaust the limited memory capacity of the modern accelerator like GPUs,
particularly in long-context inference tasks. Existing studies reduce memory
consumption by evicting some of cached data that have less important impact on
inference accuracy. But the benefit in practice is far from ideal due to the
static cache allocation across different LLM network layers. This paper
observes that the layer-specific cached data have very different impacts on
accuracy. We quantify this difference, and give experimental and theoretical
validation. We accordingly make a formal analysis and shows that customizing
the cache size for each layer in a personalized manner can yield a significant
memory reduction, while still providing comparable accuracy. We simulate the
cache allocation as a combinatorial optimization problem and give a global
optimal solution. In particular, we devise a mini- and sampling-based inference
over a lightweight variant of the LLM model, so as to quickly capture the
difference and then feed it into the personalized algorithms. Extensive
experiments on real-world datasets demonstrate that our proposals can reduce **KV**
cache memory consumption by 61.6% on average, improve computational efficiency
by 2.1x and then increase the throughput by up to 5.5x.


## Transcorrelated Theory with Pseudopotentials

>Authors: Kristoffer Simula, Evelin Martine Corvid Christlmaier, Maria-Andreea Filip, J. Philip Haupt, Daniel Kats, Pablo Lopez-Rios, Ali Alavi

>2024-12-08

> http://arxiv.org/abs/2412.05885v1

The transcorrelated (TC) method performs a similarity transformation on the
  electronic Schr\"odinger equation via Jastrow factorization of the wave
function. This
  has demonstrated significant advancements in computational
  electronic structure theory by
  improving basis set convergence and compactifying the description of the wave
function. In
  this work, we introduce a new approach that incorporates pseudopotentials
(PPs) into the
  TC framework, significantly accelerating Jastrow factor optimization and
reducing
  computational costs. Our results for ionization potentials, atomization
energies, and
  dissociation curves of first-row atoms and molecules show that PPs provide
chemically
  accurate descriptions across a range of systems and give guidelines for
future
  theory and applications.
  The new pseudopotential-based TC method opens possibilities for applying TC
to more complex
  and larger systems, such as transition metals and solid-state systems.


## [CLS] Token Tells Everything Needed for Training-free Efficient MLLMs

>Authors: Ao Wang, Fengyuan Sun, Hui Chen, Zijia Lin, Jungong Han, Guiguang Ding

>2024-12-08

> http://arxiv.org/abs/2412.05819v1

Multimodal Large Language Models (MLLMs) have recently demonstrated strong
performance across a wide range of vision-language tasks, garnering significant
attention in the computer vision. However, their efficient deployment remains a
substantial challenge due to high computational costs and memory requirements.
Recognizing the redundancy of information within the vision modality, recent
studies have explored methods for compressing visual tokens in MLLMs to enhance
efficiency in a training-free manner. Despite their effectiveness, existing
methods like Fast rely on the attention between visual tokens and prompt text
tokens as the importance indicator, overlooking the relevance to response text
and thus introducing perception bias. In this paper, we demonstrate that in
MLLMs, the [CLS] token in the visual encoder inherently knows which visual
tokens are important for MLLMs. Building on this prior, we introduce a simple
yet effective method for train-free visual token compression, called VTC-CLS.
Firstly, it leverages the attention score of the [CLS] token on visual tokens
as an importance indicator for **pruning** visual tokens. Besides, we also explore
ensembling the importance scores derived by the [CLS] token from different
layers to capture the key visual information more comprehensively. Extensive
experiments demonstrate that our VTC-CLS achieves the state-of-the-art
performance across various tasks compared with baseline methods. It also brings
notably less computational costs in a training-free manner, highlighting its
effectiveness and superiority. Code and models are available at
\url{https://github.com/THU-MIG/VTC-CLS}.


## Mixture of Hidden-Dimensions Transformer

>Authors: Yilong Chen, Junyuan Shang, Zhengyu Zhang, Jiawei Sheng, Tingwen Liu, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang

>2024-12-07

> http://arxiv.org/abs/2412.05644v3

Transformer models encounter challenges in scaling hidden dimensions
efficiently, as uniformly increasing them inflates computational and memory
costs while failing to emphasize the most relevant features for each token. For
further understanding, we study hidden dimension **sparsity** and observe that
trained Transformers utilize only a small fraction of token dimensions,
revealing an "activation flow" pattern. Notably, there are shared
sub-dimensions with sustained activation across multiple consecutive tokens and
specialized sub-dimensions uniquely activated for each token. To better model
token-relevant sub-dimensions, we propose MoHD (Mixture of Hidden Dimensions),
a **sparse** conditional activation architecture. Particularly, MoHD employs shared
sub-dimensions for common token features and a routing mechanism to dynamically
activate specialized sub-dimensions. To mitigate potential information loss
from **sparsity**, we design activation scaling and group fusion mechanisms to
preserve activation flow. In this way, MoHD expands hidden dimensions with
negligible increases in computation or parameters, efficient training and
inference while maintaining performance. Evaluations across 10 NLP tasks show
that MoHD surpasses Vanilla Transformers in parameter efficiency and task
performance. It achieves 1.7% higher performance with 50% fewer activation
parameters and 3.7% higher performance with a 3x parameter expansion at
constant activation cost. MOHD offers a new perspective for scaling the model,
showcasing the potential of hidden dimension **sparsity** to boost efficiency


## Entropy-Based Sensing Schemes for Energy Efficiency in Massive MTC

>Authors: Sergi Liesegang, Antonio Pascual-Iserte, Olga Muñoz

>2024-12-07

> http://arxiv.org/abs/2412.05629v1

Machine-type communications (MTC) are crucial in the evolution of mobile
communication systems. Within this context, we distinguish the so-called
massive MTC (mMTC), where a large number of devices coexist in the same
geographical area. In the case of sensors, a high correlation in the collected
information is expected. In this letter, we evaluate the impact of correlation
on the entropy of a set of **quantize**d Gaussian sources. This model allows us to
express the sensed data with the data correlation matrix. Given the nature of
mMTC, these matrices may be well approximated as rank deficient. Accordingly,
we exploit this singularity to design a technique for switching off several
sensors that maximizes the entropy under power-related constraints. The
discrete optimization problem is transformed into a convex formulation that can
be solved numerically.


## Strain-engineering spin-valley locking effect in altermagnetic monolayer with multipiezo properties

>Authors: Yuqian Jiang, Xinge Zhang, Haoyue Bai, Yuping Tian, Wei-Jiang Gong, Xiangru Kong

>2024-12-07

> http://arxiv.org/abs/2412.05597v1

Recently, altermagnetism (AM) in condensed matter systems has attracted much
attention due to the physical properties arising from the alternating spins in
both real space and reciprocal space. In our work, we propose a stable
monolayer Janus Nb2SeTeO with altermagnetic ground state and a new type of
spin-valley locking (SVL) effect. The monolayer Janus Nb2SeTeO exhibits a
mutipizeo effect with a large out-of-plane piezoelectricity and piezovalley
effect with large valley polarization. The piezovalley effect is induced by the
uniaxial strain effect in different directions, which contributes the anomalous
valley Hall effect (AVHE) in the AM system. Moreover, the compressive uniaxial
strain could induce the quantum anomalous Hall effect (QAHE) in the AM system,
where the chirality of the dissipationless topological edge states could be
manipulated by the direction of uniaxial strain. These manifest topological
phase transitions could be realized via the piezovalley effect in the AM
system. Furthermore, the AM quantum spin Hall effect (QSHE) could be induced by
the biaxial strain effect, which contributes the **quantize**d spin Hall
conductance. Our work reveals that strain-engineering technique could provide
as an important method to tune the dissipationless edge states in monolayer
Janus Nb2SeTeO. By designing the SVL effect could emerge new physics in AM
systems, such as AVHE, QAHE and QSHE.


## UMSPU Universal Multi-Size Phase Unwrapping via Mutual Self-Distillation and Adaptive Boosting Ensemble Segmenters

>Authors: Lintong Du, Huazhen Liu, Yijia Zhang, ShuXin Liu, Yuan Qu, Zenghui Zhang, Jiamiao Yang

>2024-12-07

> http://arxiv.org/abs/2412.05584v1

Spatial phase unwrapping is a key technique for extracting phase information
to obtain 3D morphology and other features. Modern industrial measurement
scenarios demand high precision, large image sizes, and high speed. However,
conventional methods struggle with noise resistance and processing speed.
Current deep learning methods are limited by the receptive field size and
**sparse** semantic information, making them ineffective for large size images. To
address this issue, we propose a mutual self-distillation (MSD) mechanism and
adaptive boosting ensemble segmenters to construct a universal multi-size phase
unwrapping network (UMSPU). MSD performs hierarchical attention refinement and
achieves cross-layer collaborative learning through bidirectional distillation,
ensuring fine-grained semantic representation across image sizes. The adaptive
boosting ensemble segmenters combine weak segmenters with different receptive
fields into a strong one, ensuring stable segmentation across spatial
frequencies. Experimental results show that UMSPU overcomes image size
limitations, achieving high precision across image sizes ranging from 256*256
to 2048*2048 (an 8 times increase). It also outperforms existing methods in
speed, robustness, and generalization. Its practicality is further validated in
structured light imaging and InSAR. We believe that UMSPU offers a universal
solution for phase unwrapping, with broad potential for industrial
applications.


## ULMRec User-centric Large Language Model for Sequential Recommendation

>Authors: Minglai Shao, Hua Huang, Qiyao Peng, Hongtao Liu

>2024-12-07

> http://arxiv.org/abs/2412.05543v1

Recent advances in Large Language Models (LLMs) have demonstrated promising
performance in sequential recommendation tasks, leveraging their superior
language understanding capabilities. However, existing LLM-based recommendation
approaches predominantly focus on modeling item-level co-occurrence patterns
while failing to adequately capture user-level personalized preferences. This
is problematic since even users who display similar behavioral patterns (e.g.,
clicking or purchasing similar items) may have fundamentally different
underlying interests. To alleviate this problem, in this paper, we propose
ULMRec, a framework that effectively integrates user personalized preferences
into LLMs for sequential recommendation. Considering there has the semantic gap
between item IDs and LLMs, we replace item IDs with their corresponding titles
in user historical behaviors, enabling the model to capture the item semantics.
For integrating the user personalized preference, we design two key components:
(1) user indexing: a personalized user indexing mechanism that leverages vector
**quantization** on user reviews and user IDs to generate meaningful and unique
user representations, and (2) alignment tuning: an alignment-based tuning stage
that employs comprehensive preference alignment tasks to enhance the model's
capability in capturing personalized information. Through this design, ULMRec
achieves deep integration of language semantics with user personalized
preferences, facilitating effective adaptation to recommendation. Extensive
experiments on two public datasets demonstrate that ULMRec significantly
outperforms existing methods, validating the effectiveness of our approach.


## The BrowserGym Ecosystem for Web Agent Research

>Authors: Thibault Le Sellier De Chezelles, Maxime Gasse, Alexandre Drouin, Massimo Caccia, Léo Boisvert, Megh Thakkar, Tom Marty, Rim Assouel, Sahar Omidi Shayegan, Lawrence Keunho Jang, Xing Han Lù, Ori Yoran, Dehan Kong, Frank F. Xu, Siva Reddy, Quentin Cappart, Graham Neubig, Ruslan Salakhutdinov, Nicolas Chapados, Alexandre Lacoste

>2024-12-06

> http://arxiv.org/abs/2412.05467v3

The BrowserGym ecosystem addresses the growing need for efficient evaluation
and benchmarking of web agents, particularly those leveraging automation and
Large Language Models (LLMs) for web interaction tasks. Many existing
benchmarks suffer from fragmentation and inconsistent evaluation methodologies,
making it challenging to achieve reliable comparisons and reproducible results.
BrowserGym aims to solve this by providing a unified, gym-like environment with
well-defined observation and action spaces, facilitating standardized
evaluation across diverse benchmarks. Combined with AgentLab, a complementary
framework that aids in agent creation, testing, and analysis, BrowserGym offers
flexibility for integrating new benchmarks while ensuring consistent evaluation
and comprehensive experiment management. This standardized approach seeks to
reduce the time and complexity of developing web agents, supporting more
reliable comparisons and facilitating in-depth analysis of agent behaviors, and
could result in more adaptable, capable agents, ultimately accelerating
innovation in LLM-driven automation. As a supporting evidence, we conduct the
first large-scale, multi-benchmark web agent experiment and compare the
performance of 6 state-of-the-art LLMs across all benchmarks currently
available in BrowserGym. Among other findings, our results highlight a large
discrepancy between OpenAI and Anthropic's latests models, with
Claude-3.5-Sonnet leading the way on almost all benchmarks, except on
vision-related tasks where GPT-4o is superior. Despite these advancements, our
results emphasize that building robust and efficient web agents remains a
significant challenge, due to the inherent complexity of real-world web
environments and the limitations of current models.


## HiVeGen -- Hierarchical LLM-based Verilog Generation for Scalable Chip Design

>Authors: Jinwei Tang, Jiayin Qin, Kiran Thorat, Chen Zhu-Tian, Yu Cao, Yang, Zhao, Caiwen Ding

>2024-12-06

> http://arxiv.org/abs/2412.05393v1

With Large Language Models (LLMs) recently demonstrating impressive
proficiency in code generation, it is promising to extend their abilities to
Hardware Description Language (HDL). However, LLMs tend to generate single HDL
code blocks rather than hierarchical structures for hardware designs, leading
to hallucinations, particularly in complex designs like Domain-Specific
Accelerators (DSAs). To address this, we propose HiVeGen, a hierarchical
LLM-based Verilog generation framework that decomposes generation tasks into
LLM-manageable hierarchical submodules. HiVeGen further harnesses the
advantages of such hierarchical structures by integrating automatic Design
Space Exploration (DSE) into hierarchy-aware prompt generation, introducing
weight-based retrieval to enhance code reuse, and enabling real-time
human-computer interaction to lower error-correction cost, significantly
improving the quality of generated designs.


## Sparse autoencoders reveal selective remapping of visual concepts during adaptation

>Authors: Hyesu Lim, Jinho Choi, Jaegul Choo, Steffen Schneider

>2024-12-06

> http://arxiv.org/abs/2412.05276v1

Adapting foundation models for specific purposes has become a standard
approach to build machine learning systems for downstream applications. Yet, it
is an open question which mechanisms take place during adaptation. Here we
develop a new Sparse Autoencoder (SAE) for the CLIP vision transformer, named
PatchSAE, to extract interpretable concepts at granular levels (e.g. shape,
color, or semantics of an object) and their patch-wise spatial attributions. We
explore how these concepts influence the model output in downstream image
classification tasks and investigate how recent state-of-the-art prompt-based
adaptation techniques change the association of model inputs to these concepts.
While activations of concepts slightly change between adapted and non-adapted
models, we find that the majority of gains on common adaptation tasks can be
explained with the existing concepts already present in the non-adapted
foundation model. This work provides a concrete framework to train and use SAEs
for Vision Transformers and provides insights into explaining adaptation
mechanisms.


## APOLLO SGD-like Memory, AdamW-level Performance

>Authors: Hanqing Zhu, Zhenyu Zhang, Wenyan Cong, Xi Liu, Sem Park, Vikas Chandra, Bo Long, David Z. Pan, Zhangyang Wang, Jinwon Lee

>2024-12-06

> http://arxiv.org/abs/2412.05270v2

Large language models (LLMs) are notoriously memory-intensive during
training, particularly with the popular AdamW optimizer. This memory burden
necessitates using more or higher-end GPUs or reducing batch sizes, limiting
training scalability and throughput. To address this, various memory-efficient
optimizers have been proposed to reduce optimizer memory usage. However, they
face critical challenges: (i) reliance on costly SVD operations; (ii)
significant performance trade-offs compared to AdamW; and (iii) still
substantial optimizer memory overhead to maintain competitive performance.
  In this work, we identify that AdamW's learning rate adaptation rule can be
effectively coarsened as a structured learning rate update. Based on this
insight, we propose Approximated Gradient Scaling for Memory-Efficient LLM
Optimization (APOLLO), which approximates learning rate scaling using an
auxiliary low-rank optimizer state based on pure random projection. This
structured learning rate update rule makes APOLLO highly tolerant to further
memory reductions while delivering comparable pre-training performance. Even
its rank-1 variant, APOLLO-Mini, achieves superior pre-training performance
compared to AdamW with SGD-level memory costs.
  Extensive experiments demonstrate that the APOLLO series performs on-par with
or better than AdamW, while achieving greater memory savings by nearly
eliminating the optimization states of AdamW. These savings provide significant
system-level benefits: (1) Enhanced Throughput: 3x throughput on an 8xA100-80GB
setup compared to AdamW by supporting 4x larger batch sizes. (2) Improved Model
Scalability: Pre-training LLaMA-13B with naive DDP on A100-80GB GPUs without
system-level optimizations. (3) Low-End GPU Friendly Pre-training: Pre-training
LLaMA-7B on a single GPU using less than 12 GB of memory with weight
**quantization**.


## Incremental Sentence Processing Mechanisms in Autoregressive Transformer Language Models

>Authors: Michael Hanna, Aaron Mueller

>2024-12-06

> http://arxiv.org/abs/2412.05353v1

Autoregressive transformer language models (LMs) possess strong syntactic
abilities, often successfully handling phenomena from agreement to NPI
licensing. However, the features they use to incrementally process language
inputs are not well understood. In this paper, we fill this gap by studying the
mechanisms underlying garden path sentence processing in LMs. We ask: (1) Do
LMs use syntactic features or shallow heuristics to perform incremental
sentence processing? (2) Do LMs represent only one potential interpretation, or
multiple? and (3) Do LMs reanalyze or repair their initial incorrect
representations? To address these questions, we use **sparse** autoencoders to
identify interpretable features that determine which continuation - and thus
which reading - of a garden path sentence the LM prefers. We find that while
many important features relate to syntactic structure, some reflect
syntactically irrelevant heuristics. Moreover, while most active features
correspond to one reading of the sentence, some features correspond to the
other, suggesting that LMs assign weight to both possibilities simultaneously.
Finally, LMs do not re-use features from garden path sentence processing to
answer follow-up questions.


## A text-to-tabular approach to generate synthetic patient data using LLMs

>Authors: Margaux Tornqvist, Jean-Daniel Zucker, Tristan Fauvel, Nicolas Lambert, Mathilde Berthelot, Antoine Movschin

>2024-12-06

> http://arxiv.org/abs/2412.05153v1

Access to large-scale high-quality healthcare databases is key to accelerate
medical research and make insightful discoveries about diseases. However,
access to such data is often limited by patient privacy concerns, data sharing
restrictions and high costs. To overcome these limitations, synthetic patient
data has emerged as an alternative. However, synthetic data generation (SDG)
methods typically rely on machine learning (ML) models trained on original
data, leading back to the data scarcity problem. We propose an approach to
generate synthetic tabular patient data that does not require access to the
original data, but only a description of the desired database. We leverage
prior medical knowledge and in-context learning capabilities of large language
models (LLMs) to generate realistic patient data, even in a low-resource
setting. We quantitatively evaluate our approach against state-of-the-art SDG
models, using fidelity, privacy, and utility metrics. Our results show that
while LLMs may not match the performance of state-of-the-art models trained on
the original data, they effectively generate realistic patient data with
well-preserved clinical correlations. An ablation study highlights key elements
of our prompt contributing to high-quality synthetic patient data generation.
This approach, which is easy to use and does not require original data or
advanced ML skills, is particularly valuable for quickly generating
custom-designed patient data, supporting project implementation and providing
educational resources.


## Learning Hidden Physics and System Parameters with Deep Operator Networks

>Authors: Vijay Kag, Dibakar Roy Sarkar, Birupaksha Pal, Somdatta Goswami

>2024-12-06

> http://arxiv.org/abs/2412.05133v1

Big data is transforming scientific progress by enabling the discovery of
novel models, enhancing existing frameworks, and facilitating precise
uncertainty quantification, while advancements in scientific machine learning
complement this by providing powerful tools to solve inverse problems to
identify the complex systems where traditional methods falter due to **sparse** or
noisy data. We introduce two innovative neural operator frameworks tailored for
discovering hidden physics and identifying unknown system parameters from
**sparse** measurements. The first framework integrates a popular neural operator,
DeepONet, and a physics-informed neural network to capture the relationship
between **sparse** data and the underlying physics, enabling the accurate discovery
of a family of governing equations. The second framework focuses on system
parameter identification, leveraging a DeepONet pre-trained on **sparse** sensor
measurements to initialize a physics-constrained inverse model. Both frameworks
excel in handling limited data and preserving physical consistency.
Benchmarking on the Burgers' equation and reaction-diffusion system
demonstrates state-of-the-art performance, achieving average $L_2$ errors of
$\mathcal{O}(10^{-2})$ for hidden physics discovery and absolute errors of
$\mathcal{O}(10^{-3})$ for parameter identification. These results underscore
the frameworks' robustness, efficiency, and potential for solving complex
scientific problems with minimal observational data.


## Towards the interoperability of low-code platforms

>Authors: Iván Alfonso, Aaron Conrardy, Jordi Cabot

>2024-12-06

> http://arxiv.org/abs/2412.05075v1

With the promise of accelerating software development, low-code platforms
(LCPs) are becoming popular across various industries. Nevertheless, there are
still barriers hindering their adoption. Among them, vendor lock-in is a major
concern, especially considering the lack of interoperability between these
platforms. Typically, after modeling an application in one LCP, migrating to
another requires starting from scratch remodeling everything (the data model,
the graphical user interface, workflows, etc.), in the new platform.
  To overcome this situation, this work proposes an approach to improve the
interoperability of LCPs by (semi)automatically migrating models specified in
one platform to another one. The concrete migration path depends on the
capabilities of the source and target tools. We first analyze popular LCPs,
characterize their import and export alternatives and define transformations
between those data formats when available. This is then complemented with an
LLM-based solution, where image recognition features of large language models
are employed to migrate models based on a simple image export of the model at
hand. The full pipelines are implemented on top of the BESSER modeling
framework that acts as a pivot representation between the tools.


## Flash Communication Reducing Tensor Parallelization Bottleneck for Fast Large Language Model Inference

>Authors: Qingyuan Li, Bo Zhang, Liang Ye, Yifan Zhang, Wei Wu, Yerui Sun, Lin Ma, Yuchen Xie

>2024-12-06

> http://arxiv.org/abs/2412.04964v2

The ever-increasing sizes of large language models necessitate distributed
solutions for fast inference that exploit multi-dimensional parallelism, where
computational loads are split across various accelerators such as GPU clusters.
However, this approach often introduces significant communication overhead,
especially on devices with limited bandwidth. In this paper, we introduce Flash
Communication, a novel **low-bit** compression technique designed to alleviate the
tensor-parallelism communication bottleneck during inference. Our method
substantially boosts intra-node communication speed by more than 3x and reduces
the time-to-first-token by 2x, with nearly no sacrifice in model accuracy.
Extensive experiments on various up-to-date LLMs demonstrate the effectiveness
of our approach.


## Continuous Speech Tokens Makes LLMs Robust Multi-Modality Learners

>Authors: Ze Yuan, Yanqing Liu, Shujie Liu, Sheng Zhao

>2024-12-06

> http://arxiv.org/abs/2412.04917v1

Recent advances in GPT-4o like multi-modality models have demonstrated
remarkable progress for direct speech-to-speech conversation, with real-time
speech interaction experience and strong speech understanding ability. However,
current research focuses on discrete speech tokens to align with discrete text
tokens for language modelling, which depends on an audio codec with residual
connections or independent group tokens, such a codec usually leverages large
scale and diverse datasets training to ensure that the discrete speech codes
have good representation for varied domain, noise, style data reconstruction as
well as a well-designed codec **quantize**r and encoder-decoder architecture for
discrete token language modelling. This paper introduces Flow-Omni, a
continuous speech token based GPT-4o like model, capable of real-time speech
interaction and low streaming latency. Specifically, first, instead of
cross-entropy loss only, we combine flow matching loss with a pretrained
autoregressive LLM and a small MLP network to predict the probability
distribution of the continuous-valued speech tokens from speech prompt. second,
we incorporated the continuous speech tokens to Flow-Omni multi-modality
training, thereby achieving robust speech-to-speech performance with discrete
text tokens and continuous speech tokens together. Experiments demonstrate
that, compared to discrete text and speech multi-modality training and its
variants, the continuous speech tokens mitigate robustness issues by avoiding
the inherent flaws of discrete speech code's representation loss for LLM.


## Dynamics of Aggregation Processes and Electrophysical Properties of Transformer Oil-Based Magnetic Fluids

>Authors: Alexander D. Kurilov, Anastasia V. Gubareva, Sergei A. Zubkov, Yulia A. Alekhina, Alexander V. Simakin, Denis N. Chausov

>2024-12-06

> http://arxiv.org/abs/2412.04911v1

Magnetic fluids exhibit tunable structures and electrophysical properties,
making them promising for adaptive optical systems, biomedical sensors, and
microelectromechanical devices. However, the dynamic evolution of their
microstructure under varying magnetic fields remains insufficiently explored.
  This study investigates the structural and dielectric properties of
transformer oil-based magnetic fluids containing 0.2-10 vol% magnetite
nanoparticles, across a frequency range of 20 Hz to 10 MHz. Particular
attention is given to the dynamics of aggregate reorientation in response to
alternating magnetic fields. Experimental results demonstrate that low
nanoparticle concentrations lead to a linear increase in dielectric
permittivity and conductivity, consistent with the Maxwell-Wagner model. In
contrast, higher concentrations exhibit conductivity saturation and dispersion
effects due to the formation of elongated aggregates.
  An analysis based on the Boyle polarization model describes the relaxation
and structural changes associated with aggregation dynamics. Changes in the
magnetic field orientation induce aggregate reconfiguration and significant
structural transformations. At early stages, elongated chains form,
subsequently thickening until an equilibrium state is reached. Elevated
temperatures accelerate these processes by reducing medium viscosity and
aggregate order.
  The findings highlight the critical role of reorientation dynamics in
designing high-speed magnetic sensors, vibration isolation systems, and
adaptive devices operating in dynamic magnetic environments.


## Adaptive Dropout for Pruning Conformers

>Authors: Yotaro Kubo, Xingyu Cai, Michiel Bacchiani

>2024-12-06

> http://arxiv.org/abs/2412.04836v1

This paper proposes a method to effectively perform joint
training-and-**pruning** based on adaptive dropout layers with unit-wise retention
probabilities. The proposed method is based on the estimation of a unit-wise
retention probability in a dropout layer. A unit that is estimated to have a
small retention probability can be considered to be prunable. The retention
probability of the unit is estimated using back-propagation and the
Gumbel-Softmax technique. This **pruning** method is applied at several application
points in Conformers such that the effective number of parameters can be
significantly reduced. Specifically, adaptive dropout layers are introduced in
three locations in each Conformer block: (a) the hidden layer of the
feed-forward-net component, (b) the query vectors and the value vectors of the
self-attention component, and (c) the input vectors of the LConv component. The
proposed method is evaluated by conducting a speech recognition experiment on
the LibriSpeech task. It was shown that this approach could simultaneously
achieve a parameter reduction and accuracy improvement. The word error rates
improved by approx 1% while reducing the number of parameters by 54%.


## Direct Quantized Training of Language Models with Stochastic Rounding

>Authors: Kaiyan Zhao, Tsuguchika Tabaru, Kenichi Kobayashi, Takumi Honda, Masafumi Yamazaki, Yoshimasa Tsuruoka

>2024-12-06

> http://arxiv.org/abs/2412.04787v1

Although recent **quantize**d Large Language Models (LLMs), such as BitNet, have
paved the way for significant reduction in memory usage during deployment with
binary or ternary weights, training these models still demands substantial
memory footprints. This is partly because high-precision (i.e., un**quantize**d)
weight matrices required for straight-through estimation must be maintained
throughout the whole training process. To address this, we explore the
potential of directly updating the **quantize**d low-precision weight matrices
without relying on the straight-through estimator during backpropagation,
thereby saving memory usage during training. Specifically, we employ a
stochastic rounding technique to minimize information loss caused by the use of
**low-bit** weights throughout training. Experimental results on our
LLaMA-structured models indicate that (1) training with only low-precision
weights is feasible even when they are constrained to ternary values, (2)
extending the bit width to 8 bits results in only a 5% loss degradation
compared to BitNet b1.58 while offering the potential for reduced memory usage
during training, and (3) our models can also perform inference using ternary
weights, showcasing their flexibility in deployment.


## IterNorm Fast Iterative Normalization

>Authors: ChangMin Ye, Yonguk Sim, Youngchae Kim, SeongMin Jin, Doo Seok Jeong

>2024-12-06

> http://arxiv.org/abs/2412.04778v1

Transformer-based large language models are a memory-bound model whose
operation is based on a large amount of data that are marginally reused. Thus,
the data movement between a host and accelerator likely dictates the total
wall-clock time. Layer normalization is one of the key workloads in the
transformer model, following each of multi-head attention and feed-forward
network blocks. To reduce data movement, layer normalization needs to be
performed on the same chip as the matrix-matrix multiplication engine. To this
end, we introduce an iterative L2-normalization method for 1D input (IterNorm),
ensuring fast convergence to the steady-state solution within five iteration
steps and high precision, outperforming the fast inverse square root algorithm
in six out of nine cases for FP32 and five out of nine for BFloat16 across the
embedding lengths used in the OPT models. Implemented in 32/28nm CMOS, the
IterNorm macro normalizes $d$-dimensional vectors, where $64 \leq d \leq 1024$,
with a latency of 112-227 cycles at 100MHz/1.05V.


## Ltri-LLM Streaming Long Context Inference for LLMs with Training-Free Dynamic Triangular Attention Pattern

>Authors: Hongyin Tang, Di Xiu, Lanrui Wang, Xiurui Geng, Jingang Wang, Xunliang Cai

>2024-12-06

> http://arxiv.org/abs/2412.04757v1

The quadratic computational complexity of the attention mechanism in current
Large Language Models (LLMs) renders inference with long contexts prohibitively
expensive. To address this challenge, various approaches aim to retain critical
portions of the context to optimally approximate Full Attention (FA) through
Key-Value (**KV**) compression or Sparse Attention (SA), enabling the processing of
virtually unlimited text lengths in a streaming manner. However, these methods
struggle to achieve performance levels comparable to FA, particularly in
retrieval tasks. In this paper, our analysis of attention head patterns reveals
that LLMs' attention distributions show strong local correlations, naturally
reflecting a chunking mechanism for input context. We propose Ltri-LLM
framework, which divides **KV**s into spans, stores them in an offline index, and
retrieves the relevant **KV**s into memory for various queries. Experimental
results on popular long text benchmarks show that Ltri-LLM can achieve
performance close to FA while maintaining efficient, streaming-based inference.

