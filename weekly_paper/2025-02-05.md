# 2025-02-05

# Table of Contents
* [Cache Me If You Must Adaptive Key-Value Quantization for Large Language Models](#Cache-Me-If-You-Must-Adaptive-Key-Value-Quantization-for-Large-Language-Models)
* [Low-cost Microfluidic Testbed for Molecular Communications with Integrated Hydrodynamic Gating and Screen-printed Sensors](#Low-cost-Microfluidic-Testbed-for-Molecular-Communications-with-Integrated-Hydrodynamic-Gating-and-Screen-printed-Sensors)
* [PixelWorld Towards Perceiving Everything as Pixels](#PixelWorld-Towards-Perceiving-Everything-as-Pixels)
* [Judge Decoding Faster Speculative Sampling Requires Going Beyond Model Alignment](#Judge-Decoding-Faster-Speculative-Sampling-Requires-Going-Beyond-Model-Alignment)
* [Multi-beam-energy control unit based on triple bend achromats](#Multi-beam-energy-control-unit-based-on-triple-bend-achromats)
* [Accelerating Diffusion Transformer via Error-Optimized Cache](#Accelerating-Diffusion-Transformer-via-Error-Optimized-Cache)
* [A Zero-Shot Generalization Framework for LLM-Driven Cross-Domain Sequential Recommendation](#A-Zero-Shot-Generalization-Framework-for-LLM-Driven-Cross-Domain-Sequential-Recommendation)
* [A Tensor-Train Decomposition based Compression of LLMs on Group Vector Systolic Accelerator](#A-Tensor-Train-Decomposition-based-Compression-of-LLMs-on-Group-Vector-Systolic-Accelerator)
* [Brain-inspired sparse training enables Transformers and LLMs to perform as fully connected](#Brain-inspired-sparse-training-enables-Transformers-and-LLMs-to-perform-as-fully-connected)
* [Unraveling Zeroth-Order Optimization through the Lens of Low-Dimensional Structured Perturbations](#Unraveling-Zeroth-Order-Optimization-through-the-Lens-of-Low-Dimensional-Structured-Perturbations)
* [$\infty$-Video A Training-Free Approach to Long Video Understanding via Continuous-Time Memory Consolidation](#$\infty$-Video-A-Training-Free-Approach-to-Long-Video-Understanding-via-Continuous-Time-Memory-Consolidation)
* [Pivoting Factorization A Compact Meta Low-Rank Representation of Sparsity for Efficient Inference in Large Language Models](#Pivoting-Factorization-A-Compact-Meta-Low-Rank-Representation-of-Sparsity-for-Efficient-Inference-in-Large-Language-Models)
* [Importing Phantoms Measuring LLM Package Hallucination Vulnerabilities](#Importing-Phantoms-Measuring-LLM-Package-Hallucination-Vulnerabilities)
* [TV-Dialogue Crafting Theme-Aware Video Dialogues with Immersive Interaction](#TV-Dialogue-Crafting-Theme-Aware-Video-Dialogues-with-Immersive-Interaction)
* [From Bits to Qubits Challenges in Classical-Quantum Integration](#From-Bits-to-Qubits-Challenges-in-Classical-Quantum-Integration)
* [Can We Predict the Effect of Prompts?](#Can-We-Predict-the-Effect-of-Prompts?)
* [Partially Rewriting a Transformer in Natural Language](#Partially-Rewriting-a-Transformer-in-Natural-Language)
* [Transcoders Beat Sparse Autoencoders for Interpretability](#Transcoders-Beat-Sparse-Autoencoders-for-Interpretability)
* [Survey and Improvement Strategies for Gene Prioritization with Large Language Models](#Survey-and-Improvement-Strategies-for-Gene-Prioritization-with-Large-Language-Models)
* [RUN Reversible Unfolding Network for Concealed Object Segmentation](#RUN-Reversible-Unfolding-Network-for-Concealed-Object-Segmentation)
* [Strong and Controllable 3D Motion Generation](#Strong-and-Controllable-3D-Motion-Generation)
* [Deep learning with reflection high-energy electron diffraction images to predict cation ratio in Sr$_x$Ti$_{1-x}$O3 thin films](#Deep-learning-with-reflection-high-energy-electron-diffraction-images-to-predict-cation-ratio-in-Sr$_x$Ti$_{1-x}$O3-thin-films)
* [Streaming DiLoCo with overlapping communication Towards a Distributed Free Lunch](#Streaming-DiLoCo-with-overlapping-communication-Towards-a-Distributed-Free-Lunch)
* [CLoQ Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization](#CLoQ-Enhancing-Fine-Tuning-of-Quantized-LLMs-via-Calibrated-LoRA-Initialization)
* [SANA 1.5 Efficient Scaling of Training-Time and Inference-Time Compute in Linear Diffusion Transformer](#SANA-1.5-Efficient-Scaling-of-Training-Time-and-Inference-Time-Compute-in-Linear-Diffusion-Transformer)
* [CodeBrain Impute Any Brain MRI via Instance-specific Scalar-quantized Codes](#CodeBrain-Impute-Any-Brain-MRI-via-Instance-specific-Scalar-quantized-Codes)
* [Decentralised convex optimisation with probability-proportional-to-size quantization](#Decentralised-convex-optimisation-with-probability-proportional-to-size-quantization)
* [Leveraging Sparsity for Sample-Efficient Preference Learning A Theoretical Perspective](#Leveraging-Sparsity-for-Sample-Efficient-Preference-Learning-A-Theoretical-Perspective)
* [Mixed-Precision Graph Neural Quantization for Low Bit Large Language Models](#Mixed-Precision-Graph-Neural-Quantization-for-Low-Bit-Large-Language-Models)
* [Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models](#Self-supervised-Quantized-Representation-for-Seamlessly-Integrating-Knowledge-Graphs-with-Large-Language-Models)
* [AlphaAdamAsynchronous Masked Optimization with Dynamic Alpha for Selective Updates](#AlphaAdamAsynchronous-Masked-Optimization-with-Dynamic-Alpha-for-Selective-Updates)
* [Large Language Models Think Too Fast To Explore Effectively](#Large-Language-Models-Think-Too-Fast-To-Explore-Effectively)
* [The Numerical Approximation of Caputo Fractional Derivative of Higher Orders Using A Shifted Gegenbauer Pseudospectral Method Two-Point Boundary Value Problems of the Bagley Torvik Type Case Study](#The-Numerical-Approximation-of-Caputo-Fractional-Derivative-of-Higher-Orders-Using-A-Shifted-Gegenbauer-Pseudospectral-Method-Two-Point-Boundary-Value-Problems-of-the-Bagley-Torvik-Type-Case-Study)
* [Matrix Product Sketching via Coordinated Sampling](#Matrix-Product-Sketching-via-Coordinated-Sampling)
* [Aggregation Schemes for Single-Vector WSI Representation Learning in Digital Pathology](#Aggregation-Schemes-for-Single-Vector-WSI-Representation-Learning-in-Digital-Pathology)
* [2SSP A Two-Stage Framework for Structured Pruning of LLMs](#2SSP-A-Two-Stage-Framework-for-Structured-Pruning-of-LLMs)
* [Hybrid Graphs for Table-and-Text based Question Answering using LLMs](#Hybrid-Graphs-for-Table-and-Text-based-Question-Answering-using-LLMs)
* [Sparse Autoencoders Can Interpret Randomly Initialized Transformers](#Sparse-Autoencoders-Can-Interpret-Randomly-Initialized-Transformers)
* [DReSS Data-driven Regularized Structured Streamlining for Large Language Models](#DReSS-Data-driven-Regularized-Structured-Streamlining-for-Large-Language-Models)
* [Analysis of the Motion Sickness and the Lack of Comfort in Car Passengers](#Analysis-of-the-Motion-Sickness-and-the-Lack-of-Comfort-in-Car-Passengers)
* [Shared DIFF Transformer](#Shared-DIFF-Transformer)
* [Byzantine-Robust Federated Learning over Ring-All-Reduce Distributed Computing](#Byzantine-Robust-Federated-Learning-over-Ring-All-Reduce-Distributed-Computing)
* [Dynamical Shortcomings in the Generalized SU(2) Proca Theory Challenges for Cosmic Acceleration](#Dynamical-Shortcomings-in-the-Generalized-SU(2)-Proca-Theory-Challenges-for-Cosmic-Acceleration)
* [ViT-2SPN Vision Transformer-based Dual-Stream Self-Supervised Pretraining Networks for Retinal OCT Classification](#ViT-2SPN-Vision-Transformer-based-Dual-Stream-Self-Supervised-Pretraining-Networks-for-Retinal-OCT-Classification)
* [Optimizing Large Language Model Training Using FP4 Quantization](#Optimizing-Large-Language-Model-Training-Using-FP4-Quantization)
* [Wormholes, branes and finite matrices in sine dilaton gravity](#Wormholes,-branes-and-finite-matrices-in-sine-dilaton-gravity)
* [Graph of Attacks with Pruning Optimizing Stealthy Jailbreak Prompt Generation for Enhanced LLM Content Moderation](#Graph-of-Attacks-with-Pruning-Optimizing-Stealthy-Jailbreak-Prompt-Generation-for-Enhanced-LLM-Content-Moderation)
* [Graph Transformers for inverse physics reconstructing flows around arbitrary 2D airfoils](#Graph-Transformers-for-inverse-physics-reconstructing-flows-around-arbitrary-2D-airfoils)
* [Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver](#Generative-quantum-combinatorial-optimization-by-means-of-a-novel-conditional-generative-quantum-eigensolver)
* [Bones of Contention Exploring Query-Efficient Attacks Against Skeleton Recognition Systems](#Bones-of-Contention-Exploring-Query-Efficient-Attacks-Against-Skeleton-Recognition-Systems)
* [Not Every Patch is Needed Towards a More Efficient and Effective Backbone for Video-based Person Re-identification](#Not-Every-Patch-is-Needed-Towards-a-More-Efficient-and-Effective-Backbone-for-Video-based-Person-Re-identification)
* [Post-Training Quantization for Vision Mamba with k-Scaled Quantization and Reparameterization](#Post-Training-Quantization-for-Vision-Mamba-with-k-Scaled-Quantization-and-Reparameterization)
* [On the acceleration of gradient methods the triangle steepest descent method](#On-the-acceleration-of-gradient-methods-the-triangle-steepest-descent-method)
* [Point Cloud Upsampling as Statistical Shape Model for Pelvic](#Point-Cloud-Upsampling-as-Statistical-Shape-Model-for-Pelvic)
* [Image-Space Gridding for Nonrigid Motion-Corrected MR Image Reconstruction](#Image-Space-Gridding-for-Nonrigid-Motion-Corrected-MR-Image-Reconstruction)
* [Variational Schrödinger Momentum Diffusion](#Variational-Schrödinger-Momentum-Diffusion)
* [VeriFact Verifying Facts in LLM-Generated Clinical Text with Electronic Health Records](#VeriFact-Verifying-Facts-in-LLM-Generated-Clinical-Text-with-Electronic-Health-Records)
* [Large Language Model Critics for Execution-Free Evaluation of Code Changes](#Large-Language-Model-Critics-for-Execution-Free-Evaluation-of-Code-Changes)
* [Sparse Autoencoders Trained on the Same Data Learn Different Features](#Sparse-Autoencoders-Trained-on-the-Same-Data-Learn-Different-Features)
* [Efficient evaluation of real-time path integrals](#Efficient-evaluation-of-real-time-path-integrals)
* [Mixture-of-Mamba Enhancing Multi-Modal State-Space Models with Modality-Aware Sparsity](#Mixture-of-Mamba-Enhancing-Multi-Modal-State-Space-Models-with-Modality-Aware-Sparsity)
* [Provence efficient and robust context pruning for retrieval-augmented generation](#Provence-efficient-and-robust-context-pruning-for-retrieval-augmented-generation)
* [MILP initialization for solving parabolic PDEs with PINNs](#MILP-initialization-for-solving-parabolic-PDEs-with-PINNs)
* [SampleLLM Optimizing Tabular Data Synthesis in Recommendations](#SampleLLM-Optimizing-Tabular-Data-Synthesis-in-Recommendations)
* [One-Bit Sigma-Delta DFRC Waveform Design Using Quantization Noise for Radar Probing](#One-Bit-Sigma-Delta-DFRC-Waveform-Design-Using-Quantization-Noise-for-Radar-Probing)
* [Information Consistent Pruning How to Efficiently Search for Sparse Networks?](#Information-Consistent-Pruning-How-to-Efficiently-Search-for-Sparse-Networks?)
* [ARWKV Pretrain is not what we need, an RNN-Attention-Based Language Model Born from Transformer](#ARWKV-Pretrain-is-not-what-we-need,-an-RNN-Attention-Based-Language-Model-Born-from-Transformer)
* [Improving Network Threat Detection by Knowledge Graph, Large Language Model, and Imbalanced Learning](#Improving-Network-Threat-Detection-by-Knowledge-Graph,-Large-Language-Model,-and-Imbalanced-Learning)
* [Semantic Communication with Entropy-and-Channel-Adaptive Rate Control](#Semantic-Communication-with-Entropy-and-Channel-Adaptive-Rate-Control)
* [MetaOcc Surround-View 4D Radar and Camera Fusion Framework for 3D Occupancy Prediction with Dual Training Strategies](#MetaOcc-Surround-View-4D-Radar-and-Camera-Fusion-Framework-for-3D-Occupancy-Prediction-with-Dual-Training-Strategies)
* [Qwen2.5-1M Technical Report](#Qwen2.5-1M-Technical-Report)
* [Scaling Large Vision-Language Models for Enhanced Multimodal Comprehension In Biomedical Image Analysis](#Scaling-Large-Vision-Language-Models-for-Enhanced-Multimodal-Comprehension-In-Biomedical-Image-Analysis)
* [Decentralized Low-Rank Fine-Tuning of Large Language Models](#Decentralized-Low-Rank-Fine-Tuning-of-Large-Language-Models)
* [ToMoE Converting Dense Large Language Models to Mixture-of-Experts through Dynamic Structural Pruning](#ToMoE-Converting-Dense-Large-Language-Models-to-Mixture-of-Experts-through-Dynamic-Structural-Pruning)
* [You Only Prune Once Designing Calibration-Free Model Compression With Policy Learning](#You-Only-Prune-Once-Designing-Calibration-Free-Model-Compression-With-Policy-Learning)
* [PIP Perturbation-based Iterative Pruning for Large Language Models](#PIP-Perturbation-based-Iterative-Pruning-for-Large-Language-Models)
* [Exploring the Collaborative Co-Creation Process with AI A Case Study in Novice Music Production](#Exploring-the-Collaborative-Co-Creation-Process-with-AI-A-Case-Study-in-Novice-Music-Production)
* [Inductive Biases for Zero-shot Systematic Generalization in Language-informed Reinforcement Learning](#Inductive-Biases-for-Zero-shot-Systematic-Generalization-in-Language-informed-Reinforcement-Learning)
* [Lightweight and Post-Training Structured Pruning for On-Device Large Lanaguage Models](#Lightweight-and-Post-Training-Structured-Pruning-for-On-Device-Large-Lanaguage-Models)
* [ABXI Invariant Interest Adaptation for Task-Guided Cross-Domain Sequential Recommendation](#ABXI-Invariant-Interest-Adaptation-for-Task-Guided-Cross-Domain-Sequential-Recommendation)
* [Task-KV Task-aware KV Cache Optimization via Semantic Differentiation of Attention Heads](#Task-KV-Task-aware-KV-Cache-Optimization-via-Semantic-Differentiation-of-Attention-Heads)
* [FBQuant FeedBack Quantization for Large Language Models](#FBQuant-FeedBack-Quantization-for-Large-Language-Models)
* [CG-RAG Research Question Answering by Citation Graph Retrieval-Augmented LLMs](#CG-RAG-Research-Question-Answering-by-Citation-Graph-Retrieval-Augmented-LLMs)
* [OptiSeq Optimizing Example Ordering for In-Context Learning](#OptiSeq-Optimizing-Example-Ordering-for-In-Context-Learning)
* [AKVQ-VL Attention-Aware KV Cache Adaptive 2-Bit Quantization for Vision-Language Models](#AKVQ-VL-Attention-Aware-KV-Cache-Adaptive-2-Bit-Quantization-for-Vision-Language-Models)
* [RotateKV Accurate and Robust 2-Bit KV Cache Quantization for LLMs via Outlier-Aware Adaptive Rotations](#RotateKV-Accurate-and-Robust-2-Bit-KV-Cache-Quantization-for-LLMs-via-Outlier-Aware-Adaptive-Rotations)
* [Light3R-SfM Towards Feed-forward Structure-from-Motion](#Light3R-SfM-Towards-Feed-forward-Structure-from-Motion)
* [FlexiGPT Pruning and Extending Large Language Models with Low-Rank Weight Sharing](#FlexiGPT-Pruning-and-Extending-Large-Language-Models-with-Low-Rank-Weight-Sharing)
* [GraPPI A Retrieve-Divide-Solve GraphRAG Framework for Large-scale Protein-protein Interaction Exploration](#GraPPI-A-Retrieve-Divide-Solve-GraphRAG-Framework-for-Large-scale-Protein-protein-Interaction-Exploration)
* [Predictor-Feedback Stabilization of Globally Lipschitz Nonlinear Systems with State and Input Quantization](#Predictor-Feedback-Stabilization-of-Globally-Lipschitz-Nonlinear-Systems-with-State-and-Input-Quantization)
* [Real-world Edge Neural Network Implementations Leak Private Interactions Through Physical Side Channel](#Real-world-Edge-Neural-Network-Implementations-Leak-Private-Interactions-Through-Physical-Side-Channel)
* [Advancing data-driven broadband seismic wavefield simulation with multi-conditional diffusion model](#Advancing-data-driven-broadband-seismic-wavefield-simulation-with-multi-conditional-diffusion-model)
* [Fast Think-on-Graph Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph](#Fast-Think-on-Graph-Wider,-Deeper-and-Faster-Reasoning-of-Large-Language-Model-on-Knowledge-Graph)
* [Dense-SfM Structure from Motion with Dense Consistent Matching](#Dense-SfM-Structure-from-Motion-with-Dense-Consistent-Matching)
* [Dynamic Token Reduction during Generation for Vision Language Models](#Dynamic-Token-Reduction-during-Generation-for-Vision-Language-Models)
* [HWPQ Hessian-free Weight Pruning-Quantization For LLM Compression And Acceleration](#HWPQ-Hessian-free-Weight-Pruning-Quantization-For-LLM-Compression-And-Acceleration)
* [VarDrop Enhancing Training Efficiency by Reducing Variate Redundancy in Periodic Time Series Forecasting](#VarDrop-Enhancing-Training-Efficiency-by-Reducing-Variate-Redundancy-in-Periodic-Time-Series-Forecasting)
* [WaveMax Radar Waveform Design via Convex Maximization of FrFT Phase Retrieval](#WaveMax-Radar-Waveform-Design-via-Convex-Maximization-of-FrFT-Phase-Retrieval)
* [EFiGP Eigen-Fourier Physics-Informed Gaussian Process for Inference of Dynamic Systems](#EFiGP-Eigen-Fourier-Physics-Informed-Gaussian-Process-for-Inference-of-Dynamic-Systems)
* [High-intensity wave vortices around subwavelength holes from ocean tides to nanooptics](#High-intensity-wave-vortices-around-subwavelength-holes-from-ocean-tides-to-nanooptics)
* [Where Do You Go? Pedestrian Trajectory Prediction using Scene Features](#Where-Do-You-Go?-Pedestrian-Trajectory-Prediction-using-Scene-Features)
* [An Efficient Diffusion-based Non-Autoregressive Solver for Traveling Salesman Problem](#An-Efficient-Diffusion-based-Non-Autoregressive-Solver-for-Traveling-Salesman-Problem)
* [On Disentangled Training for Nonlinear Transform in Learned Image Compression](#On-Disentangled-Training-for-Nonlinear-Transform-in-Learned-Image-Compression)
* [LVPruning An Effective yet Simple Language-Guided Vision Token Pruning Approach for Multi-modal Large Language Models](#LVPruning-An-Effective-yet-Simple-Language-Guided-Vision-Token-Pruning-Approach-for-Multi-modal-Large-Language-Models)
* [Sigma Differential Rescaling of Query, Key and Value for Efficient Language Models](#Sigma-Differential-Rescaling-of-Query,-Key-and-Value-for-Efficient-Language-Models)
* [QMamba Post-Training Quantization for Vision State Space Models](#QMamba-Post-Training-Quantization-for-Vision-State-Space-Models)
* [Compiler Support for Speculation in Decoupled Access/Execute Architectures](#Compiler-Support-for-Speculation-in-Decoupled-Access/Execute-Architectures)
* [Diffusion-based Perceptual Neural Video Compression with Temporal Diffusion Information Reuse](#Diffusion-based-Perceptual-Neural-Video-Compression-with-Temporal-Diffusion-Information-Reuse)
* [A Parallel Block Preconditioner-Based VIE-FFT Algorithm for Modeling the Electromagnetic Response From Nanostructures](#A-Parallel-Block-Preconditioner-Based-VIE-FFT-Algorithm-for-Modeling-the-Electromagnetic-Response-From-Nanostructures)
* [MambaQuant Quantizing the Mamba Family with Variance Aligned Rotation Methods](#MambaQuant-Quantizing-the-Mamba-Family-with-Variance-Aligned-Rotation-Methods)
* [FreEformer Frequency Enhanced Transformer for Multivariate Time Series Forecasting](#FreEformer-Frequency-Enhanced-Transformer-for-Multivariate-Time-Series-Forecasting)
* [OstQuant Refining Large Language Model Quantization with Orthogonal and Scaling Transformations for Better Distribution Fitting](#OstQuant-Refining-Large-Language-Model-Quantization-with-Orthogonal-and-Scaling-Transformations-for-Better-Distribution-Fitting)
* [Unveiling Discrete Clues Superior Healthcare Predictions for Rare Diseases](#Unveiling-Discrete-Clues-Superior-Healthcare-Predictions-for-Rare-Diseases)
* [Qrazor Reliable and effortless 4-bit llm quantization by significant data razoring](#Qrazor-Reliable-and-effortless-4-bit-llm-quantization-by-significant-data-razoring)
* [OSUM Advancing Open Speech Understanding Models with Limited Resources in Academia](#OSUM-Advancing-Open-Speech-Understanding-Models-with-Limited-Resources-in-Academia)
* [Hypothesis Generation for Materials Discovery and Design Using Goal-Driven and Constraint-Guided LLM Agents](#Hypothesis-Generation-for-Materials-Discovery-and-Design-Using-Goal-Driven-and-Constraint-Guided-LLM-Agents)
* [SRMT Shared Memory for Multi-agent Lifelong Pathfinding](#SRMT-Shared-Memory-for-Multi-agent-Lifelong-Pathfinding)
* [Accelerate High-Quality Diffusion Models with Inner Loop Feedback](#Accelerate-High-Quality-Diffusion-Models-with-Inner-Loop-Feedback)
* [Attention-Driven Hierarchical Reinforcement Learning with Particle Filtering for Source Localization in Dynamic Fields](#Attention-Driven-Hierarchical-Reinforcement-Learning-with-Particle-Filtering-for-Source-Localization-in-Dynamic-Fields)
* [Efficient Prompt Compression with Evaluator Heads for Long-Context Transformer Inference](#Efficient-Prompt-Compression-with-Evaluator-Heads-for-Long-Context-Transformer-Inference)
* [GANQ GPU-Adaptive Non-Uniform Quantization for Large Language Models](#GANQ-GPU-Adaptive-Non-Uniform-Quantization-for-Large-Language-Models)
* [Computational modelling of biological systems now and then revisiting tools and visions from the beginning of the century](#Computational-modelling-of-biological-systems-now-and-then-revisiting-tools-and-visions-from-the-beginning-of-the-century)
* [Unified CNNs and transformers underlying learning mechanism reveals multi-head attention modus vivendi](#Unified-CNNs-and-transformers-underlying-learning-mechanism-reveals-multi-head-attention-modus-vivendi)
* [Regularization, Semi-supervision, and Supervision for a Plausible Attention-Based Explanation](#Regularization,-Semi-supervision,-and-Supervision-for-a-Plausible-Attention-Based-Explanation)
* [Applications and Challenges of AI and Microscopy in Life Science Research A Review](#Applications-and-Challenges-of-AI-and-Microscopy-in-Life-Science-Research-A-Review)
* [High-efficient machine learning projection method for incompressible Navier-Stokes equations](#High-efficient-machine-learning-projection-method-for-incompressible-Navier-Stokes-equations)
* [DWTNeRF Boosting Few-shot Neural Radiance Fields via Discrete Wavelet Transform](#DWTNeRF-Boosting-Few-shot-Neural-Radiance-Fields-via-Discrete-Wavelet-Transform)
* [SoMa Identifying, Exploring, and Understanding the DRAM Communication Scheduling Space for DNN Accelerators](#SoMa-Identifying,-Exploring,-and-Understanding-the-DRAM-Communication-Scheduling-Space-for-DNN-Accelerators)
* [BLR-MoE Boosted Language-Routing Mixture of Experts for Domain-Robust Multilingual E2E ASR](#BLR-MoE-Boosted-Language-Routing-Mixture-of-Experts-for-Domain-Robust-Multilingual-E2E-ASR)
* [Academic Case Reports Lack Diversity Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related to Post COVID-19 Condition](#Academic-Case-Reports-Lack-Diversity-Assessing-the-Presence-and-Diversity-of-Sociodemographic-and-Behavioral-Factors-related-to-Post-COVID-19-Condition)
* [The Journey Matters Average Parameter Count over Pre-training Unifies Sparse and Dense Scaling Laws](#The-Journey-Matters-Average-Parameter-Count-over-Pre-training-Unifies-Sparse-and-Dense-Scaling-Laws)
* [Parallel Sequence Modeling via Generalized Spatial Propagation Network](#Parallel-Sequence-Modeling-via-Generalized-Spatial-Propagation-Network)
* [Efficient Algorithm for Sparse Fourier Transform of Generalized q-ary Functions](#Efficient-Algorithm-for-Sparse-Fourier-Transform-of-Generalized-q-ary-Functions)
* [Dissecting the NVIDIA Hopper Architecture through Microbenchmarking and Multiple Level Analysis](#Dissecting-the-NVIDIA-Hopper-Architecture-through-Microbenchmarking-and-Multiple-Level-Analysis)
* [Combinatorics on bi-$γ$-positivity of $1/k$-Eulerian polynomials](#Combinatorics-on-bi-$γ$-positivity-of-$1/k$-Eulerian-polynomials)
* [Rate-Aware Learned Speech Compression](#Rate-Aware-Learned-Speech-Compression)
* [SMamba Sparse Mamba for Event-based Object Detection](#SMamba-Sparse-Mamba-for-Event-based-Object-Detection)
* [Phase Transitions in Phase-Only Compressed Sensing](#Phase-Transitions-in-Phase-Only-Compressed-Sensing)
* [Coarse-to-Fine Lightweight Meta-Embedding for ID-Based Recommendation](#Coarse-to-Fine-Lightweight-Meta-Embedding-for-ID-Based-Recommendation)
* [Geometrical scheduling of adiabatic control without information of energy spectra](#Geometrical-scheduling-of-adiabatic-control-without-information-of-energy-spectra)
* [Keypoint Detection Empowered Near-Field User Localization and Channel Reconstruction](#Keypoint-Detection-Empowered-Near-Field-User-Localization-and-Channel-Reconstruction)
* [Large Language Models with Human-In-The-Loop Validation for Systematic Review Data Extraction](#Large-Language-Models-with-Human-In-The-Loop-Validation-for-Systematic-Review-Data-Extraction)
* [Glinthawk A Two-Tiered Architecture for High-Throughput LLM Inference](#Glinthawk-A-Two-Tiered-Architecture-for-High-Throughput-LLM-Inference)
* [Efficient Bearing Sensor Data Compression via an Asymmetrical Autoencoder with a Lifting Wavelet Transform Layer](#Efficient-Bearing-Sensor-Data-Compression-via-an-Asymmetrical-Autoencoder-with-a-Lifting-Wavelet-Transform-Layer)
* [Industrial Upgrading and New Quality Productive Forces Evidence from China's Provincial Panel Data (2003-2022)](#Industrial-Upgrading-and-New-Quality-Productive-Forces-Evidence-from-China's-Provincial-Panel-Data-(2003-2022))
* [Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing](#Training-free-Ultra-Small-Model-for-Universal-Sparse-Reconstruction-in-Compressed-Sensing)
* [Open Sourcing GPTs Economics of Open Sourcing Advanced AI Models](#Open-Sourcing-GPTs-Economics-of-Open-Sourcing-Advanced-AI-Models)
* [Meta-Instance Selection. Instance Selection as a Classification Problem with Meta-Features](#Meta-Instance-Selection.-Instance-Selection-as-a-Classification-Problem-with-Meta-Features)
* [Curiosity-Driven Reinforcement Learning from Human Feedback](#Curiosity-Driven-Reinforcement-Learning-from-Human-Feedback)
* [Practical Modulo Sampling Mitigating High-Frequency Components](#Practical-Modulo-Sampling-Mitigating-High-Frequency-Components)
* [Direct ab initio calculation of magnons in altermagnets method, spin-space symmetry aspects, and application to MnTe](#Direct-ab-initio-calculation-of-magnons-in-altermagnets-method,-spin-space-symmetry-aspects,-and-application-to-MnTe)
* [Hybrid Photonic-digital Accelerator for Attention Mechanism](#Hybrid-Photonic-digital-Accelerator-for-Attention-Mechanism)
* [Spin-phonon coupling and thermal Hall effect in Kitaev spin liquid](#Spin-phonon-coupling-and-thermal-Hall-effect-in-Kitaev-spin-liquid)
* [Sparse L0-norm based Kernel-free Quadratic Surface Support Vector Machines](#Sparse-L0-norm-based-Kernel-free-Quadratic-Surface-Support-Vector-Machines)
* [Playing the Lottery With Concave Regularizers for Sparse Trainable Neural Networks](#Playing-the-Lottery-With-Concave-Regularizers-for-Sparse-Trainable-Neural-Networks)
* [LF-Steering Latent Feature Activation Steering for Enhancing Semantic Consistency in Large Language Models](#LF-Steering-Latent-Feature-Activation-Steering-for-Enhancing-Semantic-Consistency-in-Large-Language-Models)
* [FSMoE A Flexible and Scalable Training System for Sparse Mixture-of-Experts Models](#FSMoE-A-Flexible-and-Scalable-Training-System-for-Sparse-Mixture-of-Experts-Models)
* [Unveiling the Mystery of Weight in Large Foundation Models Gaussian Distribution Never Fades](#Unveiling-the-Mystery-of-Weight-in-Large-Foundation-Models-Gaussian-Distribution-Never-Fades)
* [LUT-DLA Lookup Table as Efficient Extreme Low-Bit Deep Learning Accelerator](#LUT-DLA-Lookup-Table-as-Efficient-Extreme-Low-Bit-Deep-Learning-Accelerator)
* [Scalable Machine Learning Training Infrastructure for Online Ads Recommendation and Auction Scoring Modeling at Google](#Scalable-Machine-Learning-Training-Infrastructure-for-Online-Ads-Recommendation-and-Auction-Scoring-Modeling-at-Google)
* [4bit-Quantization in Vector-Embedding for RAG](#4bit-Quantization-in-Vector-Embedding-for-RAG)
* [Dynamical response of noncollinear spin systems at constrained magnetic moments](#Dynamical-response-of-noncollinear-spin-systems-at-constrained-magnetic-moments)
* [ACCEPT Diagnostic Forecasting of Battery Degradation Through Contrastive Learning](#ACCEPT-Diagnostic-Forecasting-of-Battery-Degradation-Through-Contrastive-Learning)
* [Accelerating Large Language Models through Partially Linear Feed-Forward Network](#Accelerating-Large-Language-Models-through-Partially-Linear-Feed-Forward-Network)
* [AIRCHITECT v2 Learning the Hardware Accelerator Design Space through Unified Representations](#AIRCHITECT-v2-Learning-the-Hardware-Accelerator-Design-Space-through-Unified-Representations)
* [MultiPruner Balanced Structure Removal in Foundation Models](#MultiPruner-Balanced-Structure-Removal-in-Foundation-Models)
* [AI Explainability for Power Electronics From a Lipschitz Continuity Perspective](#AI-Explainability-for-Power-Electronics-From-a-Lipschitz-Continuity-Perspective)
* [Steering Large Language Models with Feature Guided Activation Additions](#Steering-Large-Language-Models-with-Feature-Guided-Activation-Additions)
* [Quantum field theory on curved manifolds](#Quantum-field-theory-on-curved-manifolds)


## Cache Me If You Must Adaptive Key-Value Quantization for Large Language Models

>Authors: Alina Shutova, Vladimir Malinovskii, Vage Egiazarian, Denis Kuznedelev, Denis Mazur, Nikita Surkov, Ivan Ermakov, Dan Alistarh

>2025-01-31

> http://arxiv.org/abs/2501.19392v1

Efficient real-world deployments of large language models (LLMs) rely on
Key-Value (**KV**) caching for processing and generating long outputs, reducing the
need for repetitive computation. For large contexts, Key-Value caches can take
up tens of gigabytes of device memory, as they store vector representations for
each token and layer. Recent work has shown that the cached vectors can be
compressed through **quantization**, **pruning** or merging, but these techniques often
compromise quality towards higher compression rates. In this work, we aim to
improve Key & Value compression by exploiting two observations: 1) the inherent
dependencies between keys and values across different layers, and 2)
high-compression mechanisms for internal network states. We propose AQUA-**KV**, an
adaptive **quantization** for Key-Value caches that relies on compact adapters to
exploit existing dependencies between Keys and Values, and aims to "optimally"
compress the information that cannot be predicted. AQUA-**KV** significantly
improves compression rates, while maintaining high accuracy on state-of-the-art
LLM families. On Llama 3.2 LLMs, we achieve near-lossless inference at 2-2.5
bits per value with under $1\%$ relative error in perplexity and LongBench
scores. AQUA-**KV** is one-shot, simple, and efficient: it can be calibrated on a
single GPU within 1-6 hours, even for 70B models.


## Low-cost Microfluidic Testbed for Molecular Communications with Integrated Hydrodynamic Gating and Screen-printed Sensors

>Authors: Maide Miray Albay, Eren Akyol, Fariborz Mirlou, Levent Beker, Murat Kuscu

>2025-01-31

> http://arxiv.org/abs/2501.19341v1

Molecular Communications (MC), transferring information via chemical signals,
holds promise for transformative healthcare applications within the Internet of
Bio-Nano Things (IoBNT) framework. Despite promising advances toward practical
MC systems, progress has been constrained by experimental testbeds that are
costly, difficult to customize, and require labor-intensive fabrication. Here,
we address these challenges by introducing a low-cost ($\sim$\$1 per unit),
rapidly fabricated ($<$1 hour), and highly customizable microfluidic testbed
that integrates hydrodynamic gating and screen-printed potentiometric sensors.
This platform enables precise spatiotemporal control over chemical signals and
supports reconfigurable channel architectures along with on-demand sensor
functionalization. As a proof of concept, we demonstrate a pH-based MC system
combining a polyaniline (PANI)-functionalized sensor for real-time signal
detection with a programmable hydrodynamic gating architecture, patterned in a
double-sided adhesive tape, as the transmitter. By dynamically mixing
phosphate-buffered saline (PBS) with an acidic solution (pH 3), the testbed
reliably generates pH-encoded pulses. Experimental results confirm robust
control over pulse amplitude and pulse width, enabling the simulation of
end-to-end MC scenarios with 4-ary concentration shift keying (CSK) modulation.
By combining affordability and rapid prototyping without compromising
customizability, this platform is poised to accelerate the translation of MC
concepts into practical IoBNT applications.


## PixelWorld Towards Perceiving Everything as Pixels

>Authors: Zhiheng Lyu, Xueguang Ma, Wenhu Chen

>2025-01-31

> http://arxiv.org/abs/2501.19339v1

Existing foundation models typically process visual input as pixels and
textual input as tokens, a paradigm that contrasts with human perception, where
both modalities are processed in a unified manner. With the rise of embodied
and agentic AI, where inputs primarily come from camera pixels, the need for a
unified perception framework becomes increasingly evident. In this paper, we
propose to unify all modalities (text, tables, code, diagrams, images, etc) as
pixel inputs, i.e. "Perceive Everything as Pixels" (PEAP). We introduce
PixelWorld, a novel evaluation suite that unifies all the mentioned modalities
into pixel space to gauge the existing models' performance. Our findings show
that (1) PEAP outperforms baseline with token-based input in multimodal
datasets, benefiting from unified input for better disambiguation, (2)
significant declines in reasoning and coding capabilities across all models
when processing pixel-based input, underscoring the need to enhance foundation
models' perceptual abilities, (3) larger models can maintain strong performance
on non-reasoning tasks under PEAP, while smaller models like Phi-3.5-V suffer
significant performance degradation, (4) the attention pattern of PEAP is
highly aligned with text token input, (5) PEAP can be accelerated significantly
by exploiting the spatial **sparsity**. We conclude that the existing frontier
models are competent in pixel perception, however, there is still headroom for
improvement. Our code, dataset will be released upon acceptance.


## Judge Decoding Faster Speculative Sampling Requires Going Beyond Model Alignment

>Authors: Gregor Bachmann, Sotiris Anagnostidis, Albert Pumarola, Markos Georgopoulos, Artsiom Sanakoyeu, Yuming Du, Edgar Schönfeld, Ali Thabet, Jonas Kohler

>2025-01-31

> http://arxiv.org/abs/2501.19309v1

The performance of large language models (LLMs) is closely linked to their
underlying size, leading to ever-growing networks and hence slower inference.
Speculative decoding has been proposed as a technique to accelerate
autoregressive generation, leveraging a fast draft model to propose candidate
tokens, which are then verified in parallel based on their likelihood under the
target model. While this approach guarantees to reproduce the target output, it
incurs a substantial penalty: many high-quality draft tokens are rejected, even
when they represent objectively valid continuations. Indeed, we show that even
powerful draft models such as GPT-4o, as well as human text cannot achieve high
acceptance rates under the standard verification scheme. This severely limits
the speedup potential of current speculative decoding methods, as an early
rejection becomes overwhelmingly likely when solely relying on alignment of
draft and target.
  We thus ask the following question: Can we adapt verification to recognize
correct, but non-aligned replies? To this end, we draw inspiration from the
LLM-as-a-judge framework, which demonstrated that LLMs are able to rate answers
in a versatile way. We carefully design a dataset to elicit the same capability
in the target model by training a compact module on top of the embeddings to
produce ``judgements" of the current continuation. We showcase our strategy on
the Llama-3.1 family, where our 8b/405B-Judge achieves a speedup of 9x over
Llama-405B, while maintaining its quality on a large range of benchmarks. These
benefits remain present even in optimized inference frameworks, where our
method reaches up to 141 tokens/s for 8B/70B-Judge and 129 tokens/s for 8B/405B
on 2 and 8 H100s respectively.


## Multi-beam-energy control unit based on triple bend achromats

>Authors: Liuyang Wu, Zihan Zhu, Bingyang Yan, Jiawei Yan, Haixiao Deng

>2025-01-31

> http://arxiv.org/abs/2501.19295v1

X-ray free electron lasers (XFELs) are the new generation of particle
accelerator-based light sources, capable of producing tunable, high-power X-ray
pulses that are increasingly vital across various scientific disciplines.
Recently, continuous-wave (CW) XFELs driven by superconducting linear
accelerators have garnered significant attention due to their ability to
enhance availability by supporting multiple undulator lines simultaneously.
However, different undulator lines typically require distinct electron beam
qualities, particularly varying electron beam energy to achieve a wide range of
photon energy tunability. Consequently, precise bunch-to-bunch control of
electron beam energy is essential. A double-bend achromat based electron beam
delay system has been proposed to enable multi-beam energy operations in
CW-XFELs. In this paper, we introduce a novel delay system comprising four
triple-bend achromats (TBAs). Based on parameters of the Shanghai
High-Repetition-Rate XFEL and Extreme Light Facility, start-to-end simulations
demonstrate that the TBA-based delay system achieves better electron beam
qualities while providing a wide beam energy tuning range.


## Accelerating Diffusion Transformer via Error-Optimized Cache

>Authors: Junxiang Qiu, Shuo Wang, Jinda Lu, Lin Liu, Houcheng Jiang, Yanbin Hao

>2025-01-31

> http://arxiv.org/abs/2501.19243v1

Diffusion Transformer (DiT) is a crucial method for content generation.
However, it needs a lot of time to sample. Many studies have attempted to use
caching to reduce the time consumption of sampling. Existing caching methods
accelerate generation by reusing DiT features from the previous time step and
skipping calculations in the next, but they tend to locate and cache low-error
modules without focusing on reducing caching-induced errors, resulting in a
sharp decline in generated content quality when increasing caching intensity.
To solve this problem, we propose the Error-Optimized Cache (EOC). This method
introduces three key improvements: (1) Prior knowledge extraction: Extract and
process the caching differences; (2) A judgment method for cache optimization:
Determine whether certain caching steps need to be optimized; (3) Cache
optimization: reduce caching errors. Experiments show that this algorithm
significantly reduces the error accumulation caused by caching (especially
over-caching). On the ImageNet dataset, without significantly increasing the
computational burden, this method improves the quality of the generated images
under the over-caching, rule-based, and training-based methods. Specifically,
the Fr\'echet Inception Distance (FID) values are improved as follows: from
6.857 to 5.821, from 3.870 to 3.692 and form 3.539 to 3.451 respectively.


## A Zero-Shot Generalization Framework for LLM-Driven Cross-Domain Sequential Recommendation

>Authors: Yunzhe Li, Junting Wang, Hari Sundaram, Zhining Liu

>2025-01-31

> http://arxiv.org/abs/2501.19232v1

Zero-shot cross-domain sequential recommendation (ZCDSR) enables predictions
in unseen domains without the need for additional training or fine-tuning,
making it particularly valuable in data-**sparse** environments where traditional
models struggle. Recent advancements in large language models (LLMs) have
greatly improved ZCDSR by leveraging rich pretrained representations to
facilitate cross-domain knowledge transfer. However, a key challenge persists:
domain semantic bias, which arises from variations in vocabulary and content
focus across domains. This misalignment leads to inconsistencies in item
embeddings and hinders generalization.
  To address this issue, we propose a novel framework designed to enhance
LLM-based ZCDSR by improving cross-domain alignment at both the item and
sequential levels. At the item level, we introduce a generalization loss that
promotes inter-domain compactness by aligning embeddings of similar items
across domains while maintaining intra-domain diversity to preserve unique item
characteristics. This prevents embeddings from becoming overly generic while
ensuring effective transferability. At the sequential level, we develop a
method for transferring user behavioral patterns by clustering user sequences
in the source domain and applying attention-based aggregation for target domain
inference. This dynamic adaptation of user embeddings allows effective
zero-shot recommendations without requiring target-domain interactions.
  Comprehensive experiments across multiple datasets and domains demonstrate
that our framework significantly improves sequential recommendation performance
in the ZCDSR setting. By mitigating domain bias and enhancing the
transferability of sequential patterns, our method provides a scalable and
robust approach for achieving more effective zero-shot recommendations across
domains.


## A Tensor-Train Decomposition based Compression of LLMs on Group Vector Systolic Accelerator

>Authors: Sixiao Huang, Tintin Wang, Ang Li, Ao Shen, Kai Li, Keyao Jiang, Mingqiang Huang, Hao Yu

>2025-01-31

> http://arxiv.org/abs/2501.19135v1

Large language models (LLMs) are both storage-intensive and
computation-intensive, posing significant challenges when deployed on
resource-constrained hardware. As linear layers in LLMs are mainly resource
consuming parts, this paper develops a tensor-train decomposition (TTD) for
LLMs with a further hardware implementation on FPGA. TTD compression is applied
to the linear layers in ChatGLM3-6B and LLaMA2-7B models with compression
ratios (CRs) for the whole network 1.94$\times$ and 1.60$\times$, respectively.
The compressed LLMs are further implemented on FPGA hardware within a highly
efficient group vector systolic array (GVSA) architecture, which has DSP-shared
parallel vector PEs for TTD inference, as well as optimized data communication
in the accelerator. Experimental results show that the corresponding TTD based
LLM accelerator implemented on FPGA achieves 1.45$\times$ and 1.57$\times$
reduction in first token delay for ChatGLM3-6B and LLaMA2-7B models,
respectively.


## Brain-inspired sparse training enables Transformers and LLMs to perform as fully connected

>Authors: Yingtao Zhang, Jialin Zhao, Wenjing Wu, Ziheng Liao, Umberto Michieli, Carlo Vittorio Cannistraci

>2025-01-31

> http://arxiv.org/abs/2501.19107v1

This study aims to enlarge our current knowledge on application of
brain-inspired network science principles for training artificial neural
networks (ANNs) with **sparse** connectivity. Dynamic **sparse** training (DST) can
reduce the computational demands in ANNs, but faces difficulties to keep peak
performance at high **sparsity** levels. The Cannistraci-Hebb training (CHT) is a
brain-inspired method for growing connectivity in DST. CHT leverages a
gradient-free, topology-driven link regrowth, which has shown ultra-**sparse** (1%
connectivity or lower) advantage across various tasks compared to fully
connected networks. Yet, CHT suffers two main drawbacks: (i) its time
complexity is O(Nd^3) - N node network size, d node degree - hence it can apply
only to ultra-**sparse** networks. (ii) it selects top link prediction scores,
which is inappropriate for the early training epochs, when the network presents
unreliable connections. We propose a GPU-friendly approximation of the CH link
predictor, which reduces the computational complexity to O(N^3), enabling a
fast implementation of CHT in large-scale models. We introduce the
Cannistraci-Hebb training soft rule (CHTs), which adopts a strategy for
sampling connections in both link removal and regrowth, balancing the
exploration and exploitation of network topology. To improve performance, we
integrate CHTs with a sigmoid gradual density decay (CHTss). Empirical results
show that, using 1% of connections, CHTs outperforms fully connected networks
in MLP on visual classification tasks, compressing some networks to < 30%
nodes. Using 5% of the connections, CHTss outperforms fully connected networks
in two Transformer-based machine translation tasks. Using 30% of the
connections, CHTss achieves superior performance compared to other dynamic
**sparse** training methods in language modeling, and it surpasses the fully
connected counterpart in zero-shot evaluations.


## Unraveling Zeroth-Order Optimization through the Lens of Low-Dimensional Structured Perturbations

>Authors: Sihwan Park, Jihun Yun, SungYub Kim, Souvik Kundu, Eunho Yang

>2025-01-31

> http://arxiv.org/abs/2501.19099v1

Zeroth-order (ZO) optimization has emerged as a promising alternative to
gradient-based backpropagation methods, particularly for black-box optimization
and large language model (LLM) fine-tuning. However, ZO methods suffer from
slow convergence due to high-variance stochastic gradient estimators. While
structured perturbations, such as **sparsity** and low-rank constraints, have been
explored to mitigate these issues, their effectiveness remains highly
under-explored. In this work, we develop a unified theoretical framework that
analyzes both the convergence and generalization properties of ZO optimization
under structured perturbations. We show that high dimensionality is the primary
bottleneck and introduce the notions of \textit{stable rank} and
\textit{effective overlap} to explain how structured perturbations reduce
gradient noise and accelerate convergence. Using the uniform stability under
our framework, we then provide the first theoretical justification for why
these perturbations enhance generalization. Additionally, through empirical
analysis, we identify that \textbf{block coordinate descent} (BCD) to be an
effective structured perturbation method. Extensive experiments show that,
compared to existing alternatives, memory-efficient ZO (MeZO) with BCD
(\textit{MeZO-BCD}) can provide improved converge with a faster wall-clock
time/iteration by up to $\times\textbf{2.09}$ while yielding similar or better
accuracy.


## $\infty$-Video A Training-Free Approach to Long Video Understanding via Continuous-Time Memory Consolidation

>Authors: Saul Santos, António Farinhas, Daniel C. McNamee, André F. T. Martins

>2025-01-31

> http://arxiv.org/abs/2501.19098v1

Current video-language models struggle with long-video understanding due to
limited context lengths and reliance on **sparse** frame subsampling, often leading
to information loss. This paper introduces $\infty$-Video, which can process
arbitrarily long videos through a continuous-time long-term memory (LTM)
consolidation mechanism. Our framework augments video Q-formers by allowing
them to process unbounded video contexts efficiently and without requiring
additional training. Through continuous attention, our approach dynamically
allocates higher granularity to the most relevant video segments, forming
"sticky" memories that evolve over time. Experiments with Video-LLaMA and
VideoChat2 demonstrate improved performance in video question-answering tasks,
showcasing the potential of continuous-time LTM mechanisms to enable scalable
and training-free comprehension of long videos.


## Pivoting Factorization A Compact Meta Low-Rank Representation of Sparsity for Efficient Inference in Large Language Models

>Authors: Jialin Zhao, Yingtao Zhang, Carlo Vittorio Cannistraci

>2025-01-31

> http://arxiv.org/abs/2501.19090v1

The rapid growth of Large Language Models has driven demand for effective
model compression techniques to reduce memory and computation costs. Low-rank
**pruning** has gained attention for its tensor coherence and GPU compatibility
across all densities. However, low-rank **pruning** has struggled to match the
performance of semi-structured **pruning**, often doubling perplexity (PPL) at
similar densities. In this paper, we propose Pivoting Factorization (PIFA), a
novel lossless meta low-rank representation that unsupervisedly learns a
compact form of any low-rank representation, effectively eliminating redundant
information. PIFA identifies pivot rows (linearly independent rows) and
expresses non-pivot rows as linear combinations, achieving an additional 24.2\%
memory savings and 24.6\% faster inference over low-rank layers at r/d = 0.5,
thereby significantly enhancing performance at the same density. To mitigate
the performance degradation caused by low-rank **pruning**, we introduce a novel,
retraining-free low-rank reconstruction method that minimizes error
accumulation (M). MPIFA, combining M and PIFA into an end-to-end framework,
significantly outperforms existing low-rank **pruning** methods and, for the first
time, achieves performance comparable to semi-structured **pruning**, while
surpassing it in GPU efficiency and compatibility.


## Importing Phantoms Measuring LLM Package Hallucination Vulnerabilities

>Authors: Arjun Krishna, Erick Galinkin, Leon Derczynski, Jeffrey Martin

>2025-01-31

> http://arxiv.org/abs/2501.19012v1

Large Language Models (LLMs) have become an essential tool in the
programmer's toolkit, but their tendency to hallucinate code can be used by
malicious actors to introduce vulnerabilities to broad swathes of the software
supply chain. In this work, we analyze package hallucination behaviour in LLMs
across popular programming languages examining both existing package references
and fictional dependencies. By analyzing this package hallucination behaviour
we find potential attacks and suggest defensive strategies to defend against
these attacks. We discover that package hallucination rate is predicated not
only on model choice, but also programming language, model size, and
specificity of the coding task request. The Pareto optimality boundary between
code generation performance and package hallucination is **sparse**ly populated,
suggesting that coding models are not being optimized for secure code.
Additionally, we find an inverse correlation between package hallucination rate
and the HumanEval coding benchmark, offering a heuristic for evaluating the
propensity of a model to hallucinate packages. Our metrics, findings and
analyses provide a base for future models, securing AI-assisted software
development workflows against package supply chain attacks.


## TV-Dialogue Crafting Theme-Aware Video Dialogues with Immersive Interaction

>Authors: Sai Wang, Fan Ma, Xinyi Li, Hehe Fan, Yu Wu

>2025-01-31

> http://arxiv.org/abs/2501.18940v1

Recent advancements in LLMs have accelerated the development of dialogue
generation across text and images, yet video-based dialogue generation remains
underexplored and presents unique challenges. In this paper, we introduce
Theme-aware Video Dialogue Crafting (TVDC), a novel task aimed at generating
new dialogues that align with video content and adhere to user-specified
themes. We propose TV-Dialogue, a novel multi-modal agent framework that
ensures both theme alignment (i.e., the dialogue revolves around the theme) and
visual consistency (i.e., the dialogue matches the emotions and behaviors of
characters in the video) by enabling real-time immersive interactions among
video characters, thereby accurately understanding the video content and
generating new dialogue that aligns with the given themes. To assess the
generated dialogues, we present a multi-granularity evaluation benchmark with
high accuracy, interpretability and reliability, demonstrating the
effectiveness of TV-Dialogue on self-collected dataset over directly using
existing LLMs. Extensive experiments reveal that TV-Dialogue can generate
dialogues for videos of any length and any theme in a zero-shot manner without
training. Our findings underscore the potential of TV-Dialogue for various
applications, such as video re-creation, film dubbing and its use in downstream
multimodal tasks.


## From Bits to Qubits Challenges in Classical-Quantum Integration

>Authors: Sudhanshu Pravin Kulkarni, Daniel E. Huang, E. Wes Bethel

>2025-01-31

> http://arxiv.org/abs/2501.18905v1

While quantum computing holds immense potential for tackling previously
intractable problems, its current practicality remains limited. A critical
aspect of realizing quantum utility is the ability to efficiently interface
with data from the classical world. This research focuses on the crucial phase
of quantum encoding, which enables the transformation of classical information
into quantum states for processing within quantum systems. We focus on three
prominent encoding models: Phase Encoding, Qubit Lattice, and Flexible
Representation of Quantum Images (FRQI) for cost and efficiency analysis. The
aim of quantifying their different characteristics is to analyze their impact
on quantum processing workflows. This comparative analysis offers valuable
insights into their limitations and potential to accelerate the development of
practical quantum computing solutions.


## Can We Predict the Effect of Prompts?

>Authors: Jae Yong Lee, Sungmin Kang, Shin Yoo

>2025-01-31

> http://arxiv.org/abs/2501.18883v1

Large Language Models (LLMs) are machine learning models that have seen
widespread adoption due to their capability of handling previously difficult
tasks. LLMs, due to their training, are sensitive to how exactly a question is
presented, also known as prompting. However, prompting well is challenging, as
it has been difficult to uncover principles behind prompting -- generally,
trial-and-error is the most common way of improving prompts, despite its
significant computational cost. In this context, we argue it would be useful to
perform `predictive prompt analysis', in which an automated technique would
perform a quick analysis of a prompt and predict how the LLM would react to it,
relative to a goal provided by the user. As a demonstration of the concept, we
present Syntactic Prevalence Analyzer (SPA), a predictive prompt analysis
approach based on **sparse** autoencoders (SAEs). SPA accurately predicted how
often an LLM would generate target syntactic structures during code synthesis,
with up to 0.994 Pearson correlation between the predicted and actual
prevalence of the target structure. At the same time, SPA requires only 0.4\%
of the time it takes to run the LLM on a benchmark. As LLMs are increasingly
used during and integrated into modern software development, our proposed
predictive prompt analysis concept has the potential to significantly ease the
use of LLMs for both practitioners and researchers.


## Partially Rewriting a Transformer in Natural Language

>Authors: Gonçalo Paulo, Nora Belrose

>2025-01-31

> http://arxiv.org/abs/2501.18838v1

The greatest ambition of mechanistic interpretability is to completely
rewrite deep neural networks in a format that is more amenable to human
understanding, while preserving their behavior and performance. In this paper,
we attempt to partially rewrite a large language model using simple natural
language explanations. We first approximate one of the feedforward networks in
the LLM with a wider MLP with **sparse**ly activating neurons - a transcoder - and
use an automated interpretability pipeline to generate explanations for these
neurons. We then replace the first layer of this **sparse** MLP with an LLM-based
simulator, which predicts the activation of each neuron given its explanation
and the surrounding context. Finally, we measure the degree to which these
modifications distort the model's final output. With our pipeline, the model's
increase in loss is statistically similar to entirely replacing the **sparse** MLP
output with the zero vector. We employ the same protocol, this time using a
**sparse** autoencoder, on the residual stream of the same layer and obtain similar
results. These results suggest that more detailed explanations are needed to
improve performance substantially above the zero ablation baseline.


## Transcoders Beat Sparse Autoencoders for Interpretability

>Authors: Gonçalo Paulo, Stepan Shabalin, Nora Belrose

>2025-01-31

> http://arxiv.org/abs/2501.18823v1

Sparse autoencoders (SAEs) extract human-interpretable features from deep
neural networks by transforming their activations into a **sparse**, higher
dimensional latent space, and then reconstructing the activations from these
latents. Transcoders are similar to SAEs, but they are trained to reconstruct
the output of a component of a deep network given its input. In this work, we
compare the features found by transcoders and SAEs trained on the same model
and data, finding that transcoder features are significantly more
interpretable. We also propose _skip transcoders_, which add an affine skip
connection to the transcoder architecture, and show that these achieve lower
reconstruction loss with no effect on interpretability.


## Survey and Improvement Strategies for Gene Prioritization with Large Language Models

>Authors: Matthew Neeley, Guantong Qi, Guanchu Wang, Ruixiang Tang, Dongxue Mao, Chaozhong Liu, Sasidhar Pasupuleti, Bo Yuan, Fan Xia, Pengfei Liu, Zhandong Liu, Xia Hu

>2025-01-30

> http://arxiv.org/abs/2501.18794v1

Rare diseases are challenging to diagnose due to limited patient data and
genetic diversity. Despite advances in variant prioritization, many cases
remain undiagnosed. While large language models (LLMs) have performed well in
medical exams, their effectiveness in diagnosing rare genetic diseases has not
been assessed. To identify causal genes, we benchmarked various LLMs for gene
prioritization. Using multi-agent and Human Phenotype Ontology (HPO)
classification, we categorized patients based on phenotypes and solvability
levels. As gene set size increased, LLM performance deteriorated, so we used a
divide-and-conquer strategy to break the task into smaller subsets. At
baseline, GPT-4 outperformed other LLMs, achieving near 30% accuracy in ranking
causal genes correctly. The multi-agent and HPO approaches helped distinguish
confidently solved cases from challenging ones, highlighting the importance of
known gene-phenotype associations and phenotype specificity. We found that
cases with specific phenotypes or clear associations were more accurately
solved. However, we observed biases toward well-studied genes and input order
sensitivity, which hindered gene prioritization. Our divide-and-conquer
strategy improved accuracy by overcoming these biases. By utilizing HPO
classification, novel multi-agent techniques, and our LLM strategy, we improved
causal gene identification accuracy compared to our baseline evaluation. This
approach streamlines rare disease diagnosis, facilitates reanalysis of unsolved
cases, and accelerates gene discovery, supporting the development of targeted
diagnostics and therapies.


## RUN Reversible Unfolding Network for Concealed Object Segmentation

>Authors: Chunming He, Rihan Zhang, Fengyang Xiao, Chenyu Fang, Longxiang Tang, Yulun Zhang, Linghe Kong, Deng-Ping Fan, Kai Li, Sina Farsiu

>2025-01-30

> http://arxiv.org/abs/2501.18783v1

Existing concealed object segmentation (COS) methods frequently utilize
reversible strategies to address uncertain regions. However, these approaches
are typically restricted to the mask domain, leaving the potential of the RGB
domain underexplored. To address this, we propose the Reversible Unfolding
Network (RUN), which applies reversible strategies across both mask and RGB
domains through a theoretically grounded framework, enabling accurate
segmentation. RUN first formulates a novel COS model by incorporating an extra
residual **sparsity** constraint to minimize segmentation uncertainties. The
iterative optimization steps of the proposed model are then unfolded into a
multistage network, with each step corresponding to a stage. Each stage of RUN
consists of two reversible modules: the Segmentation-Oriented Foreground
Separation (SOFS) module and the Reconstruction-Oriented Background Extraction
(ROBE) module. SOFS applies the reversible strategy at the mask level and
introduces Reversible State Space to capture non-local information. ROBE
extends this to the RGB domain, employing a reconstruction network to address
conflicting foreground and background regions identified as distortion-prone
areas, which arise from their separate estimation by independent modules. As
the stages progress, RUN gradually facilitates reversible modeling of
foreground and background in both the mask and RGB domains, directing the
network's attention to uncertain regions and mitigating false-positive and
false-negative results. Extensive experiments demonstrate the superior
performance of RUN and highlight the potential of unfolding-based frameworks
for COS and other high-level vision tasks. We will release the code and models.


## Strong and Controllable 3D Motion Generation

>Authors: Canxuan Gang

>2025-01-30

> http://arxiv.org/abs/2501.18726v1

Human motion generation is a significant pursuit in generative computer
vision with widespread applications in film-making, video games, AR/VR, and
human-robot interaction. Current methods mainly utilize either diffusion-based
generative models or autoregressive models for text-to-motion generation.
However, they face two significant challenges: (1) The generation process is
time-consuming, posing a major obstacle for real-time applications such as
gaming, robot manipulation, and other online settings. (2) These methods
typically learn a relative motion representation guided by text, making it
difficult to generate motion sequences with precise joint-level control. These
challenges significantly hinder progress and limit the real-world application
of human motion generation techniques. To address this gap, we propose a simple
yet effective architecture consisting of two key components. Firstly, we aim to
improve hardware efficiency and computational complexity in transformer-based
diffusion models for human motion generation. By customizing flash linear
attention, we can optimize these models specifically for generating human
motion efficiently. Furthermore, we will customize the consistency model in the
motion latent space to further accelerate motion generation. Secondly, we
introduce Motion ControlNet, which enables more precise joint-level control of
human motion compared to previous text-to-motion generation methods. These
contributions represent a significant advancement for text-to-motion
generation, bringing it closer to real-world applications.


## Deep learning with reflection high-energy electron diffraction images to predict cation ratio in Sr$_x$Ti$_{1-x}$O3 thin films

>Authors: Sumner B. Harris, Patrick T. Gemperline, Christopher M. Rouleau, Rama K. Vasudevan, Ryan B. Comes

>2025-01-30

> http://arxiv.org/abs/2501.18523v1

Machine learning (ML) with in situ diagnostics offers a transformative
approach to accelerate, understand, and control thin film synthesis by
uncovering relationships between synthesis conditions and material properties.
In this study, we demonstrate the application of deep learning to predict the
stoichiometry of Sr$_x$Ti$_{1-x}$O3 thin films using reflection high-energy
electron diffraction images acquired during pulsed laser deposition. A gated
convolutional neural network trained for regression of the Sr atomic fraction
achieved accurate predictions with a small dataset of 31 samples. Explainable
AI techniques revealed a previously unknown correlation between diffraction
streak features and cation stoichiometry in Sr$_x$Ti$_{1-x}$O3 thin films. Our
results demonstrate how ML can be used to transform a ubiquitous in situ
diagnostic tool, that is usually limited to qualitative assessments, into a
quantitative surrogate measurement of continuously valued thin film properties.
Such methods are critically needed to enable real-time control, autonomous
workflows, and accelerate traditional synthesis approaches.


## Streaming DiLoCo with overlapping communication Towards a Distributed Free Lunch

>Authors: Arthur Douillard, Yanislav Donchev, Keith Rush, Satyen Kale, Zachary Charles, Zachary Garrett, Gabriel Teston, Dave Lacey, Ross McIlroy, Jiajun Shen, Alexandre Ramé, Arthur Szlam, Marc'Aurelio Ranzato, Paul Barham

>2025-01-30

> http://arxiv.org/abs/2501.18512v1

Training of large language models (LLMs) is typically distributed across a
large number of accelerators to reduce training time. Since internal states and
parameter gradients need to be exchanged at each and every single gradient
step, all devices need to be co-located using low-latency high-bandwidth
communication links to support the required high volume of exchanged bits.
Recently, distributed algorithms like DiLoCo have relaxed such co-location
constraint: accelerators can be grouped into ``workers'', where
synchronizations between workers only occur infrequently. This in turn means
that workers can afford being connected by lower bandwidth communication links
without affecting learning quality. However, in these methods, communication
across workers still requires the same peak bandwidth as before, as the
synchronizations require all parameters to be exchanged across all workers. In
this paper, we improve DiLoCo in three ways. First, we synchronize only subsets
of parameters in sequence, rather than all at once, which greatly reduces peak
bandwidth. Second, we allow workers to continue training while synchronizing,
which decreases wall clock time. Third, we **quantize** the data exchanged by
workers, which further reduces bandwidth across workers. By properly combining
these modifications, we show experimentally that we can distribute training of
billion-scale parameters and reach similar quality as before, but reducing
required bandwidth by two orders of magnitude.


## CLoQ Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization

>Authors: Yanxia Deng, Aozhong Zhang, Naigang Wang, Selcuk Gurses, Zi Yang, Penghang Yin

>2025-01-30

> http://arxiv.org/abs/2501.18475v1

Fine-tuning large language models (LLMs) using low-rank adaptation (LoRA) has
become a highly efficient approach for downstream tasks, particularly in
scenarios with limited computational resources. However, applying LoRA
techniques to **quantize**d LLMs poses unique challenges due to the reduced
representational precision of **quantize**d weights. In this paper, we introduce
CLoQ (Calibrated LoRA initialization for Quantized LLMs), a simplistic
initialization strategy designed to overcome these challenges. Our approach
focuses on minimizing the layer-wise discrepancy between the original LLM and
its **quantize**d counterpart with LoRA components during initialization. By
leveraging a small calibration dataset, CLoQ **quantize**s a pre-trained LLM and
determines the optimal LoRA components for each layer, ensuring a strong
foundation for subsequent fine-tuning. A key contribution of this work is a
novel theoretical result that enables the accurate and closed-form construction
of these optimal LoRA components. We validate the efficacy of CLoQ across
multiple tasks such as language generation, arithmetic reasoning, and
commonsense reasoning, demonstrating that it consistently outperforms existing
LoRA fine-tuning methods for **quantize**d LLMs, especially at ultra **low-bit**
widths.


## SANA 1.5 Efficient Scaling of Training-Time and Inference-Time Compute in Linear Diffusion Transformer

>Authors: Enze Xie, Junsong Chen, Yuyang Zhao, Jincheng Yu, Ligeng Zhu, Yujun Lin, Zhekai Zhang, Muyang Li, Junyu Chen, Han Cai, Bingchen Liu, Daquan Zhou, Song Han

>2025-01-30

> http://arxiv.org/abs/2501.18427v1

This paper presents SANA-1.5, a linear Diffusion Transformer for efficient
scaling in text-to-image generation. Building upon SANA-1.0, we introduce three
key innovations: (1) Efficient Training Scaling: A depth-growth paradigm that
enables scaling from 1.6B to 4.8B parameters with significantly reduced
computational resources, combined with a memory-efficient 8-bit optimizer. (2)
Model Depth Pruning: A block importance analysis technique for efficient model
compression to arbitrary sizes with minimal quality loss. (3) Inference-time
Scaling: A repeated sampling strategy that trades computation for model
capacity, enabling smaller models to match larger model quality at inference
time. Through these strategies, SANA-1.5 achieves a text-image alignment score
of 0.72 on GenEval, which can be further improved to 0.80 through inference
scaling, establishing a new SoTA on GenEval benchmark. These innovations enable
efficient model scaling across different compute budgets while maintaining high
quality, making high-quality image generation more accessible.


## CodeBrain Impute Any Brain MRI via Instance-specific Scalar-quantized Codes

>Authors: Yicheng Wu, Tao Song, Zhonghua Wu, Zongyuan Ge, Zhaolin Chen, Jianfei Cai

>2025-01-30

> http://arxiv.org/abs/2501.18328v1

MRI imputation aims to synthesize the missing modality from one or more
available ones, which is highly desirable since it reduces scanning costs and
delivers comprehensive MRI information to enhance clinical diagnosis. In this
paper, we propose a unified model, CodeBrain, designed to adapt to various
brain MRI imputation scenarios. The core design lies in casting various
inter-modality transformations as a full-modality code prediction task. To this
end, CodeBrain is trained in two stages: Reconstruction and Code Prediction.
First, in the Reconstruction stage, we reconstruct each MRI modality, which is
mapped into a shared latent space followed by a scalar **quantization**. Since such
**quantization** is lossy and the code is low dimensional, another MRI modality
belonging to the same subject is randomly selected to generate common features
to supplement the code and boost the target reconstruction. In the second
stage, we train another encoder by a customized grading loss to predict the
full-modality codes from randomly masked MRI samples, supervised by the
corresponding **quantize**d codes generated from the first stage. In this way, the
inter-modality transformation is achieved by mapping the instance-specific
codes in a finite scalar space. We evaluated the proposed CodeBrain model on
two public brain MRI datasets (i.e., IXI and BraTS 2023). Extensive experiments
demonstrate that our CodeBrain model achieves superior imputation performance
compared to four existing methods, establishing a new state of the art for
unified brain MRI imputation. Codes will be released.


## Decentralised convex optimisation with probability-proportional-to-size quantization

>Authors: Dmitrii Pasechniuk, Pavel Dvurechensky, César A. Uribe, Alexander Gasnikov

>2025-01-30

> http://arxiv.org/abs/2501.18312v1

Communication is one of the bottlenecks of distributed optimisation and
learning. To overcome this bottleneck, we propose a novel **quantization** method
that transforms a vector into a sample of components' indices drawn from a
categorical distribution with probabilities proportional to values at those
components. Then, we propose a primal and a primal-dual accelerated stochastic
gradient methods that use our proposed **quantization**, and derive their
convergence rates in terms of probabilities of large deviations. We focus on
affine-constrained convex optimisation and its application to decentralised
distributed optimisation problems. To illustrate the work of our algorithm, we
apply it to the decentralised computation of semi-discrete entropy regularized
Wasserstein barycenters.


## Leveraging Sparsity for Sample-Efficient Preference Learning A Theoretical Perspective

>Authors: Yunzhen Yao, Lie He, Michael Gastpar

>2025-01-30

> http://arxiv.org/abs/2501.18282v2

This paper considers the sample-efficiency of preference learning, which
models and predicts human choices based on comparative judgments. The minimax
optimal estimation rate $\Theta(d/n)$ in traditional estimation theory requires
that the number of samples $n$ scales linearly with the dimensionality of the
feature space $d$. However, the high dimensionality of the feature space and
the high cost of collecting human-annotated data challenge the efficiency of
traditional estimation methods. To remedy this, we leverage **sparsity** in the
preference model and establish sharp estimation rates. We show that under the
**sparse** random utility model, where the parameter of the reward function is
$k$-**sparse**, the minimax optimal rate can be reduced to $\Theta(k/n \log(d/k))$.
Furthermore, we analyze the $\ell_{1}$-regularized estimator and show that it
achieves near-optimal rate under mild assumptions on the Gram matrix.
Experiments on synthetic data and LLM alignment data validate our theoretical
findings, showing that **sparsity**-aware methods significantly reduce sample
complexity and improve prediction accuracy.


## Mixed-Precision Graph Neural Quantization for Low Bit Large Language Models

>Authors: Wanlong Liu, Yichen Xiao, Dingyi Zeng, Hongyang Zhao, Wenyu Chen, Malu Zhang

>2025-01-30

> http://arxiv.org/abs/2501.18154v1

Post-Training Quantization (PTQ) is pivotal for deploying large language
models (LLMs) within resource-limited settings by significantly reducing
resource demands. However, existing PTQ strategies underperform at low bit
levels < 3 bits due to the significant difference between the **quantize**d and
original weights. To enhance the **quantization** performance at low bit widths, we
introduce a Mixed-precision Graph Neural PTQ (MG-PTQ) approach, employing a
graph neural network (GNN) module to capture dependencies among weights and
adaptively assign **quantization** bit-widths. Through the information propagation
of the GNN module, our method more effectively captures dependencies among
target weights, leading to a more accurate assessment of weight importance and
optimized allocation of **quantization** strategies. Extensive experiments on the
WikiText2 and C4 datasets demonstrate that our MG-PTQ method outperforms
previous state-of-the-art PTQ method GPTQ, setting new benchmarks for
**quantization** performance under **low-bit** conditions.


## Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models

>Authors: Qika Lin, Tianzhe Zhao, Kai He, Zhen Peng, Fangzhi Xu, Ling Huang, Jingying Ma, Mengling Feng

>2025-01-30

> http://arxiv.org/abs/2501.18119v1

Due to the presence of the natural gap between Knowledge Graph (KG)
structures and the natural language, the effective integration of holistic
structural information of KGs with Large Language Models (LLMs) has emerged as
a significant question. To this end, we propose a two-stage framework to learn
and apply **quantize**d codes for each entity, aiming for the seamless integration
of KGs with LLMs. Firstly, a self-supervised **quantize**d representation (SSQR)
method is proposed to compress both KG structural and semantic knowledge into
discrete codes (\ie, tokens) that align the format of language sentences. We
further design KG instruction-following data by viewing these learned codes as
features to directly input to LLMs, thereby achieving seamless integration. The
experiment results demonstrate that SSQR outperforms existing unsupervised
**quantize**d methods, producing more distinguishable codes. Further, the
fine-tuned LLaMA2 and LLaMA3.1 also have superior performance on KG link
prediction and triple classification tasks, utilizing only 16 tokens per entity
instead of thousands in conventional prompting methods.


## AlphaAdamAsynchronous Masked Optimization with Dynamic Alpha for Selective Updates

>Authors: Da Chang, Yu Li, Ganzhao Yuan

>2025-01-30

> http://arxiv.org/abs/2501.18094v1

In the training of large language models (LLMs), updating parameters more
efficiently and stably has always been an important challenge. To achieve
efficient parameter updates, existing methods usually achieve performance
comparable to full parameter updates through methods such as low-dimensional
decomposition or layer-wise selective updates. In this work, we propose
AlphaAdam, an optimization framework for LLM from the perspective of
intra-layer parameter updates. By decoupling parameter updates and dynamically
adjusting their strength, AlphaAdam accelerates convergence and improves
training stability. We construct parameter masks based on the consistency of
historical momentum and gradient direction and combine them with an adaptive
mask strength strategy to ensure efficient optimization and theoretical
convergence guarantees, which is also applicable to most momentum-based
optimizers. Extensive experiments show that AlphaAdam outperforms
state-of-the-art methods such as AdamW in terms of convergence speed and
computational efficiency across tasks, including GPT-2 pre-trained and
fine-tuned RoBERTa and Llama-7B. Our AlphaAdam implements an optimizer
enhancement framework for LLMs through intra-layer asynchronous masked adaptive
updates. Our code is available in this
\href{https://github.com/MaeChd/AlphaAdam}{link}


## Large Language Models Think Too Fast To Explore Effectively

>Authors: Lan Pan, Hanbo Xie, Robert C. Wilson

>2025-01-29

> http://arxiv.org/abs/2501.18009v1

Large Language Models have emerged many intellectual capacities. While
numerous benchmarks assess their intelligence, limited attention has been given
to their ability to explore, an essential capacity for discovering new
information and adapting to novel environments in both natural and artificial
systems. The extent to which LLMs can effectively explore, particularly in
open-ended tasks, remains unclear. This study investigates whether LLMs can
surpass humans in exploration during an open-ended task, using Little Alchemy 2
as a paradigm, where agents combine elements to discover new ones. Results show
most LLMs underperform compared to humans, except for the o1 model, with those
traditional LLMs relying primarily on uncertainty driven strategies, unlike
humans who balance uncertainty and empowerment. Representational analysis of
the models with Sparse Autoencoders revealed that uncertainty and choices are
represented at earlier transformer blocks, while empowerment values are
processed later, causing LLMs to think too fast and make premature decisions,
hindering effective exploration. These findings shed light on the limitations
of LLM exploration and suggest directions for improving their adaptability.


## The Numerical Approximation of Caputo Fractional Derivative of Higher Orders Using A Shifted Gegenbauer Pseudospectral Method Two-Point Boundary Value Problems of the Bagley Torvik Type Case Study

>Authors: Kareem T. Elgindy

>2025-01-29

> http://arxiv.org/abs/2501.17956v2

This work presents a new framework for approximating Caputo fractional
derivatives (FDs) of any positive order using a shifted Gegenbauer
pseudospectral (SGPS) method. By transforming the Caputo FD into a scaled
integral of the $m$th-derivative of the Lagrange interpolating polynomial (with
$m$ being the ceiling of the fractional order $\alpha$), we mitigate the
singularity near zero, improving stability and accuracy. The method links
$m$th-derivatives of shifted Gegenbauer (SG) polynomials with SG polynomials of
lower degrees, allowing for precise integration using SG quadratures. We employ
orthogonal collocation and SG quadratures in barycentric form to obtain an
accurate and efficient approach for solving fractional differential equations.
We provide error analysis showing that the SGPS method is convergent in a
semi-analytic framework and conditionally convergent with exponential rate for
smooth functions in finite-precision arithmetic. This exponential convergence
improves accuracy compared to wavelet-based, operational matrix, and finite
difference methods. The SGPS method is flexible, with adjustable SG parameters
for optimal performance. A key contribution is the fractional SG integration
matrix (FSGIM), which enables efficient computation of Caputo FDs via
matrix-vector multiplications and accelerates the SGPS method through
pre-computation and storage. The method remains within double-precision limits,
making it computationally efficient. It handles any positive fractional order
$\alpha$ and outperforms existing schemes in solving Caputo fractional
two-point boundary value problems (TPBVPs) of the Bagley-Torvik type.


## Matrix Product Sketching via Coordinated Sampling

>Authors: Majid Daliri, Juliana Freire, Danrong Li, Christopher Musco

>2025-01-29

> http://arxiv.org/abs/2501.17836v1

We revisit the well-studied problem of approximating a matrix product,
$\mathbf{A}^T\mathbf{B}$, based on small space sketches
$\mathcal{S}(\mathbf{A})$ and $\mathcal{S}(\mathbf{B})$ of $\mathbf{A} \in
\R^{n \times d}$ and $\mathbf{B}\in \R^{n \times m}$. We are interested in the
setting where the sketches must be computed independently of each other, except
for the use of a shared random seed. We prove that, when $\mathbf{A}$ and
$\mathbf{B}$ are **sparse**, methods based on \emph{coordinated random sampling}
can outperform classical linear sketching approaches, like
Johnson-Lindenstrauss Projection or CountSketch. For example, to obtain
Frobenius norm error $\epsilon\|\mathbf{A}\|_F\|\mathbf{B}\|_F$, coordinated
sampling requires sketches of size $O(s/\epsilon^2)$ when $\mathbf{A}$ and
$\mathbf{B}$ have at most $s \leq d,m$ non-zeros per row. In contrast, linear
sketching leads to sketches of size $O(d/\epsilon^2)$ and $O(m/\epsilon^2)$ for
$\mathbf{A}$ and $\mathbf{B}$. We empirically evaluate our approach on two
applications: 1) distributed linear regression in databases, a problem
motivated by tasks like dataset discovery and augmentation, and 2)
approximating attention matrices in transformer-based language models. In both
cases, our sampling algorithms yield an order of magnitude improvement over
linear sketching.


## Aggregation Schemes for Single-Vector WSI Representation Learning in Digital Pathology

>Authors: Sobhan Hemati, Ghazal Alabtah, Saghir Alfasly, H. R. Tizhoosh

>2025-01-29

> http://arxiv.org/abs/2501.17822v1

A crucial step to efficiently integrate Whole Slide Images (WSIs) in
computational pathology is assigning a single high-quality feature vector,
i.e., one embedding, to each WSI. With the existence of many pre-trained deep
neural networks and the emergence of foundation models, extracting embeddings
for sub-images (i.e., tiles or patches) is straightforward. However, for WSIs,
given their high resolution and gigapixel nature, inputting them into existing
GPUs as a single image is not feasible. As a result, WSIs are usually split
into many patches. Feeding each patch to a pre-trained model, each WSI can then
be represented by a set of patches, hence, a set of embeddings. Hence, in such
a setup, WSI representation learning reduces to set representation learning
where for each WSI we have access to a set of patch embeddings. To obtain a
single embedding from a set of patch embeddings for each WSI, multiple
set-based learning schemes have been proposed in the literature. In this paper,
we evaluate the WSI search performance of multiple recently developed
aggregation techniques (mainly set representation learning techniques)
including simple average or max pooling operations, Deep Sets, Memory networks,
Focal attention, Gaussian Mixture Model (GMM) Fisher Vector, and deep **sparse**
and binary Fisher Vector on four different primary sites including bladder,
breast, kidney, and Colon from TCGA. Further, we benchmark the search
performance of these methods against the median of minimum distances of patch
embeddings, a non-aggregating approach used for WSI retrieval.


## 2SSP A Two-Stage Framework for Structured Pruning of LLMs

>Authors: Fabrizio Sandri, Elia Cunegatti, Giovanni Iacca

>2025-01-29

> http://arxiv.org/abs/2501.17771v1

We propose a novel Two-Stage framework for Structured Pruning (2SSP) for
**pruning** Large Language Models (LLMs), which combines two different strategies
of **pruning**, namely Width and Depth Pruning. The first stage (Width Pruning)
removes entire neurons, hence their corresponding rows and columns, aiming to
preserve the connectivity among the pruned structures in the intermediate state
of the Feed-Forward Networks in each Transformer block. This is done based on
an importance score measuring the impact of each neuron over the output
magnitude. The second stage (Depth Pruning), instead, removes entire Attention
submodules. This is done by applying an iterative process that removes the
Attention submodules with the minimum impact on a given metric of interest (in
our case, perplexity). We also propose a novel mechanism to balance the
**sparsity** rate of the two stages w.r.t. to the desired global **sparsity**. We test
2SSP on four LLM families and three **sparsity** rates (25\%, 37.5\%, and 50\%),
measuring the resulting perplexity over three language modeling datasets as
well as the performance over six downstream tasks. Our method consistently
outperforms five state-of-the-art competitors over three language modeling and
six downstream tasks, with an up to two-order-of-magnitude gain in terms of
**pruning** time. The code is available at available at
\url{https://github.com/FabrizioSandri/2SSP}.


## Hybrid Graphs for Table-and-Text based Question Answering using LLMs

>Authors: Ankush Agarwal, Ganesh S, Chaitanya Devaguptapu

>2025-01-29

> http://arxiv.org/abs/2501.17767v1

Answering questions that require reasoning and aggregation across both
structured (tables) and unstructured (raw text) data sources presents
significant challenges. Current methods rely on fine-tuning and high-quality,
human-curated data, which is difficult to obtain. Recent advances in Large
Language Models (LLMs) have shown promising results for multi-hop question
answering (QA) over single-source text data in a zero-shot setting, yet
exploration into multi-source Table-Text QA remains limited. In this paper, we
present a novel Hybrid Graph-based approach for Table-Text QA that leverages
LLMs without fine-tuning. Our method constructs a unified Hybrid Graph from
textual and tabular data, **pruning** information based on the input question to
provide the LLM with relevant context concisely. We evaluate our approach on
the challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs,
including GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot
performance on both datasets, improving Exact Match scores by up to 10% on
Hybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up
to 53% compared to the original context.


## Sparse Autoencoders Can Interpret Randomly Initialized Transformers

>Authors: Thomas Heap, Tim Lawson, Lucy Farnik, Laurence Aitchison

>2025-01-29

> http://arxiv.org/abs/2501.17727v1

Sparse autoencoders (SAEs) are an increasingly popular technique for
interpreting the internal representations of transformers. In this paper, we
apply SAEs to 'interpret' random transformers, i.e., transformers where the
parameters are sampled IID from a Gaussian rather than trained on text data. We
find that random and trained transformers produce similarly interpretable SAE
latents, and we confirm this finding quantitatively using an open-source
auto-interpretability pipeline. Further, we find that SAE quality metrics are
broadly similar for random and trained transformers. We find that these results
hold across model sizes and layers. We discuss a number of number interesting
questions that this work raises for the use of SAEs and auto-interpretability
in the context of mechanistic interpretability.


## DReSS Data-driven Regularized Structured Streamlining for Large Language Models

>Authors: Mingkuan Feng, Jinyang Wu, Shuai Zhang, Pengpeng Shao, Ruihan Jin, Zhengqi Wen, Jianhua Tao, Feihu Che

>2025-01-29

> http://arxiv.org/abs/2501.17905v1

Large language models (LLMs) have achieved significant progress across
various domains, but their increasing scale results in high computational and
memory costs. Recent studies have revealed that LLMs exhibit **sparsity**,
providing the potential to reduce model size through **pruning** techniques.
However, existing **pruning** methods typically follow a prune-then-finetune
paradigm. Since the pruned components still contain valuable information, their
direct removal often leads to irreversible performance degradation, imposing a
substantial computational burden to recover performance during finetuning. In
this paper, we propose a novel paradigm that first applies regularization, then
prunes, and finally finetunes. Based on this paradigm, we introduce DReSS, a
simple and effective Data-driven Regularized Structured Streamlining method for
LLMs. By leveraging a small amount of data to regularize the components to be
pruned, DReSS explicitly transfers the important information to the remaining
parts of the model in advance. Compared to direct **pruning**, this can reduce the
information loss caused by parameter removal, thereby enhancing its language
modeling capabilities. Experimental results demonstrate that DReSS
significantly outperforms existing **pruning** methods even under extreme **pruning**
ratios, significantly reducing latency and increasing throughput.


## Analysis of the Motion Sickness and the Lack of Comfort in Car Passengers

>Authors: Estibaliz Asua, Jon Gutiérrez-Zaballa, Óscar Mata-Carballeira, Jon Ander Ruiz, Inés del Campo

>2025-01-29

> http://arxiv.org/abs/2501.17664v1

Advanced driving assistance systems (ADAS) are primarily designed to increase
driving safety and reduce traffic congestion without paying too much attention
to passenger comfort or motion sickness. However, in view of autonomous cars,
and taking into account that the lack of comfort and motion sickness increase
in passengers, analysis from a comfort perspective is essential in the future
car investigation. The aim of this work is to study in detail how passenger's
comfort evaluation parameters vary depending on the driving style, car or road.
The database used has been developed by compiling the **acceleration**s suffered by
passengers when three drivers cruise two different vehicles on different types
of routes. In order to evaluate both comfort and motion sickness, first, the
numerical values of the main comfort evaluation variables reported in the
literature have been analyzed. Moreover, a complementary statistical analysis
of probability density and a power spectral analysis are performed. Finally,
quantitative results are compared with passenger qualitative feedback. The
results show the high dependence of comfort evaluation variables' value with
the road type. In addition, it has been demonstrated that the driving style and
vehicle dynamics amplify or attenuate those values. Additionally, it has been
demonstrated that contributions from longitudinal and lateral **acceleration**s
have a much greater effect in the lack of comfort than vertical ones. Finally,
based on the concrete results obtained, a new experimental campaign is
proposed.


## Shared DIFF Transformer

>Authors: Yueyang Cang, Yuhang Liu, Xiaoteng Zhang, Xiangju Wang

>2025-01-29

> http://arxiv.org/abs/2501.17900v1

DIFF Transformer improves attention allocation by enhancing focus on relevant
context while suppressing noise. It introduces a differential attention
mechanism that calculates the difference between two independently generated
attention distributions, effectively reducing noise and promoting **sparse**
attention patterns. However, the independent signal generation in DIFF
Transformer results in parameter redundancy and suboptimal utilization of
information. In this work, we propose Shared DIFF Transformer, which draws on
the idea of a differential amplifier by introducing a shared base matrix to
model global patterns and incorporating low-rank updates to enhance
task-specific flexibility. This design significantly reduces parameter
redundancy, improves efficiency, and retains strong noise suppression
capabilities. Experimental results show that, compared to DIFF Transformer, our
method achieves better performance in tasks such as long-sequence modeling, key
information retrieval, and in-context learning. Our work provides a novel and
efficient approach to optimizing differential attention mechanisms and
advancing robust Transformer architectures.


## Byzantine-Robust Federated Learning over Ring-All-Reduce Distributed Computing

>Authors: Minghong Fang, Zhuqing Liu, Xuecen Zhao, Jia Liu

>2025-01-29

> http://arxiv.org/abs/2501.17392v1

Federated learning (FL) has gained attention as a distributed learning
paradigm for its data privacy benefits and accelerated convergence through
parallel computation. Traditional FL relies on a server-client (SC)
architecture, where a central server coordinates multiple clients to train a
global model, but this approach faces scalability challenges due to server
communication bottlenecks. To overcome this, the ring-all-reduce (RAR)
architecture has been introduced, eliminating the central server and achieving
bandwidth optimality. However, the tightly coupled nature of RAR's ring
topology exposes it to unique Byzantine attack risks not present in SC-based
FL. Despite its potential, designing Byzantine-robust RAR-based FL algorithms
remains an open problem. To address this gap, we propose BRACE
(Byzantine-robust ring-all-reduce), the first RAR-based FL algorithm to achieve
both Byzantine robustness and communication efficiency. We provide theoretical
guarantees for the convergence of BRACE under Byzantine attacks, demonstrate
its bandwidth efficiency, and validate its practical effectiveness through
experiments. Our work offers a foundational understanding of Byzantine-robust
RAR-based FL design.


## Dynamical Shortcomings in the Generalized SU(2) Proca Theory Challenges for Cosmic Acceleration

>Authors: Santiago Garcia-Serna, J. Bayron Orjuela-Quintana, Yeinzon Rodriguez, Gabriel Gomez, Cesar A. Valenzuela-Toledo

>2025-01-28

> http://arxiv.org/abs/2501.17280v1

The Generalized SU(2) Proca (GSU2P) theory has recently garnered attention
for its potential to describe key phases of cosmic evolution, including
primordial inflation and late-time accelerated expansion. However, its full
cosmological implications remain unexplored. In this work, we perform a
comprehensive analysis of the dynamical properties of the GSU2P theory in a
flat, homogeneous, and isotropic spacetime, through a dynamical-system
approach. Our analysis reveals the presence of three pairs of fixed points, one
of them corresponding to de-Sitter expansion which may represent either a
stable or unstable phase in the evolution of the universe. These points,
nonetheless, give rise to an indeterminate or infinite Hubble parameter, which
renders them cosmologically unviable. Additionally, we find two key
pseudostationary states: the ``attractor lines'', along which the system
exhibits constant-roll dynamics, and the ``central zone'', characterized by
oscillatory radiation-like behaviour of the field. The dynamics within the
central zone could represent a graceful exit from the primordial inflationary
phase to a radiation dominated phase, or a state of the dark energy component
prior to the late-time cosmic **acceleration**. However, within the central zone,
the dynamics of the vector field leads to recurrent instances of a nonphysical
expansion rate. The absence of a limit cycle in the central zone further
exacerbates the issue, as the system may follow unbounded phase-space
trajectories, and the expansion rate becomes complex once it escapes the
region. Collectively, these challenges undermine the viability of the GSU2P
theory as a cosmological model for cosmic **acceleration**.


## ViT-2SPN Vision Transformer-based Dual-Stream Self-Supervised Pretraining Networks for Retinal OCT Classification

>Authors: Mohammadreza Saraei, Igor Kozak, Eung-Joo Lee

>2025-01-28

> http://arxiv.org/abs/2501.17260v1

Optical Coherence Tomography (OCT) is a non-invasive imaging modality
essential for diagnosing various eye diseases. Despite its clinical
significance, developing OCT-based diagnostic tools faces challenges, such as
limited public datasets, **sparse** annotations, and privacy concerns. Although
deep learning has made progress in automating OCT analysis, these challenges
remain unresolved. To address these limitations, we introduce the Vision
Transformer-based Dual-Stream Self-Supervised Pretraining Network (ViT-2SPN), a
novel framework designed to enhance feature extraction and improve diagnostic
accuracy. ViT-2SPN employs a three-stage workflow: Supervised Pretraining,
Self-Supervised Pretraining (SSP), and Supervised Fine-Tuning. The pretraining
phase leverages the OCTMNIST dataset (97,477 unlabeled images across four
disease classes) with data augmentation to create dual-augmented views. A
Vision Transformer (ViT-Base) backbone extracts features, while a negative
cosine similarity loss aligns feature representations. Pretraining is conducted
over 50 epochs with a learning rate of 0.0001 and momentum of 0.999.
Fine-tuning is performed on a stratified 5.129% subset of OCTMNIST using
10-fold cross-validation. ViT-2SPN achieves a mean AUC of 0.93, accuracy of
0.77, precision of 0.81, recall of 0.75, and an F1 score of 0.76, outperforming
existing SSP-based methods.


## Optimizing Large Language Model Training Using FP4 Quantization

>Authors: Ruizhe Wang, Yeyun Gong, Xiao Liu, Guoshuai Zhao, Ziyue Yang, Baining Guo, Zhengjun Zha, Peng Cheng

>2025-01-28

> http://arxiv.org/abs/2501.17116v1

The growing computational demands of training large language models (LLMs)
necessitate more efficient methods. Quantized training presents a promising
solution by enabling **low-bit** arithmetic operations to reduce these costs. While
FP8 precision has demonstrated feasibility, leveraging FP4 remains a challenge
due to significant **quantization** errors and limited representational capacity.
This work introduces the first FP4 training framework for LLMs, addressing
these challenges with two key innovations: a differentiable **quantization**
estimator for precise weight updates and an outlier clamping and compensation
strategy to prevent activation collapse. To ensure stability, the framework
integrates a mixed-precision training scheme and vector-wise **quantization**.
Experimental results demonstrate that our FP4 framework achieves accuracy
comparable to BF16 and FP8, with minimal degradation, scaling effectively to
13B-parameter LLMs trained on up to 100B tokens. With the emergence of
next-generation hardware supporting FP4, our framework sets a foundation for
efficient ultra-low precision training.


## Wormholes, branes and finite matrices in sine dilaton gravity

>Authors: Andreas Blommaert, Adam Levine, Thomas G. Mertens, Jacopo Papalini, Klaas Parmentier

>2025-01-28

> http://arxiv.org/abs/2501.17091v1

We compute the double trumpet in sine dilaton gravity via WdW **quantization**.
The wormhole size is discretized. The wormhole amplitude matches the spectral
correlation of a finite-cut matrix integral, where matrices have large but
finite dimensions. This strongly suggests an identification of the sine dilaton
gravity theory with the q-deformed JT gravity matrix integral. At the very
least, it captures all universal content of that matrix model. The disk
decomposes into the physical (gauge invariant) solutions of the WdW equation,
which are trumpets with discrete sizes. This decomposition modifies the usual
no-boundary wavefunction to a normalizable one in sine dilaton gravity. We
furthermore present an exact **quantization** of sine dilaton gravity with open and
closed end of the world branes. These EOW branes correspond with FZZT branes
for the two Liouville theories that make up sine dilaton gravity. The WdW
equation implies redundancies in this space of branes, leaving a one parameter
family of gauge invariant branes. One gauge choice corresponds with branes
discussed by Okuyama in the context of chord diagrams and of DSSYK. Legendre
transforming the EOW brane amplitude reproduces the trumpet, independent of the
WdW **quantization** calculation. One could read our work as fleshing out the
Hilbert space of closed universes in sine dilaton gravity.


## Graph of Attacks with Pruning Optimizing Stealthy Jailbreak Prompt Generation for Enhanced LLM Content Moderation

>Authors: Daniel Schwartz, Dmitriy Bespalov, Zhe Wang, Ninad Kulkarni, Yanjun Qi

>2025-01-28

> http://arxiv.org/abs/2501.18638v1

We present a modular pipeline that automates the generation of stealthy
jailbreak prompts derived from high-level content policies, enhancing LLM
content moderation. First, we address query inefficiency and jailbreak strength
by developing Graph of Attacks with Pruning (GAP), a method that utilizes
strategies from prior jailbreaks, resulting in 92% attack success rate on
GPT-3.5 using only 54% of the queries of the prior algorithm. Second, we
address the cold-start issue by automatically generating seed prompts from the
high-level policy using LLMs. Finally, we demonstrate the utility of these
generated jailbreak prompts of improving content moderation by fine-tuning
PromptGuard, a model trained to detect jailbreaks, increasing its accuracy on
the Toxic-Chat dataset from 5.1% to 93.89%.


## Graph Transformers for inverse physics reconstructing flows around arbitrary 2D airfoils

>Authors: Gregory Duthé, Imad Abdallah, Eleni Chatzi

>2025-01-28

> http://arxiv.org/abs/2501.17081v1

We introduce a Graph Transformer framework that serves as a general inverse
physics engine on meshes, demonstrated through the challenging task of
reconstructing aerodynamic flow fields from **sparse** surface measurements. While
deep learning has shown promising results in forward physics simulation,
inverse problems remain particularly challenging due to their ill-posed nature
and the difficulty of propagating information from limited boundary
observations. Our approach addresses these challenges by combining the
geometric expressiveness of message-passing neural networks with the global
reasoning of Transformers, enabling efficient learning of inverse mappings from
boundary conditions to complete states. We evaluate this framework on a
comprehensive dataset of steady-state RANS simulations around diverse airfoil
geometries, where the task is to reconstruct full pressure and velocity fields
from surface pressure measurements alone. The architecture achieves high
reconstruction accuracy while maintaining fast inference times. We conduct
experiments and provide insights into the relative importance of local
geometric processing and global attention mechanisms in mesh-based inverse
problems. We also find that the framework is robust to reduced sensor coverage.
These results suggest that Graph Transformers can serve as effective inverse
physics engines across a broader range of applications where complete system
states must be reconstructed from limited boundary observations.


## Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver

>Authors: Shunya Minami, Kouhei Nakaji, Yohichi Suzuki, Alán Aspuru-Guzik, Tadashi Kadowaki

>2025-01-28

> http://arxiv.org/abs/2501.16986v1

Quantum computing is entering a transformative phase with the emergence of
logical quantum processors, which hold the potential to tackle complex problems
beyond classical capabilities. While significant progress has been made,
applying quantum algorithms to real-world problems remains challenging. Hybrid
quantum-classical techniques have been explored to bridge this gap, but they
often face limitations in expressiveness, trainability, or scalability. In this
work, we introduce conditional Generative Quantum Eigensolver
(conditional-GQE), a context-aware quantum circuit generator powered by an
encoder-decoder Transformer. Focusing on combinatorial optimization, we train
our generator for solving problems with up to 10 qubits, exhibiting nearly
perfect performance on new problems. By leveraging the high expressiveness and
flexibility of classical generative models, along with an efficient
preference-based training scheme, conditional-GQE provides a generalizable and
scalable framework for quantum circuit generation. Our approach advances hybrid
quantum-classical computing and contributes to accelerate the transition toward
fault-tolerant quantum computing.


## Bones of Contention Exploring Query-Efficient Attacks Against Skeleton Recognition Systems

>Authors: Yuxin Cao, Kai Ye, Derui Wang, Minhui Xue, Hao Ge, Chenxiong Qian, Jin Song Dong

>2025-01-28

> http://arxiv.org/abs/2501.16843v1

Skeleton action recognition models have secured more attention than
video-based ones in various applications due to privacy preservation and lower
storage requirements. Skeleton data are typically transmitted to cloud servers
for action recognition, with results returned to clients via Apps/APIs.
However, the vulnerability of skeletal models against adversarial perturbations
gradually reveals the unreliability of these systems. Existing black-box
attacks all operate in a decision-based manner, resulting in numerous queries
that hinder efficiency and feasibility in real-world applications. Moreover,
all attacks off the shelf focus on only restricted perturbations, while
ignoring model weaknesses when encountered with non-semantic perturbations. In
this paper, we propose two query-effIcient Skeletal Adversarial AttaCks,
ISAAC-K and ISAAC-N. As a black-box attack, ISAAC-K utilizes Grad-CAM in a
surrogate model to extract key joints where minor **sparse** perturbations are then
added to fool the classifier. To guarantee natural adversarial motions, we
introduce constraints of both bone length and temporal consistency. ISAAC-K
finds stronger adversarial examples on $\ell_\infty$ norm, which can encompass
those on other norms. Exhaustive experiments substantiate that ISAAC-K can
uplift the attack efficiency of the perturbations under 10 skeletal models.
Additionally, as a byproduct, ISAAC-N fools the classifier by replacing
skeletons unrelated to the action. We surprisingly find that skeletal models
are vulnerable to large perturbations where the part-wise non-semantic joints
are just replaced, leading to a query-free no-box attack without any prior
knowledge. Based on that, four adaptive defenses are eventually proposed to
improve the robustness of skeleton recognition models.


## Not Every Patch is Needed Towards a More Efficient and Effective Backbone for Video-based Person Re-identification

>Authors: Lanyun Zhu, Tianrun Chen, Deyi Ji, Jieping Ye, Jun Liu

>2025-01-28

> http://arxiv.org/abs/2501.16811v1

This paper proposes a new effective and efficient plug-and-play backbone for
video-based person re-identification (ReID). Conventional video-based ReID
methods typically use CNN or transformer backbones to extract deep features for
every position in every sampled video frame. Here, we argue that this
exhaustive feature extraction could be unnecessary, since we find that
different frames in a ReID video often exhibit small differences and contain
many similar regions due to the relatively slight movements of human beings.
Inspired by this, a more selective, efficient paradigm is explored in this
paper. Specifically, we introduce a patch selection mechanism to reduce
computational cost by choosing only the crucial and non-repetitive patches for
feature extraction. Additionally, we present a novel network structure that
generates and utilizes pseudo frame global context to address the issue of
incomplete views resulting from **sparse** inputs. By incorporating these new
designs, our backbone can achieve both high performance and low computational
cost. Extensive experiments on multiple datasets show that our approach reduces
the computational cost by 74\% compared to ViT-B and 28\% compared to ResNet50,
while the accuracy is on par with ViT-B and outperforms ResNet50 significantly.


## Post-Training Quantization for Vision Mamba with k-Scaled Quantization and Reparameterization

>Authors: Bo-Yun Shi, Yi-Cheng Lo, An-Yeu, Wu

>2025-01-28

> http://arxiv.org/abs/2501.16738v1

The Mamba model, utilizing a structured state-space model (SSM), offers
linear time complexity and demonstrates significant potential. Vision Mamba
(ViM) extends this framework to vision tasks by incorporating a bidirectional
SSM and patch embedding, surpassing Transformer-based models in performance.
While model **quantization** is essential for efficient computing, existing works
have focused solely on the original Mamba model and have not been applied to
ViM. Additionally, they neglect quantizing the SSM layer, which is central to
Mamba and can lead to substantial error propagation by naive **quantization** due
to its inherent structure. In this paper, we focus on the post-training
**quantization** (PTQ) of ViM. We address the issues with three core techniques: 1)
a k-scaled token-wise **quantization** method for linear and convolutional layers,
2) a reparameterization technique to simplify hidden state **quantization**, and 3)
a factor-determining method that reduces computational overhead by integrating
operations. Through these methods, the error caused by PTQ can be mitigated.
Experimental results on ImageNet-1k demonstrate only a 0.8-1.2\% accuracy
degradation due to PTQ, highlighting the effectiveness of our approach.


## On the acceleration of gradient methods the triangle steepest descent method

>Authors: Ya Shen, Qing-Na Li, Yu-Hong Dai

>2025-01-28

> http://arxiv.org/abs/2501.16731v1

The gradient type of methods has been a competitive choice in solving large
scale problems arising from various applications such as machine learning.
However, there is still space to accelerate the gradient methods. To this end,
in this paper, we pay attention to the cyclic steepest descent method (CSD),
and prove that the CSD method has a gradient subsequence that is
R-superlinearly convergent for the 2-dimensional strictly convex quadratic
case. Moreover, we propose a new gradient method called triangle steepest
descent method (TSD) which has a parameter $j$ to control the number of cycles.
This method is motivated by utilizing a geometric property of the steepest
descent method (SD) method to get around the zigzag behavior. We show that the
TSD method is at least R-linearly convergent for strictly convex quadratic
problems. The advantage of the TSD method is that it is not sensitive to the
condition number of a strictly convex quadratic problem. For example, it
performs better than other competitive gradient methods when the condition
number reaches 1e20 or 1e100 for some strictly convex quadratic problems.
Extensive numerical results verify the efficiency of the TSD method compared to
other types of gradient methods.


## Point Cloud Upsampling as Statistical Shape Model for Pelvic

>Authors: Tongxu Zhang, Bei Wang

>2025-01-28

> http://arxiv.org/abs/2501.16716v1

We propose a novel framework that integrates medical image segmentation and
point cloud upsampling for accurate shape reconstruction of pelvic models.
Using the SAM-Med3D model for segmentation and a point cloud upsampling network
trained on the MedShapeNet dataset, our method transforms **sparse** medical
imaging data into high-resolution 3D bone models. This framework leverages
prior knowledge of anatomical shapes, achieving smoother and more complete
reconstructions. Quantitative evaluations using metrics such as Chamfer
Distance etc, demonstrate the effectiveness of the point cloud upsampling in
pelvic model. Our approach offers potential applications in reconstructing
other skeletal structures, providing a robust solution for medical image
analysis and statistical shape modeling.


## Image-Space Gridding for Nonrigid Motion-Corrected MR Image Reconstruction

>Authors: Kwang Eun Jang, Mario O. Malavé, Dwight G. Nishimura

>2025-01-28

> http://arxiv.org/abs/2501.16713v1

Motion remains a major challenge in magnetic resonance (MR) imaging,
particularly in free-breathing cardiac MR imaging, where data are acquired over
multiple heartbeats at varying respiratory phases. We adopt a model-based
approach for nonrigid motion correction, addressing two challenges: (a) motion
representation and (b) motion estimation. For motion representation, we derive
image-space gridding by adapting the nonuniform fast Fourier transform (NUFFT)
to represent and compute nonrigid motion, which provides an exact
forward-adjoint pair of linear operators. We then introduce nonrigid SENSE
operators that incorporate nonrigid motion into the multi-coil MR acquisition
model. For motion estimation, we employ both low-resolution 3D image-based
navigators (iNAVs) and high-resolution 3D self-navigating image-based
navigators (self-iNAVs). During each heartbeat, data are acquired along two
types of non-Cartesian trajectories: a subset of a high-resolution trajectory
that **sparse**ly covers 3D k-space, followed by a full low-resolution trajectory.
We reconstruct 3D iNAVs for each heartbeat using the full low-resolution data,
which are then used to estimate bulk motion and identify the respiratory phase
of each heartbeat. By combining data from multiple heartbeats within the same
respiratory phase, we reconstruct high-resolution 3D self-iNAVs, allowing
estimation of nonrigid respiratory motion. For each respiratory phase, we
construct the nonrigid SENSE operator, reformulating the nonrigid
motion-corrected reconstruction as a standard regularized inverse problem. In a
preliminary study, the proposed method enhanced sharpness of the coronary
arteries and improved image quality in non-cardiac regions, outperforming
translational motion-corrected reconstruction.


## Variational Schrödinger Momentum Diffusion

>Authors: Kevin Rojas, Yixin Tan, Molei Tao, Yuriy Nevmyvaka, Wei Deng

>2025-01-28

> http://arxiv.org/abs/2501.16675v1

The momentum Schr\"odinger Bridge (mSB) has emerged as a leading method for
accelerating generative diffusion processes and reducing transport costs.
However, the lack of simulation-free properties inevitably results in high
training costs and affects scalability. To obtain a trade-off between transport
properties and scalability, we introduce variational Schr\"odinger momentum
diffusion (VSMD), which employs linearized forward score functions (variational
scores) to eliminate the dependence on simulated forward trajectories. Our
approach leverages a multivariate diffusion process with adaptively
transport-optimized variational scores. Additionally, we apply a
critical-damping transform to stabilize training by removing the need for score
estimations for both velocity and samples. Theoretically, we prove the
convergence of samples generated with optimal variational scores and momentum
diffusion. Empirical results demonstrate that VSMD efficiently generates
anisotropic shapes while maintaining transport efficacy, outperforming
overdamped alternatives, and avoiding complex denoising processes. Our approach
also scales effectively to real-world data, achieving competitive results in
time series and image generation.


## VeriFact Verifying Facts in LLM-Generated Clinical Text with Electronic Health Records

>Authors: Philip Chung, Akshay Swaminathan, Alex J. Goodell, Yeasul Kim, S. Momsen Reincke, Lichy Han, Ben Deverett, Mohammad Amin Sadeghi, Abdel-Badih Ariss, Marc Ghanem, David Seong, Andrew A. Lee, Caitlin E. Coombes, Brad Bradshaw, Mahir A. Sufian, Hyo Jung Hong, Teresa P. Nguyen, Mohammad R. Rasouli, Komal Kamra, Mark A. Burbridge, James C. McAvoy, Roya Saffary, Stephen P. Ma, Dev Dash, James Xie, Ellen Y. Wang, Clifford A. Schmiesing, Nigam Shah, Nima Aghaeepour

>2025-01-28

> http://arxiv.org/abs/2501.16672v1

Methods to ensure factual accuracy of text generated by large language models
(LLM) in clinical medicine are lacking. VeriFact is an artificial intelligence
system that combines retrieval-augmented generation and LLM-as-a-Judge to
verify whether LLM-generated text is factually supported by a patient's medical
history based on their electronic health record (EHR). To evaluate this system,
we introduce VeriFact-BHC, a new dataset that decomposes Brief Hospital Course
narratives from discharge summaries into a set of simple statements with
clinician annotations for whether each statement is supported by the patient's
EHR clinical notes. Whereas highest agreement between clinicians was 88.5%,
VeriFact achieves up to 92.7% agreement when compared to a denoised and
adjudicated average human clinican ground truth, suggesting that VeriFact
exceeds the average clinician's ability to fact-check text against a patient's
medical record. VeriFact may accelerate the development of LLM-based EHR
applications by removing current evaluation bottlenecks.


## Large Language Model Critics for Execution-Free Evaluation of Code Changes

>Authors: Aashish Yadavally, Hoan Nguyen, Laurent Callot, Gauthier Guinet

>2025-01-28

> http://arxiv.org/abs/2501.16655v1

Large language models (LLMs) offer a promising way forward for automating
software engineering tasks, such as bug fixes, feature additions, etc., via
multi-step LLM-based agentic workflows. However, existing metrics for
evaluating such workflows, mainly build status and occasionally log analysis,
are too **sparse** and limited in providing the information needed to assess the
quality of changes made. In this work, we designed LLM-based critics to derive
well-structured and rigorous intermediate/step-level, execution-free evaluation
proxies for repo-level code changes. Importantly, we assume access to the gold
test patch for the problem (i.e., reference-aware) to assess both semantics and
executability of generated patches. With the gold test patch as a reference, we
predict executability of all editing locations with an F1 score of 91.6%,
aggregating which, we can predict the build status in 84.8% of the instances in
SWE-bench. In particular, such an execution-focused LLM critic outperforms
other reference-free and reference-aware LLM critics by 38.9% to 72.5%.
Moreover, we demonstrate the usefulness of such a reference-aware framework in
comparing patches generated by different agentic workflows. Finally, we
open-source the library developed for this project, which allows further usage
for either other agentic workflows or other benchmarks. The source code is
available at https://github.com/amazon-science/code-agent-eval.


## Sparse Autoencoders Trained on the Same Data Learn Different Features

>Authors: Gonçalo Paulo, Nora Belrose

>2025-01-28

> http://arxiv.org/abs/2501.16615v2

Sparse autoencoders (SAEs) are a useful tool for uncovering
human-interpretable features in the activations of large language models
(LLMs). While some expect SAEs to find the true underlying features used by a
model, our research shows that SAEs trained on the same model and data,
differing only in the random seed used to initialize their weights, identify
different sets of features. For example, in an SAE with 131K latents trained on
a feedforward network in Llama 3 8B, only 30% of the features were shared
across different seeds. We observed this phenomenon across multiple layers of
three different LLMs, two datasets, and several SAE architectures. While ReLU
SAEs trained with the L1 **sparsity** loss showed greater stability across seeds,
SAEs using the state-of-the-art TopK activation function were more
seed-dependent, even when controlling for the level of **sparsity**. Our results
suggest that the set of features uncovered by an SAE should be viewed as a
pragmatically useful decomposition of activation space, rather than an
exhaustive and universal list of features "truly used" by the model.


## Efficient evaluation of real-time path integrals

>Authors: Job Feldbrugge, Joshua Y. L. Jones

>2025-01-27

> http://arxiv.org/abs/2501.16323v1

The Feynman path integral has revolutionized modern approaches to quantum
physics. Although the path integral formalism has proven very successful and
spawned several approximation schemes, the direct evaluation of real-time path
integrals is still extremely expensive and numerically delicate due to its
high-dimensional and oscillatory nature. We propose an efficient method for the
numerical evaluation of the real-time world-line path integral for theories
where the potential is dominated by a quadratic at infinity. This is done by
rewriting the high-dimensional oscillatory integral in terms of a series of
low-dimensional oscillatory integrals, that we efficiently evaluate with
Picard-Lefschetz theory or approximate with the eikonal approximation.
Subsequently, these integrals are stitched together with a series of fast
Fourier transformations to recover the lattice regularized Feynman path
integral. Our method directly applies to problems in quantum mechanics, the
word-line **quantization** of quantum field theory, and quantum gravity.


## Mixture-of-Mamba Enhancing Multi-Modal State-Space Models with Modality-Aware Sparsity

>Authors: Weixin Liang, Junhong Shen, Genghan Zhang, Ning Dong, Luke Zettlemoyer, Lili Yu

>2025-01-27

> http://arxiv.org/abs/2501.16295v1

State Space Models (SSMs) have emerged as efficient alternatives to
Transformers for sequential modeling, but their inability to leverage
modality-specific features limits their performance in multi-modal pretraining.
Here, we propose Mixture-of-Mamba, a novel SSM architecture that introduces
modality-aware **sparsity** through modality-specific parameterization of the Mamba
block. Building on Mixture-of-Transformers (W. Liang et al. arXiv:2411.04996;
2024), we extend the benefits of modality-aware **sparsity** to SSMs while
preserving their computational efficiency. We evaluate Mixture-of-Mamba across
three multi-modal pretraining settings: Transfusion (interleaved text and
continuous image tokens with diffusion loss), Chameleon (interleaved text and
discrete image tokens), and an extended three-modality framework incorporating
speech. Mixture-of-Mamba consistently reaches the same loss values at earlier
training steps with significantly reduced computational costs. In the
Transfusion setting, Mixture-of-Mamba achieves equivalent image loss using only
34.76% of the training FLOPs at the 1.4B scale. In the Chameleon setting,
Mixture-of-Mamba reaches similar image loss with just 42.50% of the FLOPs at
the 1.4B scale, and similar text loss with just 65.40% of the FLOPs. In the
three-modality setting, MoM matches speech loss at 24.80% of the FLOPs at the
1.4B scale. Our ablation study highlights the synergistic effects of decoupling
projection components, where joint decoupling yields greater gains than
individual modifications. These results establish modality-aware **sparsity** as a
versatile and effective design principle, extending its impact from
Transformers to SSMs and setting new benchmarks in multi-modal pretraining. Our
code can be accessed at https://github.com/Weixin-Liang/Mixture-of-Mamba


## Provence efficient and robust context pruning for retrieval-augmented generation

>Authors: Nadezhda Chirkova, Thibault Formal, Vassilina Nikoulina, Stéphane Clinchant

>2025-01-27

> http://arxiv.org/abs/2501.16214v1

Retrieval-augmented generation improves various aspects of large language
models (LLMs) generation, but suffers from computational overhead caused by
long contexts as well as the propagation of irrelevant retrieved information
into generated responses. Context **pruning** deals with both aspects, by removing
irrelevant parts of retrieved contexts before LLM generation. Existing context
**pruning** approaches are however limited, and do not provide a universal model
that would be both efficient and robust in a wide range of scenarios, e.g.,
when contexts contain a variable amount of relevant information or vary in
length, or when evaluated on various domains. In this work, we close this gap
and introduce Provence (Pruning and Reranking Of retrieVEd relevaNt ContExts),
an efficient and robust context pruner for Question Answering, which
dynamically detects the needed amount of **pruning** for a given context and can be
used out-of-the-box for various domains. The three key ingredients of Provence
are formulating the context **pruning** task as sequence labeling, unifying context
**pruning** capabilities with context reranking, and training on diverse data. Our
experimental results show that Provence enables context **pruning** with negligible
to no drop in performance, in various domains and settings, at almost no cost
in a standard RAG pipeline. We also conduct a deeper analysis alongside various
ablations to provide insights into training context pruners for future work.


## MILP initialization for solving parabolic PDEs with PINNs

>Authors: Sirui Li, Federica Bragone, Matthieu Barreau, Kateryna Morozovska

>2025-01-27

> http://arxiv.org/abs/2501.16153v1

Physics-Informed Neural Networks (PINNs) are a powerful deep learning method
capable of providing solutions and parameter estimations of physical systems.
Given the complexity of their neural network structure, the convergence speed
is still limited compared to numerical methods, mainly when used in
applications that model realistic systems. The network initialization follows a
random distribution of the initial weights, as in the case of traditional
neural networks, which could lead to severe model convergence bottlenecks. To
overcome this problem, we follow current studies that deal with optimal initial
weights in traditional neural networks. In this paper, we use a convex
optimization model to improve the initialization of the weights in PINNs and
accelerate convergence. We investigate two optimization models as a first
training step, defined as pre-training, one involving only the boundaries and
one including physics. The optimization is focused on the first layer of the
neural network part of the PINN model, while the other weights are randomly
initialized. We test the methods using a practical application of the heat
diffusion equation to model the temperature distribution of power transformers.
The PINN model with boundary pre-training is the fastest converging method at
the current stage.


## SampleLLM Optimizing Tabular Data Synthesis in Recommendations

>Authors: Jingtong Gao, Zhaocheng Du, Xiaopeng Li, Yichao Wang, Xiangyang Li, Huifeng Guo, Ruiming Tang, Xiangyu Zhao

>2025-01-27

> http://arxiv.org/abs/2501.16125v2

Tabular data synthesis is crucial in machine learning, yet existing general
methods-primarily based on statistical or deep learning models-are highly
data-dependent and often fall short in recommender systems. This limitation
arises from their difficulty in capturing complex distributions and
understanding feature relationships from **sparse** and limited data, along with
their inability to grasp semantic feature relations. Recently, Large Language
Models (LLMs) have shown potential in generating synthetic data samples through
few-shot learning and semantic understanding. However, they often suffer from
inconsistent distribution and lack of diversity due to their inherent
distribution disparity with the target dataset. To address these challenges and
enhance tabular data synthesis for recommendation tasks, we propose a novel
two-stage framework named SampleLLM to improve the quality of LLM-based tabular
data synthesis for recommendations by ensuring better distribution alignment.
In the first stage, SampleLLM employs LLMs with Chain-of-Thought prompts and
diverse exemplars to generate data that closely aligns with the target dataset
distribution, even when input samples are limited. The second stage uses an
advanced feature attribution-based importance sampling method to refine feature
relationships within the synthesized data, reducing any distribution biases
introduced by the LLM. Experimental results on three recommendation datasets,
two general datasets, and online deployment illustrate that SampleLLM
significantly surpasses existing methods for recommendation tasks and holds
promise for a broader range of tabular data scenarios.


## One-Bit Sigma-Delta DFRC Waveform Design Using Quantization Noise for Radar Probing

>Authors: Wai-Yiu Keung, Hei Victor Cheng, Wing-Kin Ma

>2025-01-27

> http://arxiv.org/abs/2501.15868v1

Dual-functional radar-communication (DFRC) signal design has received much
attention lately. We consider the scenario of one-bit massive multi-input
multi-output (MIMO) wherein one-bit DACs are employed for the sake of saving
hardware costs. Specifically, a spatial Sigma-Delta $(\Sigma\Delta)$ modulation
scheme is proposed for one-bit MIMO-DFRC waveform design. Unlike the existing
approaches which require large-scale binary optimization, the proposed scheme
performs $\Sigma\Delta$ modulation on a continuous-valued DFRC signal. The
subsequent waveform design is formulated as a constrained least square problem,
which can be efficiently solved. Moreover, we leverage **quantization** noise for
radar probing purposes, rather than treating it as unwanted noise. Numerical
results demonstrate that the proposed scheme performs well in both radar
probing and downlink precoding.


## Information Consistent Pruning How to Efficiently Search for Sparse Networks?

>Authors: Soheil Gharatappeh, Salimeh Yasaei Sekeh

>2025-01-26

> http://arxiv.org/abs/2501.15592v1

Iterative magnitude **pruning** methods (IMPs), proven to be successful in
reducing the number of insignificant nodes in over-parameterized deep neural
networks (DNNs), have been getting an enormous amount of attention with the
rapid deployment of DNNs into cutting-edge technologies with computation and
memory constraints. Despite IMPs popularity in **pruning** networks, a fundamental
limitation of existing IMP algorithms is the significant training time required
for each **pruning** iteration. Our paper introduces a novel \textit{stopping
criterion} for IMPs that monitors information and gradient flows between
networks layers and minimizes the training time. Information Consistent Pruning
(\ourmethod{}) eliminates the need to retrain the network to its original
performance during intermediate steps while maintaining overall performance at
the end of the **pruning** process. Through our experiments, we demonstrate that
our algorithm is more efficient than current IMPs across multiple dataset-DNN
combinations. We also provide theoretical insights into the core idea of our
algorithm alongside mathematical explanations of flow-based IMP. Our code is
available at \url{https://github.com/Sekeh-Lab/InfCoP}.


## ARWKV Pretrain is not what we need, an RNN-Attention-Based Language Model Born from Transformer

>Authors: Lin Yueyu, Li Zhiyuan, Peter Yue, Liu Xiao

>2025-01-26

> http://arxiv.org/abs/2501.15570v1

As is known, hybrid quadratic and subquadratic attention models in multi-head
architectures have surpassed both Transformer and Linear RNN models , with
these works primarily focusing on reducing **KV** complexity and improving
efficiency. For further research on expressiveness, we introduce our series of
models distilled from Qwen 2.5, based on pure native RW**KV**-7 attention, which
aims to make RNN more expressive and demonstrates state tracking ability beyond
transformers. We work with QRWK 32B based on RW**KV**-6 architecture, another
approach that reduces the entire knowledge processing time to just 8 hours
using 16 AMD MI300X GPUs while maintaining Qwen 2.5's performance. In fact, the
distillation process can utilize any LLM, not just Qwen, and enables knowledge
transfer from larger LLMs to smaller ones with more fewer tokens. We will
explain the detailed process and share our insights on building more powerful
foundation models. Please note that this is an ongoing work that will be
updated continuously. The model checkpoints and source code are available at
\href{https://github.com/yynil/RW**KV**Inside}{https://github.com/yynil/RW**KV**Inside},
\href{https://huggingface.co/RW**KV**-Red-Team/ARW**KV**-7B-Preview-0.1}{https://huggingface.co/RW**KV**-Red-Team/ARW**KV**-7B-Preview-0.1}.


## Improving Network Threat Detection by Knowledge Graph, Large Language Model, and Imbalanced Learning

>Authors: Lili Zhang, Quanyan Zhu, Herman Ray, Ying Xie

>2025-01-26

> http://arxiv.org/abs/2501.16393v1

Network threat detection has been challenging due to the complexities of
attack activities and the limitation of historical threat data to learn from.
To help enhance the existing practices of using analytics, machine learning,
and artificial intelligence methods to detect the network threats, we propose
an integrated modelling framework, where Knowledge Graph is used to analyze the
users' activity patterns, Imbalanced Learning techniques are used to prune and
weigh Knowledge Graph, and LLM is used to retrieve and interpret the users'
activities from Knowledge Graph. The proposed framework is applied to Agile
Threat Detection through Online Sequential Learning. The preliminary results
show the improved threat capture rate by 3%-4% and the increased
interpretabilities of risk predictions based on the users' activities.


## Semantic Communication with Entropy-and-Channel-Adaptive Rate Control

>Authors: Weixuan Chen, Yuhao Chen, Qianqian Yang, Chongwen Huang, Qian Wang, Zehui Xiong, Zhaoyang Zhang

>2025-01-26

> http://arxiv.org/abs/2501.15414v1

Traditional wireless image transmission methods struggle to balance rate
efficiency and reconstruction quality under varying channel conditions. To
address these challenges, we propose a novel semantic communication (SemCom)
system that integrates entropy-aware and channel-adaptive mechanisms for
wireless image transmission over multi-user multiple-input multiple-output
(MU-MIMO) fading channels. Unlike existing approaches, our system dynamically
adjusts transmission rates based on the entropy of feature maps, channel state
information (CSI), and signal-to-noise ratio (SNR), ensuring optimal resource
utilization and robust performance. The system employs feature map **pruning**,
channel attention, spatial attention, and multihead self-attention (MHSA)
mechanisms to prioritize critical semantic features and effectively reconstruct
images. Experimental results demonstrate that the proposed system outperforms
state-of-the-art benchmarks, including BPG+LDPC+4QAM and Deep JSCC, in terms of
rate-distortion performance, flexibility, and robustness, particularly under
challenging conditions such as low SNR, imperfect CSI, and inter-user
interference. This work establishes a strong foundation for adaptive-rate
SemCom systems and highlights their potential for real-time, bandwidthintensive
applications.


## MetaOcc Surround-View 4D Radar and Camera Fusion Framework for 3D Occupancy Prediction with Dual Training Strategies

>Authors: Long Yang, Lianqing Zheng, Wenjin Ai, Minghao Liu, Sen Li, Qunshu Lin, Shengyu Yan, Jie Bai, Zhixiong Ma, Xichan Zhu

>2025-01-26

> http://arxiv.org/abs/2501.15384v1

3D occupancy prediction is crucial for autonomous driving perception. Fusion
of 4D radar and camera provides a potential solution of robust occupancy
prediction on serve weather with least cost. How to achieve effective
multi-modal feature fusion and reduce annotation costs remains significant
challenges. In this work, we propose MetaOcc, a novel multi-modal occupancy
prediction framework that fuses surround-view cameras and 4D radar for
comprehensive environmental perception. We first design a height self-attention
module for effective 3D feature extraction from **sparse** radar points. Then, a
local-global fusion mechanism is proposed to adaptively capture modality
contributions while handling spatio-temporal misalignments. Temporal alignment
and fusion module is employed to further aggregate historical feature.
Furthermore, we develop a semi-supervised training procedure leveraging
open-set segmentor and geometric constraints for pseudo-label generation,
enabling robust perception with limited annotations. Extensive experiments on
OmniHD-Scenes dataset demonstrate that MetaOcc achieves state-of-the-art
performance, surpassing previous methods by significant margins. Notably, as
the first semi-supervised 4D radar and camera fusion-based occupancy prediction
approach, MetaOcc maintains 92.5% of the fully-supervised performance while
using only 50% of ground truth annotations, establishing a new benchmark for
multi-modal 3D occupancy prediction. Code and data are available at
https://github.com/LucasYang567/MetaOcc.


## Qwen2.5-1M Technical Report

>Authors: An Yang, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoyan Huang, Jiandong Jiang, Jianhong Tu, Jianwei Zhang, Jingren Zhou, Junyang Lin, Kai Dang, Kexin Yang, Le Yu, Mei Li, Minmin Sun, Qin Zhu, Rui Men, Tao He, Weijia Xu, Wenbiao Yin, Wenyuan Yu, Xiafei Qiu, Xingzhang Ren, Xinlong Yang, Yong Li, Zhiying Xu, Zipeng Zhang

>2025-01-26

> http://arxiv.org/abs/2501.15383v1

We introduce Qwen2.5-1M, a series of models that extend the context length to
1 million tokens. Compared to the previous 128K version, the Qwen2.5-1M series
have significantly enhanced long-context capabilities through long-context
pre-training and post-training. Key techniques such as long data synthesis,
progressive pre-training, and multi-stage supervised fine-tuning are employed
to effectively enhance long-context performance while reducing training costs.
  To promote the use of long-context models among a broader user base, we
present and open-source our inference framework. This framework includes a
length extrapolation method that can expand the model context lengths by at
least four times, or even more, without additional training. To reduce
inference costs, we implement a **sparse** attention method along with chunked
prefill optimization for deployment scenarios and a **sparsity** refinement method
to improve precision. Additionally, we detail our optimizations in the
inference engine, including kernel optimization, pipeline parallelism, and
scheduling optimization, which significantly enhance overall inference
performance. By leveraging our inference framework, the Qwen2.5-1M models
achieve a remarkable 3x to 7x prefill speedup in scenarios with 1 million
tokens of context. This framework provides an efficient and powerful solution
for developing applications that require long-context processing using
open-source models.
  The Qwen2.5-1M series currently includes the open-source models
Qwen2.5-7B-Instruct-1M and Qwen2.5-14B-Instruct-1M, as well as the API-accessed
model Qwen2.5-Turbo. Evaluations show that Qwen2.5-1M models have been greatly
improved in long-context tasks without compromising performance in
short-context scenarios. Specifically, the Qwen2.5-14B-Instruct-1M model
significantly outperforms GPT-4o-mini in long-context tasks and supports
contexts eight times longer.


## Scaling Large Vision-Language Models for Enhanced Multimodal Comprehension In Biomedical Image Analysis

>Authors: Robinson Umeike, Neil Getty, Fangfang Xia, Rick Stevens

>2025-01-26

> http://arxiv.org/abs/2501.15370v1

Large language models (LLMs) have demonstrated immense capabilities in
understanding textual data and are increasingly being adopted to help
researchers accelerate scientific discovery through knowledge extraction
(information retrieval), knowledge distillation (summarizing key findings and
methodologies into concise forms), and knowledge synthesis (aggregating
information from multiple scientific sources to address complex queries,
generate hypothesis and formulate experimental plans). However, scientific data
often exists in both visual and textual modalities. Vision language models
(VLMs) address this by incorporating a pretrained vision backbone for
processing images and a cross-modal projector that adapts image tokens into the
LLM dimensional space, thereby providing richer multimodal comprehension.
Nevertheless, off-the-shelf VLMs show limited capabilities in handling
domain-specific data and are prone to hallucinations. We developed intelligent
assistants finetuned from LLaVA models to enhance multimodal understanding in
low-dose radiation therapy (LDRT)-a benign approach used in the treatment of
cancer-related illnesses. Using multilingual data from 42,673 articles, we
devise complex reasoning and detailed description tasks for visual question
answering (VQA) benchmarks. Our assistants, trained on 50,882 image-text pairs,
demonstrate superior performance over base models as evaluated using
LLM-as-a-judge approach, particularly in reducing hallucination and improving
domain-specific comprehension.


## Decentralized Low-Rank Fine-Tuning of Large Language Models

>Authors: Sajjad Ghiasvand, Mahnoosh Alizadeh, Ramtin Pedarsani

>2025-01-26

> http://arxiv.org/abs/2501.15361v1

The emergence of Large Language Models (LLMs) such as GPT-4, LLaMA, and BERT
has transformed artificial intelligence, enabling advanced capabilities across
diverse applications. While parameter-efficient fine-tuning (PEFT) techniques
like LoRA offer computationally efficient adaptations of these models, their
practical deployment often assumes centralized data and training environments.
However, real-world scenarios frequently involve distributed, privacy-sensitive
datasets that require decentralized solutions. Federated learning (FL)
addresses data privacy by coordinating model updates across clients, but it is
typically based on centralized aggregation through a parameter server, which
can introduce bottlenecks and communication constraints. Decentralized
learning, in contrast, eliminates this dependency by enabling direct
collaboration between clients, improving scalability and efficiency in
distributed environments. Despite its advantages, decentralized LLM fine-tuning
remains underexplored. In this work, we propose \texttt{Dec-LoRA}, an algorithm
for decentralized fine-tuning of LLMs based on low-rank adaptation (LoRA).
Through extensive experiments on BERT and LLaMA-2 models, we evaluate
\texttt{Dec-LoRA}'s performance in handling data heterogeneity and **quantization**
constraints, enabling scalable, privacy-preserving LLM fine-tuning in
decentralized settings.


## ToMoE Converting Dense Large Language Models to Mixture-of-Experts through Dynamic Structural Pruning

>Authors: Shangqian Gao, Ting Hua, Reza Shirkavand, Chi-Heng Lin, Zhen Tang, Zhengao Li, Longge Yuan, Fangyi Li, Zeyu Zhang, Alireza Ganjdanesh, Lou Qian, Xu Jie, Yen-Chang Hsu

>2025-01-25

> http://arxiv.org/abs/2501.15316v1

Large Language Models (LLMs) have demonstrated remarkable abilities in
tackling a wide range of complex tasks. However, their huge computational and
memory costs raise significant challenges in deploying these models on
resource-constrained devices or efficiently serving them. Prior approaches have
attempted to alleviate these problems by permanently removing less important
model structures, yet these methods often result in substantial performance
degradation due to the permanent deletion of model parameters. In this work, we
tried to mitigate this issue by reducing the number of active parameters
without permanently removing them. Specifically, we introduce a differentiable
dynamic **pruning** method that pushes dense models to maintain a fixed number of
active parameters by converting their MLP layers into a Mixture of Experts
(MoE) architecture. Our method, even without fine-tuning, consistently
outperforms previous structural **pruning** techniques across diverse model
families, including Phi-2, LLaMA-2, LLaMA-3, and Qwen-2.5.


## You Only Prune Once Designing Calibration-Free Model Compression With Policy Learning

>Authors: Ayan Sengupta, Siddhant Chaudhary, Tanmoy Chakraborty

>2025-01-25

> http://arxiv.org/abs/2501.15296v1

The ever-increasing size of large language models (LLMs) presents significant
challenges for deployment due to their heavy computational and memory
requirements. Current model **pruning** techniques attempt to alleviate these
issues by relying heavily on external calibration datasets to determine which
parameters to prune or compress, thus limiting their flexibility and
scalability across different compression ratios. Moreover, these methods often
cause severe performance degradation, particularly in downstream tasks, when
subjected to higher compression rates. In this paper, we propose PruneNet, a
novel model compression method that addresses these limitations by
reformulating model **pruning** as a policy learning process. PruneNet decouples
the **pruning** process from the model architecture, eliminating the need for
calibration datasets. It learns a stochastic **pruning** policy to assess parameter
importance solely based on intrinsic model properties while preserving the
spectral structure to minimize information loss. PruneNet can compress the
LLaMA-2-7B model in just 15 minutes, achieving over 80% retention of its
zero-shot performance with a 30% compression ratio, outperforming existing
methods that retain only 75% performance. Furthermore, on complex multitask
language understanding tasks, PruneNet demonstrates its robustness by
preserving up to 80% performance of the original model, proving itself a
superior alternative to conventional structured compression techniques.


## PIP Perturbation-based Iterative Pruning for Large Language Models

>Authors: Yi Cao, Wei-Jie Xu, Yucheng Shen, Weijie Shi, Chi-Min Chan, Jiajie Xu

>2025-01-25

> http://arxiv.org/abs/2501.15278v1

The rapid increase in the parameter counts of Large Language Models (LLMs),
reaching billions or even trillions, presents significant challenges for their
practical deployment, particularly in resource-constrained environments. To
ease this issue, we propose PIP (Perturbation-based Iterative Pruning), a novel
double-view structured **pruning** method to optimize LLMs, which combines
information from two different views: the unperturbed view and the perturbed
view. With the calculation of gradient differences, PIP iteratively prunes
those that struggle to distinguish between these two views. Our experiments
show that PIP reduces the parameter count by approximately 20% while retaining
over 85% of the original model's accuracy across varied benchmarks. In some
cases, the performance of the pruned model is within 5% of the unpruned
version, demonstrating PIP's ability to preserve key aspects of model
effectiveness. Moreover, PIP consistently outperforms existing state-of-the-art
(SOTA) structured **pruning** methods, establishing it as a leading technique for
optimizing LLMs in environments with constrained resources. Our code is
available at: https://github.com/caoyiiiiii/PIP.


## Exploring the Collaborative Co-Creation Process with AI A Case Study in Novice Music Production

>Authors: Yue Fu, Michele Newman, Lewis Going, Qiuzi Feng, Jin Ha Lee

>2025-01-25

> http://arxiv.org/abs/2501.15276v1

Artificial intelligence is reshaping creative domains, yet its co-creative
processes, especially in group settings with novice users, remain under
explored. To bridge this gap, we conducted a case study in a college-level
course where nine undergraduate students were tasked with creating three
original music tracks using AI tools over 10 weeks. The study spanned the
entire creative journey from ideation to releasing these songs on Spotify.
Participants leveraged AI for music and lyric production, cover art, and
distribution. Our findings highlight how AI transforms creative workflows:
accelerating ideation but compressing the traditional preparation stage, and
requiring novices to navigate a challenging idea selection and validation
phase. We also identified a new "collaging and refinement" stage, where
participants creatively combined diverse AI-generated outputs into cohesive
works. Furthermore, AI influenced group social dynamics and role division among
human creators. Based on these insights, we propose the Human-AI Co-Creation
Stage Model and the Human-AI Agency Model, offering new perspectives on
collaborative co-creation with AI.


## Inductive Biases for Zero-shot Systematic Generalization in Language-informed Reinforcement Learning

>Authors: Negin Hashemi Dijujin, Seyed Roozbeh Razavi Rohani, Mohammad Mahdi Samiei, Mahdieh Soleymani Baghshah

>2025-01-25

> http://arxiv.org/abs/2501.15270v1

Sample efficiency and systematic generalization are two long-standing
challenges in reinforcement learning. Previous studies have shown that
involving natural language along with other observation modalities can improve
generalization and sample efficiency due to its compositional and open-ended
nature. However, to transfer these properties of language to the
decision-making process, it is necessary to establish a proper language
grounding mechanism. One approach to this problem is applying inductive biases
to extract fine-grained and informative representations from the observations,
which makes them more connectable to the language units. We provide
architecture-level inductive biases for modularity and **sparsity** mainly based on
Neural Production Systems (NPS). Alongside NPS, we assign a central role to
memory in our architecture. It can be seen as a high-level information
aggregator which feeds policy/value heads with comprehensive information and
simultaneously guides selective attention in NPS through attentional feedback.
Our results in the BabyAI environment suggest that the proposed model's
systematic generalization and sample efficiency are improved significantly
compared to previous models. An extensive ablation study on variants of the
proposed method is conducted, and the effectiveness of each employed technique
on generalization, sample efficiency, and training stability is specified.


## Lightweight and Post-Training Structured Pruning for On-Device Large Lanaguage Models

>Authors: Zihuai Xu, Yang Xu, Hongli Xu, Yunming Liao, Zhiwei Yao, Zuan Xie

>2025-01-25

> http://arxiv.org/abs/2501.15255v1

Considering the hardware-friendly characteristics and broad applicability,
structured **pruning** has emerged as an efficient solution to reduce the resource
demands of large language models (LLMs) on resource-constrained devices.
Traditional structured **pruning** methods often need fine-tuning to recover
performance loss, which incurs high memory overhead and substantial data
requirements, rendering them unsuitable for on-device applications.
Additionally, post-training structured **pruning** techniques typically necessitate
specific activation functions or architectural modifications, thereby limiting
their scope of applications. Herein, we introduce COMP, a lightweight
post-training structured **pruning** method that employs a hybrid-granularity
**pruning** strategy. COMP initially prunes selected model layers based on their
importance at a coarse granularity, followed by fine-grained neuron **pruning**
within the dense layers of each remaining model layer. To more accurately
evaluate neuron importance, COMP introduces a new matrix condition-based
metric. Subsequently, COMP utilizes mask tuning to recover accuracy without the
need for fine-tuning, significantly reducing memory consumption. Experimental
results demonstrate that COMP improves performance by 6.13\% on the LLaMA-2-7B
model with a 20\% **pruning** ratio compared to LLM-Pruner, while simultaneously
reducing memory overhead by 80\%.


## ABXI Invariant Interest Adaptation for Task-Guided Cross-Domain Sequential Recommendation

>Authors: Qingtian Bian, Marcus Vinícius de Carvalho, Tieying Li, Jiaxing Xu, Hui Fang, Yiping Ke

>2025-01-25

> http://arxiv.org/abs/2501.15118v1

Cross-Domain Sequential Recommendation (CDSR) has recently gained attention
for countering data **sparsity** by transferring knowledge across domains. A common
approach merges domain-specific sequences into cross-domain sequences, serving
as bridges to connect domains. One key challenge is to correctly extract the
shared knowledge among these sequences and appropriately transfer it. Most
existing works directly transfer unfiltered cross-domain knowledge rather than
extracting domain-invariant components and adaptively integrating them into
domain-specific modelings. Another challenge lies in aligning the
domain-specific and cross-domain sequences. Existing methods align these
sequences based on timestamps, but this approach can cause prediction
mismatches when the current tokens and their targets belong to different
domains. In such cases, the domain-specific knowledge carried by the current
tokens may degrade performance. To address these challenges, we propose the
A-B-Cross-to-Invariant Learning Recommender (ABXI). Specifically, leveraging
LoRA's effectiveness for efficient adaptation, ABXI incorporates two types of
LoRAs to facilitate knowledge adaptation. First, all sequences are processed
through a shared encoder that employs a domain LoRA for each sequence, thereby
preserving unique domain characteristics. Next, we introduce an invariant
projector that extracts domain-invariant interests from cross-domain
representations, utilizing an invariant LoRA to adapt these interests into
modeling each specific domain. Besides, to avoid prediction mismatches, all
domain-specific sequences are aligned to match the domains of the cross-domain
ground truths. Experimental results on three datasets demonstrate that our
approach outperforms other CDSR counterparts by a large margin. The codes are
available in \url{https://github.com/DiMarzioBian/ABXI}.


## Task-KV Task-aware KV Cache Optimization via Semantic Differentiation of Attention Heads

>Authors: Xingyang He, Jie Liu, Shaowei Chen

>2025-01-25

> http://arxiv.org/abs/2501.15113v1

**KV** cache is a widely used **acceleration** technique for large language models
(LLMs) inference. However, its memory requirement grows rapidly with input
length. Previous studies have reduced the size of **KV** cache by either removing
the same number of unimportant tokens for all attention heads or by allocating
differentiated **KV** cache budgets for pre-identified attention heads. However,
due to the importance of attention heads varies across different tasks, the
pre-identified attention heads fail to adapt effectively to various downstream
tasks. To address this issue, we propose Task-**KV**, a method that leverages the
semantic differentiation of attention heads to allocate differentiated **KV** cache
budgets across various tasks. We demonstrate that attention heads far from the
semantic center (called heterogeneous heads) make an significant contribution
to task outputs and semantic understanding. In contrast, other attention heads
play the role of aggregating important information and focusing reasoning.
Task-**KV** allocates full **KV** cache budget to heterogeneous heads to preserve
comprehensive semantic information, while reserving a small number of recent
tokens and attention sinks for non-heterogeneous heads. Furthermore, we
innovatively introduce middle activations to preserve key contextual
information aggregated from non-heterogeneous heads. To dynamically perceive
semantic differences among attention heads, we design a semantic separator to
distinguish heterogeneous heads from non-heterogeneous ones based on their
distances from the semantic center. Experimental results on multiple benchmarks
and different model architectures demonstrate that Task-**KV** significantly
outperforms existing baseline methods.


## FBQuant FeedBack Quantization for Large Language Models

>Authors: Yijiang Liu, Hengyu Fang, Liulu He, Rongyu Zhang, Yichuan Bai, Yuan Du, Li Du

>2025-01-25

> http://arxiv.org/abs/2501.16385v1

Deploying Large Language Models (LLMs) on edge devices is increasingly
important, as it eliminates reliance on network connections, reduces expensive
API calls, and enhances user privacy. However, on-device deployment is
challenging due to the limited computational resources of edge devices. In
particular, the key bottleneck stems from memory bandwidth constraints related
to weight loading. Weight-only **quantization** effectively reduces memory access,
yet often induces significant accuracy degradation. Recent efforts to
incorporate sub-branches have shown promise for mitigating **quantization** errors,
but these methods either lack robust optimization strategies or rely on
suboptimal objectives. To address these gaps, we propose FeedBack Quantization
(FBQuant), a novel approach inspired by negative feedback mechanisms in
automatic control. FBQuant inherently ensures that the reconstructed weights
remain bounded by the **quantization** process, thereby reducing the risk of
overfitting. To further offset the additional latency introduced by
sub-branches, we develop an efficient CUDA kernel that decreases 60\% of extra
inference time. Comprehensive experiments demonstrate the efficiency and
effectiveness of FBQuant across various LLMs. Notably, for 3-bit Llama2-7B,
FBQuant improves zero-shot accuracy by 1.2\%.


## CG-RAG Research Question Answering by Citation Graph Retrieval-Augmented LLMs

>Authors: Yuntong Hu, Zhihan Lei, Zhongjie Dai, Allen Zhang, Abhinav Angirekula, Zheng Zhang, Liang Zhao

>2025-01-25

> http://arxiv.org/abs/2501.15067v1

Research question answering requires accurate retrieval and contextual
understanding of scientific literature. However, current Retrieval-Augmented
Generation (RAG) methods often struggle to balance complex document
relationships with precise information retrieval. In this paper, we introduce
Contextualized Graph Retrieval-Augmented Generation (CG-RAG), a novel framework
that integrates **sparse** and dense retrieval signals within graph structures to
enhance retrieval efficiency and subsequently improve generation quality for
research question answering. First, we propose a contextual graph
representation for citation graphs, effectively capturing both explicit and
implicit connections within and across documents. Next, we introduce
Lexical-Semantic Graph Retrieval (LeSeGR), which seamlessly integrates **sparse**
and dense retrieval signals with graph encoding. It bridges the gap between
lexical precision and semantic understanding in citation graph retrieval,
demonstrating generalizability to existing graph retrieval and hybrid retrieval
methods. Finally, we present a context-aware generation strategy that utilizes
the retrieved graph-structured information to generate precise and contextually
enriched responses using large language models (LLMs). Extensive experiments on
research question answering benchmarks across multiple domains demonstrate that
our CG-RAG framework significantly outperforms RAG methods combined with
various state-of-the-art retrieval approaches, delivering superior retrieval
accuracy and generation quality.


## OptiSeq Optimizing Example Ordering for In-Context Learning

>Authors: Rahul Atul Bhope, Praveen Venkateswaran, K. R. Jayaram, Vatche Isahagian, Vinod Muthusamy, Nalini Venkatasubramanian

>2025-01-25

> http://arxiv.org/abs/2501.15030v1

Developers using LLMs in their applications and agents have provided plenty
of anecdotal evidence that in-context-learning (ICL) is fragile. In addition to
the quantity and quality of examples, we show that the order in which the
in-context examples are listed in the prompt affects the output of the LLM and,
consequently, their performance. In this paper, we present OptiSeq, which
introduces a score based on log probabilities of LLM outputs to prune the
universe of possible example orderings in few-shot ICL and recommend the best
order(s) by distinguishing between correct and incorrect outputs resulting from
different order permutations. Through a detailed empirical evaluation on
multiple LLMs, datasets and prompts, we demonstrate that OptiSeq improves
accuracy by 6 - 10.5 percentage points across multiple tasks.


## AKVQ-VL Attention-Aware KV Cache Adaptive 2-Bit Quantization for Vision-Language Models

>Authors: Zunhai Su, Wang Shen, Linge Li, Zhe Chen, Hanyu Wei, Huangqi Yu, Kehong Yuan

>2025-01-25

> http://arxiv.org/abs/2501.15021v1

Vision-language models (VLMs) show remarkable performance in multimodal
tasks. However, excessively long multimodal inputs lead to oversized Key-Value
(**KV**) caches, resulting in significant memory consumption and I/O bottlenecks.
Previous **KV** **quantization** methods for Large Language Models (LLMs) may alleviate
these issues but overlook the attention saliency differences of multimodal
tokens, resulting in suboptimal performance. In this paper, we investigate the
attention-aware token saliency patterns in VLM and propose A**KV**Q-VL. A**KV**Q-VL
leverages the proposed Text-Salient Attention (TSA) and Pivot-Token-Salient
Attention (PSA) patterns to adaptively allocate bit budgets. Moreover,
achieving extremely **low-bit** **quantization** requires effectively addressing
outliers in **KV** tensors. A**KV**Q-VL utilizes the Walsh-Hadamard transform (WHT) to
construct outlier-free **KV** caches, thereby reducing **quantization** difficulty.
Evaluations of 2-bit **quantization** on 12 long-context and multimodal tasks
demonstrate that A**KV**Q-VL maintains or even improves accuracy, outperforming
LLM-oriented methods. A**KV**Q-VL can reduce peak memory usage by 2.13x, support up
to 3.25x larger batch sizes and 2.46x throughput.


## RotateKV Accurate and Robust 2-Bit KV Cache Quantization for LLMs via Outlier-Aware Adaptive Rotations

>Authors: Zunhai Su, Zhe Chen, Wang Shen, Hanyu Wei, Linge Li, Huangqi Yu, Kehong Yuan

>2025-01-25

> http://arxiv.org/abs/2501.16383v2

Key-Value (**KV**) cache facilitates efficient large language models (LLMs)
inference by avoiding recomputation of past **KV**s. As the batch size and context
length increase, the oversized **KV** caches become a significant memory
bottleneck, highlighting the need for efficient compression. Existing **KV**
**quantization** rely on fine-grained **quantization** or the retention of a
significant portion of high bit-widths caches, both of which compromise
compression ratio and often fail to maintain robustness at extremely low
average bit-widths. In this work, we explore the potential of rotation
technique for 2-bit **KV** **quantization** and propose Rotate**KV**, which achieves
accurate and robust performance through the following innovations: (i)
Outlier-Aware Rotation, which utilizes channel-reordering to adapt the
rotations to varying channel-wise outlier distributions without sacrificing the
computational efficiency of the fast Walsh-Hadamard transform (FWHT); (ii)
Pre-RoPE Grouped-Head Rotation, which mitigates the impact of rotary position
embedding (RoPE) on proposed outlier-aware rotation and further smooths
outliers across heads; (iii) Attention-Sink-Aware Quantization, which leverages
the massive activations to precisely identify and protect attention sinks.
Rotate**KV** achieves less than 0.3 perplexity (PPL) degradation with 2-bit
**quantization** on WikiText-2 using LLaMA-2-13B, maintains strong CoT reasoning
and long-context capabilities, with less than 1.7\% degradation on GSM8K,
outperforming existing methods even at lower average bit-widths. Rotate**KV** also
showcases a 3.97x reduction in peak memory usage, supports 5.75x larger batch
sizes, and achieves a 2.32x speedup in decoding stage.


## Light3R-SfM Towards Feed-forward Structure-from-Motion

>Authors: Sven Elflein, Qunjie Zhou, Sérgio Agostinho, Laura Leal-Taixé

>2025-01-24

> http://arxiv.org/abs/2501.14914v1

We present Light3R-SfM, a feed-forward, end-to-end learnable framework for
efficient large-scale Structure-from-Motion (SfM) from unconstrained image
collections. Unlike existing SfM solutions that rely on costly matching and
global optimization to achieve accurate 3D reconstructions, Light3R-SfM
addresses this limitation through a novel latent global alignment module. This
module replaces traditional global optimization with a learnable attention
mechanism, effectively capturing multi-view constraints across images for
robust and precise camera pose estimation. Light3R-SfM constructs a **sparse**
scene graph via retrieval-score-guided shortest path tree to dramatically
reduce memory usage and computational overhead compared to the naive approach.
Extensive experiments demonstrate that Light3R-SfM achieves competitive
accuracy while significantly reducing runtime, making it ideal for 3D
reconstruction tasks in real-world applications with a runtime constraint. This
work pioneers a data-driven, feed-forward SfM approach, paving the way toward
scalable, accurate, and efficient 3D reconstruction in the wild.


## FlexiGPT Pruning and Extending Large Language Models with Low-Rank Weight Sharing

>Authors: James Seale Smith, Chi-Heng Lin, Shikhar Tuli, Haris Jeelani, Shangqian Gao, Yilin Shen, Hongxia Jin, Yen-Chang Hsu

>2025-01-24

> http://arxiv.org/abs/2501.14713v2

The rapid proliferation of large language models (LLMs) in natural language
processing (NLP) has created a critical need for techniques that enable
efficient deployment on memory-constrained devices without compromising
performance. We present a method to prune LLMs that selectively prunes model
blocks based on an importance score and replaces them with a low-parameter
replacement strategy. Specifically, we propose a principled metric to replace
each pruned block using a weight-sharing mechanism that leverages unpruned
counterparts from the model and block-specific low-rank adapters. Furthermore,
we facilitate the learning of these replacement blocks with output feature
normalization and an adapter initialization scheme built on low-rank SVD
reconstructions. Empirical evaluations demonstrate substantial performance
gains over existing methods, achieving state-of-the-art performance on 5/6
benchmarks for a compression rate of 30% and 6/6 benchmarks for a compression
rate of 40%. We also demonstrate that our approach can extend smaller models,
boosting performance on 6/6 benchmarks using only ~0.3% tokens of extended
training with minimal additional parameter costs.


## GraPPI A Retrieve-Divide-Solve GraphRAG Framework for Large-scale Protein-protein Interaction Exploration

>Authors: Ziwen Li, Xiang 'Anthony' Chen, Youngseung Jeon

>2025-01-24

> http://arxiv.org/abs/2501.16382v1

Drug discovery (DD) has tremendously contributed to maintaining and improving
public health. Hypothesizing that inhibiting protein misfolding can slow
disease progression, researchers focus on target identification (Target ID) to
find protein structures for drug binding. While Large Language Models (LLMs)
and Retrieval-Augmented Generation (RAG) frameworks have accelerated drug
discovery, integrating models into cohesive workflows remains challenging. We
conducted a user study with drug discovery researchers to identify the
applicability of LLMs and RAGs in Target ID. We identified two main findings:
1) an LLM should provide multiple Protein-Protein Interactions (PPIs) based on
an initial protein and protein candidates that have a therapeutic impact; 2)
the model must provide the PPI and relevant explanations for better
understanding. Based on these observations, we identified three limitations in
previous approaches for Target ID: 1) semantic ambiguity, 2) lack of
explainability, and 3) short retrieval units. To address these issues, we
propose GraPPI, a large-scale knowledge graph (KG)-based retrieve-divide-solve
agent pipeline RAG framework to support large-scale PPI signaling pathway
exploration in understanding therapeutic impacts by decomposing the analysis of
entire PPI pathways into sub-tasks focused on the analysis of PPI edges.


## Predictor-Feedback Stabilization of Globally Lipschitz Nonlinear Systems with State and Input Quantization

>Authors: Florent Koudohode, Nikolaos Bekiaris-Liberis

>2025-01-24

> http://arxiv.org/abs/2501.14696v1

We develop a switched nonlinear predictor-feedback control law to achieve
global asymptotic stabilization for nonlinear systems with arbitrarily long
input delay, under state **quantization**. The proposed design generalizes the
nonlinear predictor-feedback framework by incorporating **quantize**d measurements
of both the plant and actuator states into the predictor state formulation. Due
to the mismatch between the (inapplicable) exact predictor state and the
predictor state constructed in the presence of state **quantization**, a global
stabilization result is possible under a global Lipschitzness assumption on the
vector field, as well as under the assumption of existence of a globally
Lipschitz, nominal feedback law that achieves global exponential stability of
the delay and **quantization**-free system. To address the constraints imposed by
**quantization**, a dynamic switching strategy is constructed, adjusting the
**quantize**r's tunable parameter in a piecewise constant manner-initially
increasing the **quantization** range, to capture potentially large system states
and subsequently refining the precision to reduce **quantization** error. The
global asymptotic stability of the closed-loop system is established through
solutions estimates derived using backstepping transformations, combined with
small-gain and input-to-state stability arguments. We also extend our approach
to the case of input **quantization**.


## Real-world Edge Neural Network Implementations Leak Private Interactions Through Physical Side Channel

>Authors: Zhuoran Liu, Senna van Hoek, Péter Horváth, Dirk Lauret, Xiaoyun Xu, Lejla Batina

>2025-01-24

> http://arxiv.org/abs/2501.14512v1

Neural networks have become a fundamental component of numerous practical
applications, and their implementations, which are often accelerated by
hardware, are integrated into all types of real-world physical devices. User
interactions with neural networks on hardware accelerators are commonly
considered privacy-sensitive. Substantial efforts have been made to uncover
vulnerabilities and enhance privacy protection at the level of machine learning
algorithms, including membership inference attacks, differential privacy, and
federated learning. However, neural networks are ultimately implemented and
deployed on physical devices, and current research pays comparatively less
attention to privacy protection at the implementation level. In this paper, we
introduce a generic physical side-channel attack, ScaAR, that extracts user
interactions with neural networks by leveraging electromagnetic (EM) emissions
of physical devices. Our proposed attack is implementation-agnostic, meaning it
does not require the adversary to possess detailed knowledge of the hardware or
software implementations, thanks to the capabilities of deep learning-based
side-channel analysis (DLSCA). Experimental results demonstrate that, through
the EM side channel, ScaAR can effectively extract the class label of user
interactions with neural classifiers, including inputs and outputs, on the
AMD-Xilinx MPSoC ZCU104 FPGA and Raspberry Pi 3 B. In addition, for the first
time, we provide side-channel analysis on edge Large Language Model (LLM)
implementations on the Raspberry Pi 5, showing that EM side channel leaks
interaction data, and different LLM tokens can be distinguishable from the EM
traces.


## Advancing data-driven broadband seismic wavefield simulation with multi-conditional diffusion model

>Authors: Zhengfa Bi, Nori Nakata, Rie Nakata, Pu Ren, Xinming Wu, Michael W. Mahoney

>2025-01-24

> http://arxiv.org/abs/2501.14348v1

Sparse distributions of seismic sensors and sources pose challenges for
subsurface imaging, source characterization, and ground motion modeling. While
large-N arrays have shown the potential of dense observational data, their
deployment over extensive areas is constrained by economic and logistical
limitations. Numerical simulations offer an alternative, but modeling realistic
wavefields remains computationally expensive. To address these challenges, we
develop a multi-conditional diffusion transformer for generating seismic
wavefields without requiring prior geological knowledge. Our method produces
high-resolution wavefields that accurately capture both amplitude and phase
information across diverse source and station configurations. The model first
generates amplitude spectra conditioned on input attributes and subsequently
refines wavefields through iterative phase optimization. We validate our
approach using data from the Geysers geothermal field, demonstrating the
generation of wavefields with spatial continuity and fidelity in both spectral
amplitude and phase. These synthesized wavefields hold promise for advancing
structural imaging and source characterization in seismology.


## Fast Think-on-Graph Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph

>Authors: Xujian Liang, Zhaoquan Gu

>2025-01-24

> http://arxiv.org/abs/2501.14300v1

Graph Retrieval Augmented Generation (GRAG) is a novel paradigm that takes
the naive RAG system a step further by integrating graph information, such as
knowledge graph (KGs), into large-scale language models (LLMs) to mitigate
hallucination. However, existing GRAG still encounter limitations: 1) simple
paradigms usually fail with the complex problems due to the narrow and shallow
correlations capture from KGs 2) methods of strong coupling with KGs tend to be
high computation cost and time consuming if the graph is dense. In this paper,
we propose the Fast Think-on-Graph (FastToG), an innovative paradigm for
enabling LLMs to think ``community by community" within KGs. To do this,
FastToG employs community detection for deeper correlation capture and two
stages community **pruning** - coarse and fine **pruning** for faster retrieval.
Furthermore, we also develop two Community-to-Text methods to convert the graph
structure of communities into textual form for better understanding by LLMs.
Experimental results demonstrate the effectiveness of FastToG, showcasing
higher accuracy, faster reasoning, and better explainability compared to the
previous works.


## Dense-SfM Structure from Motion with Dense Consistent Matching

>Authors: JongMin Lee, Sungjoo Yoo

>2025-01-24

> http://arxiv.org/abs/2501.14277v1

We present Dense-SfM, a novel Structure from Motion (SfM) framework designed
for dense and accurate 3D reconstruction from multi-view images. Sparse
keypoint matching, which traditional SfM methods often rely on, limits both
accuracy and point density, especially in texture-less areas. Dense-SfM
addresses this limitation by integrating dense matching with a Gaussian
Splatting (GS) based track extension which gives more consistent, longer
feature tracks. To further improve reconstruction accuracy, Dense-SfM is
equipped with a multi-view kernelized matching module leveraging transformer
and Gaussian Process architectures, for robust track refinement across
multi-views. Evaluations on the ETH3D and Texture-Poor SfM datasets show that
Dense-SfM offers significant improvements in accuracy and density over
state-of-the-art methods.


## Dynamic Token Reduction during Generation for Vision Language Models

>Authors: Xiaoyu Liang, Chaofeng Guan, Jiaying Lu, Huiyao Chen, Huan Wang, Haoji Hu

>2025-01-24

> http://arxiv.org/abs/2501.14204v1

Vision-Language Models (VLMs) have achieved notable success in multimodal
tasks but face practical limitations due to the quadratic complexity of decoder
attention mechanisms and autoregressive generation. Existing methods like FASTV
and VTW have achieved notable results in reducing redundant visual tokens, but
these approaches focus on **pruning** tokens in a single forward pass without
systematically analyzing the redundancy of visual tokens throughout the entire
generation process. In this paper, we introduce a dynamic **pruning** strategy
tailored for VLMs, namedDynamic Rate (DyRate), which progressively adjusts the
compression rate during generation. Our analysis of the distribution of
attention reveals that the importance of visual tokens decreases throughout the
generation process, inspiring us to adopt a more aggressive compression rate.
By integrating a lightweight predictor based on attention distribution, our
approach enables flexible adjustment of **pruning** rates based on the attention
distribution. Our experimental results demonstrate that our method not only
reduces computational demands but also maintains the quality of responses.


## HWPQ Hessian-free Weight Pruning-Quantization For LLM Compression And Acceleration

>Authors: Yuhan Kang, Zhongdi Luo, Mei Wen, Yang Shi, Jun He, Jianchao Yang, Zeyu Xue, Jing Feng, Xinwang Liu

>2025-01-24

> http://arxiv.org/abs/2501.16376v1

Large Language Models (LLMs) have achieved remarkable success across numerous
domains. However, the high time complexity of existing **pruning** and **quantization**
methods significantly hinders their effective deployment on
resource-constrained consumer or edge devices. In this study, we propose a
novel Hessian-free Weight Pruning-Quantization (HWPQ) method. HWPQ eliminates
the need for computationally intensive Hessian matrix calculations by
introducing a contribution-based weight metric, which evaluates the importance
of weights without relying on second-order derivatives. Additionally, we employ
the Exponentially Weighted Moving Average (EWMA) technique to bypass weight
sorting, enabling the selection of weights that contribute most to LLM accuracy
and further reducing time complexity. Our approach is extended to support 2:4
structured **sparsity** **pruning**, facilitating efficient execution on modern
hardware accelerators. Experimental results demonstrate that HWPQ significantly
enhances the compression performance of LLaMA2. Compared to state-of-the-art
**quantization** and **pruning** frameworks, HWPQ achieves average speedups of 5.97x
(up to 20.75x) in **quantization** time and 12.29x (up to 56.02x) in **pruning** time,
while largely preserving model accuracy. Furthermore, we observe a 1.50x
inference speedup compared to the baseline.


## VarDrop Enhancing Training Efficiency by Reducing Variate Redundancy in Periodic Time Series Forecasting

>Authors: Junhyeok Kang, Yooju Shin, Jae-Gil Lee

>2025-01-24

> http://arxiv.org/abs/2501.14183v2

Variate tokenization, which independently embeds each variate as separate
tokens, has achieved remarkable improvements in multivariate time series
forecasting. However, employing self-attention with variate tokens incurs a
quadratic computational cost with respect to the number of variates, thus
limiting its training efficiency for large-scale applications. To address this
issue, we propose VarDrop, a simple yet efficient strategy that reduces the
token usage by omitting redundant variate tokens during training. VarDrop
adaptively excludes redundant tokens within a given batch, thereby reducing the
number of tokens used for dot-product attention while preserving essential
information. Specifically, we introduce k-dominant frequency hashing (k-DFH),
which utilizes the ranked dominant frequencies in the frequency domain as a
hash value to efficiently group variate tokens exhibiting similar periodic
behaviors. Then, only representative tokens in each group are sampled through
stratified sampling. By performing **sparse** attention with these selected tokens,
the computational cost of scaled dot-product attention is significantly
alleviated. Experiments conducted on public benchmark datasets demonstrate that
VarDrop outperforms existing efficient baselines.


## WaveMax Radar Waveform Design via Convex Maximization of FrFT Phase Retrieval

>Authors: Samuel Pinilla, Kumar Vijay Mishra, Brian M. Sadler

>2025-01-24

> http://arxiv.org/abs/2501.14164v1

The ambiguity function (AF) is a critical tool in radar waveform design,
representing the two-dimensional correlation between a transmitted signal and
its time-delayed, frequency-shifted version. Obtaining a radar signal to match
a specified AF magnitude is a bi-variate variant of the well-known phase
retrieval problem. Prior approaches to this problem were either limited to a
few classes of waveforms or lacked a computable procedure to estimate the
signal. Our recent work provided a framework for solving this problem for both
band- and time-limited signals using non-convex optimization. In this paper, we
introduce a novel approach WaveMax that formulates waveform recovery as a
convex optimization problem by relying on the fractional Fourier transform
(FrFT)-based AF. We exploit the fact that AF of the FrFT of the original signal
is equivalent to a rotation of the original AF. In particular, we reconstruct
the radar signal by solving a low-rank minimization problem, which approximates
the waveform using the leading eigenvector of a matrix derived from the AF. Our
theoretical analysis shows that unique waveform reconstruction is achievable
with a sample size no more than three times the signal frequencies or time
samples. Numerical experiments validate the efficacy of WaveMax in recovering
signals from noiseless and noisy AF, including scenarios with randomly and
uniformly sampled **sparse** data.


## EFiGP Eigen-Fourier Physics-Informed Gaussian Process for Inference of Dynamic Systems

>Authors: Jianhong Chen, Shihao Yang

>2025-01-23

> http://arxiv.org/abs/2501.14107v1

Parameter estimation and trajectory reconstruction for data-driven dynamical
systems governed by ordinary differential equations (ODEs) are essential tasks
in fields such as biology, engineering, and physics. These inverse problems --
estimating ODE parameters from observational data -- are particularly
challenging when the data are noisy, **sparse**, and the dynamics are nonlinear. We
propose the Eigen-Fourier Physics-Informed Gaussian Process (EFiGP), an
algorithm that integrates Fourier transformation and eigen-decomposition into a
physics-informed Gaussian Process framework. This approach eliminates the need
for numerical integration, significantly enhancing computational efficiency and
accuracy. Built on a principled Bayesian framework, EFiGP incorporates the ODE
system through probabilistic conditioning, enforcing governing equations in the
Fourier domain while truncating high-frequency terms to achieve denoising and
computational savings. The use of eigen-decomposition further simplifies
Gaussian Process covariance operations, enabling efficient recovery of
trajectories and parameters even in dense-grid settings. We validate the
practical effectiveness of EFiGP on three benchmark examples, demonstrating its
potential for reliable and interpretable modeling of complex dynamical systems
while addressing key challenges in trajectory recovery and computational cost.


## High-intensity wave vortices around subwavelength holes from ocean tides to nanooptics

>Authors: Kateryna Domina, Pablo Alonso-González, Andrei Bylinkin, María Barra-Burillo, Ana I. F. Tresguerres-Mata, Francisco Javier Alfaro-Mozaz, Saül Vélez, Fèlix Casanova, Luis E. Hueso, Rainer Hillenbrand, Konstantin Y. Bliokh, Alexey Y. Nikitin

>2025-01-23

> http://arxiv.org/abs/2501.13860v1

Vortices are ubiquitous in nature; they appear in a variety of phenomena
ranging from galaxy formation in astrophysics to topological defects in quantum
fluids. In particular, wave vortices have attracted enormous attention and
found applications in optics, acoustics, electron microscopy, etc. Such
vortices carry **quantize**d phase singularities accompanied by zero intensity in
the center, and quantum-like orbital angular momentum, with the minimum
localization scale of the wavelength. Here we describe a conceptually novel
type of wave vortices, which can appear around arbitrarily small `holes' (i.e.,
excluded areas or defects) in a homogeneous 2D plane. Such vortices are
characterized by high intensity and confinement at the edges of the hole and
hence subwavelength localization of the angular momentum. We demonstrate the
appearance of such vortices in: (i) optical near fields around metallic
nanodiscs on a dielectric substrate, (ii) phonon-polariton fields around
nanoholes in a polaritonic slab, and (iii) ocean tidal waves around islands of
New Zealand and Madagascar. We also propose a simple toy model of the
generation of such subwavelength vortices via the interference of a
point-dipole source and a plane wave, where the vortex sign is controlled by
the mutual phase between these waves. Our findings open avenues for
subwavelength vortex/angular-momentum-based applications in various wave
fields.


## Where Do You Go? Pedestrian Trajectory Prediction using Scene Features

>Authors: Mohammad Ali Rezaei, Fardin Ayar, Ehsan Javanmardi, Manabu Tsukada, Mahdi Javanmardi

>2025-01-23

> http://arxiv.org/abs/2501.13848v1

Accurate prediction of pedestrian trajectories is crucial for enhancing the
safety of autonomous vehicles and reducing traffic fatalities involving
pedestrians. While numerous studies have focused on modeling interactions among
pedestrians to forecast their movements, the influence of environmental factors
and scene-object placements has been comparatively underexplored. In this
paper, we present a novel trajectory prediction model that integrates both
pedestrian interactions and environmental context to improve prediction
accuracy. Our approach captures spatial and temporal interactions among
pedestrians within a **sparse** graph framework. To account for pedestrian-scene
interactions, we employ advanced image enhancement and semantic segmentation
techniques to extract detailed scene features. These scene and interaction
features are then fused through a cross-attention mechanism, enabling the model
to prioritize relevant environmental factors that influence pedestrian
movements. Finally, a temporal convolutional network processes the fused
features to predict future pedestrian trajectories. Experimental results
demonstrate that our method significantly outperforms existing state-of-the-art
approaches, achieving ADE and FDE values of 0.252 and 0.372 meters,
respectively, underscoring the importance of incorporating both social
interactions and environmental context in pedestrian trajectory prediction.


## An Efficient Diffusion-based Non-Autoregressive Solver for Traveling Salesman Problem

>Authors: Mingzhao Wang, You Zhou, Zhiguang Cao, Yubin Xiao, Xuan Wu, Wei Pang, Yuan Jiang, Hui Yang, Peng Zhao, Yuanshu Li

>2025-01-23

> http://arxiv.org/abs/2501.13767v1

Recent advances in neural models have shown considerable promise in solving
Traveling Salesman Problems (TSPs) without relying on much hand-crafted
engineering. However, while non-autoregressive (NAR) approaches benefit from
faster inference through parallelism, they typically deliver solutions of
inferior quality compared to autoregressive ones. To enhance the solution
quality while maintaining fast inference, we propose DEITSP, a diffusion model
with efficient iterations tailored for TSP that operates in a NAR manner.
Firstly, we introduce a one-step diffusion model that integrates the controlled
discrete noise addition process with self-consistency enhancement, enabling
optimal solution prediction through simultaneous denoising of multiple
solutions. Secondly, we design a dual-modality graph transformer to bolster the
extraction and fusion of features from node and edge modalities, while further
accelerating the inference with fewer layers. Thirdly, we develop an efficient
iterative strategy that alternates between adding and removing noise to improve
exploration compared to previous diffusion methods. Additionally, we devise a
scheduling framework to progressively refine the solution space by adjusting
noise levels, facilitating a smooth search for optimal solutions. Extensive
experiments on real-world and large-scale TSP instances demonstrate that DEITSP
performs favorably against existing neural approaches in terms of solution
quality, inference latency, and generalization ability. Our code is available
at $\href{https://github.com/DEITSP/DEITSP}{https://github.com/DEITSP/DEITSP}$.


## On Disentangled Training for Nonlinear Transform in Learned Image Compression

>Authors: Han Li, Shaohui Li, Wenrui Dai, Maida Cao, Nuowen Kan, Chenglin Li, Junni Zou, Hongkai Xiong

>2025-01-23

> http://arxiv.org/abs/2501.13751v2

Learned image compression (LIC) has demonstrated superior rate-distortion
(R-D) performance compared to traditional codecs, but is challenged by training
inefficiency that could incur more than two weeks to train a state-of-the-art
model from scratch. Existing LIC methods overlook the slow convergence caused
by compacting energy in learning nonlinear transforms. In this paper, we first
reveal that such energy compaction consists of two components, i.e., feature
decorrelation and uneven energy modulation. On such basis, we propose a linear
auxiliary transform (AuxT) to disentangle energy compaction in training
nonlinear transforms. The proposed AuxT obtains coarse approximation to achieve
efficient energy compaction such that distribution fitting with the nonlinear
transforms can be simplified to fine details. We then develop wavelet-based
linear shortcuts (WLSs) for AuxT that leverages wavelet-based downsampling and
orthogonal linear projection for feature decorrelation and subband-aware
scaling for uneven energy modulation. AuxT is lightweight and plug-and-play to
be integrated into diverse LIC models to address the slow convergence issue.
Experimental results demonstrate that the proposed approach can accelerate
training of LIC models by 2 times and simultaneously achieves an average 1\%
BD-rate reduction. To our best knowledge, this is one of the first successful
attempt that can significantly improve the convergence of LIC with comparable
or superior rate-distortion performance. Code will be released at
\url{https://github.com/qingshi9974/AuxT}


## LVPruning An Effective yet Simple Language-Guided Vision Token Pruning Approach for Multi-modal Large Language Models

>Authors: Yizheng Sun, Yanze Xin, Hao Li, Jingyuan Sun, Chenghua Lin, Riza Batista-Navarro

>2025-01-23

> http://arxiv.org/abs/2501.13652v1

Multi-modal Large Language Models (MLLMs) have achieved remarkable success by
integrating visual and textual modalities. However, they incur significant
computational overhead due to the large number of vision tokens processed,
limiting their practicality in resource-constrained environments. We introduce
Language-Guided Vision Token Pruning (LVPruning) for MLLMs, an effective yet
simple method that significantly reduces the computational burden while
preserving model performance. LVPruning employs cross-attention modules to
compute the importance of vision tokens based on their interaction with
language tokens, determining which to prune. Importantly, LVPruning can be
integrated without modifying the original MLLM parameters, which makes
LVPruning simple to apply or remove. Our experiments show that LVPruning can
effectively reduce up to 90% of vision tokens by the middle layer of LLaVA-1.5,
resulting in a 62.1% decrease in inference Tera Floating-Point Operations Per
Second (TFLOPs), with an average performance loss of just 0.45% across nine
multi-modal benchmarks.


## Sigma Differential Rescaling of Query, Key and Value for Efficient Language Models

>Authors: Zhenghao Lin, Zihao Tang, Xiao Liu, Yeyun Gong, Yi Cheng, Qi Chen, Hang Li, Ying Xin, Ziyue Yang, Kailai Yang, Yu Yan, Xiao Liang, Shuai Lu, Yiming Huang, Zheheng Luo, Lei Qu, Xuan Feng, Yaoxiang Wang, Yuqing Xia, Feiyang Chen, Yuting Jiang, Yasen Hu, Hao Ni, Binyang Li, Guoshuai Zhao, Jui-Hao Chiang, Zhongxin Guo, Chen Lin, Kun Kuang, Wenjie Li, Yelong Shen, Jian Jiao, Peng Cheng, Mao Yang

>2025-01-23

> http://arxiv.org/abs/2501.13629v1

We introduce Sigma, an efficient large language model specialized for the
system domain, empowered by a novel architecture including DiffQ**KV** attention,
and pre-trained on our meticulously collected system domain data. DiffQ**KV**
attention significantly enhances the inference efficiency of Sigma by
optimizing the Query (Q), Key (K), and Value (V) components in the attention
mechanism differentially, based on their varying impacts on the model
performance and efficiency indicators. Specifically, we (1) conduct extensive
experiments that demonstrate the model's varying sensitivity to the compression
of K and V components, leading to the development of differentially compressed
**KV**, and (2) propose augmented Q to expand the Q head dimension, which enhances
the model's representation capacity with minimal impacts on the inference
speed. Rigorous theoretical and empirical analyses reveal that DiffQ**KV**
attention significantly enhances efficiency, achieving up to a 33.36%
improvement in inference speed over the conventional grouped-query attention
(GQA) in long-context scenarios. We pre-train Sigma on 6T tokens from various
sources, including 19.5B system domain data that we carefully collect and 1T
tokens of synthesized and rewritten data. In general domains, Sigma achieves
comparable performance to other state-of-arts models. In the system domain, we
introduce the first comprehensive benchmark AIMicius, where Sigma demonstrates
remarkable performance across all tasks, significantly outperforming GPT-4 with
an absolute improvement up to 52.5%.


## QMamba Post-Training Quantization for Vision State Space Models

>Authors: Yinglong Li, Xiaoyu Liu, Jiacheng Li, Ruikang Xu, Yinda Chen, Zhiwei Xiong

>2025-01-23

> http://arxiv.org/abs/2501.13624v1

State Space Models (SSMs), as key components of Mamaba, have gained
increasing attention for vision models recently, thanks to their efficient long
sequence modeling capability. Given the computational cost of deploying SSMs on
resource-limited edge devices, Post-Training Quantization (PTQ) is a technique
with the potential for efficient deployment of SSMs. In this work, we propose
QMamba, one of the first PTQ frameworks to our knowledge, designed for vision
SSMs based on the analysis of the activation distributions in SSMs. We reveal
that the distribution of discrete parameters exhibits long-tailed skewness and
the distribution of the hidden state sequence exhibits highly dynamic
variations. Correspondingly, we design Long-tailed Skewness Quantization (LtSQ)
to **quantize** discrete parameters and Temporal Group Quantization (TGQ) to
**quantize** hidden states, which reduces the **quantization** errors. Extensive
experiments demonstrate that QMamba outperforms advanced PTQ methods on vision
models across multiple model sizes and architectures. Notably, QMamba surpasses
existing methods by 21.0% on ImageNet classification with 4-bit activations.


## Compiler Support for Speculation in Decoupled Access/Execute Architectures

>Authors: Robert Szafarczyk, Syed Waqar Nabi, Wim Vanderbauwhede

>2025-01-23

> http://arxiv.org/abs/2501.13553v1

Irregular codes are bottlenecked by memory and communication latency.
Decoupled access/execute (DAE) is a common technique to tackle this problem. It
relies on the compiler to separate memory address generation from the rest of
the program, however, such a separation is not always possible due to control
and data dependencies between the access and execute slices, resulting in a
loss of decoupling.
  In this paper, we present compiler support for speculation in DAE
architectures that preserves decoupling in the face of control dependencies. We
speculate memory requests in the access slice and poison mis-speculations in
the execute slice without the need for replays or synchronization. Our
transformation works on arbitrary, reducible control flow and is proven to
preserve sequential consistency. We show that our approach applies to a wide
range of architectural work on CPU/GPU prefetchers, CGRAs, and accelerators,
enabling DAE on a wider range of codes than before.


## Diffusion-based Perceptual Neural Video Compression with Temporal Diffusion Information Reuse

>Authors: Wenzhuo Ma, Zhenzhong Chen

>2025-01-23

> http://arxiv.org/abs/2501.13528v1

Recently, foundational diffusion models have attracted considerable attention
in image compression tasks, whereas their application to video compression
remains largely unexplored. In this article, we introduce DiffVC, a
diffusion-based perceptual neural video compression framework that effectively
integrates foundational diffusion model with the video conditional coding
paradigm. This framework uses temporal context from previously decoded frame
and the reconstructed latent representation of the current frame to guide the
diffusion model in generating high-quality results. To accelerate the iterative
inference process of diffusion model, we propose the Temporal Diffusion
Information Reuse (TDIR) strategy, which significantly enhances inference
efficiency with minimal performance loss by reusing the diffusion information
from previous frames. Additionally, to address the challenges posed by
distortion differences across various bitrates, we propose the Quantization
Parameter-based Prompting (QPP) mechanism, which utilizes **quantization**
parameters as prompts fed into the foundational diffusion model to explicitly
modulate intermediate features, thereby enabling a robust variable bitrate
diffusion-based neural compression framework. Experimental results demonstrate
that our proposed solution delivers excellent performance in both perception
metrics and visual quality.


## A Parallel Block Preconditioner-Based VIE-FFT Algorithm for Modeling the Electromagnetic Response From Nanostructures

>Authors: Chengnian Huang, Wei E. I. Sha

>2025-01-23

> http://arxiv.org/abs/2501.13512v1

The superior ability of nanostructures to manipulate light has propelled
extensive applications in nano-electromagnetic components and devices.
Computational electromagnetics plays a critical role in characterizing and
optimizing the nanostructures. In this work, a parallel block preconditioner
based volume integral equation (VIE)-fast Fourier transform (FFT) algorithm is
proposed to model the electromagnetic response from representative
nanostructures. The VIE using uniform Cartesian grids is first built, and then
the entire volumetric domain is partitioned into geometric subdomains based on
the regularity and topology of the nanostructure. The block diagonal matrix is
thus established, whose inverse matrix serves as a preconditioner for the
original matrix equation. The resulting linear system is solved by the
bi-conjugate gradient stabilized (BiCGSTAB) method with different residual
error tolerances in the inner and outer iteration processes; and the FFT
algorithm is used to accelerate the matrix-vector product (MVM) operations
throughout. Furthermore, because of the independence between the inner
processes of solving block matrix equations, the OpenMP framework is empolyed
to execute the parallel operations. Numerical experiments indicate that the
proposed method is effective and reduces both the iteration number and the
computational time significantly for the representative nano-electromagnetic
problems like the dielectric focusing metasurfaces and the plasmonic solar
cells.


## MambaQuant Quantizing the Mamba Family with Variance Aligned Rotation Methods

>Authors: Zukang Xu, Yuxuan Yue, Xing Hu, Zhihang Yuan, Zixu Jiang, Zhixuan Chen, Jiangyong Yu, Chen Xu, Sifan Zhou, Dawei Yang

>2025-01-23

> http://arxiv.org/abs/2501.13484v1

Mamba is an efficient sequence model that rivals Transformers and
demonstrates significant potential as a foundational architecture for various
tasks. Quantization is commonly used in neural networks to reduce model size
and computational latency. However, applying **quantization** to Mamba remains
underexplored, and existing **quantization** methods, which have been effective for
CNN and Transformer models, appear inadequate for Mamba models (e.g., Quarot
suffers a 21% accuracy drop on Vim-T$^\dagger$ even under W8A8). We have
pioneered the exploration of this issue and identified several key challenges.
First, significant outliers are present in gate projections, output
projections, and matrix multiplications. Second, Mamba's unique parallel scan
further amplifies these outliers, leading to uneven and heavy-tailed data
distributions. Third, even with the application of the Hadamard transform, the
variance across channels in weights and activations still remains inconsistent.
To these ends, we propose MambaQuant, a post-training **quantization** (PTQ)
framework consisting of: 1) Karhunen-Loeve Transformation (KLT) enhanced
rotation, rendering the rotation matrix adaptable to diverse channel
distributions. 2) Smooth-Fused rotation, which equalizes channel variances and
can merge additional parameters into model weights. Experiments show that
MambaQuant can **quantize** both weights and activations into 8-bit with less than
1% accuracy loss for Mamba-based vision and language tasks. To the best of our
knowledge, MambaQuant is the first comprehensive PTQ design for the Mamba
family, paving the way for further advancements in its application.


## FreEformer Frequency Enhanced Transformer for Multivariate Time Series Forecasting

>Authors: Wenzhen Yue, Yong Liu, Xianghua Ying, Bowei Xing, Ruohao Guo, Ji Shi

>2025-01-23

> http://arxiv.org/abs/2501.13989v1

This paper presents \textbf{FreEformer}, a simple yet effective model that
leverages a \textbf{Fre}quency \textbf{E}nhanced Trans\textbf{former} for
multivariate time series forecasting. Our work is based on the assumption that
the frequency spectrum provides a global perspective on the composition of
series across various frequencies and is highly suitable for robust
representation learning. Specifically, we first convert time series into the
complex frequency domain using the Discrete Fourier Transform (DFT). The
Transformer architecture is then applied to the frequency spectra to capture
cross-variate dependencies, with the real and imaginary parts processed
independently. However, we observe that the vanilla attention matrix exhibits a
low-rank characteristic, thus limiting representation diversity. This could be
attributed to the inherent **sparsity** of the frequency domain and the
strong-value-focused nature of Softmax in vanilla attention. To address this,
we enhance the vanilla attention mechanism by introducing an additional
learnable matrix to the original attention matrix, followed by row-wise L1
normalization. Theoretical analysis~demonstrates that this enhanced attention
mechanism improves both feature diversity and gradient flow. Extensive
experiments demonstrate that FreEformer consistently outperforms
state-of-the-art models on eighteen real-world benchmarks covering electricity,
traffic, weather, healthcare and finance. Notably, the enhanced attention
mechanism also consistently improves the performance of state-of-the-art
Transformer-based forecasters.


## OstQuant Refining Large Language Model Quantization with Orthogonal and Scaling Transformations for Better Distribution Fitting

>Authors: Xing Hu, Yuan Cheng, Dawei Yang, Zukang Xu, Zhihang Yuan, Jiangyong Yu, Chen Xu, Zhe Jiang, Sifan Zhou

>2025-01-23

> http://arxiv.org/abs/2501.13987v1

Post-training **quantization** (PTQ) has emerged as a widely adopted technique
for compressing and accelerating Large Language Models (LLMs). The major
challenge in LLM **quantization** is that uneven and heavy-tailed data
distributions can expand the **quantization** range, thereby reducing bit precision
for most values. Recent methods attempt to eliminate outliers and balance
inter-channel differences by employing linear transformations; however, they
remain heuristic and are often overlook optimizing the data distribution across
the entire **quantization** space.In this paper, we introduce Quantization Space
Utilization Rate (QSUR), a novel metric that effectively assesses the
quantizability of transformed data by measuring the space utilization of the
data in the **quantization** space. We complement QSUR with mathematical
derivations that examine the effects and limitations of various
transformations, guiding our development of Orthogonal and Scaling
Transformation-based Quantization (OSTQuant). OSQuant employs a learnable
equivalent transformation, consisting of an orthogonal transformation and a
scaling transformation, to optimize the distributions of weights and
activations across the entire **quantization** space. Futhermore, we propose the
KL-Top loss function, designed to mitigate noise during optimization while
retaining richer semantic information within the limited calibration data
imposed by PTQ. OSTQuant outperforms existing work on various LLMs and
benchmarks. In the W4-only setting, it retains 99.5\% of the floating-point
accuracy. In the more challenging W4A4**KV**4 configuration, OSTQuant reduces the
performance gap by 32\% on the LLaMA-3-8B model compared to state-of-the-art
methods.
\href{https://github.com/BrotherHappy/OSTQuant}{https://github.com/BrotherHappy/OSTQuant}.


## Unveiling Discrete Clues Superior Healthcare Predictions for Rare Diseases

>Authors: Chuang Zhao, Hui Tang, Jiheng Zhang, Xiaomeng Li

>2025-01-23

> http://arxiv.org/abs/2501.16373v1

Accurate healthcare prediction is essential for improving patient outcomes.
Existing work primarily leverages advanced frameworks like attention or graph
networks to capture the intricate collaborative (CO) signals in electronic
health records. However, prediction for rare diseases remains challenging due
to limited co-occurrence and inadequately tailored approaches. To address this
issue, this paper proposes UDC, a novel method that unveils discrete clues to
bridge consistent textual knowledge and CO signals within a unified semantic
space, thereby enriching the representation semantics of rare diseases.
Specifically, we focus on addressing two key sub-problems: (1) acquiring
distinguishable discrete encodings for precise disease representation and (2)
achieving semantic alignment between textual knowledge and the CO signals at
the code level. For the first sub-problem, we refine the standard vector
**quantize**d process to include condition awareness. Additionally, we develop an
advanced contrastive approach in the decoding stage, leveraging synthetic and
mixed-domain targets as hard negatives to enrich the perceptibility of the
reconstructed representation for downstream tasks. For the second sub-problem,
we introduce a novel codebook update strategy using co-teacher distillation.
This approach facilitates bidirectional supervision between textual knowledge
and CO signals, thereby aligning semantically equivalent information in a
shared discrete latent space. Extensive experiments on three datasets
demonstrate our superiority.


## Qrazor Reliable and effortless 4-bit llm quantization by significant data razoring

>Authors: Dongyoung Lee, Seungkyu Choi, Ik Joon Chang

>2025-01-23

> http://arxiv.org/abs/2501.13331v1

Large-scale language models (LLMs) have demonstrated outstanding performance
in language processing tasks, yet their deployment is often hindered by high
memory demands and computational complexity. Although **low-bit** **quantization**
techniques, such as 4-bit **quantization**, present a potential solution, they
frequently lead to significant accuracy degradation or require substantial
effort for such aggressive **quantization** approaches. To overcome these
challenges, we introduce QRazor, a reliable and effortless **quantization** scheme
designed to enable 4-bit **quantization** for weights, activations, and **KV** cache in
transformer-based LLMs. The scheme involves two main stages: **quantization** and
compression. During the **quantization** stage, weights, activations, and **KV** cache
values are **quantize**d with wider 8 or 16-bit integers as a basis to achieve
nearly identical accuracy to the original full-precision LLM models, using the
absolute max scaling. Subsequently, all data are compressed to 4-bit using our
proposed significant data razoring (SDR) technique, which retains only the four
most salient bits while discarding the others. Furthermore, we present an
integer-based arithmetic unit dedicated to QRazor, enabling direct
low-precision arithmetic operations without decompressing the SDR data. Despite
the reduced **quantization** effort, QRazor achieves LLM accuracies better or
comparable to state-of-the-art 4-bit methods. By also validating the hardware
efficiency, our decompression-free arithmetic unit achieves 61.2% and 57.8%
reduction in area and power consumption, respectively.


## OSUM Advancing Open Speech Understanding Models with Limited Resources in Academia

>Authors: Xuelong Geng, Kun Wei, Qijie Shao, Shuiyun Liu, Zhennan Lin, Zhixian Zhao, Guojian Li, Wenjie Tian, Peikun Chen, Yangze Li, Pengcheng Guo, Mingchen Shao, Shuiyuan Wang, Yuang Cao, Chengyou Wang, Tianyi Xu, Yuhang Dai, Xinfa Zhu, Yue Li, Li Zhang, Lei Xie

>2025-01-23

> http://arxiv.org/abs/2501.13306v1

Large Language Models (LLMs) have made significant progress in various
downstream tasks, inspiring the development of Speech Understanding Language
Models (SULMs) to enable comprehensive speech-based interactions. However, most
advanced SULMs are developed by the industry, leveraging large-scale datasets
and computational resources that are not readily available to the academic
community. Moreover, the lack of transparency in training details creates
additional barriers to further innovation. In this study, we present OSUM, an
Open Speech Understanding Model designed to explore the potential of training
SLUMs under constrained academic resources. The OSUM model combines a Whisper
encoder with a Qwen2 LLM and supports a wide range of speech tasks, including
speech recognition (ASR), speech recognition with timestamps (SRWT), vocal
event detection (VED), speech emotion recognition (SER), speaking style
recognition (SSR), speaker gender classification (SGC), speaker age prediction
(SAP), and speech-to-text chat (STTC). By employing an ASR+X training strategy,
OSUM achieves efficient and stable multi-task training by simultaneously
optimizing ASR alongside target tasks. Beyond delivering strong performance,
OSUM emphasizes transparency by providing openly available data preparation and
training methodologies, offering valuable insights and practical guidance for
the academic community. By doing so, we aim to accelerate research and
innovation in advanced SULM technologies.


## Hypothesis Generation for Materials Discovery and Design Using Goal-Driven and Constraint-Guided LLM Agents

>Authors: Shrinidhi Kumbhar, Venkatesh Mishra, Kevin Coutinho, Divij Handa, Ashif Iquebal, Chitta Baral

>2025-01-23

> http://arxiv.org/abs/2501.13299v1

Materials discovery and design are essential for advancing technology across
various industries by enabling the development of application-specific
materials. Recent research has leveraged Large Language Models (LLMs) to
accelerate this process. We explore the potential of LLMs to generate viable
hypotheses that, once validated, can expedite materials discovery.
Collaborating with materials science experts, we curated a novel dataset from
recent journal publications, featuring real-world goals, constraints, and
methods for designing real-world applications. Using this dataset, we test
LLM-based agents that generate hypotheses for achieving given goals under
specific constraints. To assess the relevance and quality of these hypotheses,
we propose a novel scalable evaluation metric that emulates the process a
materials scientist would use to evaluate a hypothesis critically. Our curated
dataset, proposed method, and evaluation framework aim to advance future
research in accelerating materials discovery and design with LLMs.


## SRMT Shared Memory for Multi-agent Lifelong Pathfinding

>Authors: Alsu Sagirova, Yuri Kuratov, Mikhail Burtsev

>2025-01-22

> http://arxiv.org/abs/2501.13200v1

Multi-agent reinforcement learning (MARL) demonstrates significant progress
in solving cooperative and competitive multi-agent problems in various
environments. One of the principal challenges in MARL is the need for explicit
prediction of the agents' behavior to achieve cooperation. To resolve this
issue, we propose the Shared Recurrent Memory Transformer (SRMT) which extends
memory transformers to multi-agent settings by pooling and globally
broadcasting individual working memories, enabling agents to exchange
information implicitly and coordinate their actions. We evaluate SRMT on the
Partially Observable Multi-Agent Pathfinding problem in a toy Bottleneck
navigation task that requires agents to pass through a narrow corridor and on a
POGEMA benchmark set of tasks. In the Bottleneck task, SRMT consistently
outperforms a variety of reinforcement learning baselines, especially under
**sparse** rewards, and generalizes effectively to longer corridors than those seen
during training. On POGEMA maps, including Mazes, Random, and MovingAI, SRMT is
competitive with recent MARL, hybrid, and planning-based algorithms. These
results suggest that incorporating shared recurrent memory into the
transformer-based architectures can enhance coordination in decentralized
multi-agent systems. The source code for training and evaluation is available
on GitHub: https://github.com/Aloriosa/srmt.


## Accelerate High-Quality Diffusion Models with Inner Loop Feedback

>Authors: Matthew Gwilliam, Han Cai, Di Wu, Abhinav Shrivastava, Zhiyu Cheng

>2025-01-22

> http://arxiv.org/abs/2501.13107v2

We propose Inner Loop Feedback (ILF), a novel approach to accelerate
diffusion models' inference. ILF trains a lightweight module to predict future
features in the denoising process by leveraging the outputs from a chosen
diffusion backbone block at a given time step. This approach exploits two key
intuitions; (1) the outputs of a given block at adjacent time steps are
similar, and (2) performing partial computations for a step imposes a lower
burden on the model than skipping the step entirely. Our method is highly
flexible, since we find that the feedback module itself can simply be a block
from the diffusion backbone, with all settings copied. Its influence on the
diffusion forward can be tempered with a learnable scaling factor from zero
initialization. We train this module using distillation losses; however, unlike
some prior work where a full diffusion backbone serves as the student, our
model freezes the backbone, training only the feedback module. While many
efforts to optimize diffusion models focus on achieving acceptable image
quality in extremely few steps (1-4 steps), our emphasis is on matching best
case results (typically achieved in 20 steps) while significantly reducing
runtime. ILF achieves this balance effectively, demonstrating strong
performance for both class-to-image generation with diffusion transformer (DiT)
and text-to-image generation with DiT-based PixArt-alpha and PixArt-sigma. The
quality of ILF's 1.7x-1.8x speedups are confirmed by FID, CLIP score, CLIP
Image Quality Assessment, ImageReward, and qualitative comparisons. Project
information is available at https://mgwillia.github.io/ilf.


## Attention-Driven Hierarchical Reinforcement Learning with Particle Filtering for Source Localization in Dynamic Fields

>Authors: Yiwei Shi, Mengyue Yang, Qi Zhang, Weinan Zhang, Cunjia Liu, Weiru Liu

>2025-01-22

> http://arxiv.org/abs/2501.13084v1

In many real-world scenarios, such as gas leak detection or environmental
pollutant tracking, solving the Inverse Source Localization and
Characterization problem involves navigating complex, dynamic fields with
**sparse** and noisy observations. Traditional methods face significant challenges,
including partial observability, temporal and spatial dynamics,
out-of-distribution generalization, and reward **sparsity**. To address these
issues, we propose a hierarchical framework that integrates Bayesian inference
and reinforcement learning. The framework leverages an attention-enhanced
particle filtering mechanism for efficient and accurate belief updates, and
incorporates two complementary execution strategies: Attention Particle
Filtering Planning and Attention Particle Filtering Reinforcement Learning.
These approaches optimize exploration and adaptation under uncertainty.
Theoretical analysis proves the convergence of the attention-enhanced particle
filter, while extensive experiments across diverse scenarios validate the
framework's superior accuracy, adaptability, and computational efficiency. Our
results highlight the framework's potential for broad applications in dynamic
field estimation tasks.


## Efficient Prompt Compression with Evaluator Heads for Long-Context Transformer Inference

>Authors: Weizhi Fei, Xueyan Niu, Guoqing Xie, Yingqing Liu, Bo Bai, Wei Han

>2025-01-22

> http://arxiv.org/abs/2501.12959v1

Although applications involving long-context inputs are crucial for the
effective utilization of large language models (LLMs), they also result in
increased computational costs and reduced performance. To address this
challenge, we propose an efficient, training-free prompt compression method
that retains key information within compressed prompts. We identify specific
attention heads in transformer-based LLMs, which we designate as evaluator
heads, that are capable of selecting tokens in long inputs that are most
significant for inference. Building on this discovery, we develop EHPC, an
Evaluator Head-based Prompt Compression method, which enables LLMs to rapidly
"skim through" input prompts by leveraging only the first few layers with
evaluator heads during the pre-filling stage, subsequently passing only the
important tokens to the model for inference. EHPC achieves state-of-the-art
results across two mainstream benchmarks: prompt compression and long-context
inference **acceleration**. Consequently, it effectively reduces the complexity and
costs associated with commercial API calls. We further demonstrate that EHPC
attains competitive results compared to key-value cache-based **acceleration**
methods, thereby highlighting its potential to enhance the efficiency of LLMs
for long-context tasks.


## GANQ GPU-Adaptive Non-Uniform Quantization for Large Language Models

>Authors: Pengxiang Zhao, Xiaoming Yuan

>2025-01-22

> http://arxiv.org/abs/2501.12956v1

Large Language Models (LLMs) face significant deployment challenges due to
their substantial resource requirements. While **low-bit** **quantize**d weights can
reduce memory usage and improve inference efficiency, current hardware lacks
native support for mixed-precision General Matrix Multiplication (mpGEMM),
resulting in inefficient de**quantization**-based implementations. Moreover,
uniform **quantization** methods often fail to capture weight distributions
adequately, leading to performance degradation. We propose GANQ (GPU-Adaptive
Non-Uniform Quantization), a layer-wise post-training non-uniform **quantization**
framework optimized for hardware-efficient lookup table-based mpGEMM. GANQ
achieves superior **quantization** performance by utilizing a training-free,
GPU-adaptive optimization algorithm to efficiently reduce layer-wise
**quantization** errors. Extensive experiments demonstrate GANQ's ability to reduce
the perplexity gap from the FP16 baseline compared to state-of-the-art methods
for both 3-bit and 4-bit **quantization**. Furthermore, when deployed on a single
NVIDIA RTX 4090 GPU, GANQ's **quantize**d models achieve up to 2.57$\times$ speedup
over the baseline, advancing memory and inference efficiency in LLM deployment.


## Computational modelling of biological systems now and then revisiting tools and visions from the beginning of the century

>Authors: Axel Loewe, Peter J. Hunter, Peter Kohl

>2025-01-22

> http://arxiv.org/abs/2501.13142v1

Since the turn of the millennium, computational modelling of biological
systems has evolved remarkably and sees matured use spanning basic and clinical
research. While the topic of the peri-millennial debate about the virtues and
limitations of 'reductionism and integrationism' seems less controversial
today, a new apparent dichotomy dominates discussions: mechanistic vs.
data-driven modelling. In light of this distinction, we provide an overview of
recent achievements and new challenges with a focus on the cardiovascular
system. Attention has shifted from generating a universal model of the human to
either models of individual humans (digital twins) or entire cohorts of models
representative of clinical populations to enable in silico clinical trials.
Disease-specific parameterisation, inter-individual and intra-individual
variability, uncertainty quantification as well as interoperable, standardised,
and quality-controlled data are important issues today, which call for open
tools, data and metadata standards, as well as strong community interactions.
The quantitative, biophysical, and highly controlled approach provided by in
silico methods has become an integral part of physiological and medical
research. In silico methods have the potential to accelerate future progress
also in the fields of integrated multi-physics modelling, multi-scale models,
virtual cohort studies, and machine learning beyond what is feasible today. In
fact, mechanistic and data-driven modelling can complement each other
synergistically and fuel tomorrow's artificial intelligence applications to
further our understanding of physiology and disease mechanisms, to generate new
hypotheses and assess their plausibility, and thus to contribute to the
evolution of preventive, diagnostic, and therapeutic approaches.


## Unified CNNs and transformers underlying learning mechanism reveals multi-head attention modus vivendi

>Authors: Ella Koresh, Ronit D. Gross, Yuval Meir, Yarden Tzach, Tal Halevi, Ido Kanter

>2025-01-22

> http://arxiv.org/abs/2501.12900v1

Convolutional neural networks (CNNs) evaluate short-range correlations in
input images which progress along the layers, whereas vision transformer (ViT)
architectures evaluate long-range correlations, using repeated transformer
encoders composed of fully connected layers. Both are designed to solve complex
classification tasks but from different perspectives. This study demonstrates
that CNNs and ViT architectures stem from a unified underlying learning
mechanism, which quantitatively measures the single-nodal performance (SNP) of
each node in feedforward (FF) and multi-head attention (MHA) subblocks. Each
node identifies small clusters of possible output labels, with additional noise
represented as labels outside these clusters. These features are progressively
sharpened along the transformer encoders, enhancing the signal-to-noise ratio.
This unified underlying learning mechanism leads to two main findings. First,
it enables an efficient applied nodal diagonal connection (ANDC) **pruning**
technique without affecting the accuracy. Second, based on the SNP, spontaneous
symmetry breaking occurs among the MHA heads, such that each head focuses its
attention on a subset of labels through cooperation among its SNPs.
Consequently, each head becomes an expert in recognizing its designated labels,
representing a quantitative MHA modus vivendi mechanism. These results are
based on a compact convolutional transformer architecture trained on the
CIFAR-100 and Flowers-102 datasets and call for their extension to other
architectures and applications, such as natural language processing.


## Regularization, Semi-supervision, and Supervision for a Plausible Attention-Based Explanation

>Authors: Duc Hau Nguyen, Cyrielle Mallart, Guillaume Gravier, Pascale Sébillot

>2025-01-22

> http://arxiv.org/abs/2501.12775v1

Attention mechanism is contributing to the majority of recent advances in
machine learning for natural language processing. Additionally, it results in
an attention map that shows the proportional influence of each input in its
decision. Empirical studies postulate that attention maps can be provided as an
explanation for model output. However, it is still questionable to ask whether
this explanation helps regular people to understand and accept the model output
(the plausibility of the explanation). Recent studies show that attention
weights in the RNN encoders are hardly plausible because they spread on input
tokens. We thus propose 3 additional constraints to the learning objective
function to improve the plausibility of the attention map: regularization to
increase the attention weight **sparsity**, semi-supervision to supervise the map
by a heuristic and supervision by human annotation. Results show that all
techniques can improve the attention map plausibility at some level. We also
observe that specific instructions for human annotation might have a negative
effect on classification performance. Beyond the attention map, the result of
experiments on text classification tasks also shows that no matter how the
constraint brings the gain, the contextualization layer plays a crucial role in
finding the right space for finding plausible tokens.


## Applications and Challenges of AI and Microscopy in Life Science Research A Review

>Authors: Himanshu Buckchash, Gyanendra Kumar Verma, Dilip K. Prasad

>2025-01-22

> http://arxiv.org/abs/2501.13135v1

The complexity of human biology and its intricate systems holds immense
potential for advancing human health, disease treatment, and scientific
discovery. However, traditional manual methods for studying biological
interactions are often constrained by the sheer volume and complexity of
biological data. Artificial Intelligence (AI), with its proven ability to
analyze vast datasets, offers a transformative approach to addressing these
challenges. This paper explores the intersection of AI and microscopy in life
sciences, emphasizing their potential applications and associated challenges.
We provide a detailed review of how various biological systems can benefit from
AI, highlighting the types of data and labeling requirements unique to this
domain. Particular attention is given to microscopy data, exploring the
specific AI techniques required to process and interpret this information. By
addressing challenges such as data heterogeneity and annotation scarcity, we
outline potential solutions and emerging trends in the field. Written primarily
from an AI perspective, this paper aims to serve as a valuable resource for
researchers working at the intersection of AI, microscopy, and biology. It
summarizes current advancements, key insights, and open problems, fostering an
understanding that encourages interdisciplinary collaborations. By offering a
comprehensive yet concise synthesis of the field, this paper aspires to
catalyze innovation, promote cross-disciplinary engagement, and accelerate the
adoption of AI in life science research.


## High-efficient machine learning projection method for incompressible Navier-Stokes equations

>Authors: Ruilin Chen, Xiaowei Jin, Nikolaus A. Adams, Hui Li

>2025-01-22

> http://arxiv.org/abs/2501.13966v1

This study proposes a high-efficient machine learning (ML) projection method
using forward-generated data for incompressible Navier-Stokes equations. A
Poisson neural network (Poisson-NN) embedded method and a wavelet transform
convolutional neural network multigrid (WTCNN-MG) method are proposed,
integrated into the projection method framework in patchwork and overall
differentiable manners with MG method, respectively. The solution of the
pressure Poisson equation split from the Navier-Stokes equations is first
generated either following a random field (e.g. Gaussian random field, GRF,
computational complexity O(NlogN), N is the number of spatial points) or
physical laws (e.g. a kind of spectra, computational complexity O(NM), M is the
number of modes), then the source terms, boundary conditions and initial
conditions are constructed via balance of equations, avoiding the difficulties
of obtaining high-fidelity training datasets. The feasibility of generated data
for training Poisson-NN and WTCNN as well as the **acceleration** performances of
the Poisson-NN embedded method and WTCNN-MG method are validated. The results
indicate that even without any DNS data, the generated data can train these two
models with excellent generalization and accuracy. The data following physical
laws can significantly improve the high-frequency approximation, convergence
rate, generalization and accuracy than that generated following GRF. The ML
projection method offers significant improvements in computational efficiency.
Particularly, the Poisson-NN embedded method achieves an average speed-up of
5.83 times over the traditional MG method, while the WTCNN-MG method offers an
even greater average speed-up of 7.03 times, demonstrating impressive
**acceleration** performance.


## DWTNeRF Boosting Few-shot Neural Radiance Fields via Discrete Wavelet Transform

>Authors: Hung Nguyen, Blark Runfa Li, Truong Nguyen

>2025-01-22

> http://arxiv.org/abs/2501.12637v2

Neural Radiance Fields (NeRF) has achieved superior performance in novel view
synthesis and 3D scene representation, but its practical applications are
hindered by slow convergence and reliance on dense training views. To this end,
we present DWTNeRF, a unified framework based on Instant-NGP's fast-training
hash encoding. It is coupled with regularization terms designed for few-shot
NeRF, which operates on **sparse** training views. Our DWTNeRF additionally
includes a novel Discrete Wavelet loss that allows explicit prioritization of
low frequencies directly in the training objective, reducing few-shot NeRF's
overfitting on high frequencies in earlier training stages. We also introduce a
model-based approach, based on multi-head attention, that is compatible with
INGP, which are sensitive to architectural changes. On the 3-shot LLFF
benchmark, DWTNeRF outperforms Vanilla INGP by 15.07% in PSNR, 24.45% in SSIM
and 36.30% in LPIPS. Our approach encourages a re-thinking of current few-shot
approaches for fast-converging implicit representations like INGP or 3DGS.


## SoMa Identifying, Exploring, and Understanding the DRAM Communication Scheduling Space for DNN Accelerators

>Authors: Jingwei Cai, Xuan Wang, Mingyu Gao, Sen Peng, Zijian Zhu, Yuchen Wei, Zuotong Wu, Kaisheng Ma

>2025-01-22

> http://arxiv.org/abs/2501.12634v1

Modern Deep Neural Network (DNN) accelerators are equipped with increasingly
larger on-chip buffers to provide more opportunities to alleviate the
increasingly severe DRAM bandwidth pressure. However, most existing research on
buffer utilization still primarily focuses on single-layer dataflow scheduling
optimization. As buffers grow large enough to accommodate most single-layer
weights in most networks, the impact of single-layer dataflow optimization on
DRAM communication diminishes significantly. Therefore, developing new
paradigms that fuse multiple layers to fully leverage the increasingly abundant
on-chip buffer resources to reduce DRAM accesses has become particularly
important, yet remains an open challenge. To address this challenge, we first
identify the optimization opportunities in DRAM communication scheduling by
analyzing the drawbacks of existing works on the layer fusion paradigm and
recognizing the vast optimization potential in scheduling the timing of data
prefetching from and storing to DRAM. To fully exploit these optimization
opportunities, we develop a Tensor-centric Notation and its corresponding
parsing method to represent different DRAM communication scheduling schemes and
depict the overall space of DRAM communication scheduling. Then, to thoroughly
and efficiently explore the space of DRAM communication scheduling for diverse
accelerators and workloads, we develop an end-to-end scheduling framework,
SoMa, which has already been developed into a compiler for our commercial
accelerator product. Compared with the state-of-the-art (SOTA) Cocco framework,
SoMa achieves, on average, a 2.11x performance improvement and a 37.3%
reduction in energy cost simultaneously. Then, we leverage SoMa to study
optimizations for LLM, perform design space exploration (DSE), and analyze the
DRAM communication scheduling space through a practical example, yielding
some..(more)


## BLR-MoE Boosted Language-Routing Mixture of Experts for Domain-Robust Multilingual E2E ASR

>Authors: Guodong Ma, Wenxuan Wang, Lifeng Zhou, Yuting Yang, Yuke Li, Binbin Du

>2025-01-22

> http://arxiv.org/abs/2501.12602v1

Recently, the Mixture of Expert (MoE) architecture, such as LR-MoE, is often
used to alleviate the impact of language confusion on the multilingual ASR
(MASR) task. However, it still faces language confusion issues, especially in
mismatched domain scenarios. In this paper, we decouple language confusion in
LR-MoE into confusion in self-attention and router. To alleviate the language
confusion in self-attention, based on LR-MoE, we propose to apply attention-MoE
architecture for MASR. In our new architecture, MoE is utilized not only on
feed-forward network (FFN) but also on self-attention. In addition, to improve
the robustness of the LID-based router on language confusion, we propose expert
**pruning** and router augmentation methods. Combining the above, we get the
boosted language-routing MoE (BLR-MoE) architecture. We verify the
effectiveness of the proposed BLR-MoE in a 10,000-hour MASR dataset.


## Academic Case Reports Lack Diversity Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related to Post COVID-19 Condition

>Authors: Juan Andres Medina Florez, Shaina Raza, Rashida Lynn, Zahra Shakeri, Brendan T. Smith, Elham Dolatabadi

>2025-01-21

> http://arxiv.org/abs/2501.12538v2

Understanding the prevalence, disparities, and symptom variations of Post
COVID-19 Condition (PCC) for vulnerable populations is crucial to improving
care and addressing intersecting inequities. This study aims to develop a
comprehensive framework for integrating social determinants of health (SDOH)
into PCC research by leveraging NLP techniques to analyze disparities and
variations in SDOH representation within PCC case reports. Following
construction of a PCC Case Report Corpus, comprising over 7,000 case reports
from the LitCOVID repository, a subset of 709 reports were annotated with 26
core SDOH-related entity types using pre-trained named entity recognition (NER)
models, human review, and data augmentation to improve quality, diversity and
representation of entity types. An NLP pipeline integrating NER, natural
language inference (NLI), trigram and frequency analyses was developed to
extract and analyze these entities. Both encoder-only transformer models and
RNN-based models were assessed for the NER objective.
  Fine-tuned encoder-only BERT models outperformed traditional RNN-based models
in generalizability to distinct sentence structures and greater class **sparsity**.
Exploratory analysis revealed variability in entity richness, with prevalent
entities like condition, age, and access to care, and underrepresentation of
sensitive categories like race and housing status. Trigram analysis highlighted
frequent co-occurrences among entities, including age, gender, and condition.
The NLI objective (entailment and contradiction analysis) showed attributes
like "Experienced violence or abuse" and "Has medical insurance" had high
entailment rates (82.4%-80.3%), while attributes such as "Is
female-identifying," "Is married," and "Has a terminal condition" exhibited
high contradiction rates (70.8%-98.5%).


## The Journey Matters Average Parameter Count over Pre-training Unifies Sparse and Dense Scaling Laws

>Authors: Tian Jin, Ahmed Imtiaz Humayun, Utku Evci, Suvinay Subramanian, Amir Yazdanbakhsh, Dan Alistarh, Gintare Karolina Dziugaite

>2025-01-21

> http://arxiv.org/abs/2501.12486v1

Pruning eliminates unnecessary parameters in neural networks; it offers a
promising solution to the growing computational demands of large language
models (LLMs). While many focus on post-training **pruning**, **sparse**
pre-training--which combines **pruning** and pre-training into a single
phase--provides a simpler alternative. In this work, we present the first
systematic exploration of optimal **sparse** pre-training configurations for LLMs
through an examination of 80 unique **pruning** schedules across different **sparsity**
levels and training durations. We find that initiating **pruning** at 25% of total
training compute and concluding at 75% achieves near-optimal final evaluation
loss. These findings provide valuable insights for efficient and effective
**sparse** pre-training of LLMs. Furthermore, we propose a new scaling law that
modifies the Chinchilla scaling law to use the average parameter count over
pre-training. Through empirical and theoretical validation, we demonstrate that
this modified scaling law accurately models evaluation loss for both **sparse**ly
and densely pre-trained LLMs, unifying scaling laws across pre-training
paradigms. Our findings indicate that while **sparse** pre-training achieves the
same final model quality as dense pre-training for equivalent compute budgets,
it provides substantial benefits through reduced model size, enabling
significant potential computational savings during inference.


## Parallel Sequence Modeling via Generalized Spatial Propagation Network

>Authors: Hongjun Wang, Wonmin Byeon, Jiarui Xu, Jinwei Gu, Ka Chun Cheung, Xiaolong Wang, Kai Han, Jan Kautz, Sifei Liu

>2025-01-21

> http://arxiv.org/abs/2501.12381v1

We present the Generalized Spatial Propagation Network (GSPN), a new
attention mechanism optimized for vision tasks that inherently captures 2D
spatial structures. Existing attention models, including transformers, linear
attention, and state-space models like Mamba, process multi-dimensional data as
1D sequences, compromising spatial coherence and efficiency. GSPN overcomes
these limitations by directly operating on spatially coherent image data and
forming dense pairwise connections through a line-scan approach. Central to
GSPN is the Stability-Context Condition, which ensures stable, context-aware
propagation across 2D sequences and reduces the effective sequence length to
$\sqrt{N}$ for a square map with N elements, significantly enhancing
computational efficiency. With learnable, input-dependent weights and no
reliance on positional embeddings, GSPN achieves superior spatial fidelity and
state-of-the-art performance in vision tasks, including ImageNet
classification, class-guided image generation, and text-to-image generation.
Notably, GSPN accelerates SD-XL with softmax-attention by over $84\times$ when
generating 16K images.


## Efficient Algorithm for Sparse Fourier Transform of Generalized q-ary Functions

>Authors: Darin Tsui, Kunal Talreja, Amirali Aghazadeh

>2025-01-21

> http://arxiv.org/abs/2501.12365v1

Computing the Fourier transform of a $q$-ary function
$f:\mathbb{Z}_{q}^n\rightarrow \mathbb{R}$, which maps $q$-ary sequences to
real numbers, is an important problem in mathematics with wide-ranging
applications in biology, signal processing, and machine learning. Previous
studies have shown that, under the **sparsity** assumption, the Fourier transform
can be computed efficiently using fast and sample-efficient algorithms.
However, in many practical settings, the function is defined over a more
general space -- the space of generalized $q$-ary sequences $\mathbb{Z}_{q_1}
\times \mathbb{Z}_{q_2} \times \cdots \times \mathbb{Z}_{q_n}$ -- where each
$\mathbb{Z}_{q_i}$ corresponds to integers modulo $q_i$. A naive approach
involves setting $q=\max_i{q_i}$ and treating the function as $q$-ary, which
results in heavy computational overheads. Herein, we develop GFast, an
algorithm that computes the $S$-**sparse** Fourier transform of $f$ with a sample
complexity of $O(Sn)$, computational complexity of $O(Sn \log N)$, and a
failure probability that approaches zero as $N=\prod_{i=1}^n q_i \rightarrow
\infty$ with $S = N^\delta$ for some $0 \leq \delta < 1$. In the presence of
noise, we further demonstrate that a robust version of GFast computes the
transform with a sample complexity of $O(Sn^2)$ and computational complexity of
$O(Sn^2 \log N)$ under the same high probability guarantees. Using large-scale
synthetic experiments, we demonstrate that GFast computes the **sparse** Fourier
transform of generalized $q$-ary functions using $16\times$ fewer samples and
running $8\times$ faster than existing algorithms. In real-world protein
fitness datasets, GFast explains the predictive interactions of a neural
network with $>25\%$ smaller normalized mean-squared error compared to existing
algorithms.


## Dissecting the NVIDIA Hopper Architecture through Microbenchmarking and Multiple Level Analysis

>Authors: Weile Luo, Ruibo Fan, Zeyu Li, Dayou Du, Hongyuan Liu, Qiang Wang, Xiaowen Chu

>2025-01-21

> http://arxiv.org/abs/2501.12084v1

Modern GPUs, with their specialized hardware like tensor cores, are essential
for demanding AI and deep learning applications. This study presents a
comprehensive, multi-level microbenchmarking analysis of the NVIDIA Hopper GPU
architecture, delving into its performance characteristics and novel features.
We benchmark Hopper's memory subsystem latency and throughput, comparing its L2
partitioned cache behavior and global memory access patterns against recent GPU
generations, Ampere and Ada Lovelace. Our analysis reveals significant
performance differences and architectural improvements in Hopper. A core
contribution of this work is a detailed evaluation of Hopper's
fourth-generation tensor cores, including their FP8 precision support and the
novel asynchronous wgmma instructions, assessing their impact on matrix
multiply-accumulate operations. We further investigate the performance
implications of other key Hopper innovations: DPX instructions for accelerating
dynamic programming algorithms, distributed shared memory (DSM) for inter-SM
communication, and the Tensor Memory Accelerator (TMA) for asynchronous data
movement. This multi-level approach encompasses instruction-level
microbenchmarks, library-level analysis of the Transformer Engine, and
application-level benchmarks of tensor core performance within large language
models. Our findings provide valuable, in-depth insights for software
developers seeking to optimize performance and develop accurate performance
models for the Hopper architecture, ultimately contributing to a deeper
understanding of its potential for accelerating AI and other computationally
intensive workloads.


## Combinatorics on bi-$γ$-positivity of $1/k$-Eulerian polynomials

>Authors: Sherry H. F. Yan, Xubo Yang, Zhicong Lin

>2025-01-21

> http://arxiv.org/abs/2501.12055v1

The $1/k$-Eulerian polynomials $A^{(k)}_{n}(x)$ were introduced as ascent
polynomials over $k$-inversion sequences by Savage and Viswanathan. The
bi-$\gamma$-positivity of the $1/k$-Eulerian polynomials $A^{(k)}_{n}(x)$ was
known but to give a combinatorial interpretation of the corresponding
bi-$\gamma$-coefficients still remains open. The study of the theme of
bi-$\gamma$-positivities from purely combinatorial aspect was proposed by
Athanasiadis. In this paper, we provide a combinatorial interpretation for the
bi-$\gamma$-coefficients of $A^{(k)}_{n}(x)$ by using the model of certain
ordered labeled forests. Our combinatorial approach consists of three main
steps:
  (i) construct a bijection between $k$-Stirling permutations and certain
forests that are named increasing pruned even $k$-ary forests;
  (ii) introduce a generalized Foata--Strehl action on increasing pruned even
$k$-ary trees which implies the longest ascent-plateau polynomials over
$k$-Stirling permutations with initial letter $1$ are $\gamma$-positive, a
result that may have independent interest;
  (iii) develop two crucial transformations on increasing pruned even $k$-ary
forests to conclude our combinatorial interpretation.


## Rate-Aware Learned Speech Compression

>Authors: Jun Xu, Zhengxue Cheng, Guangchuan Chi, Yuhan Liu, Yuelin Hu, Li Song

>2025-01-21

> http://arxiv.org/abs/2501.11999v1

The rapid rise of real-time communication and large language models has
significantly increased the importance of speech compression. Deep
learning-based neural speech codecs have outperformed traditional signal-level
speech codecs in terms of rate-distortion (RD) performance. Typically, these
neural codecs employ an encoder-**quantize**r-decoder architecture, where audio is
first converted into latent code feature representations and then into discrete
tokens. However, this architecture exhibits insufficient RD performance due to
two main drawbacks: (1) the inadequate performance of the **quantize**r,
challenging training processes, and issues such as codebook collapse; (2) the
limited representational capacity of the encoder and decoder, making it
difficult to meet feature representation requirements across various bitrates.
In this paper, we propose a rate-aware learned speech compression scheme that
replaces the **quantize**r with an advanced channel-wise entropy model to improve
RD performance, simplify training, and avoid codebook collapse. We employ
multi-scale convolution and linear attention mixture blocks to enhance the
representational capacity and flexibility of the encoder and decoder.
Experimental results demonstrate that the proposed method achieves
state-of-the-art RD performance, obtaining 53.51% BD-Rate bitrate saving in
average, and achieves 0.26 BD-VisQol and 0.44 BD-PESQ gains.


## SMamba Sparse Mamba for Event-based Object Detection

>Authors: Nan Yang, Yang Wang, Zhanwen Liu, Meng Li, Yisheng An, Xiangmo Zhao

>2025-01-21

> http://arxiv.org/abs/2501.11971v1

Transformer-based methods have achieved remarkable performance in event-based
object detection, owing to the global modeling ability. However, they neglect
the influence of non-event and noisy regions and process them uniformly,
leading to high computational overhead. To mitigate computation cost, some
researchers propose window attention based sparsification strategies to discard
unimportant regions, which sacrifices the global modeling ability and results
in suboptimal performance. To achieve better trade-off between accuracy and
efficiency, we propose Sparse Mamba (SMamba), which performs adaptive
sparsification to reduce computational effort while maintaining global modeling
capability. Specifically, a Spatio-Temporal Continuity Assessment module is
proposed to measure the information content of tokens and discard uninformative
ones by leveraging the spatiotemporal distribution differences between activity
and noise events. Based on the assessment results, an Information-Prioritized
Local Scan strategy is designed to shorten the scan distance between
high-information tokens, facilitating interactions among them in the spatial
dimension. Furthermore, to extend the global interaction from 2D space to 3D
representations, a Global Channel Interaction module is proposed to aggregate
channel information from a global spatial perspective. Results on three
datasets (Gen1, 1Mpx, and eTram) demonstrate that our model outperforms other
methods in both performance and efficiency.


## Phase Transitions in Phase-Only Compressed Sensing

>Authors: Junren Chen, Lexiao Lai, Arian Maleki

>2025-01-21

> http://arxiv.org/abs/2501.11905v1

The goal of phase-only compressed sensing is to recover a structured signal
$\mathbf{x}$ from the phases $\mathbf{z} = {\rm sign}(\mathbf{\Phi}\mathbf{x})$
under some complex-valued sensing matrix $\mathbf{\Phi}$. Exact reconstruction
of the signal's direction is possible: we can reformulate it as a linear
compressed sensing problem and use basis pursuit (i.e., constrained norm
minimization). For $\mathbf{\Phi}$ with i.i.d. complex-valued Gaussian entries,
this paper shows that the phase transition is approximately located at the
statistical dimension of the descent cone of a signal-dependent norm.
Leveraging this insight, we derive asymptotically precise formulas for the
phase transition locations in phase-only sensing of both **sparse** signals and
low-rank matrices. Our results prove that the minimum number of measurements
required for exact recovery is smaller for phase-only measurements than for
traditional linear compressed sensing. For instance, in recovering a 1-**sparse**
signal with sufficiently large dimension, phase-only compressed sensing
requires approximately 68% of the measurements needed for linear compressed
sensing. This result disproves earlier conjecture suggesting that the two phase
transitions coincide. Our proof hinges on the Gaussian min-max theorem and the
key observation that, up to a signal-dependent orthogonal transformation, the
sensing matrix in the reformulated problem behaves as a nearly Gaussian matrix.


## Coarse-to-Fine Lightweight Meta-Embedding for ID-Based Recommendation

>Authors: Yang Wang, Haipeng Liu, Zeqian Yi, Biao Qian, Meng Wang

>2025-01-21

> http://arxiv.org/abs/2501.11870v1

The state-of-the-art recommendation systems have shifted the attention to
efficient recommendation, e.g., on-device recommendation, under memory
constraints. To this end, the existing methods either focused on the
lightweight embeddings for both users and items, or involved on-device systems
enjoying the compact embeddings to enhance reusability and reduces space
complexity. However, they focus solely on the coarse granularity of embedding,
while overlook the fine-grained semantic nuances, to adversarially downgrade
the efficacy of meta-embeddings in capturing the intricate relationship over
both user and item, consequently resulting into the suboptimal recommendations.
In this paper, we aim to study how the meta-embedding can efficiently learn
varied grained semantics, together with how the fine-grained meta-embedding can
strengthen the representation of coarse-grained meta-embedding. To answer these
questions, we develop a novel graph neural networks (GNNs) based recommender
where each user and item serves as the node, linked directly to coarse-grained
virtual nodes and indirectly to fine-grained virtual nodes, ensuring different
grained semantic learning, while disclosing: 1) In contrast to coarse-grained
semantics, fine-grained semantics are well captured through **sparse**
meta-embeddings, which adaptively 2) balance the embedding uniqueness and
memory constraint. Additionally, the initialization method come up upon
SparsePCA, along with a soft thresholding activation function to render the
**sparse**ness of the meta-embeddings. We propose a weight bridging update strategy
that focuses on matching each coarse-grained meta-embedding with several
fine-grained meta-embeddings based on the users/items' semantics. Extensive
experiments substantiate our method's superiority over existing baselines. Our
code is available at https://github.com/htyjers/C2F-MetaEmbed.


## Geometrical scheduling of adiabatic control without information of energy spectra

>Authors: Yuta Shingu, Takuya Hatomura

>2025-01-21

> http://arxiv.org/abs/2501.11846v1

Adiabatic control is a fundamental technique for manipulating quantum
systems, guided by the quantum adiabatic theorem, which ensures suppressed
nonadiabatic transitions under slow parameter variations. Quantum annealing, a
heuristic algorithm leveraging adiabatic control, seeks the ground states of
Ising spin glass models and has drawn attention for addressing combinatorial
optimization problems. However, exponentially small energy gaps in such models
often necessitate impractically long runtime to satisfy the adiabatic
condition. Despite this limitation, improving the quality of approximate
solutions remains crucial for practical applications. The quantum adiabatic
brachistochrone provides a method to enhance adiabaticity by minimizing an
action representing nonadiabaticity via the variational principle. While
effective, its implementation requires detailed energy spectra, complicating
its use in quantum annealing. Shortcuts to adiabaticity by counterdiabatic
driving offer alternative approaches for accelerating adiabatic processes.
However, the theory of shortcuts to adiabaticity often faces challenges such as
nonlocal control requirements, high computational cost, and trade-offs between
speed and energy efficiency. In this work, we propose a novel quantum adiabatic
brachistochrone protocol tailored for quantum annealing that eliminates the
need for energy spectrum information. Our approach builds on advancements in
counterdiabatic driving to design efficient parameter schedules. We demonstrate
the effectiveness of our method through numerical simulations on the
transverse-field Ising chain and axial next-nearest neighbor Ising models.


## Keypoint Detection Empowered Near-Field User Localization and Channel Reconstruction

>Authors: Mengyuan Li, Yu Han, Zhizheng Lu, Shi Jin, Yongxu Zhu, Chao-Kai Wen

>2025-01-21

> http://arxiv.org/abs/2501.11844v1

In the near-field region of an extremely large-scale multiple-input
multiple-output (XL MIMO) system, channel reconstruction is typically addressed
through **sparse** parameter estimation based on compressed sensing (CS) algorithms
after converting the received pilot signals into the transformed domain.
However, the exhaustive search on the codebook in CS algorithms consumes
significant computational resources and running time, particularly when a large
number of antennas are equipped at the base station (BS). To overcome this
challenge, we propose a novel scheme to replace the high-cost exhaustive search
procedure. We visualize the **sparse** channel matrix in the transformed domain as
a channel image and design the channel keypoint detection network (CKNet) to
locate the user and scatterers in high speed. Subsequently, we use a
small-scale newtonized orthogonal matching pursuit (NOMP) based refiner to
further enhance the precision. Our method is applicable to both the Cartesian
domain and the Polar domain. Additionally, to deal with scenarios with a
flexible number of propagation paths, we further design FlexibleCKNet to
predict both locations and confidence scores. Our experimental results validate
that the CKNet and FlexibleCKNet-empowered channel reconstruction scheme can
significantly reduce the computational complexity while maintaining high
accuracy in both user and scatterer localization and channel reconstruction
tasks.


## Large Language Models with Human-In-The-Loop Validation for Systematic Review Data Extraction

>Authors: Noah L. Schroeder, Chris Davis Jaldi, Shan Zhang

>2025-01-21

> http://arxiv.org/abs/2501.11840v1

Systematic reviews are time-consuming endeavors. Historically speaking,
knowledgeable humans have had to screen and extract data from studies before it
can be analyzed. However, large language models (LLMs) hold promise to greatly
accelerate this process. After a pilot study which showed great promise, we
investigated the use of freely available LLMs for extracting data for
systematic reviews. Using three different LLMs, we extracted 24 types of data,
9 explicitly stated variables and 15 derived categorical variables, from 112
studies that were included in a published scoping review. Overall we found that
Gemini 1.5 Flash, Gemini 1.5 Pro, and Mistral Large 2 performed reasonably
well, with 71.17%, 72.14%, and 62.43% of data extracted being consistent with
human coding, respectively. While promising, these results highlight the dire
need for a human-in-the-loop (HIL) process for AI-assisted data extraction. As
a result, we present a free, open-source program we developed (AIDE) to
facilitate user-friendly, HIL data extraction with LLMs.


## Glinthawk A Two-Tiered Architecture for High-Throughput LLM Inference

>Authors: Pouya Hamadanian, Sadjad Fouladi

>2025-01-20

> http://arxiv.org/abs/2501.11779v1

Large Language Models (LLM) have revolutionized natural language processing,
but their inference demands substantial resources, while under-utilizing
high-end accelerators like GPUs. A major bottleneck arises from the attention
mechanism, which requires storing large key-value caches, limiting the maximum
achievable throughput way below the available computing resources. Current
approaches attempt to mitigate this issue through memory-efficient attention
and paging mechanisms, but remained constrained by the assumption that all
operations must be performed on high-end accelerators.
  In this work, we propose Glinthawk, a two-tiered architecture that decouples
the attention mechanism from the rest of the Transformer model. This approach
allows the memory requirements for attention to scale independently, enabling
larger batch sizes and more efficient use of the high-end accelerators. We
prototype Glinthawk with NVIDIA T4 GPUs as one tier and standard CPU VMs as the
other. Compared to a traditional single-tier setup, it improves throughput by
$5.9\times$ and reduces cost of generation by $2.8\times$. For longer sequence
lengths, it achieves $16.3\times$ throughput improvement at $2.4\times$ less
cost. Our evaluation shows that this architecture can tolerate moderate network
latency with minimal performance degradation, making it highly effective for
latency-tolerant, throughput-oriented applications such as batch processing. We
shared our prototype publicly at \url{https://github.com/microsoft/glinthawk}.


## Efficient Bearing Sensor Data Compression via an Asymmetrical Autoencoder with a Lifting Wavelet Transform Layer

>Authors: Xin Zhu, Ahmet Enis Cetin

>2025-01-20

> http://arxiv.org/abs/2501.11737v1

Bearing data compression is vital to manage the large volumes of data
generated during condition monitoring. In this paper, a novel asymmetrical
autoencoder with a lifting wavelet transform (LWT) layer is developed to
compress bearing sensor data. The encoder part of the network consists of a
convolutional layer followed by a wavelet filterbank layer. Specifically, a
dual-channel convolutional block with diverse convolutional kernel sizes and
varying processing depths is integrated into the wavelet filterbank layer to
enable comprehensive feature extraction from the wavelet domain. Additionally,
the adaptive hard-thresholding nonlinearity is applied to remove redundant
components while denoising the primary wavelet coefficients. On the decoder
side, inverse LWT, along with multiple linear layers and activation functions,
is employed to reconstruct the original signals. Furthermore, to enhance
compression efficiency, a **sparsity** constraint is introduced during training to
impose **sparsity** on the latent representations. The experimental results
demonstrate that the proposed approach achieves superior data compression
performance compared to state-of-the-art methods.


## Industrial Upgrading and New Quality Productive Forces Evidence from China's Provincial Panel Data (2003-2022)

>Authors: Solar Jin

>2025-01-20

> http://arxiv.org/abs/2501.14258v1

Accelerating the deep transformation and upgrading of industrial structure
and forming new quality productive forces are essential components for China to
achieve the great rejuvenation of the Chinese Dream. After more than 40 years
of rapid development, China has entered the "new normal" of development, making
the advancement of new quality productive forces an urgent task. This paper
reviews the evolution of China's industrial structure, argues the necessity for
a new round of deep industrial transformation, and explores the impact of
industrial structure transformation and upgrading on the level of new quality
productive forces using various methods. The research findings are as
follows:(1)The deep transformation and upgrading of the industrial structure
can significantly promote the development of new quality productive forces, but
there are obvious regional differences.(2)The core indicator of the improvement
in the level of new quality productive forces is the enhancement of total
factor productivity. Furthermore, this paper summarizes past industrial
development processes and the challenges faced, and analyzes and discusses the
potential challenges that may arise in promoting the development of new quality
productive forces through deep industrial structure transformation, based on
empirical research results.


## Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing

>Authors: Chaoqing Tang, Huanze Zhuang, Guiyun Tian, Zhenli Zeng, Yi Ding, Wenzhong Liu, Xiang Bai

>2025-01-20

> http://arxiv.org/abs/2501.11592v2

Pre-trained large models attract widespread attention in recent years, but
they face challenges in applications that require high interpretability or have
limited resources, such as physical sensing, medical imaging, and
bioinformatics. Compressed Sensing (CS) is a well-proved theory that drives
many recent breakthroughs in these applications. However, as a typical
under-determined linear system, CS suffers from excessively long **sparse**
reconstruction times when using traditional iterative methods, particularly
with large-scale data. Current AI methods like deep unfolding fail to
substitute them because pre-trained models exhibit poor generality beyond their
training conditions and dataset distributions, or lack interpretability.
Instead of following the big model fervor, this paper proposes ultra-small
artificial neural models called coefficients learning (CL), enabling
training-free and rapid **sparse** reconstruction while perfectly inheriting the
generality and interpretability of traditional iterative methods, bringing new
feature of incorporating prior knowledges. In CL, a signal of length $n$ only
needs a minimal of $n$ trainable parameters. A case study model called CLOMP is
implemented for evaluation. Experiments are conducted on both synthetic and
real one-dimensional and two-dimensional signals, demonstrating significant
improvements in efficiency and accuracy. Compared to representative iterative
methods, CLOMP improves efficiency by 100 to 1000 folds for large-scale data.
Test results on eight diverse image datasets indicate that CLOMP improves
structural similarity index by 292%, 98%, 45% for sampling rates of 0.1, 0.3,
0.5, respectively. We believe this method can truly usher CS reconstruction
into the AI era, benefiting countless under-determined linear systems that rely
on **sparse** solution.


## Open Sourcing GPTs Economics of Open Sourcing Advanced AI Models

>Authors: Mahyar Habibi

>2025-01-20

> http://arxiv.org/abs/2501.11581v1

This paper explores the economic underpinnings of open sourcing advanced
large language models (LLMs) by for-profit companies. Empirical analysis
reveals that: (1) LLMs are compatible with R&D portfolios of numerous
technologically differentiated firms; (2) open-sourcing likelihood decreases
with an LLM's performance edge over rivals, but increases for models from large
tech companies; and (3) open-sourcing an advanced LLM led to an increase in
research-related activities. Motivated by these findings, a theoretical
framework is developed to examine factors influencing a profit-maximizing
firm's open-sourcing decision. The analysis frames this decision as a trade-off
between accelerating technology growth and securing immediate financial
returns. A key prediction from the theoretical analysis is an inverted-U-shaped
relationship between the owner's size, measured by its share of LLM-compatible
applications, and its propensity to open source the LLM. This finding suggests
that moderate market concentration may be beneficial to the open source
ecosystems of multi-purpose software technologies.


## Meta-Instance Selection. Instance Selection as a Classification Problem with Meta-Features

>Authors: Marcin Blachnik, Piotr Ciepliński

>2025-01-20

> http://arxiv.org/abs/2501.11526v1

Data **pruning**, or instance selection, is an important problem in machine
learning especially in terms of nearest neighbour classifier. However, in data
**pruning** which speeds up the prediction phase, there is an issue related to the
speed and efficiency of the process itself. In response, the study proposes an
approach involving transforming the instance selection process into a
classification task conducted in a unified meta-feature space where each
instance can be classified and assigned to either the "to keep" or "to remove"
class. This approach requires training an appropriate meta-classifier, which
can be developed based on historical instance selection results from other
datasets using reference instance selection methods as a labeling tool. This
work proposes constructing the meta-feature space based on properties extracted
from the nearest neighbor graph. Experiments conducted on 17 datasets of
varying sizes and five reference instance selection methods (ENN, Drop3, ICF,
HMN-EI, and CCIS) demonstrate that the proposed solution achieves results
comparable to reference instance selection methods while significantly reducing
computational complexity. In the proposed approach, the computational
complexity of the system depends only on identifying the k-nearest neighbors
for each data sample and running the meta-classifier. Additionally, the study
discusses the choice of meta-classifier, recommending the use of Balanced
Random Forest.


## Curiosity-Driven Reinforcement Learning from Human Feedback

>Authors: Haoran Sun, Yekun Chai, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang

>2025-01-20

> http://arxiv.org/abs/2501.11463v1

Reinforcement learning from human feedback (RLHF) has proven effective in
aligning large language models (LLMs) with human preferences, but often at the
cost of reduced output diversity. This trade-off between diversity and
alignment quality remains a significant challenge. Drawing inspiration from
curiosity-driven exploration in reinforcement learning, we introduce
curiosity-driven RLHF (CD-RLHF), a framework that incorporates intrinsic
rewards for novel states, alongside traditional **sparse** extrinsic rewards, to
optimize both output diversity and alignment quality. We demonstrate the
effectiveness of CD-RLHF through extensive experiments on a range of tasks,
including text summarization and instruction following. Our approach achieves
significant gains in diversity on multiple diversity-oriented metrics while
maintaining alignment with human preferences comparable to standard RLHF. We
make our code publicly available at https://github.com/ernie-research/CD-RLHF.


## Practical Modulo Sampling Mitigating High-Frequency Components

>Authors: Yhonatan Kvich, Shlomi Savariego, Moshe Namer, Yonina C. Eldar

>2025-01-20

> http://arxiv.org/abs/2501.11330v1

Recovering signals within limited dynamic range (DR) constraints remains a
central challenge for analog-to-digital converters (ADCs). To prevent data
loss, an ADCs DR typically must exceed that of the input signal. Modulo
sampling has recently gained attention as a promising approach for addressing
DR limitations across various signal classes. However, existing methods often
rely on ideal ADCs capable of capturing the high frequencies introduced by the
modulo operator, which is impractical in real-world hardware applications. This
paper introduces an innovative hardware-based sampling approach that addresses
these high-frequency components using an analog mixer followed by a Low-Pass
Filter (LPF). This allows the use of realistic ADCs, which do not need to
handle frequencies beyond the intended sampling rate. Our method eliminates the
requirement for high-specification ADCs and demonstrates that the resulting
samples are equivalent to those from an ideal high-spec ADC. Consequently, any
existing modulo recovery algorithm can be applied effectively. We present a
practical hardware prototype of this approach, validated through both
simulations and hardware recovery experiments. Using a recovery method designed
to handle **quantization** noise, we show that our approach effectively manages
high-frequency artifacts, enabling reliable modulo recovery with realistic
ADCs. These findings confirm that our hardware solution not only outperforms
conventional methods in high-precision settings but also demonstrates
significant real-world applicability.


## Direct ab initio calculation of magnons in altermagnets method, spin-space symmetry aspects, and application to MnTe

>Authors: L. M. Sandratskii, K. Carva, V. M. Silkin

>2025-01-20

> http://arxiv.org/abs/2501.11327v1

We suggest the method for direct ab initio calculation of magnons in complex
collinear magnets. The method is based on the density-functional-theory
calculation under two different constraints: one constraint governs the change
of the magnetization with respect to the ground state, and the other is the
symmetry constraint responsible for the value of the magnon wave vector. The
performance of the method is demonstrated by the application to an altermagnet
MnTe. An important role in both the formulation and the application of the
method play the aspects of generalized symmetry described by the spin-space
groups. The symmetry analysis connects in one coherent picture the following
three parts of the consideration: (i) the generalized translational symmetry of
the magnons as a crucial condition for their efficient ab-initio calculation,
(ii) altermagnetic spin-splitting of the electron states in the ground magnetic
state, and (iii) chirality splitting of the magnon excitations. It is
demonstrated that both the spin splitting of the electron states and the
chirality splitting of the magnons have identical patterns in the corresponding
wave vector spaces. Since the altermagnetism of MnTe is the consequence of the
presence of the Te atoms, an adequate attention is devoted to the symmetry
analysis and calculation results for the Te moments induced in the magnon
states. The knowledge of the symmetry properties of the Te moments allows to
accelerate the numerical convergence of the magnon states and serves as a test
for the accuracy of the calculations. To expose the connection between electron
band structures of the magnon states of the system and the chirality properties
of these states we investigate the transformation of the electron structure in
the transition from the collinear ground state to a noncollinear magnon state.


## Hybrid Photonic-digital Accelerator for Attention Mechanism

>Authors: Huize Li, Dan Chen, Tulika Mitra

>2025-01-20

> http://arxiv.org/abs/2501.11286v1

The wide adoption and substantial computational resource requirements of
attention-based Transformers have spurred the demand for efficient hardware
accelerators. Unlike digital-based accelerators, there is growing interest in
exploring photonics due to its high energy efficiency and ultra-fast processing
speeds. However, the significant signal conversion overhead limits the
performance of photonic-based accelerators. In this work, we propose HyAtten, a
photonic-based attention accelerator with minimize signal conversion overhead.
HyAtten incorporates a signal comparator to classify signals into two
categories based on whether they can be processed by low-resolution converters.
HyAtten integrates low-resolution converters to process all low-resolution
signals, thereby boosting the parallelism of photonic computing. For signals
requiring high-resolution conversion, HyAtten uses digital circuits instead of
signal converters to reduce area and latency overhead. Compared to
state-of-the-art photonic-based Transformer accelerator, HyAtten achieves 9.8X
performance/area and 2.2X energy-efficiency/area improvement.


## Spin-phonon coupling and thermal Hall effect in Kitaev spin liquid

>Authors: Taekoo Oh, Naoto Nagaosa

>2025-01-20

> http://arxiv.org/abs/2501.11272v1

Kitaev spin liquid (KSL), consisting of the bond direction-dependent spin
interactions in the honeycomb lattice, attracts huge attention because of its
exact solvability and prospect for applications to quantum computing. An
important feature of KSL is the half-**quantize**d thermal Hall conductivity
(HQTHC) under the magnetic field perpendicular to the lattice, but HQTHC stands
only at low temperatures. Here, in the temperature range beyond the HQTHC
regime, we theoretically propose the extrinsic phonon contribution to thermal
Hall Effect in KSL via the skew-scattering of chiral phonons by the scalar spin
chirality, which was previously studied in Mott insulators. We show the
emergence of the scalar spin chirality of fluctuating spins, estimate the
emergent field strength and its symmetric form applied to the chiral phonons,
and obtain the associated thermal Hall conductivity, which is
semi-quantitatively consistent with the existing experiments. This work
provides a basic understanding of the role of spin-phonon interactions in
strongly correlated systems.


## Sparse L0-norm based Kernel-free Quadratic Surface Support Vector Machines

>Authors: Ahmad Mousavi, Ramin Zandvakili

>2025-01-20

> http://arxiv.org/abs/2501.11268v1

Kernel-free quadratic surface support vector machine (SVM) models have gained
significant attention in machine learning. However, introducing a quadratic
classifier increases the model's complexity by quadratically expanding the
number of parameters relative to the dimensionality of the data, exacerbating
overfitting. To address this, we propose **sparse** $\ell_0$-norm based Kernel-free
quadratic surface SVMs, designed to mitigate overfitting and enhance
interpretability. Given the intractable nature of these models, we present a
penalty decomposition algorithm to efficiently obtain first-order optimality
points. Our analysis shows that the subproblems in this framework either admit
closed-form solutions or can leverage duality theory to improve computational
efficiency. Through empirical evaluations on real-world datasets, we
demonstrate the efficacy and robustness of our approach, showcasing its
potential to advance Kernel-free quadratic surface SVMs in practical
applications while addressing overfitting concerns. All the implemented models
and experiment codes are available at
\url{https://github.com/raminzandvakili/L0-QSVM}.


## Playing the Lottery With Concave Regularizers for Sparse Trainable Neural Networks

>Authors: Giulia Fracastoro, Sophie M. Fosson, Andrea Migliorati, Giuseppe C. Calafiore

>2025-01-19

> http://arxiv.org/abs/2501.11135v1

The design of **sparse** neural networks, i.e., of networks with a reduced number
of parameters, has been attracting increasing research attention in the last
few years. The use of **sparse** models may significantly reduce the computational
and storage footprint in the inference phase. In this context, the lottery
ticket hypothesis (LTH) constitutes a breakthrough result, that addresses not
only the performance of the inference phase, but also of the training phase. It
states that it is possible to extract effective **sparse** subnetworks, called
winning tickets, that can be trained in isolation. The development of effective
methods to play the lottery, i.e., to find winning tickets, is still an open
problem. In this article, we propose a novel class of methods to play the
lottery. The key point is the use of concave regularization to promote the
**sparsity** of a relaxed binary mask, which represents the network topology. We
theoretically analyze the effectiveness of the proposed method in the convex
framework. Then, we propose extended numerical tests on various datasets and
architectures, that show that the proposed method can improve the performance
of state-of-the-art algorithms.


## LF-Steering Latent Feature Activation Steering for Enhancing Semantic Consistency in Large Language Models

>Authors: Jingyuan Yang, Rongjun Li, Weixuan Wang, Ziyu Zhou, Zhiyong Feng, Wei Peng

>2025-01-19

> http://arxiv.org/abs/2501.11036v2

Large Language Models (LLMs) often generate inconsistent responses when
prompted with semantically equivalent paraphrased inputs. Recently, activation
steering, a technique that modulates LLMs' behaviours by adjusting their latent
representations during inference time, has been explored to improve the
semantic consistency of LLMs. However, these methods typically operate at the
model component level, such as layer hidden states or attention head outputs.
They face a challenge due to the ``polysemanticity issue'', where the model
components of LLMs typically encode multiple entangled features, making precise
steering difficult. To address this challenge, we drill down to feature-level
representations and propose LF-Steering, a novel activation steering approach
to precisely identify latent feature representations responsible for semantic
inconsistency. More specifically, our method maps the hidden states of the
relevant transformer layer into a **sparse**ly activated, high-dimensional feature
space based on a **sparse** autoencoder (SAE), ensuring model steering based on
decoupled feature representations with minimal interference. Comprehensive
experiments on NLU and NLG datasets demonstrate the effectiveness of our method
in enhancing semantic consistency, resulting in significant performance gains
for various NLU and NLG tasks.


## FSMoE A Flexible and Scalable Training System for Sparse Mixture-of-Experts Models

>Authors: Xinglin Pan, Wenxiang Lin, Lin Zhang, Shaohuai Shi, Zhenheng Tang, Rui Wang, Bo Li, Xiaowen Chu

>2025-01-18

> http://arxiv.org/abs/2501.10714v1

Recent large language models (LLMs) have tended to leverage **sparsity** to
reduce computations, employing the **sparse**ly activated mixture-of-experts (MoE)
technique. MoE introduces four modules, including token routing, token
communication, expert computation, and expert parallelism, that impact model
quality and training efficiency. To enable versatile usage of MoE models, we
introduce FSMoE, a flexible training system optimizing task scheduling with
three novel techniques: 1) Unified abstraction and online profiling of MoE
modules for task scheduling across various MoE implementations. 2)
Co-scheduling intra-node and inter-node communications with computations to
minimize communication overheads. 3) To support near-optimal task scheduling,
we design an adaptive gradient partitioning method for gradient aggregation and
a schedule to adaptively pipeline communications and computations. We conduct
extensive experiments with configured MoE layers and real-world MoE models on
two GPU clusters. Experimental results show that 1) our FSMoE supports four
popular types of MoE routing functions and is more efficient than existing
implementations (with up to a 1.42$\times$ speedup), and 2) FSMoE outperforms
the state-of-the-art MoE training systems (DeepSpeed-MoE and Tutel) by
1.18$\times$-1.22$\times$ on 1458 MoE layers and 1.19$\times$-3.01$\times$ on
real-world MoE models based on GPT-2 and Mixtral using a popular routing
function.


## Unveiling the Mystery of Weight in Large Foundation Models Gaussian Distribution Never Fades

>Authors: Chongjie Si, Jingjing Jiang, Wei Shen

>2025-01-18

> http://arxiv.org/abs/2501.10661v1

This paper presents a pioneering exploration of the mechanisms underlying
large foundation models' (LFMs) weights, aiming to simplify AI research.
Through extensive observation and analysis on prevailing LFMs, we find that
regardless of initialization strategies, their weights predominantly follow a
Gaussian distribution, with occasional sharp, inverted T-shaped, or linear
patterns. We further discover that the weights share the i.i.d. properties of
Gaussian noise, and explore their direct relationship. We find that
transformation weights can be derived from Gaussian noise, and they primarily
serve to increase the standard deviation of pre-trained weights, with their
standard deviation growing with layer depth. In other words, transformation
weights broaden the acceptable deviation from the optimal weights, facilitating
adaptation to downstream tasks. Building upon the above conclusions, we
thoroughly discussed the nature of optimal weights, ultimately concluding that
they should exhibit zero-mean, symmetry, and **sparsity**, with the **sparse** values
being a truncated Gaussian distribution and a few outliers. Our experiments in
LFM adaptation and editing demonstrate the effectiveness of these insights. We
hope these findings can provide a foundational understanding to pave the way
for future advancements in the LFM community.


## LUT-DLA Lookup Table as Efficient Extreme Low-Bit Deep Learning Accelerator

>Authors: Guoyu Li, Shengyu Ye, Chunyun Chen, Yang Wang, Fan Yang, Ting Cao, Cheng Liu, Mohamed M. Sabry, Mao Yang

>2025-01-18

> http://arxiv.org/abs/2501.10658v1

The emergence of neural network capabilities invariably leads to a
significant surge in computational demands due to expanding model sizes and
increased computational complexity. To reduce model size and lower inference
costs, recent research has focused on simplifying models and designing hardware
accelerators using **low-bit** **quantization**. However, due to numerical
representation limits, scalar **quantization** cannot reduce bit width lower than
1-bit, diminishing its benefits. To break through these limitations, we
introduce LUT-DLA, a Look-Up Table (LUT) Deep Learning Accelerator Framework
that utilizes vector **quantization** to convert neural network models into LUTs,
achieving extreme **low-bit** **quantization**. The LUT-DLA framework facilitates
efficient and cost-effective hardware accelerator designs and supports the
LUTBoost algorithm, which helps to transform various DNN models into LUT-based
models via multistage training, drastically cutting both computational and
hardware overhead. Additionally, through co-design space exploration, LUT-DLA
assesses the impact of various model and hardware parameters to fine-tune
hardware configurations for different application scenarios, optimizing
performance and efficiency. Our comprehensive experiments show that LUT-DLA
achieves improvements in power efficiency and area efficiency with gains of
$1.4$~$7.0\times$ and $1.5$~$146.1\times$, respectively, while maintaining only
a modest accuracy drop. For CNNs, accuracy decreases by $0.1\%$~$3.1\%$ using
the $L_2$ distance similarity, $0.1\%$~$3.4\%$ with the $L_1$ distance
similarity, and $0.1\%$~$3.8\%$ when employing the Chebyshev distance
similarity. For transformer-based models, the accuracy drop ranges from $1.4\%$
to $3.0\%$.


## Scalable Machine Learning Training Infrastructure for Online Ads Recommendation and Auction Scoring Modeling at Google

>Authors: George Kurian, Somayeh Sardashti, Ryan Sims, Felix Berger, Gary Holt, Yang Li, Jeremiah Willcock, Kaiyuan Wang, Herve Quiroz, Abdulrahman Salem, Julian Grady

>2025-01-17

> http://arxiv.org/abs/2501.10546v1

Large-scale Ads recommendation and auction scoring models at Google scale
demand immense computational resources. While specialized hardware like TPUs
have improved linear algebra computations, bottlenecks persist in large-scale
systems. This paper proposes solutions for three critical challenges that must
be addressed for efficient end-to-end execution in a widely used production
infrastructure: (1) Input Generation and Ingestion Pipeline: Efficiently
transforming raw features (e.g., "search query") into numerical inputs and
streaming them to TPUs; (2) Large Embedding Tables: Optimizing conversion of
**sparse** features into dense floating-point vectors for neural network
consumption; (3) Interruptions and Error Handling: Minimizing resource wastage
in large-scale shared datacenters. To tackle these challenges, we propose a
shared input generation technique to reduce computational load of input
generation by amortizing costs across many models. Furthermore, we propose
partitioning, pipelining, and RPC (Remote Procedure Call) coalescing software
techniques to optimize embedding operations. To maintain efficiency at scale,
we describe novel preemption notice and training hold mechanisms that minimize
resource wastage, and ensure prompt error resolution. These techniques have
demonstrated significant improvement in Google production, achieving a 116%
performance boost and an 18% reduction in training costs across representative
models.


## 4bit-Quantization in Vector-Embedding for RAG

>Authors: Taehee Jeong

>2025-01-17

> http://arxiv.org/abs/2501.10534v1

Retrieval-augmented generation (RAG) is a promising technique that has shown
great potential in addressing some of the limitations of large language models
(LLMs). LLMs have two major limitations: they can contain outdated information
due to their training data, and they can generate factually inaccurate
responses, a phenomenon known as hallucinations. RAG aims to mitigate these
issues by leveraging a database of relevant documents, which are stored as
embedding vectors in a high-dimensional space. However, one of the challenges
of using high-dimensional embeddings is that they require a significant amount
of memory to store. This can be a major issue, especially when dealing with
large databases of documents. To alleviate this problem, we propose the use of
4-bit **quantization** to store the embedding vectors. This involves reducing the
precision of the vectors from 32-bit floating-point numbers to 4-bit integers,
which can significantly reduce the memory requirements. Our approach has
several benefits. Firstly, it significantly reduces the memory storage
requirements of the high-dimensional vector database, making it more feasible
to deploy RAG systems in resource-constrained environments. Secondly, it speeds
up the searching process, as the reduced precision of the vectors allows for
faster computation. Our code is available at
https://github.com/taeheej/4bit-Quantization-in-Vector-Embedding-for-RAG


## Dynamical response of noncollinear spin systems at constrained magnetic moments

>Authors: Miquel Royo, Massimiliano Stengel

>2025-01-17

> http://arxiv.org/abs/2501.10188v1

Noncollinear magnets are notoriously difficult to describe within
first-principles approaches based on density-functional theory (DFT) because of
the presence of low-lying spin excitations. At the level of ground-state
calculations, several methods exist to constrain the magnetic moments to a
predetermined configuration, and thereby accelerate convergence towards
self-consistency. Their use in a perturbative context, however, remains very
limited. Here we present a general methodological framework to achieve
parametric control over the local spin moments at the linear-response level.
Our strategy builds on the concept of Legendre transform to switch between
various flavors of magnetic functionals, and to relate their second derivatives
via simple linear-algebra operations. Thereby, we can address an arbitrary
response function at the time-dependent DFT level of theory with optimal
accuracy and minimal computational effort. In the low frequency limit, we
identify the leading correction to the existing adiabatic formulation of the
problem [S. Ren \emph{et al.}, Phys. Rev. X {\bf 14}, 011041 (2024)],
consisting in a renormalization of the phonon and magnon masses due to electron
inertia. As a demonstration, we apply our methodology to the study of the THz
optical response in bulk CrI$_3$, where we identify a hybrid electromagnon with
mixed spin-lattice character.


## ACCEPT Diagnostic Forecasting of Battery Degradation Through Contrastive Learning

>Authors: James Sadler, Rizwaan Mohammed, Michael Castle, Kotub Uddin

>2025-01-17

> http://arxiv.org/abs/2501.10492v1

Modeling lithium-ion battery (LIB) degradation offers significant cost
savings and enhances the safety and reliability of electric vehicles (EVs) and
battery energy storage systems (BESS). Whilst data-driven methods have received
great attention for forecasting degradation, they often demonstrate limited
generalization ability and tend to underperform particularly in critical
scenarios involving accelerated degradation, which are crucial to predict
accurately. These methods also fail to elucidate the underlying causes of
degradation. Alternatively, physical models provide a deeper understanding, but
their complex parameters and inherent uncertainties limit their applicability
in real-world settings. To this end, we propose a new model - ACCEPT. Our novel
framework uses contrastive learning to map the relationship between the
underlying physical degradation parameters and observable operational
quantities, combining the benefits of both approaches. Furthermore, due to the
similarity of degradation paths between LIBs with the same chemistry, this
model transfers non-trivially to most downstream tasks, allowing for zero-shot
inference. Additionally, since categorical features can be included in the
model, it can generalize to other LIB chemistries. This work establishes a
foundational battery degradation model, providing reliable forecasts across a
range of battery types and operating conditions.


## Accelerating Large Language Models through Partially Linear Feed-Forward Network

>Authors: Gansen Hu, Zhaoguo Wang, Jinglin Wei, Wei Huang, Haibo Chen

>2025-01-17

> http://arxiv.org/abs/2501.10054v1

Large language models (LLMs) demonstrate remarkable capabilities but face
deployment challenges due to their massive parameter counts. While existing
compression techniques like **pruning** can reduce model size, it leads to
significant accuracy degradation under high compression ratios. We present a
novel perspective inspired by constant folding in compiler optimization. Our
approach enables parameter reduction by treating activation functions in LLMs
as linear functions.
  However, recent LLMs use complex non-linear activations like GELU that
prevent direct application of this technique. We propose TARDIS, which enables
optimization of LLMs with non-linear activations by partially approximating
them with linear functions in frequently occurring input ranges. For outlier
inputs, TARDIS employs an online predictor to dynamically fall back to original
computations.
  Our experiments demonstrate that TARDIS achieves 80% parameter reduction in
feed-forward networks, while significantly outperforming state-of-the-art
**pruning** methods Wanda and RIA with up to 65% higher accuracy. In practical
deployments for a 7B model, TARDIS achieves 1.6x end-to-end inference speedup
when integrated with the vLLM serving system, and 1.4x speedup with the widely
adopted HuggingFace implementation, while incurring only a 10.9% accuracy
trade-off.


## AIRCHITECT v2 Learning the Hardware Accelerator Design Space through Unified Representations

>Authors: Jamin Seo, Akshat Ramachandran, Yu-Chuan Chuang, Anirudh Itagi, Tushar Krishna

>2025-01-17

> http://arxiv.org/abs/2501.09954v1

Design space exploration (DSE) plays a crucial role in enabling custom
hardware architectures, particularly for emerging applications like AI, where
optimized and specialized designs are essential. With the growing complexity of
deep neural networks (DNNs) and the introduction of advanced foundational
models (FMs), the design space for DNN accelerators is expanding at an
exponential rate. Additionally, this space is highly non-uniform and
non-convex, making it increasingly difficult to navigate and optimize.
Traditional DSE techniques rely on search-based methods, which involve
iterative sampling of the design space to find the optimal solution. However,
this process is both time-consuming and often fails to converge to the global
optima for such design spaces. Recently, AIrchitect v1, the first attempt to
address the limitations of search-based techniques, transformed DSE into a
constant-time classification problem using recommendation networks. In this
work, we propose AIrchitect v2, a more accurate and generalizable
learning-based DSE technique applicable to large-scale design spaces that
overcomes the shortcomings of earlier approaches. Specifically, we devise an
encoder-decoder transformer model that (a) encodes the complex design space
into a uniform intermediate representation using contrastive learning and (b)
leverages a novel unified representation blending the advantages of
classification and regression to effectively explore the large DSE space
without sacrificing accuracy. Experimental results evaluated on 10^5 real DNN
workloads demonstrate that, on average, AIrchitect v2 outperforms existing
techniques by 15% in identifying optimal design points. Furthermore, to
demonstrate the generalizability of our method, we evaluate performance on
unseen model workloads (LLMs) and attain a 1.7x improvement in inference
latency on the identified hardware architecture.


## MultiPruner Balanced Structure Removal in Foundation Models

>Authors: J. Pablo Muñoz, Jinjie Yuan, Nilesh Jain

>2025-01-17

> http://arxiv.org/abs/2501.09949v1

Recently, state-of-the-art approaches for **pruning** large pre-trained models
(LPMs) have demonstrated that the training-free removal of non-critical
residual blocks in Transformers is viable for reducing model size, achieving
results that outperform previous training-free **pruning** approaches. Motivated by
these findings, we extend BlockPruner (Zhong et al., 2024) and propose
MultiPruner, a **pruning** approach that surpasses recent training-free **pruning**
methods by adopting a multidimensional, iterative, fine-grained **pruning**
strategy. In MultiPruner, multidimensional **pruning** reinstates the structural
balance in block-pruned models by sequentially compressing along three
dimensions: i) residual blocks, ii) channels of multilayer perceptrons (MLP),
and iii) attention heads. This solution enhances zero-shot accuracy on
downstream tasks compared to other techniques while improving model compression
ratios, producing compressed models with fewer computing and memory
requirements. Extensive experiments demonstrate the advantages of the proposed
method across various large pre-trained models. The code and **pruning**
configurations are available at
https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.


## AI Explainability for Power Electronics From a Lipschitz Continuity Perspective

>Authors: Xinze Li, Fanfan Lin, Homer Alan Mantooth, Juan José Rodríguez-Andina

>2025-01-17

> http://arxiv.org/abs/2501.09948v1

Lifecycle management of power converters continues to thrive with emerging
artificial intelligence (AI) solutions, yet AI mathematical explainability
remains unexplored in power electronics (PE) community. The lack of theoretical
rigor challenges adoption in mission-critical applications. Therefore, this
letter proposes a generic framework to evaluate mathematical explainability,
highlighting inference stability and training convergence from a Lipschitz
continuity perspective. Inference stability governs consistent outputs under
input perturbations, essential for robust real-time control and fault
diagnosis. Training convergence guarantees stable learning dynamics,
facilitating accurate modeling in PE contexts. Additionally, a Lipschitz-aware
learning rate selection strategy is introduced to accelerate convergence while
mitigating overshoots and oscillations. The feasibility of the proposed
Lipschitz-oriented framework is demonstrated by validating the mathematical
explainability of a state-of-the-art physics-in-architecture neural network,
and substantiated through empirical case studies on dual-active-bridge
converters. This letter serves as a clarion call for the PE community to
embrace mathematical explainability, heralding a transformative era of
trustworthy and explainable AI solutions that potentially redefine the future
of power electronics.


## Steering Large Language Models with Feature Guided Activation Additions

>Authors: Samuel Soo, Wesley Teng, Chandrasekaran Balaganesh

>2025-01-17

> http://arxiv.org/abs/2501.09929v2

Effective and reliable control over large language model (LLM) behavior is a
significant challenge. While activation steering methods, which add steering
vectors to a model's hidden states, are a promising approach, existing
techniques often lack precision and interpretability in how they influence
model outputs. We introduce Feature Guided Activation Additions (FGAA), a novel
activation steering method that leverages insights from Contrastive Activation
Addition (CAA) and Sparse Autoencoder-Targeted Steering (SAE-TS). By operating
in the latent space of a Sparse Autoencoder (SAE) and employing optimization
techniques to select desired SAE features, FGAA constructs precise steering
vectors that provide better steering effects while maintaining coherence of
steered model outputs. In this regard, evaluations on Gemma-2-2B and Gemma-2-9B
models across various steering tasks demonstrate that FGAA outperforms existing
steering methods of CAA, SAE decoder steering, and SAE-TS. Our results also
highlight important trade-offs between steering scale and general model
capabilities that are consistent across all tested steering methods.


## Quantum field theory on curved manifolds

>Authors: Tomohiro Matsuda

>2025-01-17

> http://arxiv.org/abs/2501.09919v1

Given a manifold of a system with internal degrees of freedom, such as
Lorentz symmetry or gauge symmetry, the ``curvature'' is defined for the
manifold. If one defines the local vacuum in the tangent space of the manifold,
one can define a local mapping in the vicinity of the contact point, which is
nothing but the Bogoliubov transformation. The curvature of the electromagnetic
field gives the Schwinger effect, and the curvature of the base space
introduces the local Unruh effect, which realizes Hawking radiation if applied
on the Black hole horizon. To show how the Bogoliubov transformation appears on
the manifold and why the local calculation is crucial there, we consider the
Schwinger effect with a slowly varying electric field. Then, we show what
happens in the Unruh effect if the **acceleration** is not a constant parameter.

