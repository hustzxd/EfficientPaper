# 2024-12-20

# Table of Contents
* [TheAgentCompany Benchmarking LLM Agents on Consequential Real World Tasks](#TheAgentCompany-Benchmarking-LLM-Agents-on-Consequential-Real-World-Tasks)
* [Compositional Generalization Across Distributional Shifts with Sparse Tree Operations](#Compositional-Generalization-Across-Distributional-Shifts-with-Sparse-Tree-Operations)
* [SurgSora Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation](#SurgSora-Decoupled-RGBD-Flow-Diffusion-Model-for-Controllable-Surgical-Video-Generation)
* [A purely geometrical Aharonov-Bohm effect](#A-purely-geometrical-Aharonov-Bohm-effect)
* [Machine-learning Accelerated Descriptor Design for Catalyst Discovery A CO$_2$ to Methanol Conversion Case Study](#Machine-learning-Accelerated-Descriptor-Design-for-Catalyst-Discovery-A-CO$_2$-to-Methanol-Conversion-Case-Study)
* [Mix-LN Unleashing the Power of Deeper Layers by Combining Pre-LN and Post-LN](#Mix-LN-Unleashing-the-Power-of-Deeper-Layers-by-Combining-Pre-LN-and-Post-LN)
* [Semantic Convergence Harmonizing Recommender Systems via Two-Stage Alignment and Behavioral Semantic Tokenization](#Semantic-Convergence-Harmonizing-Recommender-Systems-via-Two-Stage-Alignment-and-Behavioral-Semantic-Tokenization)
* [THÖR-MAGNI Act Actions for Human Motion Modeling in Robot-Shared Industrial Spaces](#THÖR-MAGNI-Act-Actions-for-Human-Motion-Modeling-in-Robot-Shared-Industrial-Spaces)
* [Model Decides How to Tokenize Adaptive DNA Sequence Tokenization with MxDNA](#Model-Decides-How-to-Tokenize-Adaptive-DNA-Sequence-Tokenization-with-MxDNA)
* [VIIS Visible and Infrared Information Synthesis for Severe Low-light Image Enhancement](#VIIS-Visible-and-Infrared-Information-Synthesis-for-Severe-Low-light-Image-Enhancement)
* [SCOPE Optimizing Key-Value Cache Compression in Long-context Generation](#SCOPE-Optimizing-Key-Value-Cache-Compression-in-Long-context-Generation)
* [Self-control A Better Conditional Mechanism for Masked Autoregressive Model](#Self-control-A-Better-Conditional-Mechanism-for-Masked-Autoregressive-Model)
* [Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations with Large Language Models](#Bridging-the-User-side-Knowledge-Gap-in-Knowledge-aware-Recommendations-with-Large-Language-Models)
* [Refining Salience-Aware Sparse Fine-Tuning Strategies for Language Models](#Refining-Salience-Aware-Sparse-Fine-Tuning-Strategies-for-Language-Models)
* [Pre-training a Density-Aware Pose Transformer for Robust LiDAR-based 3D Human Pose Estimation](#Pre-training-a-Density-Aware-Pose-Transformer-for-Robust-LiDAR-based-3D-Human-Pose-Estimation)
* [Communication-Efficient Personalized Federal Graph Learning via Low-Rank Decomposition](#Communication-Efficient-Personalized-Federal-Graph-Learning-via-Low-Rank-Decomposition)
* [Lightweight Safety Classification Using Pruned Language Models](#Lightweight-Safety-Classification-Using-Pruned-Language-Models)


## TheAgentCompany Benchmarking LLM Agents on Consequential Real World Tasks

>Authors: Frank F. Xu, Yufan Song, Boxuan Li, Yuxuan Tang, Kritanjali Jain, Mengxue Bao, Zora Z. Wang, Xuhui Zhou, Zhitong Guo, Murong Cao, Mingyang Yang, Hao Yang Lu, Amaad Martin, Zhe Su, Leander Maben, Raj Mehta, Wayne Chi, Lawrence Jang, Yiqing Xie, Shuyan Zhou, Graham Neubig

>2024-12-18

> http://arxiv.org/abs/2412.14161v1

We interact with computers on an everyday basis, be it in everyday life or
work, and many aspects of work can be done entirely with access to a computer
and the Internet. At the same time, thanks to improvements in large language
models (LLMs), there has also been a rapid development in AI agents that
interact with and affect change in their surrounding environments. But how
performant are AI agents at helping to accelerate or even autonomously perform
work-related tasks? The answer to this question has important implications for
both industry looking to adopt AI into their workflows, and for economic policy
to understand the effects that adoption of AI may have on the labor market. To
measure the progress of these LLM agents' performance on performing real-world
professional tasks, in this paper, we introduce TheAgentCompany, an extensible
benchmark for evaluating AI agents that interact with the world in similar ways
to those of a digital worker: by browsing the Web, writing code, running
programs, and communicating with other coworkers. We build a self-contained
environment with internal web sites and data that mimics a small software
company environment, and create a variety of tasks that may be performed by
workers in such a company. We test baseline agents powered by both closed
API-based and open-weights language models (LMs), and find that with the most
competitive agent, 24% of the tasks can be completed autonomously. This paints
a nuanced picture on task automation with LM agents -- in a setting simulating
a real workplace, a good portion of simpler tasks could be solved autonomously,
but more difficult long-horizon tasks are still beyond the reach of current
systems.


## Compositional Generalization Across Distributional Shifts with Sparse Tree Operations

>Authors: Paul Soulos, Henry Conklin, Mattia Opper, Paul Smolensky, Jianfeng Gao, Roland Fernandez

>2024-12-18

> http://arxiv.org/abs/2412.14076v1

Neural networks continue to struggle with compositional generalization, and
this issue is exacerbated by a lack of massive pre-training. One successful
approach for developing neural systems which exhibit human-like compositional
generalization is \textit{hybrid} neurosymbolic techniques. However, these
techniques run into the core issues that plague symbolic approaches to AI:
scalability and flexibility. The reason for this failure is that at their core,
hybrid neurosymbolic models perform symbolic computation and relegate the
scalable and flexible neural computation to parameterizing a symbolic system.
We investigate a \textit{unified} neurosymbolic system where transformations in
the network can be interpreted simultaneously as both symbolic and neural
computation. We extend a unified neurosymbolic architecture called the
Differentiable Tree Machine in two central ways. First, we significantly
increase the model's efficiency through the use of **sparse** vector
representations of symbolic structures. Second, we enable its application
beyond the restricted set of tree2tree problems to the more general class of
seq2seq problems. The improved model retains its prior generalization
capabilities and, since there is a fully neural path through the network,
avoids the pitfalls of other neurosymbolic techniques that elevate symbolic
computation over neural computation.


## SurgSora Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation

>Authors: Tong Chen, Shuya Yang, Junyi Wang, Long Bai, Hongliang Ren, Luping Zhou

>2024-12-18

> http://arxiv.org/abs/2412.14018v1

Medical video generation has transformative potential for enhancing surgical
understanding and pathology insights through precise and controllable visual
representations. However, current models face limitations in controllability
and authenticity. To bridge this gap, we propose SurgSora, a
motion-controllable surgical video generation framework that uses a single
input frame and user-controllable motion cues. SurgSora consists of three key
modules: the Dual Semantic Injector (DSI), which extracts object-relevant RGB
and depth features from the input frame and integrates them with segmentation
cues to capture detailed spatial features of complex anatomical structures; the
Decoupled Flow Mapper (DFM), which fuses optical flow with semantic-RGB-D
features at multiple scales to enhance temporal understanding and object
spatial dynamics; and the Trajectory Controller (TC), which allows users to
specify motion directions and estimates **sparse** optical flow, guiding the video
generation process. The fused features are used as conditions for a frozen
Stable Diffusion model to produce realistic, temporally coherent surgical
videos. Extensive evaluations demonstrate that SurgSora outperforms
state-of-the-art methods in controllability and authenticity, showing its
potential to advance surgical video generation for medical education, training,
and research.


## A purely geometrical Aharonov-Bohm effect

>Authors: Jean-Pierre Gazeau, Tomoi Koide, Romain Murenzi, Aidan Zlotak

>2024-12-18

> http://arxiv.org/abs/2412.13919v1

In this paper, we apply covariant affine integral **quantization** to study
motion in the 2D punctured plane. The associated four-dimensional phase space
is identified with the similitude group SIM(2), representing transformations of
the plane composed of translations, rotations, and dilations. Near the
punctured point, we observe that the topology influencing quantum fluctuations
gives rise to an affine vector potential, which can be interpreted as the
Aharonov-Bohm (AB) gauge potential generated by an infinite coil. This finding
suggests that the AB effect originates from the topology enforced by the
impenetrable coil, rather than from a classical gauge potential. Our results
offer a novel perspective on the AB effect, emphasizing the fundamental role of
topology in quantum mechanics.


## Machine-learning Accelerated Descriptor Design for Catalyst Discovery A CO$_2$ to Methanol Conversion Case Study

>Authors: Prajwal Pisal, Ondrej Krejci, Patrick Rinke

>2024-12-18

> http://arxiv.org/abs/2412.13838v1

Transforming CO$_2$ into methanol represents a crucial step towards closing
the carbon cycle, with thermoreduction technology nearing industrial
application. However, obtaining high methanol yields and ensuring the stability
of heterocatalysts remain significant challenges. Herein, we present a
sophisticated computational framework to accelerate the discovery of novel
thermal heterogeneous catalysts, using machine-learned force fields. We propose
a new catalytic descriptor, termed adsorption energy distribution, that
aggregates the binding energies for different catalyst facets, binding sites,
and adsorbates. The descriptor is versatile and can easily be adjusted to a
specific reaction through careful choice of the key-step reactants and reaction
intermediates. By applying unsupervised machine learning and statistical
analysis to a dataset comprising nearly 160 metallic alloys, we offer a
powerful tool for catalyst discovery. Finally, we propose new promising
candidate materials such as ZnRh and ZnPt$_3$, which to our knowledge, have not
yet been tested, and discuss their possible advantage in terms of stability.


## Mix-LN Unleashing the Power of Deeper Layers by Combining Pre-LN and Post-LN

>Authors: Pengxiang Li, Lu Yin, Shiwei Liu

>2024-12-18

> http://arxiv.org/abs/2412.13795v1

Large Language Models (LLMs) have achieved remarkable success, yet recent
findings reveal that their deeper layers often contribute minimally and can be
pruned without affecting overall performance. While some view this as an
opportunity for model compression, we identify it as a training shortfall
rooted in the widespread use of Pre-Layer Normalization (Pre-LN). We
demonstrate that Pre-LN, commonly employed in models like GPT and LLaMA, leads
to diminished gradient norms in its deeper layers, reducing their
effectiveness. In contrast, Post-Layer Normalization (Post-LN) preserves larger
gradient norms in deeper layers but suffers from vanishing gradients in earlier
layers. To address this, we introduce Mix-LN, a novel normalization technique
that combines the strengths of Pre-LN and Post-LN within the same model. Mix-LN
applies Post-LN to the earlier layers and Pre-LN to the deeper layers, ensuring
more uniform gradients across layers. This allows all parts of the
network--both shallow and deep layers--to contribute effectively to training.
Extensive experiments with various model sizes from 70M to 7B demonstrate that
Mix-LN consistently outperforms both Pre-LN and Post-LN, promoting more
balanced, healthier gradient norms throughout the network, and enhancing the
overall quality of LLM pre-training. Furthermore, we demonstrate that models
pre-trained with Mix-LN learn better compared to those using Pre-LN or Post-LN
during supervised fine-tuning (SFT) and reinforcement learning from human
feedback (RLHF), highlighting the critical importance of high-quality deep
layers. By effectively addressing the inefficiencies of deep layers in current
LLMs, Mix-LN unlocks their potential, enhancing model capacity without
increasing model size. Our code is available at
https://github.com/pixeli99/MixLN.


## Semantic Convergence Harmonizing Recommender Systems via Two-Stage Alignment and Behavioral Semantic Tokenization

>Authors: Guanghan Li, Xun Zhang, Yufei Zhang, Yifan Yin, Guojun Yin, Wei Lin

>2024-12-18

> http://arxiv.org/abs/2412.13771v1

Large language models (LLMs), endowed with exceptional reasoning
capabilities, are adept at discerning profound user interests from historical
behaviors, thereby presenting a promising avenue for the advancement of
recommendation systems. However, a notable discrepancy persists between the
**sparse** collaborative semantics typically found in recommendation systems and
the dense token representations within LLMs. In our study, we propose a novel
framework that harmoniously merges traditional recommendation models with the
prowess of LLMs. We initiate this integration by transforming ItemIDs into
sequences that align semantically with the LLMs space, through the proposed
Alignment Tokenization module. Additionally, we design a series of specialized
supervised learning tasks aimed at aligning collaborative signals with the
subtleties of natural language semantics. To ensure practical applicability, we
optimize online inference by pre-caching the top-K results for each user,
reducing latency and improving effciency. Extensive experimental evidence
indicates that our model markedly improves recall metrics and displays
remarkable scalability of recommendation systems.


## THÖR-MAGNI Act Actions for Human Motion Modeling in Robot-Shared Industrial Spaces

>Authors: Tiago Rodrigues de Almeida, Tim Schreiter, Andrey Rudenko, Luigi Palmieiri, Johannes A. Stork, Achim J. Lilienthal

>2024-12-18

> http://arxiv.org/abs/2412.13729v1

Accurate human activity and trajectory prediction are crucial for ensuring
safe and reliable human-robot interactions in dynamic environments, such as
industrial settings, with mobile robots. Datasets with fine-grained action
labels for moving people in industrial environments with mobile robots are
scarce, as most existing datasets focus on social navigation in public spaces.
This paper introduces the TH\"OR-MAGNI Act dataset, a substantial extension of
the TH\"OR-MAGNI dataset, which captures participant movements alongside robots
in diverse semantic and spatial contexts. TH\"OR-MAGNI Act provides 8.3 hours
of manually labeled participant actions derived from egocentric videos recorded
via eye-tracking glasses. These actions, aligned with the provided TH\"OR-MAGNI
motion cues, follow a long-tailed distribution with diversified **acceleration**,
velocity, and navigation distance profiles. We demonstrate the utility of
TH\"OR-MAGNI Act for two tasks: action-conditioned trajectory prediction and
joint action and trajectory prediction. We propose two efficient
transformer-based models that outperform the baselines to address these tasks.
These results underscore the potential of TH\"OR-MAGNI Act to develop
predictive models for enhanced human-robot interaction in complex environments.


## Model Decides How to Tokenize Adaptive DNA Sequence Tokenization with MxDNA

>Authors: Lifeng Qiao, Peng Ye, Yuchen Ren, Weiqiang Bai, Chaoqi Liang, Xinzhu Ma, Nanqing Dong, Wanli Ouyang

>2024-12-18

> http://arxiv.org/abs/2412.13716v1

Foundation models have made significant strides in understanding the genomic
language of DNA sequences. However, previous models typically adopt the
tokenization methods designed for natural language, which are unsuitable for
DNA sequences due to their unique characteristics. In addition, the optimal
approach to tokenize DNA remains largely under-explored, and may not be
intuitively understood by humans even if discovered. To address these
challenges, we introduce MxDNA, a novel framework where the model autonomously
learns an effective DNA tokenization strategy through gradient decent. MxDNA
employs a **sparse** Mixture of Convolution Experts coupled with a deformable
convolution to model the tokenization process, with the discontinuous,
overlapping, and ambiguous nature of meaningful genomic segments explicitly
considered. On Nucleotide Transformer Benchmarks and Genomic Benchmarks, MxDNA
demonstrates superior performance to existing methods with less pretraining
data and time, highlighting its effectiveness. Finally, we show that MxDNA
learns unique tokenization strategy distinct to those of previous methods and
captures genomic functionalities at a token level during self-supervised
pretraining. Our MxDNA aims to provide a new perspective on DNA tokenization,
potentially offering broad applications in various domains and yielding
profound insights.


## VIIS Visible and Infrared Information Synthesis for Severe Low-light Image Enhancement

>Authors: Chen Zhao, Mengyuan Yu, Fan Yang, Peiguang Jing

>2024-12-18

> http://arxiv.org/abs/2412.13655v1

Images captured in severe low-light circumstances often suffer from
significant information absence. Existing singular modality image enhancement
methods struggle to restore image regions lacking valid information. By
leveraging light-impervious infrared images, visible and infrared image fusion
methods have the potential to reveal information hidden in darkness. However,
they primarily emphasize inter-modal complementation but neglect intra-modal
enhancement, limiting the perceptual quality of output images. To address these
limitations, we propose a novel task, dubbed visible and infrared information
synthesis (VIIS), which aims to achieve both information enhancement and fusion
of the two modalities. Given the difficulty in obtaining ground truth in the
VIIS task, we design an information synthesis pretext task (ISPT) based on
image augmentation. We employ a diffusion model as the framework and design a
**sparse** attention-based dual-modalities residual (SADMR) conditioning mechanism
to enhance information interaction between the two modalities. This mechanism
enables features with prior knowledge from both modalities to adaptively and
iteratively attend to each modality's information during the denoising process.
Our extensive experiments demonstrate that our model qualitatively and
quantitatively outperforms not only the state-of-the-art methods in relevant
fields but also the newly designed baselines capable of both information
enhancement and fusion. The code is available at
https://github.com/Chenz418/VIIS.


## SCOPE Optimizing Key-Value Cache Compression in Long-context Generation

>Authors: Jialong Wu, Zhenglin Wang, Linhai Zhang, Yilong Lai, Yulan He, Deyu Zhou

>2024-12-18

> http://arxiv.org/abs/2412.13649v1

Key-Value (**KV**) cache has become a bottleneck of LLMs for long-context
generation. Despite the numerous efforts in this area, the optimization for the
decoding phase is generally ignored. However, we believe such optimization is
crucial, especially for long-output generation tasks based on the following two
observations: (i) Excessive compression during the prefill phase, which
requires specific full context impairs the comprehension of the reasoning task;
(ii) Deviation of heavy hitters occurs in the reasoning tasks with long
outputs. Therefore, SCOPE, a simple yet efficient framework that separately
performs **KV** cache optimization during the prefill and decoding phases, is
introduced. Specifically, the **KV** cache during the prefill phase is preserved to
maintain the essential information, while a novel strategy based on sliding is
proposed to select essential heavy hitters for the decoding phase. Memory usage
and memory transfer are further optimized using adaptive and discontinuous
strategies. Extensive experiments on LongGenBench show the effectiveness and
generalization of SCOPE and its compatibility as a plug-in to other
prefill-only **KV** compression methods.


## Self-control A Better Conditional Mechanism for Masked Autoregressive Model

>Authors: Qiaoying Qu, Shiyu Shen

>2024-12-18

> http://arxiv.org/abs/2412.13635v1

Autoregressive conditional image generation algorithms are capable of
generating photorealistic images that are consistent with given textual or
image conditions, and have great potential for a wide range of applications.
Nevertheless, the majority of popular autoregressive image generation methods
rely heavily on vector **quantization**, and the inherent discrete characteristic
of codebook presents a considerable challenge to achieving high-quality image
generation. To address this limitation, this paper introduces a novel
conditional introduction network for continuous masked autoregressive models.
The proposed self-control network serves to mitigate the negative impact of
vector **quantization** on the quality of the generated images, while
simultaneously enhancing the conditional control during the generation process.
In particular, the self-control network is constructed upon a continuous mask
autoregressive generative model, which incorporates multimodal conditional
information, including text and images, into a unified autoregressive sequence
in a serial manner. Through a self-attention mechanism, the network is capable
of generating images that are controllable based on specific conditions. The
self-control network discards the conventional cross-attention-based
conditional fusion mechanism and effectively unifies the conditional and
generative information within the same space, thereby facilitating more
seamless learning and fusion of multimodal features.


## Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations with Large Language Models

>Authors: Zheng Hu, Zhe Li, Ziyun Jiao, Satoshi Nakagawa, Jiawen Deng, Shimin Cai, Tao Zhou, Fuji Ren

>2024-12-18

> http://arxiv.org/abs/2412.13544v1

In recent years, knowledge graphs have been integrated into recommender
systems as item-side auxiliary information, enhancing recommendation accuracy.
However, constructing and integrating structural user-side knowledge remains a
significant challenge due to the improper granularity and inherent scarcity of
user-side features. Recent advancements in Large Language Models (LLMs) offer
the potential to bridge this gap by leveraging their human behavior
understanding and extensive real-world knowledge. Nevertheless, integrating
LLM-generated information into recommender systems presents challenges,
including the risk of noisy information and the need for additional knowledge
transfer. In this paper, we propose an LLM-based user-side knowledge inference
method alongside a carefully designed recommendation framework to address these
challenges. Our approach employs LLMs to infer user interests based on
historical behaviors, integrating this user-side information with item-side and
collaborative data to construct a hybrid structure: the Collaborative Interest
Knowledge Graph (CIKG). Furthermore, we propose a CIKG-based recommendation
framework that includes a user interest reconstruction module and a
cross-domain contrastive learning module to mitigate potential noise and
facilitate knowledge transfer. We conduct extensive experiments on three
real-world datasets to validate the effectiveness of our method. Our approach
achieves state-of-the-art performance compared to competitive baselines,
particularly for users with **sparse** interactions.


## Refining Salience-Aware Sparse Fine-Tuning Strategies for Language Models

>Authors: Xinxin Liu, Aaron Thomas, Cheng Zhang, Jianyi Cheng, Yiren Zhao, Xitong Gao

>2024-12-18

> http://arxiv.org/abs/2412.13488v1

Parameter-Efficient Fine-Tuning (PEFT) has gained prominence through low-rank
adaptation methods like LoRA. In this paper, we focus on **sparsity**-based PEFT
(SPEFT), which introduces trainable **sparse** adaptations to the weight matrices
in the model, offering greater flexibility in selecting fine-tuned parameters
compared to low-rank methods. We conduct the first systematic evaluation of
salience metrics for SPEFT, inspired by zero-cost NAS proxies, and identify
simple gradient-based metrics is reliable, and results are on par with the best
alternatives, offering both computational efficiency and robust performance.
Additionally, we compare static and dynamic masking strategies, finding that
static masking, which predetermines non-zero entries before training, delivers
efficiency without sacrificing performance, while dynamic masking offers no
substantial benefits. Across NLP tasks, a simple gradient-based, static SPEFT
consistently outperforms other fine-tuning methods for LLMs, providing a simple
yet effective baseline for SPEFT. Our work challenges the notion that
complexity is necessary for effective PEFT. Our work is open source and
available to the community at [https://github.com/0-ml/speft].


## Pre-training a Density-Aware Pose Transformer for Robust LiDAR-based 3D Human Pose Estimation

>Authors: Xiaoqi An, Lin Zhao, Chen Gong, Jun Li, Jian Yang

>2024-12-18

> http://arxiv.org/abs/2412.13454v1

With the rapid development of autonomous driving, LiDAR-based 3D Human Pose
Estimation (3D HPE) is becoming a research focus. However, due to the noise and
**sparsity** of LiDAR-captured point clouds, robust human pose estimation remains
challenging. Most of the existing methods use temporal information, multi-modal
fusion, or SMPL optimization to correct biased results. In this work, we try to
obtain sufficient information for 3D HPE only by modeling the intrinsic
properties of low-quality point clouds. Hence, a simple yet powerful method is
proposed, which provides insights both on modeling and augmentation of point
clouds. Specifically, we first propose a concise and effective density-aware
pose transformer (DAPT) to get stable keypoint representations. By using a set
of joint anchors and a carefully designed exchange module, valid information is
extracted from point clouds with different densities. Then 1D heatmaps are
utilized to represent the precise locations of the keypoints. Secondly, a
comprehensive LiDAR human synthesis and augmentation method is proposed to
pre-train the model, enabling it to acquire a better human body prior. We
increase the diversity of point clouds by randomly sampling human positions and
orientations and by simulating occlusions through the addition of laser-level
masks. Extensive experiments have been conducted on multiple datasets,
including IMU-annotated LidarHuman26M, SLOPER4D, and manually annotated Waymo
Open Dataset v2.0 (Waymo), HumanM3. Our method demonstrates SOTA performance in
all scenarios. In particular, compared with LPFormer on Waymo, we reduce the
average MPJPE by $10.0mm$. Compared with PRN on SLOPER4D, we notably reduce the
average MPJPE by $20.7mm$.


## Communication-Efficient Personalized Federal Graph Learning via Low-Rank Decomposition

>Authors: Ruyue Liu, Rong Yin, Xiangzhen Bo, Xiaoshuai Hao, Xingrui Zhou, Yong Liu, Can Ma, Weiping Wang

>2024-12-18

> http://arxiv.org/abs/2412.13442v1

Federated graph learning (FGL) has gained significant attention for enabling
heterogeneous clients to process their private graph data locally while
interacting with a centralized server, thus maintaining privacy. However, graph
data on clients are typically non-IID, posing a challenge for a single model to
perform well across all clients. Another major bottleneck of FGL is the high
cost of communication. To address these challenges, we propose a
communication-efficient personalized federated graph learning algorithm, CEFGL.
Our method decomposes the model parameters into low-rank generic and **sparse**
private models. We employ a dual-channel encoder to learn **sparse** local
knowledge in a personalized manner and low-rank global knowledge in a shared
manner. Additionally, we perform multiple local stochastic gradient descent
iterations between communication phases and integrate efficient compression
techniques into the algorithm. The advantage of CEFGL lies in its ability to
capture common and individual knowledge more precisely. By utilizing low-rank
and **sparse** parameters along with compression techniques, CEFGL significantly
reduces communication complexity. Extensive experiments demonstrate that our
method achieves optimal classification accuracy in a variety of heterogeneous
environments across sixteen datasets. Specifically, compared to the
state-of-the-art method FedStar, the proposed method (with GIN as the base
model) improves accuracy by 5.64\% on cross-datasets setting CHEM, reduces
communication bits by a factor of 18.58, and reduces the communication time by
a factor of 1.65.


## Lightweight Safety Classification Using Pruned Language Models

>Authors: Mason Sawtell, Tula Masterman, Sandi Besen, Jim Brown

>2024-12-18

> http://arxiv.org/abs/2412.13435v1

In this paper, we introduce a novel technique for content safety and prompt
injection classification for Large Language Models. Our technique, Layer
Enhanced Classification (LEC), trains a Penalized Logistic Regression (PLR)
classifier on the hidden state of an LLM's optimal intermediate transformer
layer. By combining the computational efficiency of a streamlined PLR
classifier with the sophisticated language understanding of an LLM, our
approach delivers superior performance surpassing GPT-4o and special-purpose
models fine-tuned for each task. We find that small general-purpose models
(Qwen 2.5 sizes 0.5B, 1.5B, and 3B) and other transformer-based architectures
like DeBERTa v3 are robust feature extractors allowing simple classifiers to be
effectively trained on fewer than 100 high-quality examples. Importantly, the
intermediate transformer layers of these models typically outperform the final
layer across both classification tasks. Our results indicate that a single
general-purpose LLM can be used to classify content safety, detect prompt
injections, and simultaneously generate output tokens. Alternatively, these
relatively small LLMs can be pruned to the optimal intermediate layer and used
exclusively as robust feature extractors. Since our results are consistent on
different transformer architectures, we infer that robust feature extraction is
an inherent capability of most, if not all, LLMs.

