# 2025-01-17

# Table of Contents
* [Incrementally Learning Multiple Diverse Data Domains via Multi-Source Dynamic Expansion Model](#Incrementally-Learning-Multiple-Diverse-Data-Domains-via-Multi-Source-Dynamic-Expansion-Model)
* [Benchmarking analytical electron ptychography methods for the low-dose imaging of beam-sensitive materials](#Benchmarking-analytical-electron-ptychography-methods-for-the-low-dose-imaging-of-beam-sensitive-materials)
* [Nesterov Acceleration for Ensemble Kalman Inversion and Variants](#Nesterov-Acceleration-for-Ensemble-Kalman-Inversion-and-Variants)
* [LlamaRestTest Effective REST API Testing with Small Language Models](#LlamaRestTest-Effective-REST-API-Testing-with-Small-Language-Models)
* [LoRS Efficient Low-Rank Adaptation for Sparse Large Language Model](#LoRS-Efficient-Low-Rank-Adaptation-for-Sparse-Large-Language-Model)
* [SuperSAM Crafting a SAM Supernetwork via Structured Pruning and Unstructured Parameter Prioritization](#SuperSAM-Crafting-a-SAM-Supernetwork-via-Structured-Pruning-and-Unstructured-Parameter-Prioritization)
* [Large Language Models For Text Classification Case Study And Comprehensive Review](#Large-Language-Models-For-Text-Classification-Case-Study-And-Comprehensive-Review)
* [TriMod Fusion for Multimodal Named Entity Recognition in Social Media](#TriMod-Fusion-for-Multimodal-Named-Entity-Recognition-in-Social-Media)
* [CodecFake-Omni A Large-Scale Codec-based Deepfake Speech Dataset](#CodecFake-Omni-A-Large-Scale-Codec-based-Deepfake-Speech-Dataset)
* [FramePainter Endowing Interactive Image Editing with Video Diffusion Priors](#FramePainter-Endowing-Interactive-Image-Editing-with-Video-Diffusion-Priors)
* [Investigating Energy Efficiency and Performance Trade-offs in LLM Inference Across Tasks and DVFS Settings](#Investigating-Energy-Efficiency-and-Performance-Trade-offs-in-LLM-Inference-Across-Tasks-and-DVFS-Settings)
* [PRESERVE Prefetching Model Weights and KV-Cache in Distributed LLM Serving](#PRESERVE-Prefetching-Model-Weights-and-KV-Cache-in-Distributed-LLM-Serving)
* [EEG-ReMinD Enhancing Neurodegenerative EEG Decoding through Self-Supervised State Reconstruction-Primed Riemannian Dynamics](#EEG-ReMinD-Enhancing-Neurodegenerative-EEG-Decoding-through-Self-Supervised-State-Reconstruction-Primed-Riemannian-Dynamics)
* [Categorical quantum symmetries and ribbon tensor 2-categories](#Categorical-quantum-symmetries-and-ribbon-tensor-2-categories)
* [GAC-Net_Geometric and attention-based Network for Depth Completion](#GAC-Net_Geometric-and-attention-based-Network-for-Depth-Completion)
* [Robust Hyperspectral Image Panshapring via Sparse Spatial-Spectral Representation](#Robust-Hyperspectral-Image-Panshapring-via-Sparse-Spatial-Spectral-Representation)
* [CodeCoR An LLM-Based Self-Reflective Multi-Agent Framework for Code Generation](#CodeCoR-An-LLM-Based-Self-Reflective-Multi-Agent-Framework-for-Code-Generation)
* [Scaling Up ESM2 Architectures for Long Protein Sequences Analysis Long and Quantized Approaches](#Scaling-Up-ESM2-Architectures-for-Long-Protein-Sequences-Analysis-Long-and-Quantized-Approaches)
* [Democratizing Text-to-Image Masked Generative Models with Compact Text-Aware One-Dimensional Tokens](#Democratizing-Text-to-Image-Masked-Generative-Models-with-Compact-Text-Aware-One-Dimensional-Tokens)
* [Constructing Set-Compositional and Negated Representations for First-Stage Ranking](#Constructing-Set-Compositional-and-Negated-Representations-for-First-Stage-Ranking)
* [Construction of approximate invariants for non-integrable Hamiltonian systems](#Construction-of-approximate-invariants-for-non-integrable-Hamiltonian-systems)
* [Revisiting black holes of algebraic type D with a cosmological constant](#Revisiting-black-holes-of-algebraic-type-D-with-a-cosmological-constant)
* [Occamy A 432-Core Dual-Chiplet Dual-HBM2E 768-DP-GFLOP/s RISC-V System for 8-to-64-bit Dense and Sparse Computing in 12nm FinFET](#Occamy-A-432-Core-Dual-Chiplet-Dual-HBM2E-768-DP-GFLOP/s-RISC-V-System-for-8-to-64-bit-Dense-and-Sparse-Computing-in-12nm-FinFET)
* [Toward Realistic Camouflaged Object Detection Benchmarks and Method](#Toward-Realistic-Camouflaged-Object-Detection-Benchmarks-and-Method)
* [Toward Universal Decoding of Binary Linear Block Codes via Enhanced Polar Transformations](#Toward-Universal-Decoding-of-Binary-Linear-Block-Codes-via-Enhanced-Polar-Transformations)
* [Touched by ChatGPT Using an LLM to Drive Affective Tactile Interaction](#Touched-by-ChatGPT-Using-an-LLM-to-Drive-Affective-Tactile-Interaction)
* [Integrated Wind Farm Design Optimizing Turbine Placement and Cable Routing with Wake Effects](#Integrated-Wind-Farm-Design-Optimizing-Turbine-Placement-and-Cable-Routing-with-Wake-Effects)
* [FlexQuant Elastic Quantization Framework for Locally Hosted LLM on Edge Devices](#FlexQuant-Elastic-Quantization-Framework-for-Locally-Hosted-LLM-on-Edge-Devices)
* [How GPT learns layer by layer](#How-GPT-learns-layer-by-layer)
* [Leveraging ASIC AI Chips for Homomorphic Encryption](#Leveraging-ASIC-AI-Chips-for-Homomorphic-Encryption)
* [Beam Structured Turbo Receiver for HF Skywave Massive MIMO](#Beam-Structured-Turbo-Receiver-for-HF-Skywave-Massive-MIMO)
* [Global Search for Optimal Low Thrust Spacecraft Trajectories using Diffusion Models and the Indirect Method](#Global-Search-for-Optimal-Low-Thrust-Spacecraft-Trajectories-using-Diffusion-Models-and-the-Indirect-Method)
* [Combining LLM decision and RL action selection to improve RL policy for adaptive interventions](#Combining-LLM-decision-and-RL-action-selection-to-improve-RL-policy-for-adaptive-interventions)


## Incrementally Learning Multiple Diverse Data Domains via Multi-Source Dynamic Expansion Model

>Authors: Runqing Wu, Fei Ye, Qihe Liu, Guoxi Huang, Jinyu Guo, Rongyao Hu

>2025-01-15

> http://arxiv.org/abs/2501.08878v1

Continual Learning seeks to develop a model capable of incrementally
assimilating new information while retaining prior knowledge. However, current
research predominantly addresses a straightforward learning context, wherein
all data samples originate from a singular data domain. This paper shifts focus
to a more complex and realistic learning environment, characterized by data
samples sourced from multiple distinct domains. We tackle this intricate
learning challenge by introducing a novel methodology, termed the Multi-Source
Dynamic Expansion Model (MSDEM), which leverages various pre-trained models as
backbones and progressively establishes new experts based on them to adapt to
emerging tasks. Additionally, we propose an innovative dynamic expandable
attention mechanism designed to selectively harness knowledge from multiple
backbones, thereby accelerating the new task learning. Moreover, we introduce a
dynamic graph weight router that strategically reuses all previously acquired
parameters and representations for new task learning, maximizing the positive
knowledge transfer effect, which further improves generalization performance.
We conduct a comprehensive series of experiments, and the empirical findings
indicate that our proposed approach achieves state-of-the-art performance.


## Benchmarking analytical electron ptychography methods for the low-dose imaging of beam-sensitive materials

>Authors: Hoelen L. Lalandec Robert, Max Leo Leidl, Knut Müller-Caspary, Jo Verbeeck

>2025-01-15

> http://arxiv.org/abs/2501.08874v1

This publication presents an investigation of the performance of different
analytical electron ptychography methods for low-dose imaging. In particular,
benchmarking is performed for two model-objects, monolayer MoS$_2$ and
apoferritin, by means of multislice simulations. Specific attention is given to
cases where the individual diffraction patterns remain **sparse**. After a first
rigorous introduction to the theoretical foundations of the methods, an
implementation based on the scan-frequency partitioning of calculation steps is
described, permitting a significant reduction of memory needs and high sampling
flexibility. By analyzing the role of contrast transfer and illumination
conditions, this work provides insights into the trade-off between resolution,
signal-to-noise ratio and probe focus, as is necessary for the optimization of
practical experiments. Furthermore, important differences between the different
methods are demonstrated. Overall, the results obtained for the two
model-objects demonstrate that analytical ptychography is an attractive option
for the low-dose imaging of beam-sensitive materials.


## Nesterov Acceleration for Ensemble Kalman Inversion and Variants

>Authors: Sydney Vernon, Eviatar Bach, Oliver R. A. Dunbar

>2025-01-15

> http://arxiv.org/abs/2501.08779v1

Ensemble Kalman inversion (EKI) is a derivative-free, particle-based
optimization method for solving inverse problems. It can be shown that EKI
approximates a gradient flow, which allows the application of methods for
accelerating gradient descent. Here, we show that Nesterov **acceleration** is
effective in speeding up the reduction of the EKI cost function on a variety of
inverse problems. We also implement Nesterov **acceleration** for two EKI variants,
unscented Kalman inversion and ensemble transform Kalman inversion. Our
specific implementation takes the form of a particle-level nudge that is
demonstrably simple to couple in a black-box fashion with any existing EKI
variant algorithms, comes with no additional computational expense, and with no
additional tuning hyperparameters. This work shows a pathway for future
research to translate advances in gradient-based optimization into advances in
gradient-free Kalman optimization.


## LlamaRestTest Effective REST API Testing with Small Language Models

>Authors: Myeongsoo Kim, Saurabh Sinha, Alessandro Orso

>2025-01-15

> http://arxiv.org/abs/2501.08598v1

Modern web services rely heavily on REST APIs, typically documented using the
OpenAPI specification. The widespread adoption of this standard has resulted in
the development of many black-box testing tools that generate tests based on
these specifications. Recent advancements in Natural Language Processing (NLP),
particularly with Large Language Models (LLMs), have enhanced REST API testing
by extracting actionable rules and generating input values from the
human-readable portions of the specification. However, these advancements
overlook the potential of continuously refining the identified rules and test
inputs based on server responses. To address this limitation, we present
LlamaRestTest, a novel approach that employs two custom LLMs to generate
realistic test inputs and uncover parameter dependencies during the testing
process by incorporating server responses. These LLMs are created by
fine-tuning the Llama3-8b model, using mined datasets of REST API example
values and inter-parameter dependencies. We evaluated LlamaRestTest on 12
real-world services (including popular services such as Spotify), comparing it
against RESTGPT, a GPT-powered specification-enhancement tool, as well as
several state-of-the-art REST API testing tools, including RESTler, MoRest,
EvoMaster, and ARAT-RL. Our results show that fine-tuning enables smaller LLMs
to outperform larger models in detecting actionable rules and generating inputs
for REST API testing. We evaluated configurations from the base Llama3-8B to
fine-tuned versions and explored 2-bit, 4-bit, and 8-bit **quantization** for
efficiency. LlamaRestTest surpasses state-of-the-art tools in code coverage and
error detection, even with RESTGPT-enhanced specifications, and an ablation
study highlights the impact of its novel components.


## LoRS Efficient Low-Rank Adaptation for Sparse Large Language Model

>Authors: Yuxuan Hu, Jing Zhang, Xiaodong Chen, Zhe Zhao, Cuiping Li, Hong Chen

>2025-01-15

> http://arxiv.org/abs/2501.08582v1

Existing low-rank adaptation (LoRA) methods face challenges on **sparse** large
language models (LLMs) due to the inability to maintain **sparsity**. Recent works
introduced methods that maintain **sparsity** by augmenting LoRA techniques with
additional masking mechanisms. Despite these successes, such approaches suffer
from an increased memory and computation overhead, which affects efficiency of
LoRA methods. In response to this limitation, we introduce LoRS, an innovative
method designed to achieve both memory and computation efficiency when
fine-tuning **sparse** LLMs. To mitigate the substantial memory and computation
demands associated with preserving **sparsity**, our approach incorporates
strategies of weight recompute and computational graph rearrangement. In
addition, we also improve the effectiveness of LoRS through better adapter
initialization. These innovations lead to a notable reduction in memory and
computation consumption during the fine-tuning phase, all while achieving
performance levels that outperform existing LoRA approaches.


## SuperSAM Crafting a SAM Supernetwork via Structured Pruning and Unstructured Parameter Prioritization

>Authors: Waqwoya Abebe, Sadegh Jafari, Sixing Yu, Akash Dutta, Jan Strube, Nathan R. Tallent, Luanzheng Guo, Pablo Munoz, Ali Jannesari

>2025-01-15

> http://arxiv.org/abs/2501.08504v1

Neural Architecture Search (NAS) is a powerful approach of automating the
design of efficient neural architectures. In contrast to traditional NAS
methods, recently proposed one-shot NAS methods prove to be more efficient in
performing NAS. One-shot NAS works by generating a singular weight-sharing
supernetwork that acts as a search space (container) of subnetworks. Despite
its achievements, designing the one-shot search space remains a major
challenge. In this work we propose a search space design strategy for Vision
Transformer (ViT)-based architectures. In particular, we convert the Segment
Anything Model (SAM) into a weight-sharing supernetwork called SuperSAM. Our
approach involves automating the search space design via layer-wise structured
**pruning** and parameter prioritization. While the structured **pruning** applies
probabilistic removal of certain transformer layers, parameter prioritization
performs weight reordering and slicing of MLP-blocks in the remaining layers.
We train supernetworks on several datasets using the sandwich rule. For
deployment, we enhance subnetwork discovery by utilizing a program autotuner to
identify efficient subnetworks within the search space. The resulting
subnetworks are 30-70% smaller in size compared to the original pre-trained SAM
ViT-B, yet outperform the pretrained model. Our work introduces a new and
effective method for ViT NAS search-space design.


## Large Language Models For Text Classification Case Study And Comprehensive Review

>Authors: Arina Kostina, Marios D. Dikaiakos, Dimosthenis Stefanidis, George Pallis

>2025-01-14

> http://arxiv.org/abs/2501.08457v1

Unlocking the potential of Large Language Models (LLMs) in data
classification represents a promising frontier in natural language processing.
In this work, we evaluate the performance of different LLMs in comparison with
state-of-the-art deep-learning and machine-learning models, in two different
classification scenarios: i) the classification of employees' working locations
based on job reviews posted online (multiclass classification), and 2) the
classification of news articles as fake or not (binary classification). Our
analysis encompasses a diverse range of language models differentiating in
size, **quantization**, and architecture. We explore the impact of alternative
prompting techniques and evaluate the models based on the weighted F1-score.
Also, we examine the trade-off between performance (F1-score) and time
(inference response time) for each language model to provide a more nuanced
understanding of each model's practical applicability. Our work reveals
significant variations in model responses based on the prompting strategies. We
find that LLMs, particularly Llama3 and GPT-4, can outperform traditional
methods in complex classification tasks, such as multiclass classification,
though at the cost of longer inference times. In contrast, simpler ML models
offer better performance-to-time trade-offs in simpler binary classification
tasks.


## TriMod Fusion for Multimodal Named Entity Recognition in Social Media

>Authors: Mosab Alfaqeeh

>2025-01-14

> http://arxiv.org/abs/2501.08267v1

Social media platforms serve as invaluable sources of user-generated content,
offering insights into various aspects of human behavior. Named Entity
Recognition (NER) plays a crucial role in analyzing such content by identifying
and categorizing named entities into predefined classes. However, traditional
NER models often struggle with the informal, contextually **sparse**, and ambiguous
nature of social media language. To address these challenges, recent research
has focused on multimodal approaches that leverage both textual and visual cues
for enhanced entity recognition. Despite advances, existing methods face
limitations in capturing nuanced mappings between visual objects and textual
entities and addressing distributional disparities between modalities. In this
paper, we propose a novel approach that integrates textual, visual, and hashtag
features (TriMod), utilizing Transformer-attention for effective modality
fusion. The improvements exhibited by our model suggest that named entities can
greatly benefit from the auxiliary context provided by multiple modalities,
enabling more accurate recognition. Through the experiments on a multimodal
social media dataset, we demonstrate the superiority of our approach over
existing state-of-the-art methods, achieving significant improvements in
precision, recall, and F1 score.


## CodecFake-Omni A Large-Scale Codec-based Deepfake Speech Dataset

>Authors: Jiawei Du, Xuanjun Chen, Haibin Wu, Lin Zhang, I-Ming Lin, I-Hsiang Chiu, Wenze Ren, Yuan Tseng, Yu Tsao, Jyh-Shing Roger Jang, Hung-yi Lee

>2025-01-14

> http://arxiv.org/abs/2501.08238v1

With the rapid advancement of codec-based speech generation (CoSG) systems,
creating fake speech that mimics an individual's identity and spreads
misinformation has become remarkably easy. Addressing the risks posed by such
deepfake speech has attracted significant attention. However, most existing
studies focus on detecting fake data generated by traditional speech generation
models. Research on detecting fake speech generated by CoSG systems remains
limited and largely unexplored. In this paper, we introduce CodecFake-Omni, a
large-scale dataset specifically designed to advance the study of neural
codec-based deepfake speech (CodecFake) detection and promote progress within
the anti-spoofing community. To the best of our knowledge, CodecFake-Omni is
the largest dataset of its kind till writing this paper, encompassing the most
diverse range of codec architectures. The training set is generated through
re-synthesis using nearly all publicly available open-source 31 neural audio
codec models across 21 different codec families (one codec family with
different configurations will result in multiple different codec models). The
evaluation set includes web-sourced data collected from websites generated by
17 advanced CoSG models with eight codec families. Using this large-scale
dataset, we reaffirm our previous findings that anti-spoofing models trained on
traditional spoofing datasets generated by vocoders struggle to detect
synthesized speech from current CoSG systems. Additionally, we propose a
comprehensive neural audio codec taxonomy, categorizing neural audio codecs by
their root components: vector **quantize**r, auxiliary objectives, and decoder
types, with detailed explanations and representative examples for each. Using
this comprehensive taxonomy, we conduct stratified analysis to provide valuable
insights for future CodecFake detection research.


## FramePainter Endowing Interactive Image Editing with Video Diffusion Priors

>Authors: Yabo Zhang, Xinpeng Zhou, Yihan Zeng, Hang Xu, Hui Li, Wangmeng Zuo

>2025-01-14

> http://arxiv.org/abs/2501.08225v1

Interactive image editing allows users to modify images through visual
interaction operations such as drawing, clicking, and dragging. Existing
methods construct such supervision signals from videos, as they capture how
objects change with various physical interactions. However, these models are
usually built upon text-to-image diffusion models, so necessitate (i) massive
training samples and (ii) an additional reference encoder to learn real-world
dynamics and visual consistency. In this paper, we reformulate this task as an
image-to-video generation problem, so that inherit powerful video diffusion
priors to reduce training costs and ensure temporal consistency. Specifically,
we introduce FramePainter as an efficient instantiation of this formulation.
Initialized with Stable Video Diffusion, it only uses a lightweight **sparse**
control encoder to inject editing signals. Considering the limitations of
temporal attention in handling large motion between two frames, we further
propose matching attention to enlarge the receptive field while encouraging
dense correspondence between edited and source image tokens. We highlight the
effectiveness and efficiency of FramePainter across various of editing signals:
it domainantly outperforms previous state-of-the-art methods with far less
training data, achieving highly seamless and coherent editing of images, \eg,
automatically adjust the reflection of the cup. Moreover, FramePainter also
exhibits exceptional generalization in scenarios not present in real-world
videos, \eg, transform the clownfish into shark-like shape. Our code will be
available at https://github.com/YBYBZhang/FramePainter.


## Investigating Energy Efficiency and Performance Trade-offs in LLM Inference Across Tasks and DVFS Settings

>Authors: Paul Joe Maliakel, Shashikant Ilager, Ivona Brandic

>2025-01-14

> http://arxiv.org/abs/2501.08219v1

Large language models (LLMs) have shown significant improvements in many
natural language processing (NLP) tasks, accelerating their rapid adoption
across many industries. These models are resource-intensive, requiring
extensive computational resources both during training and inference, leading
to increased energy consumption and negative environmental impact. As their
adoption accelerates, the sustainability of LLMs has become a critical issue,
necessitating strategies to optimize their runtime efficiency without
compromising performance. Hence, it is imperative to identify the parameters
that significantly influence the performance and energy efficiency of LLMs. To
that end, in this work, we investigate the effect of important parameters on
the performance and energy efficiency of LLMs during inference and examine
their trade-offs.
  First, we analyze how different types of models with varying numbers of
parameters and architectures perform on tasks like text generation, question
answering, and summarization by benchmarking LLMs such as Falcon-7B,
Mistral-7B-v0.1, T5-3B, GPT-2, GPT-J-6B, and GPT-Neo-2.7B. Second, we study
input and output sequence characteristics such as sequence length concerning
energy consumption, performance, and throughput. Finally, we explore the impact
of hardware-based power-saving techniques, i.e., Dynamic Voltage Frequency
Scaling (DVFS), on the models' latency and energy efficiency. Our extensive
benchmarking and statistical analysis reveal many interesting findings,
uncovering how specific optimizations can reduce energy consumption while
maintaining throughput and accuracy. This study provides actionable insights
for researchers and practitioners to design energy-efficient LLM inference
systems.


## PRESERVE Prefetching Model Weights and KV-Cache in Distributed LLM Serving

>Authors: Ahmet Caner Yüzügüler, Jiawei Zhuang, Lukas Cavigelli

>2025-01-14

> http://arxiv.org/abs/2501.08192v1

Large language models (LLMs) are widely used across various applications, but
their substantial computational requirements pose significant challenges,
particularly in terms of HBM bandwidth bottlenecks and inter-device
communication overhead. In this paper, we present PRESERVE, a novel prefetching
framework designed to optimize LLM inference by overlapping memory reads for
model weights and **KV**-cache with collective communication operations. Through
extensive experiments conducted on commercial AI accelerators, we demonstrate
up to 1.6x end-to-end speedup on state-of-the-art, open-source LLMs.
Additionally, we perform a design space exploration that identifies the optimal
hardware configuration for the proposed method, showing a further 1.25x
improvement in performance per cost by selecting the optimal L2 cache size. Our
results show that PRESERVE has the potential to mitigate the memory bottlenecks
and communication overheads, offering a solution to improve the performance and
scalability of the LLM inference systems.


## EEG-ReMinD Enhancing Neurodegenerative EEG Decoding through Self-Supervised State Reconstruction-Primed Riemannian Dynamics

>Authors: Zirui Wang, Zhenxi Song, Yi Guo, Yuxin Liu, Guoyang Xu, Min Zhang, Zhiguo Zhang

>2025-01-14

> http://arxiv.org/abs/2501.08139v1

The development of EEG decoding algorithms confronts challenges such as data
**sparsity**, subject variability, and the need for precise annotations, all of
which are vital for advancing brain-computer interfaces and enhancing the
diagnosis of diseases. To address these issues, we propose a novel two-stage
approach named Self-Supervised State Reconstruction-Primed Riemannian Dynamics
(EEG-ReMinD) , which mitigates reliance on supervised learning and integrates
inherent geometric features. This approach efficiently handles EEG data
corruptions and reduces the dependency on labels. EEG-ReMinD utilizes
self-supervised and geometric learning techniques, along with an attention
mechanism, to analyze the temporal dynamics of EEG features within the
framework of Riemannian geometry, referred to as Riemannian dynamics.
Comparative analyses on both intact and corrupted datasets from two different
neurodegenerative disorders underscore the enhanced performance of EEG-ReMinD.


## Categorical quantum symmetries and ribbon tensor 2-categories

>Authors: Hank Chen

>2025-01-14

> http://arxiv.org/abs/2501.08041v1

In a companion work on the combinatorial **quantization** of 4d 2-Chern-Simons
theory, the author has constructed the Hopf category of quantum 2-gauge
transformations $\tilde{\mathcal{C}}=\mathbb{U}_q\frak G$ acting on the
discrete 2-holonomy configurations on a lattice. Guided by the 2-tangle
hypothesis of Baez-Langford, we prove in this article that the
2-$\mathsf{Hilb}$-enriched 2-representation 2-category
$\operatorname{2Rep}(\mathbb{U}_q\mathfrak{G};\tilde R)$ of finite semisimple
$\mathbb{C}$-linear $\mathbb{U}_q\frak G$-module categories is braided,
planar-pivotal, rigid and dagger, hence
$\operatorname{2Rep}(\mathbb{U}_q\mathfrak{G};\tilde R)$ provides an example of
a {\it ribbon tensor 2-category}. We explicitly construct the ribbon balancing
functors, and show that it is compatible with the rigid dagger structures. This
allows one to refine the various notions of {\it framing} in a 2-category with
duals that have been previously studied in the literature. Framed 2-tangles can
then be decorated by 2-representations of categorical quantum groups with a
ribbon 2-functor into $\operatorname{2Rep}(\mathbb{U}_q\mathfrak{G};\tilde R)$,
completely analogous to the construction of decorated ribbon graphs in the
Reshetikhin-Turaev construction. We will also prove that, in the classical
limit $q=(q_\mathrm{h},q_\mathrm{v})\rightarrow 1$, the 2-category
$\operatorname{2Rep}(\mathbb{U}_{q=1}\mathfrak{G};\text{id}\otimes\text{\id})$
become pivotal in the sense of Douglas-Reutter.


## GAC-Net_Geometric and attention-based Network for Depth Completion

>Authors: Kuang Zhu, Xingli Gan, Min Sun

>2025-01-14

> http://arxiv.org/abs/2501.07988v1

Depth completion is a key task in autonomous driving, aiming to complete
**sparse** LiDAR depth measurements into high-quality dense depth maps through
image guidance. However, existing methods usually treat depth maps as an
additional channel of color images, or directly perform convolution on **sparse**
data, failing to fully exploit the 3D geometric information in depth maps,
especially with limited performance in complex boundaries and **sparse** areas. To
address these issues, this paper proposes a depth completion network combining
channel attention mechanism and 3D global feature perception (CGA-Net). The
main innovations include: 1) Utilizing PointNet++ to extract global 3D
geometric features from **sparse** depth maps, enhancing the scene perception
ability of low-line LiDAR data; 2) Designing a channel-attention-based
multimodal feature fusion module to efficiently integrate **sparse** depth, RGB
images, and 3D geometric features; 3) Combining residual learning with CSPN++
to optimize the depth refinement stage, further improving the completion
quality in edge areas and complex scenes. Experiments on the KITTI depth
completion dataset show that CGA-Net can significantly improve the prediction
accuracy of dense depth maps, achieving a new state-of-the-art (SOTA), and
demonstrating strong robustness to **sparse** and complex scenes.


## Robust Hyperspectral Image Panshapring via Sparse Spatial-Spectral Representation

>Authors: Chia-Ming Lee, Yu-Fan Lin, Li-Wei Kang, Chih-Chung Hsu

>2025-01-14

> http://arxiv.org/abs/2501.07953v1

High-resolution hyperspectral imaging plays a crucial role in various remote
sensing applications, yet its acquisition often faces fundamental limitations
due to hardware constraints. This paper introduces S$^{3}$RNet, a novel
framework for hyperspectral image pansharpening that effectively combines
low-resolution hyperspectral images (LRHSI) with high-resolution multispectral
images (HRMSI) through **sparse** spatial-spectral representation. The core of
S$^{3}$RNet is the Multi-Branch Fusion Network (MBFN), which employs parallel
branches to capture complementary features at different spatial and spectral
scales. Unlike traditional approaches that treat all features equally, our
Spatial-Spectral Attention Weight Block (SSAWB) dynamically adjusts feature
weights to maintain **sparse** representation while suppressing noise and
redundancy. To enhance feature propagation, we incorporate the Dense Feature
Aggregation Block (DFAB), which efficiently aggregates inputted features
through dense connectivity patterns. This integrated design enables S$^{3}$RNet
to selectively emphasize the most informative features from differnt scale
while maintaining computational efficiency. Comprehensive experiments
demonstrate that S$^{3}$RNet achieves state-of-the-art performance across
multiple evaluation metrics, showing particular strength in maintaining high
reconstruction quality even under challenging noise conditions. The code will
be made publicly available.


## CodeCoR An LLM-Based Self-Reflective Multi-Agent Framework for Code Generation

>Authors: Ruwei Pan, Hongyu Zhang, Chao Liu

>2025-01-14

> http://arxiv.org/abs/2501.07811v1

Code generation aims to produce code that fulfills requirements written in
natural languages automatically. Large language Models (LLMs) like ChatGPT have
demonstrated promising effectiveness in this area. Nonetheless, these LLMs
often fail to ensure the syntactic and semantic correctness of the generated
code. Recently, researchers proposed multi-agent frameworks that guide LLMs
with different prompts to analyze programming tasks, generate code, perform
testing in a sequential workflow. However, the performance of the workflow is
not robust as the code generation depends on the performance of each agent. To
address this challenge, we propose CodeCoR, a self-reflective multi-agent
framework that evaluates the effectiveness of each agent and their
collaborations. Specifically, for a given task description, four agents in
CodeCoR generate prompts, code, test cases, and repair advice, respectively.
Each agent generates more than one output and prunes away the low-quality ones.
The generated code is tested in the local environment: the code that fails to
pass the generated test cases is sent to the repair agent and the coding agent
re-generates the code based on repair advice. Finally, the code that passes the
most number of generated test cases is returned to users. Our experiments on
four widely used datasets, HumanEval, HumanEval-ET, MBPP, and MBPP-ET,
demonstrate that CodeCoR significantly outperforms existing baselines (e.g.,
CodeCoT and MapCoder), achieving an average Pass@1 score of 77.8%.


## Scaling Up ESM2 Architectures for Long Protein Sequences Analysis Long and Quantized Approaches

>Authors: Gabriel Bianchin de Oliveira, Helio Pedrini, Zanoni Dias

>2025-01-13

> http://arxiv.org/abs/2501.07747v1

Various approaches utilizing Transformer architectures have achieved
state-of-the-art results in Natural Language Processing (NLP). Based on this
success, numerous architectures have been proposed for other types of data,
such as in biology, particularly for protein sequences. Notably among these are
the ESM2 architectures, pre-trained on billions of proteins, which form the
basis of various state-of-the-art approaches in the field. However, the ESM2
architectures have a limitation regarding input size, restricting it to 1,022
amino acids, which necessitates the use of preprocessing techniques to handle
sequences longer than this limit. In this paper, we present the long and
**quantize**d versions of the ESM2 architectures, doubling the input size limit to
2,048 amino acids.


## Democratizing Text-to-Image Masked Generative Models with Compact Text-Aware One-Dimensional Tokens

>Authors: Dongwon Kim, Ju He, Qihang Yu, Chenglin Yang, Xiaohui Shen, Suha Kwak, Liang-Chieh Chen

>2025-01-13

> http://arxiv.org/abs/2501.07730v1

Image tokenizers form the foundation of modern text-to-image generative
models but are notoriously difficult to train. Furthermore, most existing
text-to-image models rely on large-scale, high-quality private datasets, making
them challenging to replicate. In this work, we introduce Text-Aware
Transformer-based 1-Dimensional Tokenizer (TA-TiTok), an efficient and powerful
image tokenizer that can utilize either discrete or continuous 1-dimensional
tokens. TA-TiTok uniquely integrates textual information during the tokenizer
decoding stage (i.e., de-tokenization), accelerating convergence and enhancing
performance. TA-TiTok also benefits from a simplified, yet effective, one-stage
training process, eliminating the need for the complex two-stage distillation
used in previous 1-dimensional tokenizers. This design allows for seamless
scalability to large datasets. Building on this, we introduce a family of
text-to-image Masked Generative Models (MaskGen), trained exclusively on open
data while achieving comparable performance to models trained on private data.
We aim to release both the efficient, strong TA-TiTok tokenizers and the
open-data, open-weight MaskGen models to promote broader access and democratize
the field of text-to-image masked generative models.


## Constructing Set-Compositional and Negated Representations for First-Stage Ranking

>Authors: Antonios Minas Krasakis, Andrew Yates, Evangelos Kanoulas

>2025-01-13

> http://arxiv.org/abs/2501.07679v1

Set compositional and negated queries are crucial for expressing complex
information needs and enable the discovery of niche items like Books about
non-European monarchs. Despite the recent advances in LLMs, first-stage ranking
remains challenging due to the requirement of encoding documents and queries
independently from each other. This limitation calls for constructing
compositional query representations that encapsulate logical operations or
negations, and can be used to match relevant documents effectively. In the
first part of this work, we explore constructing such representations in a
zero-shot setting using vector operations between lexically grounded Learned
Sparse Retrieval (LSR) representations. Specifically, we introduce Disentangled
Negation that penalizes only the negated parts of a query, and a Combined
Pseudo-Term approach that enhances LSRs ability to handle intersections. We
find that our zero-shot approach is competitive and often outperforms
retrievers fine-tuned on compositional data, highlighting certain limitations
of LSR and Dense Retrievers. Finally, we address some of these limitations and
improve LSRs representation power for negation, by allowing them to attribute
negative term scores and effectively penalize documents containing the negated
terms.


## Construction of approximate invariants for non-integrable Hamiltonian systems

>Authors: Yongjun Li, Derong Xu, Yue Hao

>2025-01-13

> http://arxiv.org/abs/2501.07568v1

We present a method to construct high-order polynomial approximate invariants
(AI) for non-integrable Hamiltonian dynamical systems, and apply it to modern
ring-based particle accelerators. Taking advantage of a special property of
one-turn transformation maps in the form of a square matrix, AIs can be
constructed order-by-order iteratively. Evaluating AI with simulation data, we
observe that AI's fluctuation is actually a measure of chaos. Through
minimizing the fluctuations with control knobs in accelerators, the stable
region of long-term motions could be enlarged.


## Revisiting black holes of algebraic type D with a cosmological constant

>Authors: Hryhorii Ovcharenko, Jiri Podolsky, Marco Astorino

>2025-01-13

> http://arxiv.org/abs/2501.07537v1

As an extension of our previous work [1] (arXiv:2409.02308), we study a
complete family of type D black holes with Kerr-like rotation, NUT twist,
**acceleration**, electric and magnetic charges, and any value of the cosmological
constant $\Lambda$. We relate various metric forms of these spacetimes, namely
those found by Plebanski-Demianski (PD), Griffiths-Podolsky (GP), and most
recently Astorino (A). By explicit coordinate transformations and proper
identification of the physical parameters we show that these representations
are locally equivalent, and cover the entire class of type D solutions of the
Einstein-Maxwell-$\Lambda$ equations, such that the (non-null) electromagnetic
field is aligned with both the (double-degenerate) principal null directions of
the Weyl tensor. In particular, we concentrate on the subclass which describes
accelerating NUT black holes without the Kerr-like rotation.


## Occamy A 432-Core Dual-Chiplet Dual-HBM2E 768-DP-GFLOP/s RISC-V System for 8-to-64-bit Dense and Sparse Computing in 12nm FinFET

>Authors: Paul Scheffler, Thomas Benz, Viviane Potocnik, Tim Fischer, Luca Colagrande, Nils Wistoff, Yichao Zhang, Luca Bertaccini, Gianmarco Ottavi, Manuel Eggimann, Matheus Cavalcante, Gianna Paulin, Frank K. Gürkaynak, Davide Rossi, Luca Benini

>2025-01-13

> http://arxiv.org/abs/2501.07330v1

ML and HPC applications increasingly combine dense and **sparse** memory access
computations to maximize storage efficiency. However, existing CPUs and GPUs
struggle to flexibly handle these heterogeneous workloads with consistently
high compute efficiency. We present Occamy, a 432-Core, 768-DP-GFLOP/s,
dual-HBM2E, dual-chiplet RISC-V system with a latency-tolerant hierarchical
interconnect and in-core streaming units (SUs) designed to accelerate dense and
**sparse** FP8-to-FP64 ML and HPC workloads. We implement Occamy's compute chiplets
in 12 nm FinFET, and its passive interposer, Hedwig, in a 65 nm node. On dense
linear algebra (LA), Occamy achieves a competitive FPU utilization of 89%. On
stencil codes, Occamy reaches an FPU utilization of 83% and a
technology-node-normalized compute density of 11.1 DP-GFLOP/s/mm2,leading
state-of-the-art (SoA) processors by 1.7x and 1.2x, respectively. On
**sparse**-dense linear algebra (LA), it achieves 42% FPU utilization and a
normalized compute density of 5.95 DP-GFLOP/s/mm2, surpassing the SoA by 5.2x
and 11x, respectively. On, **sparse**-**sparse** LA, Occamy reaches a throughput of up
to 187 GCOMP/s at 17.4 GCOMP/s/W and a compute density of 3.63 GCOMP/s/mm2.
Finally, we reach up to 75% and 54% FPU utilization on and dense (LLM) and
graph-**sparse** (GCN) ML inference workloads. Occamy's RTL is freely available
under a permissive open-source license.


## Toward Realistic Camouflaged Object Detection Benchmarks and Method

>Authors: Zhimeng Xin, Tianxu Wu, Shiming Chen, Shuo Ye, Zijing Xie, Yixiong Zou, Xinge You, Yufei Guo

>2025-01-13

> http://arxiv.org/abs/2501.07297v1

Camouflaged object detection (COD) primarily relies on semantic or instance
segmentation methods. While these methods have made significant advancements in
identifying the contours of camouflaged objects, they may be inefficient or
cost-effective for tasks that only require the specific location of the object.
Object detection algorithms offer an optimized solution for Realistic
Camouflaged Object Detection (RCOD) in such cases. However, detecting
camouflaged objects remains a formidable challenge due to the high degree of
similarity between the features of the objects and their backgrounds. Unlike
segmentation methods that perform pixel-wise comparisons to differentiate
between foreground and background, object detectors omit this analysis, further
aggravating the challenge. To solve this problem, we propose a camouflage-aware
feature refinement (CAFR) strategy. Since camouflaged objects are not rare
categories, CAFR fully utilizes a clear perception of the current object within
the prior knowledge of large models to assist detectors in deeply understanding
the distinctions between background and foreground. Specifically, in CAFR, we
introduce the Adaptive Gradient Propagation (AGP) module that fine-tunes all
feature extractor layers in large detection models to fully refine
class-specific features from camouflaged contexts. We then design the Sparse
Feature Refinement (SFR) module that optimizes the transformer-based feature
extractor to focus primarily on capturing class-specific features in
camouflaged scenarios. To facilitate the assessment of RCOD tasks, we manually
annotate the labels required for detection on three existing segmentation COD
datasets, creating a new benchmark for RCOD tasks. Code and datasets are
available at: https://github.com/zhimengXin/RCOD.


## Toward Universal Decoding of Binary Linear Block Codes via Enhanced Polar Transformations

>Authors: Chien-Ying Lin, Yu-Chih Huang, Shin-Lin Shieh, Po-Ning Chen

>2025-01-13

> http://arxiv.org/abs/2501.07279v1

Binary linear block codes (BLBCs) are essential to modern communication, but
their diverse structures often require multiple decoders, increasing
complexity. This work introduces enhanced polar decoding ($\mathsf{PD}^+$), a
universal soft decoding algorithm that transforms any BLBC into a polar-like
code compatible with efficient polar code decoders such as successive
cancellation list (SCL) decoding. Key innovations in $\mathsf{PD}^+$ include
**pruning** polar kernels, shortening codes, and leveraging a simulated annealing
algorithm to optimize transformations. These enable $\mathsf{PD}^+$ to achieve
competitive or superior performance to state-of-the-art algorithms like OSD and
GRAND across various codes, including extended BCH, extended Golay, and binary
quadratic residue codes, with significantly lower complexity. Moreover,
$\mathsf{PD}^+$ is designed to be forward-compatible with advancements in polar
code decoding techniques and AI-driven search methods, making it a robust and
versatile solution for universal BLBC decoding in both present and future
systems.


## Touched by ChatGPT Using an LLM to Drive Affective Tactile Interaction

>Authors: Qiaoqiao Ren, Tony Belpaeme

>2025-01-13

> http://arxiv.org/abs/2501.07224v1

Touch is a fundamental aspect of emotion-rich communication, playing a vital
role in human interaction and offering significant potential in human-robot
interaction. Previous research has demonstrated that a **sparse** representation of
human touch can effectively convey social tactile signals. However, advances in
human-robot tactile interaction remain limited, as many humanoid robots possess
simplistic capabilities, such as only opening and closing their hands,
restricting nuanced tactile expressions. In this study, we explore how a robot
can use **sparse** representations of tactile vibrations to convey emotions to a
person. To achieve this, we developed a wearable sleeve integrated with a 5x5
grid of vibration motors, enabling the robot to communicate diverse tactile
emotions and gestures. Using chain prompts within a Large Language Model (LLM),
we generated distinct 10-second vibration patterns corresponding to 10 emotions
(e.g., happiness, sadness, fear) and 6 touch gestures (e.g., pat, rub, tap).
Participants (N = 32) then rated each vibration stimulus based on perceived
valence and arousal. People are accurate at recognising intended emotions, a
result which aligns with earlier findings. These results highlight the LLM's
ability to generate emotional haptic data and effectively convey emotions
through tactile signals. By translating complex emotional and tactile
expressions into vibratory patterns, this research demonstrates how LLMs can
enhance physical interaction between humans and robots.


## Integrated Wind Farm Design Optimizing Turbine Placement and Cable Routing with Wake Effects

>Authors: Jaap Pedersen, Niels Lindner, Daniel Rehfeldt, Thorsten Koch

>2025-01-13

> http://arxiv.org/abs/2501.07203v1

An accelerated deployment of renewable energy sources is crucial for a
successful transformation of the current energy system, with wind energy
playing a key role in this transition. This study addresses the integrated wind
farm layout and cable routing problem, a challenging nonlinear optimization
problem. We model this problem as an extended version of the Quota Steiner Tree
Problem (QSTP), optimizing turbine placement and network connectivity
simultaneously to meet specified expansion targets. Our proposed approach
accounts for the wake effect - a region of reduced wind speed induced by each
installed turbine - and enforces minimum spacing between turbines. We introduce
an exact solution framework in terms of the novel Quota Steiner Tree Problem
with interference (QSTPI). By leveraging an interference-based splitting
strategy, we develop an advanced solver capable of tackling large-scale problem
instances. The presented approach outperforms generic state-of-the-art mixed
integer programming solvers on our dataset by up to two orders of magnitude.
Moreover, we demonstrate that our integrated method significantly reduces the
costs in contrast to a sequential approach. Thus, we provide a planning tool
that enhances existing planning methodologies for supporting a faster and
cost-efficient expansion of wind energy.


## FlexQuant Elastic Quantization Framework for Locally Hosted LLM on Edge Devices

>Authors: Yuji Chai, Mujin Kwen, David Brooks, Gu-Yeon Wei

>2025-01-13

> http://arxiv.org/abs/2501.07139v1

Deploying LLMs on edge devices presents serious technical challenges. Memory
elasticity is crucial for edge devices with unified memory, where memory is
shared and fluctuates dynamically. Existing solutions suffer from either poor
transition granularity or high storage costs. We propose FlexQuant, a novel
elasticity framework that generates an ensemble of **quantize**d models, providing
an elastic hosting solution with 15x granularity improvement and 10x storage
reduction compared to SoTA methods. FlexQuant works with most **quantization**
methods and creates a family of trade-off options under various storage limits
through our **pruning** method. It brings great performance and flexibility to the
edge deployment of LLMs.


## How GPT learns layer by layer

>Authors: Jason Du, Kelly Hong, Alishba Imran, Erfan Jahanparast, Mehdi Khfifi, Kaichun Qiao

>2025-01-13

> http://arxiv.org/abs/2501.07108v1

Large Language Models (LLMs) excel at tasks like language processing,
strategy games, and reasoning but struggle to build generalizable internal
representations essential for adaptive decision-making in agents. For agents to
effectively navigate complex environments, they must construct reliable world
models. While LLMs perform well on specific benchmarks, they often fail to
generalize, leading to brittle representations that limit their real-world
effectiveness. Understanding how LLMs build internal world models is key to
developing agents capable of consistent, adaptive behavior across tasks. We
analyze OthelloGPT, a GPT-based model trained on Othello gameplay, as a
controlled testbed for studying representation learning. Despite being trained
solely on next-token prediction with random valid moves, OthelloGPT shows
meaningful layer-wise progression in understanding board state and gameplay.
Early layers capture static attributes like board edges, while deeper layers
reflect dynamic tile changes. To interpret these representations, we compare
Sparse Autoencoders (SAEs) with linear probes, finding that SAEs offer more
robust, disentangled insights into compositional features, whereas linear
probes mainly detect features useful for classification. We use SAEs to decode
features related to tile color and tile stability, a previously unexamined
feature that reflects complex gameplay concepts like board control and
long-term planning. We study the progression of linear probe accuracy and tile
color using both SAE's and linear probes to compare their effectiveness at
capturing what the model is learning. Although we begin with a smaller language
model, OthelloGPT, this study establishes a framework for understanding the
internal representations learned by GPT models, transformers, and LLMs more
broadly. Our code is publicly available: https://github.com/ALT-JS/OthelloSAE.


## Leveraging ASIC AI Chips for Homomorphic Encryption

>Authors: Jianming Tong, Tianhao Huang, Leo de Castro, Anirudh Itagi, Jingtian Dang, Anupam Golder, Asra Ali, Jevin Jiang, Arvind, G. Edward Suh, Tushar Krishna

>2025-01-13

> http://arxiv.org/abs/2501.07047v1

Cloud-based services are making the outsourcing of sensitive client data
increasingly common. Although homomorphic encryption (HE) offers strong privacy
guarantee, it requires substantially more resources than computing on
plaintext, often leading to unacceptably large latencies in getting the
results. HE accelerators have emerged to mitigate this latency issue, but with
the high cost of ASICs. In this paper we show that HE primitives can be
converted to AI operators and accelerated on existing ASIC AI accelerators,
like TPUs, which are already widely deployed in the cloud. Adapting such
accelerators for HE requires (1) supporting modular multiplication, (2)
high-precision arithmetic in software, and (3) efficient mapping on matrix
engines. We introduce the CROSS compiler (1) to adopt Barrett reduction to
provide modular reduction support using multiplier and adder, (2) Basis Aligned
Transformation (BAT) to convert high-precision multiplication as low-precision
matrix-vector multiplication, (3) Matrix Aligned Transformation (MAT) to covert
vectorized modular operation with reduction into matrix multiplication that can
be efficiently processed on 2D spatial matrix engine. Our evaluation of CROSS
on a Google TPUv4 demonstrates significant performance improvements, with up to
161x and 5x speedup compared to the previous work on many-core CPUs and V100.
The kernel-level codes are open-sourced at
https://github.com/google/jaxite.git.


## Beam Structured Turbo Receiver for HF Skywave Massive MIMO

>Authors: Linfeng Song, Ding Shi, Xiqi Gao, Geoffrey Ye Li, Xiang-Gen Xia

>2025-01-13

> http://arxiv.org/abs/2501.07041v1

In this paper, we investigate receiver design for high frequency (HF) skywave
massive multiple-input multiple-output (MIMO) communications. We first
establish a modified beam based channel model (BBCM) by performing uniform
sampling for directional cosine with deterministic sampling interval, where the
beam matrix is constructed using a phase-shifted discrete Fourier transform
(DFT) matrix. Based on the modified BBCM, we propose a beam structured turbo
receiver (BSTR) involving low-dimensional beam domain signal detection for
grouped user terminals (UTs), which is proved to be asymptotically optimal in
terms of minimizing mean-squared error (MSE). Moreover, we extend it to
windowed BSTR by introducing a windowing approach for interference suppression
and complexity reduction, and propose a well-designed energy-focusing window.
We also present an efficient implementation of the windowed BSTR by exploiting
the structure properties of the beam matrix and the beam domain channel
**sparsity**. Simulation results validate the superior performance of the proposed
receivers but with remarkably low complexity.


## Global Search for Optimal Low Thrust Spacecraft Trajectories using Diffusion Models and the Indirect Method

>Authors: Jannik Graebner, Ryne Beeson

>2025-01-13

> http://arxiv.org/abs/2501.07005v1

Long time-duration low-thrust nonlinear optimal spacecraft trajectory global
search is a computationally and time expensive problem characterized by
clustering patterns in locally optimal solutions. During preliminary mission
design, mission parameters are subject to frequent changes, necessitating that
trajectory designers efficiently generate high-quality control solutions for
these new scenarios. Generative machine learning models can be trained to learn
how the solution structure varies with respect to a conditional parameter,
thereby accelerating the global search for missions with updated parameters. In
this work, state-of-the-art diffusion models are integrated with the indirect
approach for trajectory optimization within a global search framework. This
framework is tested on two low-thrust transfers of different complexity in the
circular restricted three-body problem. By generating and analyzing a training
data set, we develop mathematical relations and techniques to understand the
complex structures in the costate domain of locally optimal solutions for these
problems. A diffusion model is trained on this data and successfully
accelerates the global search for both problems. The model predicts how the
costate solution structure changes, based on the maximum spacecraft thrust
magnitude. Warm-starting a numerical solver with diffusion model samples for
the costates at the initial time increases the number of solutions generated
per minute for problems with unseen thrust magnitudes by one to two orders of
magnitude in comparison to samples from a uniform distribution and from an
adjoint control transformation.


## Combining LLM decision and RL action selection to improve RL policy for adaptive interventions

>Authors: Karine Karine, Benjamin M. Marlin

>2025-01-13

> http://arxiv.org/abs/2501.06980v1

Reinforcement learning (RL) is increasingly being used in the healthcare
domain, particularly for the development of personalized health adaptive
interventions. Inspired by the success of Large Language Models (LLMs), we are
interested in using LLMs to update the RL policy in real time, with the goal of
accelerating personalization. We use the text-based user preference to
influence the action selection on the fly, in order to immediately incorporate
the user preference. We use the term "user preference" as a broad term to refer
to a user personal preference, constraint, health status, or a statement
expressing like or dislike, etc. Our novel approach is a hybrid method that
combines the LLM response and the RL action selection to improve the RL policy.
Given an LLM prompt that incorporates the user preference, the LLM acts as a
filter in the typical RL action selection. We investigate different prompting
strategies and action selection strategies. To evaluate our approach, we
implement a simulation environment that generates the text-based user
preferences and models the constraints that impact behavioral dynamics. We show
that our approach is able to take into account the text-based user preferences,
while improving the RL policy, thus improving personalization in adaptive
intervention.

