<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>2026-01-09 - Efficient Paper</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.css" rel="stylesheet" />
        <link href="../../css/extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "2026-01-09";
        var mkdocs_page_input_path = "weekly_paper/2026-01-09.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
 <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> Efficient Paper
        </a>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../baseline_methods_graph/">Graph</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Weekly Paper</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../2025-12-05/">2025-12-05</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../2025-12-12/">2025-12-12</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../2025-12-19/">2025-12-19</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../2025-12-26/">2025-12-26</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../2025-12-31/">2025-12-31</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">2026-01-09</a>
    <ul class="current">
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Legacy</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../legacy/2025-10-09/">2025-10-09</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../legacy/2025-10-17/">2025-10-17</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../legacy/2025-10-24/">2025-10-24</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../legacy/2025-10-31/">2025-10-31</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../legacy/2025-11-07/">2025-11-07</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../legacy/2025-11-14/">2025-11-14</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../legacy/2025-11-21/">2025-11-21</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../legacy/2025-11-28/">2025-11-28</a>
                </li>
    </ul>
                  </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../contributors/">Contributors</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">Efficient Paper</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Weekly Paper</li>
      <li class="breadcrumb-item active">2026-01-09</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
  
                <h1 id="2026-01-09">2026-01-09</h1>
<h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="#multivector-reranking-in-the-era-of-strong-first-stage-retrievers">Multivector Reranking in the Era of Strong First-Stage Retrievers</a></li>
<li><a href="#simuagent-an-llm-based-simulink-modeling-assistant-enhanced-with-reinforcement-learning">SimuAgent An LLM-Based Simulink Modeling Assistant Enhanced with Reinforcement Learning</a></li>
<li><a href="#relayllm-efficient-reasoning-via-collaborative-decoding">RelayLLM Efficient Reasoning via Collaborative Decoding</a></li>
<li><a href="#token-level-llm-collaboration-via-fusionroute">Token-Level LLM Collaboration via FusionRoute</a></li>
<li><a href="#semantically-orthogonal-framework-for-citation-classification-disentangling-intent-and-content">Semantically Orthogonal Framework for Citation Classification Disentangling Intent and Content</a></li>
<li><a href="#multi-disciplinary-dataset-discovery-from-citation-verified-literature-contexts">Multi-Disciplinary Dataset Discovery from Citation-Verified Literature Contexts</a></li>
<li><a href="#driving-on-registers">Driving on Registers</a></li>
<li><a href="#milestones-over-outcome-unlocking-geometric-reasoning-with-sub-goal-verifiable-reward">Milestones over Outcome Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward</a></li>
<li><a href="#challenges-and-research-directions-for-large-language-model-inference-hardware">Challenges and Research Directions for Large Language Model Inference Hardware</a></li>
<li><a href="#arcaligner-adaptive-recursive-aligner-for-compressed-context-embeddings-in-rag">ArcAligner Adaptive Recursive Aligner for Compressed Context Embeddings in RAG</a></li>
<li><a href="#sparselanestp-leveraging-spatio-temporal-priors-with-sparse-transformers-for-3d-lane-detection">SparseLaneSTP Leveraging Spatio-Temporal Priors with Sparse Transformers for 3D Lane Detection</a></li>
<li><a href="#asynchronous-secure-federated-learning-with-byzantine-aggregators">Asynchronous Secure Federated Learning with Byzantine aggregators</a></li>
<li><a href="#distributed-online-convex-optimization-with-efficient-communication-improved-algorithm-and-lower-bounds">Distributed Online Convex Optimization with Efficient Communication Improved Algorithm and Lower bounds</a></li>
<li><a href="#scalersynthetic-scalable-adaptive-learning-environment-for-reasoning">SCALERSynthetic Scalable Adaptive Learning Environment for Reasoning</a></li>
<li><a href="#agentocr-reimagining-agent-history-via-optical-self-compression">AgentOCR Reimagining Agent History via Optical Self-Compression</a></li>
<li><a href="#AT^2PO-Agentic-Turn-based-Policy-Optimization-via-Tree-Search">AT<script type="math/tex">^2</script>PO Agentic Turn-based Policy Optimization via Tree Search</a></li>
<li><a href="#when-single-agent-with-skills-replace-multi-agent-systems-and-when-they-fail">When Single-Agent with Skills Replace Multi-Agent Systems and When They Fail</a></li>
<li><a href="#gpu-accelerated-int8-quantization-for-kv-cache-compression-in-large-language-models">GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models</a></li>
<li><a href="#beyond-monolithic-architectures-a-multi-agent-search-and-knowledge-optimization-framework-for-agentic-search">Beyond Monolithic Architectures A Multi-Agent Search and Knowledge Optimization Framework for Agentic Search</a></li>
<li><a href="#resmas-resilience-optimization-in-llm-based-multi-agent-systems">ResMAS Resilience Optimization in LLM-based Multi-agent Systems</a></li>
<li><a href="#lamb-llm-based-audio-captioning-with-modality-gap-bridging-via-cauchy-schwarz-divergence">LAMB LLM-based Audio Captioning with Modality Gap Bridging via Cauchy-Schwarz Divergence</a></li>
<li><a href="#llms-integrated-automatic-hate-speech-recognition-using-controllable-text-generation-models">LLMs-Integrated Automatic Hate Speech Recognition Using Controllable Text Generation Models</a></li>
<li><a href="#succeeding-at-scale-automated-multi-retriever-fusion-and-query-side-adaptation-for-multi-tenant-search">Succeeding at Scale Automated Multi-Retriever Fusion and Query-Side Adaptation for Multi-Tenant Search</a></li>
<li><a href="#all-changes-may-have-invariant-principles-improving-ever-shifting-harmful-meme-detection-via-design-concept-reproduction">All Changes May Have Invariant Principles Improving Ever-Shifting Harmful Meme Detection via Design Concept Reproduction</a></li>
<li><a href="#reasoning-over-space-enabling-geographic-reasoning-for-llm-based-generative-next-poi-recommendation">Reasoning Over Space Enabling Geographic Reasoning for LLM-Based Generative Next POI Recommendation</a></li>
<li><a href="#discrete-fourier-transform-based-point-cloud-compression-for-efficient-slam-in-featureless-terrain">Discrete Fourier Transform-based Point Cloud Compression for Efficient SLAM in Featureless Terrain</a></li>
<li><a href="#self-medrag-a-self-reflective-hybrid-retrieval-augmented-generation-framework-for-reliable-medical-question-answering">Self-MedRAG a Self-Reflective Hybrid Retrieval-Augmented Generation Framework for Reliable Medical Question Answering</a></li>
<li><a href="#linguagame-a-linguistically-grounded-game-theoretic-paradigm-for-multi-agent-dialogue-generation">LinguaGame A Linguistically Grounded Game-Theoretic Paradigm for Multi-Agent Dialogue Generation</a></li>
<li><a href="#invisible-walls-privacy-preserving-isac-empowered-by-reconfigurable-intelligent-surfaces">Invisible Walls Privacy-Preserving ISAC Empowered by Reconfigurable Intelligent Surfaces</a></li>
<li><a href="#convergence-rates-for-learning-pseudo-differential-operators">Convergence Rates for Learning Pseudo-Differential Operators</a></li>
<li><a href="#re-rankers-as-relevance-judges">Re-Rankers as Relevance Judges</a></li>
<li><a href="#spectraformer-an-attention-based-raman-unmixing-tool-for-accessing-the-graphene-buffer-layer-signature-on-sic">SpectraFormer an Attention-Based Raman Unmixing Tool for Accessing the Graphene Buffer-Layer Signature on SiC</a></li>
<li><a href="#Rate-or-Fate?-RLV^\varepsilonR-Reinforcement-Learning-with-Verifiable-Noisy-Rewards">Rate or Fate? RLV<script type="math/tex">^\varepsilon</script>R Reinforcement Learning with Verifiable Noisy Rewards</a></li>
<li><a href="#llm-guided-lifecycle-aware-clustering-of-multi-turn-customer-support-conversations">LLM-Guided Lifecycle-Aware Clustering of Multi-Turn Customer Support Conversations</a></li>
<li><a href="#phasor-agents-oscillatory-graphs-with-three-factor-plasticity-and-sleep-staged-learning">Phasor Agents Oscillatory Graphs with Three-Factor Plasticity and Sleep-Staged Learning</a></li>
<li><a href="#packcache-a-training-free-acceleration-method-for-unified-autoregressive-video-generation-via-compact-kv-cache">PackCache A Training-Free Acceleration Method for Unified Autoregressive Video Generation via Compact KV-Cache</a></li>
<li><a href="#rigourate-quantifying-scientific-exaggeration-with-evidence-aligned-claim-evaluation">RIGOURATE Quantifying Scientific Exaggeration with Evidence-Aligned Claim Evaluation</a></li>
<li><a href="#scar-gs-spatial-context-attention-for-residuals-in-progressive-gaussian-splatting">SCAR-GS Spatial Context Attention for Residuals in Progressive Gaussian Splatting</a></li>
<li><a href="#stable-language-guidance-for-vision-language-action-models">Stable Language Guidance for Vision-Language-Action Models</a></li>
<li><a href="#restok-learning-hierarchical-residuals-in-1d-visual-tokenizers-for-autoregressive-image-generation">ResTok Learning Hierarchical Residuals in 1D Visual Tokenizers for Autoregressive Image Generation</a></li>
<li><a href="#focusui-efficient-ui-grounding-via-position-preserving-visual-token-selection">FocusUI Efficient UI Grounding via Position-Preserving Visual Token Selection</a></li>
<li><a href="#decide-then-retrieve-a-training-free-framework-with-uncertainty-guided-triggering-and-dual-path-retrieval">Decide Then Retrieve A Training-Free Framework with Uncertainty-Guided Triggering and Dual-Path Retrieval</a></li>
<li><a href="#a-privacy-preserving-localization-scheme-with-node-selection-in-mobile-networks">A Privacy-Preserving Localization Scheme with Node Selection in Mobile Networks</a></li>
<li><a href="#feature-aware-one-shot-federated-learning-via-hierarchical-token-sequences">Feature-Aware One-Shot Federated Learning via Hierarchical Token Sequences</a></li>
<li><a href="#evaluating-small-decoder-only-language-models-for-grammar-correction-and-text-simplification">Evaluating Small Decoder-Only Language Models for Grammar Correction and Text Simplification</a></li>
<li><a href="#when-numbers-start-talking-implicit-numerical-coordination-among-llm-based-agents">When Numbers Start Talking Implicit Numerical Coordination Among LLM-Based Agents</a></li>
<li><a href="#where-meaning-lives-layer-wise-accessibility-of-psycholinguistic-features-in-encoder-and-decoder-language-models">Where meaning lives Layer-wise accessibility of psycholinguistic features in encoder and decoder language models</a></li>
<li><a href="#Do-LLMs-Really-Memorize-Personally-Identifiable-Information?-Revisiting-PII-Leakage-with-a-Cue-Controlled-Memorization-Framework">Do LLMs Really Memorize Personally Identifiable Information? Revisiting PII Leakage with a Cue-Controlled Memorization Framework</a></li>
<li><a href="#improving-compactness-and-reducing-ambiguity-of-cfire-rule-based-explanations">Improving Compactness and Reducing Ambiguity of CFIRE Rule-Based Explanations</a></li>
<li><a href="#edco-dynamic-curriculum-orchestration-for-domain-specific-large-language-model-fine-tuning">EDCO Dynamic Curriculum Orchestration for Domain-specific Large Language Model Fine-tuning</a></li>
<li><a href="#Visual-Merit-or-Linguistic-Crutch?-A-Close-Look-at-DeepSeek-OCR">Visual Merit or Linguistic Crutch? A Close Look at DeepSeek-OCR</a></li>
<li><a href="#How-Does-the-Thinking-Step-Influence-Model-Safety?-An-Entropy-based-Safety-Reminder-for-LRMs">How Does the Thinking Step Influence Model Safety? An Entropy-based Safety Reminder for LRMs</a></li>
<li><a href="#llm-mc-affect-llm-based-monte-carlo-modeling-of-affective-trajectories-and-latent-ambiguity-for-interpersonal-dynamic-insight">LLM-MC-Affect LLM-Based Monte Carlo Modeling of Affective Trajectories and Latent Ambiguity for Interpersonal Dynamic Insight</a></li>
<li><a href="#architecting-agentic-communities-using-design-patterns">Architecting Agentic Communities using Design Patterns</a></li>
<li><a href="#safety-utility-conflicts-are-not-global-surgical-alignment-via-head-level-diagnosis">Safety-Utility Conflicts Are Not Global Surgical Alignment via Head-Level Diagnosis</a></li>
<li><a href="#inhibitory-attacks-on-backdoor-based-fingerprinting-for-large-language-models">Inhibitory Attacks on Backdoor-based Fingerprinting for Large Language Models</a></li>
<li><a href="#physicsformer-an-efficient-and-fast-attention-based-physics-informed-neural-network-for-solving-incompressible-navier-stokes-equations">PhysicsFormer An Efficient and Fast Attention-Based Physics Informed Neural Network for Solving Incompressible Navier Stokes Equations</a></li>
<li><a href="#Jailbreaking-LLMs-&amp;-VLMs-Mechanisms,-Evaluation,-and-Unified-Defense">Jailbreaking LLMs &amp; VLMs Mechanisms, Evaluation, and Unified Defense</a></li>
<li><a href="#diffcot-diffusion-styled-chain-of-thought-reasoning-in-llms">DiffCoT Diffusion-styled Chain-of-Thought Reasoning in LLMs</a></li>
<li><a href="#layer-order-inversion-rethinking-latent-multi-hop-reasoning-in-large-language-models">Layer-Order Inversion Rethinking Latent Multi-Hop Reasoning in Large Language Models</a></li>
<li><a href="#introlm-introspective-language-models-via-prefilling-time-self-evaluation">IntroLM Introspective Language Models via Prefilling-Time Self-Evaluation</a></li>
<li><a href="#beyond-perplexity-a-lightweight-benchmark-for-knowledge-retention-in-supervised-fine-tuning">Beyond Perplexity A Lightweight Benchmark for Knowledge Retention in Supervised Fine-Tuning</a></li>
<li><a href="#from-bits-to-chips-an-llm-based-hardware-aware-quantization-agent-for-streamlined-deployment-of-llms">From Bits to Chips An LLM-based Hardware-Aware Quantization Agent for Streamlined Deployment of LLMs</a></li>
</ul>
<h2 id="multivector-reranking-in-the-era-of-strong-first-stage-retrievers">Multivector Reranking in the Era of Strong First-Stage Retrievers</h2>
<blockquote>
<p>Authors: Silvio Martinico, Franco Maria Nardini, Cosimo Rulli, Rossano Venturini</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.05200v1">http://arxiv.org/abs/2601.05200v1</a></p>
</blockquote>
<p>Learned multivector representations power modern search systems with strong retrieval effectiveness, but their real-world use is limited by the high cost of exhaustive token-level retrieval. Therefore, most systems adopt a \emph{gather-and-refine} strategy, where a lightweight gather phase selects candidates for full scoring. However, this approach requires expensive searches over large token-level indexes and often misses the documents that would rank highest under full similarity. In this paper, we reproduce several state-of-the-art multivector retrieval methods on two publicly available datasets, providing a clear picture of the current multivector retrieval field and ob<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> the inefficiency of token-level gathering. Building on top of that, we show that replacing the token-level gather phase with a single-vector document retriever -- specifically, a learned <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> retriever (LSR) -- produces a smaller and more semantically coherent candidate set. This recasts the gather-and-refine pipeline into the well-established two-stage retrieval architecture. As retrieval latency decreases, query encoding with two neural encoders becomes the dominant computational bottleneck. To mitigate this, we integrate recent inference-free LSR methods, demonstrating that they preserve the retrieval effectiveness of the dual-encoder pipeline while substantially reducing query encoding time. Finally, we investigate multiple reranking configurations that balance efficiency, memory, and effectiveness, and we introduce two optimization techniques that prune low-quality candidates early. Empirical results show that these techniques improve retrieval efficiency by up to 1.8<script type="math/tex">\times</script> with no loss in quality. Overall, our two-stage approach achieves over <script type="math/tex">24\times</script> speedup over the state-of-the-art multivector retrieval systems, while maintaining comparable or superior retrieval quality.</p>
<h2 id="simuagent-an-llm-based-simulink-modeling-assistant-enhanced-with-reinforcement-learning">SimuAgent An LLM-Based Simulink Modeling Assistant Enhanced with Reinforcement Learning</h2>
<blockquote>
<p>Authors: Yanchang Liang, Xiaowei Zhao</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.05187v1">http://arxiv.org/abs/2601.05187v1</a></p>
</blockquote>
<p>Large language models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) have revolutionized text-based code automation, but their potential in graph-oriented engineering workflows remains under-explored. We introduce SimuAgent, an <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-powered modeling and simulation agent tailored for Simulink. SimuAgent replaces verbose XML with a concise, dictionary-style Python representation, dramatically cutting token counts, improving interpretability, and enabling fast, in-process simulation. A lightweight plan-execute architecture, trained in two stages, equips the agent with both low-level tool skills and high-level design reasoning. To tackle <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> rewards in long-horizon tasks, we propose Reflection-GRPO (ReGRPO), which augments Group Relative Policy Optimization (GRPO) with self-reflection traces that supply rich intermediate feedback, accelerating convergence and boosting robustness. Experiments on SimuBench, our newly released benchmark comprising 5300 multi-domain modeling tasks, show that a Qwen2.5-7B model fine-tuned with SimuAgent converges faster and achieves higher modeling accuracy than standard RL baselines, and even surpasses GPT-4o when evaluated with few-shot prompting on the same benchmark. Ablations confirm that the two-stage curriculum and abstract-reconstruct data augmentation further enhance generalization. SimuAgent trains and runs entirely on-premise with modest hardware, delivering a privacy-pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a>, cost-effective solution for industrial model-driven engineering. SimuAgent bridges the gap between <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s and graphical modeling environments, offering a practical solution for AI-assisted engineering design in industrial settings.</p>
<h2 id="relayllm-efficient-reasoning-via-collaborative-decoding">RelayLLM Efficient Reasoning via Collaborative Decoding</h2>
<blockquote>
<p>Authors: Chengsong Huang, Tong Zheng, Langlin Huang, Jinyuan Li, Haolin Liu, Jiaxin Huang</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.05167v1">http://arxiv.org/abs/2601.05167v1</a></p>
</blockquote>
<p>Large Language Models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse granularity by offloading entire queries to <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s, resulting in significant computational waste when the SLM is capable of handling the majority of reasoning steps. To address this, we propose Relay<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>, a novel framework for efficient reasoning via token-level collaborative <a class="glightbox" href="https://img.shields.io/badge/decoding-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decoding-F08080" /></a>. Unlike routers, Relay<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> empowers the SLM to act as an active controller that dynamically invokes the <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> only for critical tokens via a special command, effectively "relaying" the generation process. We introduce a two-stage training framework, including warm-up and Group Relative Policy Optimization (GRPO) to teach the model to balance independence with strategic help-seeking. Empirical results across six benchmarks demonstrate that Relay<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> achieves an average accuracy of 49.52%, effectively bridging the performance gap between the two models. Notably, this is achieved by invoking the <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> for only 1.07% of the total generated tokens, offering a 98.2% cost reduction compared to performance-matched random routers.</p>
<h2 id="token-level-llm-collaboration-via-fusionroute">Token-Level LLM Collaboration via FusionRoute</h2>
<blockquote>
<p>Authors: Nuoya Xiong, Yuhang Zhou, Hanqing Zeng, Zhaorun Chen, Furong Huang, Shuchao Bi, Lizhu Zhang, Zhuokai Zhao</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.05106v1">http://arxiv.org/abs/2601.05106v1</a></p>
</blockquote>
<p>Large language models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) exhibit strengths across diverse domains. However, achieving strong performance across these domains with a single general-purpose model typically requires scaling to sizes that are prohibitively expensive to train and deploy. On the other hand, while smaller domain-specialized models are much more efficient, they struggle to generalize beyond their training distributions. To address this dilemma, we propose FusionRoute, a robust and effective token-level multi-<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> collaboration framework in which a lightweight router simultaneously (i) selects the most suitable expert at each <a class="glightbox" href="https://img.shields.io/badge/decoding-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decoding-F08080" /></a> step and (ii) contributes a complementary logit that refines or corrects the selected expert's next-token distribution via logit addition. Unlike existing token-level collaboration methods that rely solely on fixed expert outputs, we provide a theoretical analysis showing that pure expert-only routing is fundamentally limited: unless strong global coverage assumptions hold, it cannot in general realize the optimal <a class="glightbox" href="https://img.shields.io/badge/decoding-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decoding-F08080" /></a> policy. By augmenting expert selection with a trainable complementary generator, FusionRoute expands the effective policy class and enables recovery of optimal value functions under mild conditions. Empirically, across both Llama-3 and Gemma-2 families and diverse benchmarks spanning mathematical reasoning, code generation, and instruction following, FusionRoute outperforms both sequence- and token-level collaboration, model merging, and direct fine-tuning, while remaining competitive with domain experts on their respective tasks.</p>
<h2 id="semantically-orthogonal-framework-for-citation-classification-disentangling-intent-and-content">Semantically Orthogonal Framework for Citation Classification Disentangling Intent and Content</h2>
<blockquote>
<p>Authors: Changxu Duan, Zhiyin Tan</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.05103v1">http://arxiv.org/abs/2601.05103v1</a></p>
</blockquote>
<p>Understanding the role of citations is essential for research assessment and citation-aware digital libraries. However, existing citation classification frameworks often conflate citation intent (why a work is cited) with cited content type (what part is cited), limiting their effectiveness in auto classification due to a dilemma between fine-grained type distinctions and practical classification reliability. We introduce SOFT, a Semantically Orthogonal Framework with Two dimensions that explicitly separates citation intent from cited content type, drawing inspiration from semantic role theory. We systematically re-annotate the ACL-ARC dataset using SOFT and release a cross-disciplinary test set sampled from ACT2. Evaluation with both zero-shot and fine-tuned Large Language Models demonstrates that SOFT enables higher agreement between human annotators and <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s, and supports stronger classification performance and robust cross-domain generalization compared to ACL-ARC and SciCite annotation frameworks. These results confirm SOFT's value as a clear, reusable annotation standard, improving clarity, consistency, and generalizability for digital libraries and scholarly <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> infrastructures. All code and data are publicly available on GitHub https://github.com/zhiyintan/SOFT.</p>
<h2 id="multi-disciplinary-dataset-discovery-from-citation-verified-literature-contexts">Multi-Disciplinary Dataset Discovery from Citation-Verified Literature Contexts</h2>
<blockquote>
<p>Authors: Zhiyin Tan, Changxu Duan</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.05099v1">http://arxiv.org/abs/2601.05099v1</a></p>
</blockquote>
<p>Identifying suitable datasets for a research question remains challenging because existing dataset search engines rely heavily on metadata quality and keyword <a class="glightbox" href="https://img.shields.io/badge/overlap-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/overlap-F08080" /></a>, which often fail to capture the semantic intent of scientific investigation. We introduce a literature-driven framework that discovers datasets from citation contexts in scientific papers, enabling retrieval grounded in actual research use rather than metadata availability. Our approach combines large-scale citation-context extraction, schema-guided dataset recognition with Large Language Models, and provenance-pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> entity resolution. We evaluate the system on eight survey-derived computer science queries and find that it achieves substantially higher recall than Google Dataset Search and DataCite Commons, with normalized recall ranging from an average of 47.47% to a highest value of 81.82%. Beyond recovering gold-standard datasets, the method also surfaces additional datasets not documented in the surveys. Expert assessments across five top-level Fields of Science indicate that a substantial portion of the additional datasets are considered high utility, and some are regarded as novel for the specific topics chosen by the experts. These findings establish citation-context mining as an effective and generalizable paradigm for dataset discovery, particularly in settings where datasets lack sufficient or reliable metadata. To support reproducibility and future extensions, we release our code, evaluation datasets, and results on GitHub (https://github.com/Fireblossom/citation-context-dataset-discovery).</p>
<h2 id="driving-on-registers">Driving on Registers</h2>
<blockquote>
<p>Authors: Ellington Kirby, Alexandre Boulch, Yihong Xu, Yuan Yin, Gilles Puy, Ã‰loi Zablocki, Andrei Bursuc, Spyros Gidaris, Renaud Marlet, Florent Bartoccioni, Anh-Quan Cao, Nermin Samet, Tuan-Hung VU, Matthieu Cord</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.05083v1">http://arxiv.org/abs/2601.05083v1</a></p>
</blockquote>
<p>We present DrivoR, a simple and efficient <a class="glightbox" href="https://img.shields.io/badge/transformer-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/transformer-FF8C00" /></a>-based architecture for end-to-end autonomous driving. Our approach builds on pretrained Vision Transformers (ViTs) and introduces camera-aware register tokens that compress multi-camera features into a compact scene representation, significantly reducing downstream computation without sacrificing accuracy. These tokens drive two lightweight <a class="glightbox" href="https://img.shields.io/badge/transformer-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/transformer-FF8C00" /></a> <a class="glightbox" href="https://img.shields.io/badge/decode-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decode-F08080" /></a>rs that generate and then score candidate trajectories. The scoring <a class="glightbox" href="https://img.shields.io/badge/decode-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decode-F08080" /></a>r learns to mimic an oracle and predicts interpretable sub-scores representing aspects such as safety, comfort, and efficiency, enabling behavior-conditioned driving at inference. Despite its minimal design, DrivoR outperforms or matches strong contemporary baselines across NAVSIM-v1, NAVSIM-v2, and the photorealistic closed-loop HUGSIM benchmark. Our results show that a pure-<a class="glightbox" href="https://img.shields.io/badge/transformer-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/transformer-FF8C00" /></a> architecture, combined with targeted token <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a>, is sufficient for accurate, efficient, and adaptive end-to-end driving. Code and checkpoints will be made available via the project page.</p>
<h2 id="milestones-over-outcome-unlocking-geometric-reasoning-with-sub-goal-verifiable-reward">Milestones over Outcome Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward</h2>
<blockquote>
<p>Authors: Jianlong Chen, Daocheng Fu, Shengze Xu, Jiawei Chen, Yuan Feng, Yue Yang, Junchi Yan, Hongyuan Zha, Renqiu Xia</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.05073v1">http://arxiv.org/abs/2601.05073v1</a></p>
</blockquote>
<p>Multimodal Large Language Models (M<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) struggle with complex geometric reasoning, largely because "black box" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.</p>
<h2 id="challenges-and-research-directions-for-large-language-model-inference-hardware">Challenges and Research Directions for Large Language Model Inference Hardware</h2>
<blockquote>
<p>Authors: Xiaoyu Ma, David Patterson</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.05047v1">http://arxiv.org/abs/2601.05047v1</a></p>
</blockquote>
<p>Large Language Model (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>) inference is hard. The autoregressive Decode phase of the underlying Transformer model makes <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> inference fundamentally different from training. Exacerbated by recent AI trends, the primary challenges are memory and interconnect rather than compute. To address these challenges, we highlight four architecture research opportunities: High Bandwidth Flash for 10X memory capacity with HBM-like bandwidth; Processing-Near-Memory and 3D memory-logic stacking for high memory bandwidth; and low-latency interconnect to speedup <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a>. While our focus is datacenter AI, we also review their applicability for mobile devices.</p>
<h2 id="arcaligner-adaptive-recursive-aligner-for-compressed-context-embeddings-in-rag">ArcAligner Adaptive Recursive Aligner for Compressed Context Embeddings in RAG</h2>
<blockquote>
<p>Authors: Jianbo Li, Yi Jiang, Sendong Zhao, Bairui Hu, Haochun Wang, Bing Qin</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.05038v1">http://arxiv.org/abs/2601.05038v1</a></p>
</blockquote>
<p>Retrieval-Augmented Generation (RAG) helps <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s stay accurate, but feeding long documents into a prompt makes the model slow and expensive. This has motivated context <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a>, ranging from token <a class="glightbox" href="https://img.shields.io/badge/pruning-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/pruning-F08080" /></a> and summarization to embedding-based <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a>. While researchers have tried ''compressing'' these documents into smaller summaries or mathematical embeddings, there is a catch: the more you compress the data, the more the <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> struggles to understand it. To address this challenge, we propose ArcAligner (Adaptive recursive context <em>Aligner</em>), a lightweight module integrated into the language model layers to help the model better utilize highly compressed context representations for downstream generation. It uses an adaptive ''gating'' system that only adds extra processing power when the information is complex, keeping the system fast. Across knowledge-intensive QA benchmarks, ArcAligner consistently beats <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a> baselines at comparable <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a> rates, especially on multi-hop and long-tail settings. The source code is publicly available.</p>
<h2 id="sparselanestp-leveraging-spatio-temporal-priors-with-sparse-transformers-for-3d-lane-detection">SparseLaneSTP Leveraging Spatio-Temporal Priors with Sparse Transformers for 3D Lane Detection</h2>
<blockquote>
<p>Authors: Maximilian Pittner, Joel Janai, Mario Faigle, Alexandru Paul Condurache</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04968v1">http://arxiv.org/abs/2601.04968v1</a></p>
</blockquote>
<p>3D lane detection has emerged as a critical challenge in autonomous driving, encompassing identification and localization of lane markings and the 3D road surface. Conventional 3D methods detect lanes from dense birds-eye-viewed (BEV) features, though erroneous transformations often result in a poor feature representation misaligned with the true 3D road surface. While recent <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> lane detectors have surpassed dense BEV approaches, they completely disregard valuable lane-specific priors. Furthermore, existing methods fail to utilize historic lane observations, which yield the potential to resolve ambiguities in situations of poor visibility. To address these challenges, we present SparseLaneSTP, a novel method that integrates both geometric properties of the lane structure and temporal information into a <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> lane <a class="glightbox" href="https://img.shields.io/badge/transformer-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/transformer-FF8C00" /></a>. It introduces a new lane-specific spatio-temporal attention mechanism, a continuous lane representation tailored for <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> architectures as well as temporal regularization. Identifying weaknesses of existing 3D lane datasets, we also introduce a precise and consistent 3D lane dataset using a simple yet effective auto-labeling strategy. Our experimental section proves the benefits of our contributions and demonstrates state-of-the-art performance across all detection and error metrics on existing 3D lane detection benchmarks as well as on our novel dataset.</p>
<h2 id="asynchronous-secure-federated-learning-with-byzantine-aggregators">Asynchronous Secure Federated Learning with Byzantine aggregators</h2>
<blockquote>
<p>Authors: Antonella Del Pozzo, Achille Desreumaux, Mathieu Gestin, Alexandre Rapetti, Sara Tucci-Piergiovanni</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04930v1">http://arxiv.org/abs/2601.04930v1</a></p>
</blockquote>
<p>Privacy-pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> federated averaging is a central approach for protecting client privacy in federated learning. In this paper, we study this problem in an asynchronous <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a>s setting with malicious aggregators. We propose a new solution to provide federated averaging in this model while protecting the client's data privacy through secure aggregation and differential privacy. Our solution maintains the same performance as the state of the art across all metrics. The main contributions of this paper are threefold. First, unlike existing single- or multi-server solutions, we consider malicious aggregation servers that may manipulate the model to leak clients' data or halt computation. To tolerate this threat, we replicate the aggregators, allowing a fraction of them to be corrupted. Second, we propose a new privacy preservation protocol for protocols in asynchronous <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> models with Byzantine aggregators. In this protocol, clients mask their values and add Gaussian noise to their models. In contrast with previous works, we use the replicated servers to unmask the models, while ensuring the liveness of training even if aggregators misbehave. Third, the asynchronous <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> model introduces new challenges not present in existing approaches. In such a setting, faster clients may contribute more frequently, potentially reducing their privacy and biasing the training. To address this, we introduce an inclusion mechanism that ensures uniform client participation and balanced privacy budgets. Interestingly, the solution presented in this paper does not rely on agreement between aggregators. Thus, we circumvent the known impossibility of consensus in asynchronous settings where processes might crash. Additionally, this feature increases availability, as a consensus-based algorithm only progresses in periods of low latency.</p>
<h2 id="distributed-online-convex-optimization-with-efficient-communication-improved-algorithm-and-lower-bounds">Distributed Online Convex Optimization with Efficient Communication Improved Algorithm and Lower bounds</h2>
<blockquote>
<p>Authors: Sifan Yang, Wenhao Yang, Wei Jiang, Lijun Zhang</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04907v1">http://arxiv.org/abs/2601.04907v1</a></p>
</blockquote>
<p>We investigate distributed online convex optimization with compressed <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a>, where <script type="math/tex">n</script> learners connected by a network collaboratively minimize a sequence of global loss functions using only local information and compressed data from neighbors. Prior work has established regret bounds of <script type="math/tex">O(\max\{Ï‰^{-2}Ï^{-4}n^{1/2},Ï‰^{-4}Ï^{-8}\}n\sqrt{T})</script> and <script type="math/tex">O(\max\{Ï‰^{-2}Ï^{-4}n^{1/2},Ï‰^{-4}Ï^{-8}\}n\ln{T})</script> for convex and strongly convex functions, respectively, where <script type="math/tex">Ï‰\in(0,1]</script> is the <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a> quality factor (<script type="math/tex">Ï‰=1</script> means no <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a>) and <script type="math/tex">Ï<1</script> is the spectral gap of the <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> matrix. However, these regret bounds suffer from a \emph{quadratic} or even \emph{quartic} dependence on <script type="math/tex">Ï‰^{-1}</script>. Moreover, the \emph{super-linear} dependence on <script type="math/tex">n</script> is also undesirable. To overcome these limitations, we propose a novel algorithm that achieves improved regret bounds of <script type="math/tex">\tilde{O}(Ï‰^{-1/2}Ï^{-1}n\sqrt{T})</script> and <script type="math/tex">\tilde{O}(Ï‰^{-1}Ï^{-2}n\ln{T})</script> for convex and strongly convex functions, respectively. The primary idea is to design a \emph{two-level blocking update framework} incorporating two novel ingredients: an online gossip strategy and an error compensation scheme, which collaborate to \emph{achieve a better consensus} among learners. Furthermore, we establish the first lower bounds for this problem, justifying the optimality of our results with respect to both <script type="math/tex">Ï‰</script> and <script type="math/tex">T</script>. Additionally, we consider the bandit feedback scenario, and extend our method with the classic gradient estimators to enhance existing regret bounds.</p>
<h2 id="scalersynthetic-scalable-adaptive-learning-environment-for-reasoning">SCALERSynthetic Scalable Adaptive Learning Environment for Reasoning</h2>
<blockquote>
<p>Authors: Caijun Xu, Changyi Xiao, Zhongyuan Peng, Xinrun Wang, Yixin Cao</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04809v1">http://arxiv.org/abs/2601.04809v1</a></p>
</blockquote>
<p>Reinforcement learning (RL) offers a principled way to enhance the reasoning capabilities of large language models, yet its effectiveness hinges on training signals that remain informative as models evolve. In practice, RL progress often slows when task difficulty becomes poorly aligned with model capability, or when training is dominated by a narrow set of recurring problem patterns. To jointly address these issues, we propose SCALER (Synthetic sCalable Adaptive Learning Environment for Reasoning), a framework that sustains effective learning signals through adaptive environment design. SCALER introduces a scalable synthesis pipeline that converts real-world programming problems into verifiable reasoning environments with controllable difficulty and unbounded instance generation, enabling RL training beyond finite datasets while pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> strong correctness guarantees. Building on this, SCALER further employs an adaptive multi-environment RL strategy that dynamically adjusts instance difficulty and curates the active set of environments to track the model's capability frontier and maintain distributional diversity. This co-adaptation prevents reward <a class="glightbox" href="https://img.shields.io/badge/sparsity-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparsity-F08080" /></a>, mitigates overfitting to narrow task patterns, and supports sustained improvement throughout training. Extensive experiments show that SCALER consistently outperforms dataset-based RL baselines across diverse reasoning benchmarks and exhibits more stable, long-horizon training dynamics.</p>
<h2 id="agentocr-reimagining-agent-history-via-optical-self-compression">AgentOCR Reimagining Agent History via Optical Self-Compression</h2>
<blockquote>
<p>Authors: Lang Feng, Fuchao Yang, Feng Chen, Xin Cheng, Haiyang Xu, Zhenglin Wan, Ming Yan, Bo An</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04786v1">http://arxiv.org/abs/2601.04786v1</a></p>
</blockquote>
<p>Recent advances in large language models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) enable agentic systems trained with reinforcement learning (RL) over multi-turn interaction trajectories, but practical deployment is bottlenecked by rapidly growing textual histories that inflate token budgets and memory usage. We introduce AgentOCR, a framework that exploits the superior information density of visual tokens by representing the accumulated observation-action history as a compact rendered image. To make multi-turn rollouts scalable, AgentOCR proposes segment optical caching. By decomposing history into hashable segments and maintaining a visual <a class="glightbox" href="https://img.shields.io/badge/cache-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/cache-F08080" /></a>, this mechanism eliminates redundant re-rendering. Beyond fixed rendering, AgentOCR introduces agentic self-<a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a>, where the agent actively emits a <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a> rate and is trained with <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a>-aware reward to adaptively balance task success and token efficiency. We conduct extensive experiments on challenging agentic benchmarks, ALFWorld and search-based QA. Remarkably, results demonstrate that AgentOCR preserves over 95\% of text-based agent performance while substantially reducing token consumption (&gt;50\%), yielding consistent token and memory efficiency. Our further analysis validates a 20x rendering speedup from segment optical caching and the effective strategic balancing of self-<a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a>.</p>
<h2 id="at2po-agentic-turn-based-policy-optimization-via-tree-search">AT<script type="math/tex">^2</script>PO Agentic Turn-based Policy Optimization via Tree Search</h2>
<blockquote>
<p>Authors: Zefang Zong, Dingwei Chen, Yang Li, Qi Yi, Bo Zhou, Chengming Li, Bo Qian, Peng Chen, Jie Jiang</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04767v1">http://arxiv.org/abs/2601.04767v1</a></p>
</blockquote>
<p><a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> agents have emerged as powerful systems for tackling multi-turn tasks by interleaving internal reasoning and external tool interactions. Agentic Reinforcement Learning has recently drawn significant research attention as a critical post-training paradigm to further refine these capabilities. In this paper, we present AT<script type="math/tex">^2</script>PO (Agentic Turn-based Policy Optimization via Tree Search), a unified framework for multi-turn agentic RL that addresses three core challenges: limited exploration diversity, <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> credit assignment, and misaligned policy optimization. AT<script type="math/tex">^2</script>PO introduces a turn-level tree structure that jointly enables Entropy-Guided Tree Expansion for strategic exploration and Turn-wise Credit Assignment for fine-grained reward propagation from <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> outcomes. Complementing this, we propose Agentic Turn-based Policy Optimization, a turn-level learning objective that aligns policy updates with the natural decision granularity of agentic interactions. ATPO is orthogonal to tree search and can be readily integrated into any multi-turn RL pipeline. Experiments across seven benchmarks demonstrate consistent improvements over the state-of-the-art baseline by up to 1.84 percentage points in average, with ablation studies validating the effectiveness of each component. Our code is available at https://github.com/zzfoutofspace/ATPO.</p>
<h2 id="when-single-agent-with-skills-replace-multi-agent-systems-and-when-they-fail">When Single-Agent with Skills Replace Multi-Agent Systems and When They Fail</h2>
<blockquote>
<p>Authors: Xiaoxiao Li</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04748v1">http://arxiv.org/abs/2601.04748v1</a></p>
</blockquote>
<p>Multi-agent AI systems have proven effective for complex reasoning. These systems are compounded by specialized agents, which collaborate through explicit <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a>, but incur substantial computational overhead. A natural question arises: can we achieve similar modularity benefits with a single agent that selects from a library of skills? We explore this question by viewing skills as internalized agent behaviors. From this perspective, a multi-agent system can be compiled into an equivalent single-agent system, trading inter-agent <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> for skill selection. Our preliminary experiments suggest this approach can substantially reduce token usage and latency while maintaining competitive accuracy on reasoning benchmarks. However, this efficiency raises a deeper question that has received little attention: how does skill selection scale as libraries grow?
  Drawing on principles from cognitive science, we propose that <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> skill selection exhibits bounded capacity analogous to human decision-making. We investigate the scaling behavior of skill selection and observe a striking pattern. Rather than degrading gradually, selection accuracy remains stable up to a critical library size, then drops sharply, indicating a phase transition reminiscent of capacity limits in human cognition. Furthermore, we find evidence that semantic confusability among similar skills, rather than library size alone, plays a central role in this degradation. This perspective suggests that hierarchical organization, which has long helped humans manage complex choices, may similarly benefit AI systems. Our initial results with hierarchical routing support this hypothesis. This work opens new questions about the fundamental limits of semantic-based skill selection in <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s and offers a cognitive-grounded framework and practical guidelines for designing scalable skill-based agents.</p>
<h2 id="gpu-accelerated-int8-quantization-for-kv-cache-compression-in-large-language-models">GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models</h2>
<blockquote>
<p>Authors: Maanas Taneja, Purab Shingvi</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04719v1">http://arxiv.org/abs/2601.04719v1</a></p>
</blockquote>
<p>The key-value (<a class="glightbox" href="https://img.shields.io/badge/KV-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/KV-F08080" /></a>) <a class="glightbox" href="https://img.shields.io/badge/cache-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/cache-F08080" /></a> in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 <a class="glightbox" href="https://img.shields.io/badge/quantization-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/quantization-F08080" /></a> for <a class="glightbox" href="https://img.shields.io/badge/KV-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/KV-F08080" /></a> <a class="glightbox" href="https://img.shields.io/badge/cache-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/cache-F08080" /></a> <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a>, achieving 4<script type="math/tex">\times</script> memory reduction with minimal accuracy degradation. We develop four CUDA kernel variants -- naive, tiled, coarsened, and vectorized -- and benchmark them across realistic workload sizes up to 1 billion elements. Our vectorized kernel achieves up to 1,694<script type="math/tex">\times</script> speedup over CPU baselines while maintaining reconstruction error below 0.004 and attention score error below 0.1 even for 8K-dimensional heads. These results demonstrate that INT8 <a class="glightbox" href="https://img.shields.io/badge/quantization-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/quantization-F08080" /></a> provides a practical approach for reducing memory pressure in <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> inference with negligible computational overhead (6--58ms) and minimal impact on downstream model behavior</p>
<h2 id="beyond-monolithic-architectures-a-multi-agent-search-and-knowledge-optimization-framework-for-agentic-search">Beyond Monolithic Architectures A Multi-Agent Search and Knowledge Optimization Framework for Agentic Search</h2>
<blockquote>
<p>Authors: Yiqun Chen, Lingyong Yan, Zixuan Yang, Erhan Zhang, Jiashu Zhao, Shuaiqiang Wang, Dawei Yin, Jiaxin Mao</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04703v1">http://arxiv.org/abs/2601.04703v1</a></p>
</blockquote>
<p>Agentic search has emerged as a promising paradigm for complex information seeking by enabling Large Language Models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) to interleave reasoning with tool use. However, prevailing systems rely on monolithic agents that suffer from structural bottlenecks, including unconstrained reasoning outputs that inflate trajectories, <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> outcome-level rewards that complicate credit assignment, and stochastic search noise that destabilizes learning. To address these challenges, we propose \textbf{M-ASK} (Multi-Agent Search and Knowledge), a framework that explicitly decouples agentic search into two complementary roles: Search Behavior Agents, which plan and execute search actions, and Knowledge Management Agents, which aggregate, filter, and maintain a compact internal context. This decomposition allows each agent to focus on a well-defined subtask and reduces interference between search and context construction. Furthermore, to enable stable coordination, M-ASK employs turn-level rewards to provide granular supervision for both search decisions and knowledge updates. Experiments on multi-hop QA benchmarks demonstrate that M-ASK outperforms strong baselines, achieving not only superior answer accuracy but also significantly more stable training dynamics.\footnote{The source code for M-ASK is available at https://github.com/chenyiqun/M-ASK.}</p>
<h2 id="resmas-resilience-optimization-in-llm-based-multi-agent-systems">ResMAS Resilience Optimization in LLM-based Multi-agent Systems</h2>
<blockquote>
<p>Authors: Zhilun Zhou, Zihan Liu, Jiahe Liu, Qingyu Shao, Yihan Wang, Kun Shao, Depeng Jin, Fengli Xu</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04694v1">http://arxiv.org/abs/2601.04694v1</a></p>
</blockquote>
<p>Large Language Model-based Multi-Agent Systems (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-based MAS), where multiple <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> agents collaborate to solve complex tasks, have shown impressive performance in many areas. However, MAS are typically distributed across different devices or environments, making them vulnerable to perturbations such as agent failures. While existing works have studied the adversarial attacks and corresponding defense strategies, they mainly focus on reactively detecting and mitigating attacks after they occur rather than proactively designing inherently resilient systems. In this work, we study the resilience of <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-based MAS under perturbations and find that both the <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> topology and prompt design significantly influence system resilience. Motivated by these findings, we propose ResMAS: a two-stage framework for enhancing MAS resilience. First, we train a reward model to predict the MAS's resilience, based on which we train a topology generator to automatically design resilient topology for specific tasks through reinforcement learning. Second, we introduce a topology-aware prompt optimization method that refines each agent's prompt based on its connections and interactions with other agents. Extensive experiments across a range of tasks show that our approach substantially improves MAS resilience under various constraints. Moreover, our framework demonstrates strong generalization ability to new tasks and models, highlighting its potential for building resilient MASs.</p>
<h2 id="lamb-llm-based-audio-captioning-with-modality-gap-bridging-via-cauchy-schwarz-divergence">LAMB LLM-based Audio Captioning with Modality Gap Bridging via Cauchy-Schwarz Divergence</h2>
<blockquote>
<p>Authors: Hyeongkeun Lee, Jongmin Choi, KiHyun Nam, Joon Son Chung</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04658v1">http://arxiv.org/abs/2601.04658v1</a></p>
</blockquote>
<p>Automated Audio Captioning aims to describe the semantic content of input audio. Recent works have employed large language models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) as a text <a class="glightbox" href="https://img.shields.io/badge/decode-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decode-F08080" /></a>r to leverage their reasoning capabilities. However, prior approaches that project audio features into the <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> embedding space without considering cross-modal alignment fail to fully utilize these capabilities. To address this, we propose LAMB, an <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-based audio captioning framework that bridges the modality gap between audio embeddings and the <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> text embedding space. LAMB incorporates a Cross-Modal Aligner that minimizes Cauchy-Schwarz divergence while maximizing mutual information, yielding tighter alignment between audio and text at both global and token levels. We further design a Two-Stream Adapter that extracts semantically enriched audio embeddings, thereby delivering richer information to the Cross-Modal Aligner. Finally, leveraging the aligned audio embeddings, a proposed Token Guide directly computes scores within the <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> text embedding space to steer the output logits of generated captions. Experimental results confirm that our framework strengthens the reasoning capabilities of the <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> <a class="glightbox" href="https://img.shields.io/badge/decode-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decode-F08080" /></a>r, achieving state-of-the-art performance on AudioCaps.</p>
<h2 id="llms-integrated-automatic-hate-speech-recognition-using-controllable-text-generation-models">LLMs-Integrated Automatic Hate Speech Recognition Using Controllable Text Generation Models</h2>
<blockquote>
<p>Authors: Ryutaro Oshima, Yuya Hosoda, Youji Iiguni</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04654v1">http://arxiv.org/abs/2601.04654v1</a></p>
</blockquote>
<p>This paper proposes an automatic speech recognition (ASR) model for hate speech using large language models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s). The proposed method integrates the encoder of the ASR model with the <a class="glightbox" href="https://img.shields.io/badge/decode-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decode-F08080" /></a>r of the <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s, enabling simultaneous transcription and censorship tasks to prevent the exposure of harmful content. Instruction tuning of the <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> to mask hate-related words with specific tokens requires an annotated hate speech dataset, which is limited. We generate text samples using an <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> with the Chain-of-Thought (CoT) prompting technique guided by cultural context and examples and then convert them into speech samples using a text-to-speech (TTS) system. However, some of them contain non-hate speech samples with hate-related words, which degrades the censorship performance. This paper filters the samples which text classification models correctly label as hate content. By adjusting the threshold for the number of correct answer models, we can control the level of hate in the generated dataset, allowing us to train the <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s through curriculum learning in a gradual manner. Experimental results show that the proposed method achieves a masking accuracy of 58.6\% for hate-related words, surpassing previous baselines. We also confirm that the curriculum training contributes to the efficiency of both transcription and censorship tasks.</p>
<h2 id="succeeding-at-scale-automated-multi-retriever-fusion-and-query-side-adaptation-for-multi-tenant-search">Succeeding at Scale Automated Multi-Retriever Fusion and Query-Side Adaptation for Multi-Tenant Search</h2>
<blockquote>
<p>Authors: Prateek Jain, Shabari S Nair, Ritesh Goru, Prakhar Agarwal, Ajay Yadav, Yoga Sri Varshan Varadharajan, Constantine Caramanis</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04646v1">http://arxiv.org/abs/2601.04646v1</a></p>
</blockquote>
<p>Large-scale multi-tenant retrieval systems amass vast user query logs yet critically lack the curated relevance labels required for effective domain adaptation. This "dark data" problem is exacerbated by the operational cost of model updates: jointly fine-tuning query and document encoders requires re-indexing the entire corpus, which is prohibitive in multi-tenant environments with thousands of isolated indices. To address these dual challenges, we introduce \textbf{DevRev Search}, a passage retrieval benchmark for technical customer support constructed through a fully automatic pipeline. We employ a \textbf{fusion-based candidate generation} strategy, pooling results from diverse <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> and dense retrievers, and utilize an <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-as-a-Judge to perform rigorous \textbf{consistency filtering} and relevance assignment. We further propose a practical \textbf{Index-Pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> Adaptation} strategy: by fine-tuning only the query encoder via Low-Rank Adaptation (LoRA), we achieve competitive performance improvements while keeping the document index frozen. Our experiments on DevRev Search and SciFact demonstrate that targeting specific <a class="glightbox" href="https://img.shields.io/badge/transformer-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/transformer-FF8C00" /></a> layers in the query encoder yields optimal quality-efficiency trade-offs, offering a scalable path for personalized enterprise search.</p>
<h2 id="all-changes-may-have-invariant-principles-improving-ever-shifting-harmful-meme-detection-via-design-concept-reproduction">All Changes May Have Invariant Principles Improving Ever-Shifting Harmful Meme Detection via Design Concept Reproduction</h2>
<blockquote>
<p>Authors: Ziyou Jiang, Mingyang Li, Junjie Wang, Yuekai Huang, Jie Huang, Zhiyuan Chang, Zhaoyang Li, Qing Wang</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04567v1">http://arxiv.org/abs/2601.04567v1</a></p>
</blockquote>
<p>Harmful memes are ever-shifting in the Internet communities, which are difficult to analyze due to their type-shifting and temporal-evolving nature. Although these memes are shifting, we find that different memes may share invariant principles, i.e., the underlying design concept of malicious users, which can help us analyze why these memes are harmful. In this paper, we propose RepMD, an ever-shifting harmful meme detection method based on the design concept reproduction. We first refer to the attack tree to define the Design Concept Graph (DCG), which describes steps that people may take to design a harmful meme. Then, we derive the DCG from historical memes with design step reproduction and graph <a class="glightbox" href="https://img.shields.io/badge/pruning-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/pruning-F08080" /></a>. Finally, we use DCG to guide the Multimodal Large Language Model (M<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>) to detect harmful memes. The evaluation results show that RepMD achieves the highest accuracy with 81.1% and has slight accuracy decreases when generalized to type-shifting and temporal-evolving memes. Human evaluation shows that RepMD can improve the efficiency of human discovery on harmful memes, with 15<script type="math/tex">\sim</script>30 seconds per meme.</p>
<h2 id="reasoning-over-space-enabling-geographic-reasoning-for-llm-based-generative-next-poi-recommendation">Reasoning Over Space Enabling Geographic Reasoning for LLM-Based Generative Next POI Recommendation</h2>
<blockquote>
<p>Authors: Dongyi Lv, Qiuyu Ding, Heng-Da Xu, Zhaoxu Sun, Zhi Wang, Feng Xiong, Mu Xu</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04562v1">http://arxiv.org/abs/2601.04562v1</a></p>
</blockquote>
<p>Generative recommendation with large language models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) reframes prediction as sequence generation, yet existing <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-based recommenders remain limited in leveraging geographic signals that are crucial in mobility and local-services scenarios. Here, we present Reasoning Over Space (ROS), a framework that utilizes geography as a vital decision variable within the reasoning process. ROS introduces a Hierarchical Spatial Semantic ID (SID) that discretizes coarse-to-fine locality and POI semantics into compositional tokens, and endows <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> with a three-stage Mobility Chain-of-Thought (CoT) paradigm that models user personality, constructs an intent-aligned candidate space, and performs locality informed <a class="glightbox" href="https://img.shields.io/badge/pruning-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/pruning-F08080" /></a>. We further align the model with real world geography via spatial-guided Reinforcement Learning (RL). Experiments on three widely used location-based social network (LBSN) datasets show that ROS achieves over 10% relative gains in hit rate over strongest <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-based baselines and improves cross-city transfer, despite using a smaller backbone model.</p>
<h2 id="discrete-fourier-transform-based-point-cloud-compression-for-efficient-slam-in-featureless-terrain">Discrete Fourier Transform-based Point Cloud Compression for Efficient SLAM in Featureless Terrain</h2>
<blockquote>
<p>Authors: Riku Suzuki, Ayumi Umemura, Shreya Santra, Kentaro Uno, Kazuya Yoshida</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04551v1">http://arxiv.org/abs/2601.04551v1</a></p>
</blockquote>
<p>Simultaneous Localization and Mapping (SLAM) is an essential technology for the efficiency and reliability of unmanned robotic exploration missions. While the onboard computational capability and <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> bandwidth are critically limited, the point cloud data handled by SLAM is large in size, attracting attention to data <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a> methods. To address such a problem, in this paper, we propose a new method for compressing point cloud maps by exploiting the Discrete Fourier Transform (DFT). The proposed technique converts the Digital Elevation Model (DEM) to the frequency-domain 2D image and omits its high-frequency components, focusing on the exploration of gradual terrains such as planets and deserts. Unlike terrains with detailed structures such as artificial environments, high-frequency components contribute little to the representation of gradual terrains. Thus, this method is effective in compressing data size without significant degradation of the point cloud. We evaluated the method in terms of <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a> rate and accuracy using camera sequences of two terrains with different elevation profiles.</p>
<h2 id="self-medrag-a-self-reflective-hybrid-retrieval-augmented-generation-framework-for-reliable-medical-question-answering">Self-MedRAG a Self-Reflective Hybrid Retrieval-Augmented Generation Framework for Reliable Medical Question Answering</h2>
<blockquote>
<p>Authors: Jessica Ryan, Alexander I. Gumilang, Robert Wiliam, Derwin Suhartono</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04531v1">http://arxiv.org/abs/2601.04531v1</a></p>
</blockquote>
<p>Large Language Models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) have demonstrated significant potential in medical Question Answering (QA), yet they remain prone to hallucinations and ungrounded reasoning, limiting their reliability in high-stakes clinical scenarios. While Retrieval-Augmented Generation (RAG) mitigates these issues by incorporating external knowledge, conventional single-shot retrieval often fails to resolve complex biomedical queries requiring multi-step inference. To address this, we propose Self-MedRAG, a self-reflective hybrid framework designed to mimic the iterative hypothesis-verification process of clinical reasoning. Self-MedRAG integrates a hybrid retrieval strategy, combining <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> (BM25) and dense (Contriever) retrievers via Reciprocal Rank Fusion (RRF) to maximize evidence coverage. It employs a generator to produce answers with supporting rationales, which are then assessed by a lightweight self-reflection module using Natural Language Inference (NLI) or <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-based verification. If the rationale lacks sufficient evidentiary support, the system autonomously reformulates the query and iterates to refine the context. We evaluated Self-MedRAG on the MedQA and PubMedQA benchmarks. The results demonstrate that our hybrid retrieval approach significantly outperforms single-retriever baselines. Furthermore, the inclusion of the self-reflective loop yielded substantial gains, increasing accuracy on MedQA from 80.00% to 83.33% and on PubMedQA from 69.10% to 79.82%. These findings confirm that integrating hybrid retrieval with iterative, evidence-based self-reflection effectively reduces unsupported claims and enhances the clinical reliability of <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-based systems.</p>
<h2 id="linguagame-a-linguistically-grounded-game-theoretic-paradigm-for-multi-agent-dialogue-generation">LinguaGame A Linguistically Grounded Game-Theoretic Paradigm for Multi-Agent Dialogue Generation</h2>
<blockquote>
<p>Authors: Yuxiao Ye, Yiming Zhang, Yiran Ma, Huiyuan Xie, Huining Zhu, Zhiyuan Liu</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04516v1">http://arxiv.org/abs/2601.04516v1</a></p>
</blockquote>
<p>Large Language Models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) have enabled Multi-Agent Systems (MASs) where agents interact through natural language to solve complex tasks or simulate multi-party dialogues. Recent work on <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-based MASs has mainly focused on architecture design, such as role assignment and workflow orchestration. In contrast, this paper targets the interaction process itself, aiming to improve agents' <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> efficiency by helping them convey their intended meaning more effectively through language. To this end, we propose LinguaGame, a linguistically-grounded game-theoretic paradigm for multi-agent dialogue generation. Our approach models dialogue as a signalling game over communicative intents and strategies, solved with a training-free equilibrium approximation algorithm for inference-time decision adjustment. Unlike prior game-theoretic MASs, whose game designs are often tightly coupled with task-specific objectives, our framework relies on linguistically informed reasoning with minimal task-specific coupling. Specifically, it treats dialogue as intentional and strategic <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a>, requiring agents to infer what others aim to achieve (intents) and how they pursue those goals (strategies). We evaluate our framework in simulated courtroom proceedings and debates, with human expert assessments showing significant gains in <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> efficiency.</p>
<h2 id="invisible-walls-privacy-preserving-isac-empowered-by-reconfigurable-intelligent-surfaces">Invisible Walls Privacy-Preserving ISAC Empowered by Reconfigurable Intelligent Surfaces</h2>
<blockquote>
<p>Authors: Yinghui He, Long Fan, Lei Xie, Dusit Niyato, Chau Yuen, Jun Luo</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04488v1">http://arxiv.org/abs/2601.04488v1</a></p>
</blockquote>
<p>The environmental and target-related information inherently carried in wireless signals, such as channel state information (CSI), has brought increasing attention to integrated sensing and <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> (ISAC). However, it also raises pressing concerns about privacy leakage through eavesdropping. While existing efforts have attempted to mitigate this issue, they either fail to account for the needs of legitimate <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> and sensing users or rely on hardware with high complexity and cost. To overcome these limitations, we propose PrivISAC, a plug-and-play, low-cost solution that leverages RIS to protect user privacy while pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> ISAC performance. At the core of PrivISAC is a novel strategy in which each RIS row is assigned two distinct beamforming vectors, from which we deliberately construct a limited set of RIS configurations. During operation, exactly one configuration is randomly activated at each time slot to introduce additional perturbations, effectively masking sensitive sensing information from unauthorized eavesdroppers. To jointly ensure privacy protection and <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> performance, we design the two vectors such that their responses remain nearly identical in the <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> direction, thereby pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> stable, high-throughput transmission, while exhibiting pronounced differences in the sensing direction, which introduces sufficient perturbations to thwart eavesdroppers. Additionally, to enable legitimate sensing under such randomized configurations, we introduce a time-domain masking and demasking method that allows the authorized receiver to associate each CSI sample with its underlying configuration and eliminate configuration-induced discrepancies, thereby recovering valid CSI. We implement PrivISAC on commodity wireless devices and experiment results show that PrivISAC provides strong privacy protection while pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> high-quality legitimate ISAC.</p>
<h2 id="convergence-rates-for-learning-pseudo-differential-operators">Convergence Rates for Learning Pseudo-Differential Operators</h2>
<blockquote>
<p>Authors: Jiaheng Chen, Daniel Sanz-Alonso</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04473v1">http://arxiv.org/abs/2601.04473v1</a></p>
</blockquote>
<p>This paper establishes convergence rates for learning elliptic pseudo-differential operators, a fundamental operator class in partial differential equations and mathematical physics. In a wavelet-Galerkin framework, we formulate learning over this class as a structured infinite-dimensional regression problem with multiscale <a class="glightbox" href="https://img.shields.io/badge/sparsity-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparsity-F08080" /></a>. Building on this structure, we propose a <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a>, data- and computation-efficient estimator, which leverages a novel matrix <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a> scheme tailored to the learning task and a nested-support strategy to balance approximation and estimation errors. In addition to obtaining convergence rates for the estimator, we show that the learned operator induces an efficient and stable Galerkin solver whose numerical error matches its statistical accuracy. Our results therefore contribute to bringing together operator learning, data-driven solvers, and wavelet methods in scientific computing.</p>
<h2 id="re-rankers-as-relevance-judges">Re-Rankers as Relevance Judges</h2>
<blockquote>
<p>Authors: Chuan Meng, Jiqun Liu, Mohammad Aliannejadi, Fengran Mo, Jeff Dalton, Maarten de Rijke</p>
<p>2026-01-08</p>
<p><a href="http://arxiv.org/abs/2601.04455v1">http://arxiv.org/abs/2601.04455v1</a></p>
</blockquote>
<p>Using large language models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) to predict relevance judgments has shown promising results. Most studies treat this task as a distinct research line, e.g., focusing on prompt design for predicting relevance labels given a query and passage. However, predicting relevance judgments is essentially a form of relevance prediction, a problem extensively studied in tasks such as re-ranking. Despite this potential <a class="glightbox" href="https://img.shields.io/badge/overlap-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/overlap-F08080" /></a>, little research has explored reusing or adapting established re-ranking methods to predict relevance judgments, leading to potential resource waste and redundant development. To bridge this gap, we reproduce re-rankers in a re-ranker-as-relevance-judge setup. We design two adaptation strategies: (i) using binary tokens (e.g., "true" and "false") generated by a re-ranker as direct judgments, and (ii) converting continuous re-ranking scores into binary labels via thresholding. We perform extensive experiments on TREC-DL 2019 to 2023 with 8 re-rankers from 3 families, ranging from 220M to 32B, and analyse the evaluation bias exhibited by re-ranker-based judges. Results show that re-ranker-based relevance judges, under both strategies, can outperform UMBRELA, a state-of-the-art <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-based relevance judge, in around 40% to 50% of the cases; they also exhibit strong self-preference towards their own and same-family re-rankers, as well as cross-family bias.</p>
<h2 id="spectraformer-an-attention-based-raman-unmixing-tool-for-accessing-the-graphene-buffer-layer-signature-on-sic">SpectraFormer an Attention-Based Raman Unmixing Tool for Accessing the Graphene Buffer-Layer Signature on SiC</h2>
<blockquote>
<p>Authors: Dmitriy Poteryayev, Pietro Novelli, Annalisa Coriolano, Riccardo Dettori, Valentina Tozzini, Fabio Beltram, Massimiliano Pontil, Antonio Rossi, Stiven Forti, Camilla Coletti</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.04445v1">http://arxiv.org/abs/2601.04445v1</a></p>
</blockquote>
<p>Raman spectroscopy is a key tool for graphene characterization, yet its application to graphene grown on silicon carbide (SiC) is strongly limited by the intense and variable second-order Raman response of the substrate. This limitation is critical for buffer layer graphene, a semiconducting interfacial phase, whose vibrational signatures are <a class="glightbox" href="https://img.shields.io/badge/overlap-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/overlap-F08080" /></a>ped with the SiC background and challenging to be reliably accessed using conventional reference-based subtraction, due to strong spatial and experimental variability of the substrate signal. Here we present SpectraFormer, a <a class="glightbox" href="https://img.shields.io/badge/transformer-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/transformer-FF8C00" /></a>-based deep learning model that reconstructs the SiC Raman substrate contribution directly from post-growth partially masked spectroscopic data without relying on explicit reference measurements. By learning global correlations across the entire Raman shift range, the model captures the statistical structure of the SiC background and enables accurate reconstruction of its contribution in mixed spectra. Subtraction of the reconstructed substrate signal reveals weak vibrational features associated with ZLG that are inaccessible through conventional analysis methods. The extracted spectra are validated by ab initio vibrational calculations, allowing assignment of the resolved features to specific modes and confirming their physical consistency. By leveraging a state-of-the-art attention-based deep learning architecture, this approach establishes a robust, reference-free framework for Raman analysis of graphene on SiC and provides a foundation, compatible with real-time data acquisition, to its integration into automated, closed-loop AI-assisted growth optimization.</p>
<h2 id="rate-or-fate-rlvvarepsilonr-reinforcement-learning-with-verifiable-noisy-rewards">Rate or Fate? RLV<script type="math/tex">^\varepsilon</script>R Reinforcement Learning with Verifiable Noisy Rewards</h2>
<blockquote>
<p>Authors: Ali Rad, Khashayar Filom, Darioush Keivan, Peyman Mohajerin Esfahani, Ehsan Kamalinejad</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.04411v1">http://arxiv.org/abs/2601.04411v1</a></p>
</blockquote>
<p>Reinforcement learning with verifiable rewards (RLVR) is a simple but powerful paradigm for training <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s: sample a completion, verify it, and update. In practice, however, the verifier is almost never clean--unit tests probe only limited corner cases; human and synthetic labels are imperfect; and <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> judges (e.g., RLAIF) are noisy and can be exploited--and this problem worsens on harder domains (especially coding) where tests are <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> and increasingly model-generated. We ask a pragmatic question: does the verification noise merely slow down the learning (rate), or can it flip the outcome (fate)?
  To address this, we develop an analytically tractable multi-armed bandit view of RLVR dynamics, instantiated with GRPO and validated in controlled experiments. Modeling false positives and false negatives and grouping completions into recurring reasoning modes yields a replicator-style (natural-selection) flow on the probability simplex. The dynamics decouples into within-correct-mode competition and a one-dimensional evolution for the mass on incorrect modes, whose drift is determined solely by Youden's index J=TPR-FPR. This yields a sharp phase transition: when J&gt;0, the incorrect mass is driven toward extinction (learning); when J=0, the process is neutral; and when J&lt;0, incorrect modes amplify until they dominate (anti-learning and collapse). In the learning regime J&gt;0, noise primarily rescales convergence time ("rate, not fate"). Experiments on verifiable programming tasks under synthetic noise reproduce the predicted J=0 boundary. Beyond noise, the framework offers a general lens for analyzing RLVR stability, convergence, and algorithmic interventions.</p>
<h2 id="llm-guided-lifecycle-aware-clustering-of-multi-turn-customer-support-conversations">LLM-Guided Lifecycle-Aware Clustering of Multi-Turn Customer Support Conversations</h2>
<blockquote>
<p>Authors: Priyaranjan Pattnayak, Sanchari Chowdhuri, Amit Agarwal, Hitesh Laxmichand Patel</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.04388v1">http://arxiv.org/abs/2601.04388v1</a></p>
</blockquote>
<p>Clustering customer chat data is vital for cloud providers handling multi service queries. Traditional methods struggle with <a class="glightbox" href="https://img.shields.io/badge/overlap-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/overlap-F08080" /></a>ping concerns and create broad, static clusters that degrade over time. Reclustering disrupts continuity, making issue tracking difficult. We propose an adaptive system that segments multi turn chats into service specific concerns and incrementally refines clusters as new issues arise. Cluster quality is tracked via DaviesBouldin Index and Silhouette Scores, with <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> based splitting applied only to degraded clusters. Our method improves Silhouette Scores by over 100\% and reduces DBI by 65.6\% compared to baselines, enabling scalable, real time analytics without full reclustering.</p>
<h2 id="phasor-agents-oscillatory-graphs-with-three-factor-plasticity-and-sleep-staged-learning">Phasor Agents Oscillatory Graphs with Three-Factor Plasticity and Sleep-Staged Learning</h2>
<blockquote>
<p>Authors: Rodja Trappe</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.04362v1">http://arxiv.org/abs/2601.04362v1</a></p>
</blockquote>
<p>Phasor Agents are dynamical systems whose internal state is a Phasor Graph: a weighted graph of coupled Stuart-Landau oscillators. A Stuart-Landau oscillator is a minimal stable "rhythm generator" (the normal form near a Hopf bifurcation); each oscillator is treated as an abstract computational unit (inspired by, but not claiming to model, biological oscillatory populations). In this interpretation, oscillator phase tracks relative timing (coherence), while amplitude tracks local gain or activity. Relative phase structure serves as a representational medium; coupling weights are learned via three-factor local plasticity - eligibility traces gated by <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> global modulators and oscillation-timed write windows - without backpropagation.
  A central challenge in oscillatory substrates is stability: online weight updates can drive the network into unwanted regimes (e.g., global synchrony), collapsing representational diversity. We therefore separate wake tagging from offline consolidation, inspired by synaptic tagging-and-capture and sleep-stage dynamics: deep-sleep-like gated capture commits tagged changes safely, while REM-like replay reconstructs and perturbs experience for planning.
  A staged experiment suite validates each mechanism with ablations and falsifiers: eligibility traces preserve credit under delayed modulation; <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a>-progress signals pass timestamp-shuffle controls; phase-coherent retrieval reaches 4x diffusive baselines under noise; wake/sleep separation expands stable learning by 67 percent under matched weight-norm budgets; REM replay improves maze success rate by +45.5 percentage points; and a Tolman-style latent-learning signature - immediate competence and detour advantage after unrewarded exploration, consistent with an internal model - emerges from replay (Tolman, 1948).
  The codebase and all artifacts are open-source.</p>
<h2 id="packcache-a-training-free-acceleration-method-for-unified-autoregressive-video-generation-via-compact-kv-cache">PackCache A Training-Free Acceleration Method for Unified Autoregressive Video Generation via Compact KV-Cache</h2>
<blockquote>
<p>Authors: Kunyang Li, Mubarak Shah, Yuzhang Shang</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.04359v1">http://arxiv.org/abs/2601.04359v1</a></p>
</blockquote>
<p>A unified autoregressive model is a Transformer-based framework that addresses diverse multimodal tasks (e.g., text, image, video) as a single sequence modeling problem under a shared token space. Such models rely on the <a class="glightbox" href="https://img.shields.io/badge/KV-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/KV-F08080" /></a>-<a class="glightbox" href="https://img.shields.io/badge/cache-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/cache-F08080" /></a> mechanism to reduce attention computation from O(T^2) to O(T); however, <a class="glightbox" href="https://img.shields.io/badge/KV-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/KV-F08080" /></a>-<a class="glightbox" href="https://img.shields.io/badge/cache-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/cache-F08080" /></a> size grows linearly with the number of generated tokens, and it rapidly becomes the dominant bottleneck limiting inference efficiency and generative length. Unified autoregressive video generation inherits this limitation. Our analysis reveals that <a class="glightbox" href="https://img.shields.io/badge/KV-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/KV-F08080" /></a>-<a class="glightbox" href="https://img.shields.io/badge/cache-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/cache-F08080" /></a> tokens exhibit distinct spatiotemporal properties: (i) text and conditioning-image tokens act as persistent semantic anchors that consistently receive high attention, and (ii) attention to previous frames naturally decays with temporal distance. Leveraging these observations, we introduce PackCache, a training-free <a class="glightbox" href="https://img.shields.io/badge/KV-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/KV-F08080" /></a>-<a class="glightbox" href="https://img.shields.io/badge/cache-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/cache-F08080" /></a> management method that dynamically compacts the <a class="glightbox" href="https://img.shields.io/badge/KV-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/KV-F08080" /></a> <a class="glightbox" href="https://img.shields.io/badge/cache-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/cache-F08080" /></a> through three coordinated mechanisms: condition anchoring that preserves semantic references, cross-frame decay modeling that allocates <a class="glightbox" href="https://img.shields.io/badge/cache-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/cache-F08080" /></a> budget according to temporal distance, and spatially pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> position embedding that maintains coherent 3D structure under <a class="glightbox" href="https://img.shields.io/badge/cache-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/cache-F08080" /></a> removal. In terms of efficiency, PackCache accelerates end-to-end generation by 1.7-2.2x on 48-frame long sequences, showcasing its strong potential for enabling longer-sequence video generation. Notably, the final four frames - the portion most impacted by the progressively expanding <a class="glightbox" href="https://img.shields.io/badge/KV-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/KV-F08080" /></a>-<a class="glightbox" href="https://img.shields.io/badge/cache-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/cache-F08080" /></a> and thus the most expensive segment of the clip - PackCache delivers a 2.6x and 3.7x <a class="glightbox" href="https://img.shields.io/badge/acceleration-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/acceleration-F08080" /></a> on A40 and H200, respectively, for 48-frame videos.</p>
<h2 id="rigourate-quantifying-scientific-exaggeration-with-evidence-aligned-claim-evaluation">RIGOURATE Quantifying Scientific Exaggeration with Evidence-Aligned Claim Evaluation</h2>
<blockquote>
<p>Authors: Joseph James, Chenghao Xiao, Yucheng Li, Nafise Sadat Moosavi, Chenghua Lin</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.04350v1">http://arxiv.org/abs/2601.04350v1</a></p>
</blockquote>
<p>Scientific rigour tends to be sidelined in favour of bold statements, leading authors to overstate claims beyond what their results support. We present RIGOURATE, a two-stage multimodal framework that retrieves supporting evidence from a paper's body and assigns each claim an overstatement score. The framework consists of a dataset of over 10K claim-evidence sets from ICLR and NeurIPS papers, annotated using eight <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s, with overstatement scores calibrated using peer-review comments and validated through human evaluation. It employes a fine-tuned reranker for evidence retrieval and a fine-tuned model to predict overstatement scores with justification. Compared to strong baselines, RIGOURATE enables improved evidence retrieval and overstatement detection. Overall, our work operationalises evidential proportionality and supports clearer, more transparent scientific <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a>.</p>
<h2 id="scar-gs-spatial-context-attention-for-residuals-in-progressive-gaussian-splatting">SCAR-GS Spatial Context Attention for Residuals in Progressive Gaussian Splatting</h2>
<blockquote>
<p>Authors: Diego Revilla, Pooja Suresh, Anand Bhojan, Ooi Wei Tsang</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.04348v1">http://arxiv.org/abs/2601.04348v1</a></p>
</blockquote>
<p>Recent advances in 3D Gaussian Splatting have allowed for real-time, high-fidelity novel view synthesis. Nonetheless, these models have significant storage requirements for large and medium-sized scenes, hindering their deployment over cloud and streaming services. Some of the most recent progressive <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a> techniques for these models rely on progressive masking and scalar <a class="glightbox" href="https://img.shields.io/badge/quantization-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/quantization-F08080" /></a> techniques to reduce the bitrate of Gaussian attributes using spatial context models. While effective, scalar <a class="glightbox" href="https://img.shields.io/badge/quantization-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/quantization-F08080" /></a> may not optimally capture the correlations of high-dimensional feature vectors, which can potentially limit the rate-distortion performance.
  In this work, we introduce a novel progressive codec for 3D Gaussian Splatting that replaces traditional methods with a more powerful Residual Vector Quantization approach to compress the primitive features. Our key contribution is an auto-regressive entropy model, guided by a multi-resolution hash grid, that accurately predicts the conditional probability of each successive transmitted index, allowing for coarse and refinement layers to be compressed with high efficiency.</p>
<h2 id="stable-language-guidance-for-vision-language-action-models">Stable Language Guidance for Vision-Language-Action Models</h2>
<blockquote>
<p>Authors: Zhihao Zhan, Yuhao Chen, Jiaying Zhou, Qinhan Lv, Hao Liu, Keze Wang, Liang Lin, Guangrun Wang</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.04052v1">http://arxiv.org/abs/2601.04052v1</a></p>
</blockquote>
<p>Vision-Language-Action (VLA) models have demonstrated impressive capabilities in generalized robotic control; however, they remain notoriously brittle to linguistic perturbations. We identify a critical ``modality collapse'' phenomenon where strong visual priors overwhelm <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> linguistic signals, causing agents to overfit to specific instruction phrasings while ignoring the underlying semantic intent. To address this, we propose \textbf{Residual Semantic Steering (RSS)}, a probabilistic framework that disentangles physical affordance from semantic execution. RSS introduces two theoretical innovations: (1) \textbf{Monte Carlo Syntactic Integration}, which approximates the true semantic posterior via dense, <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-driven distributional expansion, and (2) \textbf{Residual Affordance Steering}, a dual-stream <a class="glightbox" href="https://img.shields.io/badge/decoding-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decoding-F08080" /></a> mechanism that explicitly isolates the causal influence of language by subtracting the visual affordance prior. Theoretical analysis suggests that RSS effectively maximizes the mutual information between action and intent while suppressing visual distractors. Empirical results across diverse manipulation benchmarks demonstrate that RSS achieves state-of-the-art robustness, maintaining performance even under adversarial linguistic perturbations.</p>
<h2 id="restok-learning-hierarchical-residuals-in-1d-visual-tokenizers-for-autoregressive-image-generation">ResTok Learning Hierarchical Residuals in 1D Visual Tokenizers for Autoregressive Image Generation</h2>
<blockquote>
<p>Authors: Xu Zhang, Cheng Da, Huan Yang, Kun Gai, Ming Lu, Zhan Ma</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03955v1">http://arxiv.org/abs/2601.03955v1</a></p>
</blockquote>
<p>Existing 1D visual tokenizers for autoregressive (AR) generation largely follow the design principles of language modeling, as they are built directly upon <a class="glightbox" href="https://img.shields.io/badge/transformer-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/transformer-FF8C00" /></a>s whose priors originate in language, yielding single-hierarchy latent tokens and treating visual data as flat sequential token streams. However, this language-like formulation overlooks key properties of vision, particularly the hierarchical and residual network designs that have long been essential for convergence and efficiency in visual models. To bring "vision" back to vision, we propose the Residual Tokenizer (ResTok), a 1D visual tokenizer that builds hierarchical residuals for both image tokens and latent tokens. The hierarchical representations obtained through progressively merging enable cross-level feature fusion at each layer, substantially enhancing representational capacity. Meanwhile, the semantic residuals between hierarchies prevent information <a class="glightbox" href="https://img.shields.io/badge/overlap-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/overlap-F08080" /></a>, yielding more concentrated latent distributions that are easier for AR modeling. Cross-level bindings consequently emerge without any explicit constraints. To accelerate the generation process, we further introduce a hierarchical AR generator that substantially reduces sampling steps by predicting an entire level of latent tokens at once rather than generating them strictly token-by-token. Extensive experiments demonstrate that restoring hierarchical residual priors in visual tokenization significantly improves AR image generation, achieving a gFID of 2.34 on ImageNet-256 with only 9 sampling steps. Code is available at https://github.com/Kwai-Kolors/ResTok.</p>
<h2 id="focusui-efficient-ui-grounding-via-position-preserving-visual-token-selection">FocusUI Efficient UI Grounding via Position-Preserving Visual Token Selection</h2>
<blockquote>
<p>Authors: Mingyu Ouyang, Kevin Qinghong Lin, Mike Zheng Shou, Hwee Tou Ng</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03928v1">http://arxiv.org/abs/2601.03928v1</a></p>
</blockquote>
<p>Vision-Language Models (VLMs) have shown remarkable performance in User Interface (UI) grounding tasks, driven by their ability to process increasingly high-resolution screenshots. However, screenshots are tokenized into thousands of visual tokens (e.g., about 4700 for 2K resolution), incurring significant computational overhead and diluting attention. In contrast, humans typically focus on regions of interest when interacting with UI. In this work, we pioneer the task of efficient UI grounding. Guided by practical analysis of the task's characteristics and challenges, we propose FocusUI, an efficient UI grounding framework that selects patches most relevant to the instruction while pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> positional continuity for precise grounding. FocusUI addresses two key challenges: (1) Eliminating redundant tokens in visual encoding. We construct patch-level supervision by fusing an instruction-conditioned score with a rule-based UI-graph score that down-weights large homogeneous regions to select distinct and instruction-relevant visual tokens. (2) Pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> positional continuity during visual token selection. We find that general visual token <a class="glightbox" href="https://img.shields.io/badge/pruning-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/pruning-F08080" /></a> methods suffer from severe accuracy degradation on UI grounding tasks due to broken positional information. We introduce a novel PosPad strategy, which compresses each contiguous sequence of dropped visual tokens into a single special marker placed at the sequence's last index to preserve positional continuity. Comprehensive experiments on four grounding benchmarks demonstrate that FocusUI surpasses GUI-specific baselines. On the ScreenSpot-Pro benchmark, FocusUI-7B achieves a performance improvement of 3.7% over GUI-Actor-7B. Even with only 30% visual token retention, FocusUI-7B drops by only 3.2% while achieving up to 1.44x faster inference and 17% lower peak GPU memory.</p>
<h2 id="decide-then-retrieve-a-training-free-framework-with-uncertainty-guided-triggering-and-dual-path-retrieval">Decide Then Retrieve A Training-Free Framework with Uncertainty-Guided Triggering and Dual-Path Retrieval</h2>
<blockquote>
<p>Authors: Wang Chen, Guanqiang Qi, Weikang Li, Yang Li, Deguo Xia, Jizhou Huang</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03908v1">http://arxiv.org/abs/2601.03908v1</a></p>
</blockquote>
<p>Retrieval-augmented generation (RAG) enhances large language models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) by incorporating external knowledge, but existing approaches indiscriminately trigger retrieval and rely on single-path evidence construction, often introducing noise and limiting performance gains. In this work, we propose Decide Then Retrieve (DTR), a training-free framework that adaptively determines when retrieval is necessary and how external information should be selected. DTR leverages generation uncertainty to guide retrieval triggering and introduces a dual-path retrieval mechanism with adaptive information selection to better handle <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> and ambiguous queries. Extensive experiments across five open-domain QA benchmarks, multiple model scales, and different retrievers demonstrate that DTR consistently improves EM and F1 over standard RAG and strong retrieval-enhanced baselines, while reducing unnecessary retrievals. The code and data used in this paper are available at https://github.com/ChenWangHKU/DTR.</p>
<h2 id="a-privacy-preserving-localization-scheme-with-node-selection-in-mobile-networks">A Privacy-Preserving Localization Scheme with Node Selection in Mobile Networks</h2>
<blockquote>
<p>Authors: Liangbo Xie, Mude Cai, Xiaolong Yang, Mu Zhou, Jiacheng Wang, Dusit Niyato</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.04280v1">http://arxiv.org/abs/2601.04280v1</a></p>
</blockquote>
<p>Localization in mobile networks has been widely applied in many scenarios. However, an entity responsible for location estimation exposes both the target and anchors to potential location leakage at any time, creating serious security risks. Although existing studies have proposed privacy-pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> localization algorithms, they still face challenges of insufficient positioning accuracy and excessive <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> overhead. In this article, we propose a privacy-pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> localization scheme, named PPLZN. PPLZN protects protects the location privacy of both the target and anchor nodes in crowdsourced localization. Simulation results validate the effectiveness of PPLZN. Evidently, it can achieve accurate position estimation without location leakage and outperform state-of-the-art approaches in both positioning accuracy and <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> overhead. In addition, PPLZN significantly reduces computational and <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> overhead in large-scale deployments, making it well-fitted for practical privacy-pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> localization in resource-constrained networks.</p>
<h2 id="feature-aware-one-shot-federated-learning-via-hierarchical-token-sequences">Feature-Aware One-Shot Federated Learning via Hierarchical Token Sequences</h2>
<blockquote>
<p>Authors: Shudong Liu, Hanwen Zhang, Xiuling Wang, Yuesheng Zhu, Guibo Luo</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03882v1">http://arxiv.org/abs/2601.03882v1</a></p>
</blockquote>
<p>One-shot federated learning (OSFL) reduces the <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> cost and privacy risks of iterative federated learning by constructing a global model with a single round of <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a>. However, most existing methods struggle to achieve robust performance on real-world domains such as medical imaging, or are inefficient when handling non-IID (Independent and Identically Distributed) data. To address these limitations, we introduce FALCON, a framework that enhances the effectiveness of OSFL over non-IID image data. The core idea of FALCON is to leverage the feature-aware hierarchical token sequences generation and knowledge distillation into OSFL. First, each client leverages a pretrained visual encoder with hierarchical scale encoding to compress images into hierarchical token sequences, which capture multi-scale semantics. Second, a multi-scale autoregressive <a class="glightbox" href="https://img.shields.io/badge/transformer-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/transformer-FF8C00" /></a> generator is used to model the distribution of these token sequences and generate the synthetic sequences. Third, clients upload the synthetic sequences along with the local classifier trained on the real token sequences to the server. Finally, the server incorporates knowledge distillation into global training to reduce reliance on precise distribution modeling. Experiments on medical and natural image datasets validate the effectiveness of FALCON in diverse non-IID scenarios, outperforming the best OSFL baselines by 9.58% in average accuracy.</p>
<h2 id="evaluating-small-decoder-only-language-models-for-grammar-correction-and-text-simplification">Evaluating Small Decoder-Only Language Models for Grammar Correction and Text Simplification</h2>
<blockquote>
<p>Authors: Anthony Lamelas</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03874v1">http://arxiv.org/abs/2601.03874v1</a></p>
</blockquote>
<p>Large language models have become extremely popular recently due to their ability to achieve strong performance on a variety of tasks, such as text generation and rewriting, but their size and computation cost make them difficult to access, deploy, and secure in many settings. This paper investigates whether small, <a class="glightbox" href="https://img.shields.io/badge/decode-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decode-F08080" /></a>r-only language models can provide an efficient alternative for the tasks of grammar correction and text simplification. The experiments in this paper focus on testing small language models out of the box, fine-tuned, and run sequentially on the JFLEG and ASSET datasets using established metrics. The results show that while SLMs may learn certain behaviors well, their performance remains below strong baselines and current <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s. The results also show that SLMs struggle with retaining meaning and hallucinations. These findings suggest that despite their efficiency advantages, current SLMs are not yet competitive enough with modern <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s for rewriting, and further advances in training are required for SLMs to close the performance gap between them and today's <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s.</p>
<h2 id="when-numbers-start-talking-implicit-numerical-coordination-among-llm-based-agents">When Numbers Start Talking Implicit Numerical Coordination Among LLM-Based Agents</h2>
<blockquote>
<p>Authors: Alessio Buscemi, Daniele Proverbio, Alessandro Di Stefano, The Anh Han, German Castignani, Pietro LiÃ²</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03846v1">http://arxiv.org/abs/2601.03846v1</a></p>
</blockquote>
<p><a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s-based agents increasingly operate in multi-agent environments where strategic interaction and coordination are required. While existing work has largely focused on individual agents or on interacting agents sharing explicit <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a>, less is known about how interacting agents coordinate implicitly. In particular, agents may engage in covert <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a>, relying on indirect or non-linguistic signals embedded in their actions rather than on explicit messages. This paper presents a game-theoretic study of covert <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> in <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-driven multi-agent systems. We analyse interactions across four canonical game-theoretic settings under different <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a> regimes, including explicit, restricted, and absent <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a>. Considering heterogeneous agent personalities and both one-shot and repeated games, we characterise when covert signals emerge and how they shape coordination and strategic outcomes.</p>
<h2 id="where-meaning-lives-layer-wise-accessibility-of-psycholinguistic-features-in-encoder-and-decoder-language-models">Where meaning lives Layer-wise accessibility of psycholinguistic features in encoder and decoder language models</h2>
<blockquote>
<p>Authors: Taisiia Tikhomirova, Dirk U. Wulff</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03798v1">http://arxiv.org/abs/2601.03798v1</a></p>
</blockquote>
<p>Understanding where <a class="glightbox" href="https://img.shields.io/badge/transformer-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/transformer-FF8C00" /></a> language models encode psychologically meaningful aspects of meaning is essential for both theory and practice. We conduct a systematic layer-wise probing study of 58 psycholinguistic features across 10 <a class="glightbox" href="https://img.shields.io/badge/transformer-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/transformer-FF8C00" /></a> models, spanning encoder-only and <a class="glightbox" href="https://img.shields.io/badge/decode-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decode-F08080" /></a>r-only architectures, and compare three embedding extraction methods. We find that apparent localization of meaning is strongly method-dependent: contextualized embeddings yield higher feature-specific selectivity and different layer-wise profiles than isolated embeddings. Across models and methods, final-layer representations are rarely optimal for recovering psycholinguistic information with linear probes. Despite these differences, models exhibit a shared depth ordering of meaning dimensions, with lexical properties peaking earlier and experiential and affective dimensions peaking later. Together, these results show that where meaning "lives" in <a class="glightbox" href="https://img.shields.io/badge/transformer-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/transformer-FF8C00" /></a> models reflects an interaction between methodological choices and architectural constraints.</p>
<h2 id="do-llms-really-memorize-personally-identifiable-information-revisiting-pii-leakage-with-a-cue-controlled-memorization-framework">Do LLMs Really Memorize Personally Identifiable Information? Revisiting PII Leakage with a Cue-Controlled Memorization Framework</h2>
<blockquote>
<p>Authors: Xiaoyu Luo, Yiyi Chen, Qiongxiu Li, Johannes Bjerva</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03791v1">http://arxiv.org/abs/2601.03791v1</a></p>
</blockquote>
<p>Large Language Models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) have been reported to "leak" Personally Identifiable Information (PII), with successful PII reconstruction often interpreted as evidence of memorization. We propose a principled revision of memorization evaluation for <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s, arguing that PII leakage should be evaluated under low lexical cue conditions, where target PII cannot be reconstructed through prompt-induced generalization or pattern completion. We formalize Cue-Resistant Memorization (CRM) as a cue-controlled evaluation framework and a necessary condition for valid memorization evaluation, explicitly conditioning on prompt-target <a class="glightbox" href="https://img.shields.io/badge/overlap-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/overlap-F08080" /></a> cues. Using CRM, we conduct a large-scale multilingual re-evaluation of PII leakage across 32 languages and multiple memorization paradigms. Revisiting reconstruction-based settings, including verbatim prefix-suffix completion and associative reconstruction, we find that their apparent effectiveness is driven primarily by direct surface-form cues rather than by true memorization. When such cues are controlled for, reconstruction success diminishes substantially. We further examine cue-free generation and membership inference, both of which exhibit extremely low true positive rates. Overall, our results suggest that previously reported PII leakage is better explained by cue-driven behavior than by genuine memorization, highlighting the importance of cue-controlled evaluation for reliably quantifying privacy-relevant memorization in <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s.</p>
<h2 id="improving-compactness-and-reducing-ambiguity-of-cfire-rule-based-explanations">Improving Compactness and Reducing Ambiguity of CFIRE Rule-Based Explanations</h2>
<blockquote>
<p>Authors: Sebastian MÃ¼ller, Tobias Schneider, Ruben Kemna, Vanessa Toborek</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03776v1">http://arxiv.org/abs/2601.03776v1</a></p>
</blockquote>
<p>Models trained on tabular data are widely used in sensitive domains, increasing the demand for explanation methods to meet transparency needs. CFIRE is a recent algorithm in this domain that constructs compact surrogate rule models from local explanations. While effective, CFIRE may assign rules associated with different classes to the same sample, introducing ambiguity. We investigate this ambiguity and propose a post-hoc <a class="glightbox" href="https://img.shields.io/badge/pruning-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/pruning-F08080" /></a> strategy that removes rules with low contribution or conflicting coverage, yielding smaller and less ambiguous models while pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> fidelity. Experiments across multiple datasets confirm these improvements with minimal impact on predictive performance.</p>
<h2 id="edco-dynamic-curriculum-orchestration-for-domain-specific-large-language-model-fine-tuning">EDCO Dynamic Curriculum Orchestration for Domain-specific Large Language Model Fine-tuning</h2>
<blockquote>
<p>Authors: Jing-Cheng Pang, Liu Sun, Chang Zhou, Xian Tang, Haichuan Ma, Kun Jiang, Jianlong Wang, Kai Zhang, Sijie Wu, Haoran Cai, Chenwei Wu, Xubin Li, Xin Chen</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03725v1">http://arxiv.org/abs/2601.03725v1</a></p>
</blockquote>
<p>Domain-specific large language models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s), typically developed by fine-tuning a pre-trained general-purpose <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> on specialized datasets, represent a significant advancement in applied AI. A common strategy in <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> fine-tuning is curriculum learning, which pre-orders training samples based on metrics like difficulty to improve learning efficiency compared to a random sampling strategy. However, most existing methods for <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> fine-tuning rely on a static curriculum, designed prior to training, which lacks adaptability to the model's evolving needs during fine-tuning. To address this, we propose EDCO, a novel framework based on two key concepts: inference entropy and dynamic curriculum orchestration. Inspired by recent findings that maintaining high answer entropy benefits long-term reasoning gains, EDCO prioritizes samples with high inference entropy in a continuously adapted curriculum. EDCO integrates three core components: an efficient entropy estimator that uses prefix tokens to approximate full-sequence entropy, an entropy-based curriculum generator that selects data points with the highest inference entropy, and an <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> trainer that optimizes the model on the selected curriculum. Comprehensive experiments in <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a>, medicine and law domains, EDCO outperforms traditional curriculum strategies for fine-tuning Qwen3-4B and Llama3.2-3B models under supervised and reinforcement learning settings. Furthermore, the proposed efficient entropy estimation reduces computational time by 83.5% while maintaining high accuracy.</p>
<h2 id="visual-merit-or-linguistic-crutch-a-close-look-at-deepseek-ocr">Visual Merit or Linguistic Crutch? A Close Look at DeepSeek-OCR</h2>
<blockquote>
<p>Authors: Yunhao Liang, Ruixuan Ying, Bo Li, Hong Li, Kai Yan, Qingwen Li, Min Yang, Okamoto Satoshi, Zhe Cui, Shiwen Ni</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03714v2">http://arxiv.org/abs/2601.03714v2</a></p>
</blockquote>
<p>DeepSeek-OCR utilizes an optical 2D mapping approach to achieve high-ratio vision-text <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a>, claiming to <a class="glightbox" href="https://img.shields.io/badge/decode-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decode-F08080" /></a> text tokens exceeding ten times the input visual tokens. While this suggests a promising solution for the <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> long-context bottleneck, we investigate a critical question: "Visual merit or linguistic crutch - which drives DeepSeek-OCR's performance?" By employing sentence-level and word-level semantic corruption, we isolate the model's intrinsic OCR capabilities from its language priors. Results demonstrate that without linguistic support, DeepSeek-OCR's performance plummets from approximately 90% to 20%. Comparative benchmarking against 13 baseline models reveals that traditional pipeline OCR methods exhibit significantly higher robustness to such semantic perturbations than end-to-end methods. Furthermore, we find that lower visual token counts correlate with increased reliance on priors, exacerbating hallucination risks. Context stress testing also reveals a total model collapse around 10,000 text tokens, suggesting that current optical <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a> techniques may paradoxically aggravate the long-context bottleneck. This study empirically defines DeepSeek-OCR's capability boundaries and offers essential insights for future optimizations of the vision-text <a class="glightbox" href="https://img.shields.io/badge/compression-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/compression-FF8C00" /></a> paradigm. We release all data, results and scripts used in this study at https://github.com/dududuck00/DeepSeekOCR.</p>
<h2 id="how-does-the-thinking-step-influence-model-safety-an-entropy-based-safety-reminder-for-lrms">How Does the Thinking Step Influence Model Safety? An Entropy-based Safety Reminder for LRMs</h2>
<blockquote>
<p>Authors: Su-Hyeon Kim, Hyundong Jin, Yejin Lee, Yo-Sub Han</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03662v1">http://arxiv.org/abs/2601.03662v1</a></p>
</blockquote>
<p>Large Reasoning Models (LRMs) achieve remarkable success through explicit thinking steps, yet the thinking steps introduce a novel risk by potentially amplifying unsafe behaviors. Despite this vulnerability, conventional defense mechanisms remain ineffective as they overlook the unique reasoning dynamics of LRMs. In this work, we find that the emergence of safe-reminding phrases within thinking steps plays a pivotal role in ensuring LRM safety. Motivated by this finding, we propose SafeRemind, a <a class="glightbox" href="https://img.shields.io/badge/decoding-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decoding-F08080" /></a>-time defense method that dynamically injects safe-reminding phrases into thinking steps. By leveraging entropy triggers to intervene at decision-locking points, SafeRemind redirects potentially harmful trajectories toward safer outcomes without requiring any parameter updates. Extensive evaluations across five LRMs and six benchmarks demonstrate that SafeRemind substantially enhances safety, achieving improvements of up to 45.5%p while pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> core reasoning utility.</p>
<h2 id="llm-mc-affect-llm-based-monte-carlo-modeling-of-affective-trajectories-and-latent-ambiguity-for-interpersonal-dynamic-insight">LLM-MC-Affect LLM-Based Monte Carlo Modeling of Affective Trajectories and Latent Ambiguity for Interpersonal Dynamic Insight</h2>
<blockquote>
<p>Authors: Yu-Zheng Lin, Bono Po-Jen Shih, John Paul Martin Encinas, Elizabeth Victoria Abraham Achom, Karan Himanshu Patel, Jesus Horacio Pacheco, Sicong Shao, Jyotikrishna Dass, Soheil Salehi, Pratik Satam</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03645v1">http://arxiv.org/abs/2601.03645v1</a></p>
</blockquote>
<p>Emotional coordination is a core property of human interaction that shapes how relational meaning is constructed in real time. While text-based affect inference has become increasingly feasible, prior approaches often treat sentiment as a deterministic point estimate for individual speakers, failing to capture the inherent subjectivity, latent ambiguity, and sequential coupling found in mutual exchanges. We introduce <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-MC-Affect, a probabilistic framework that characterizes emotion not as a static label, but as a continuous latent probability distribution defined over an affective space. By leveraging stochastic <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> <a class="glightbox" href="https://img.shields.io/badge/decoding-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decoding-F08080" /></a> and Monte Carlo estimation, the methodology approximates these distributions to derive high-fidelity sentiment trajectories that explicitly quantify both central affective tendencies and perceptual ambiguity. These trajectories enable a structured analysis of interpersonal coupling through sequential cross-correlation and slope-based indicators, identifying leading or lagging influences between interlocutors. To validate the interpretive capacity of this approach, we utilize teacher-student instructional dialogues as a representative case study, where our quantitative indicators successfully distill high-level interaction insights such as effective scaffolding. This work establishes a scalable and deployable pathway for understanding interpersonal dynamics, offering a generalizable solution that extends beyond education to broader social and behavioral research.</p>
<h2 id="architecting-agentic-communities-using-design-patterns">Architecting Agentic Communities using Design Patterns</h2>
<blockquote>
<p>Authors: Zoran Milosevic, Fethi Rabhi</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03624v1">http://arxiv.org/abs/2601.03624v1</a></p>
</blockquote>
<p>The rapid evolution of Large Language Models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems. This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice. We classify these patterns into three tiers: <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> Agents (task-specific automation), Agentic AI (adaptive goal-seekers), and Agentic Communities (organizational frameworks where AI agents and human participants coordinate through formal roles, protocols, and governance structures). We focus on Agentic Communities - coordination frameworks encompassing <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> Agents, Agentic AI entities, and humans - most relevant for enterprise and industrial applications. Drawing on established coordination principles from distributed systems, we ground these patterns in a formal framework that specifies collaboration agreements where AI agents and humans fill roles within governed ecosystems. This approach provides both practical guidance and formal verification capabilities, enabling expression of organizational, legal, and ethical rules through accountability mechanisms that ensure operational and verifiable governance of inter-agent <a class="glightbox" href="https://img.shields.io/badge/communication-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/communication-F08080" /></a>, negotiation, and intent modeling. We validate this framework through a clinical trial matching case study. Our goal is to provide actionable guidance to practitioners while maintaining the formal rigor essential for enterprise deployment in dynamic, multi-agent ecosystems.</p>
<h2 id="safety-utility-conflicts-are-not-global-surgical-alignment-via-head-level-diagnosis">Safety-Utility Conflicts Are Not Global Surgical Alignment via Head-Level Diagnosis</h2>
<blockquote>
<p>Authors: Wang Cai, Yilin Wen, Jinchang Hou, Du Su, Guoqiu Wang, Zhonghou Lv, Chenfu Bao, Yunfang Wu</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.04262v1">http://arxiv.org/abs/2601.04262v1</a></p>
</blockquote>
<p>Safety alignment in Large Language Models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) inherently presents a multi-objective optimization conflict, often accompanied by an unintended degradation of general capabilities. Existing mitigation strategies typically rely on global gradient geometry to resolve these conflicts, yet they overlook Modular Heterogeneity within Transformers, specifically that the functional sensitivity and degree of conflict vary substantially across different attention heads. Such global approaches impose uniform update rules across all parameters, often resulting in suboptimal trade-offs by indiscriminately updating utility sensitive heads that exhibit intense gradient conflicts. To address this limitation, we propose Conflict-Aware Sparse Tuning (CAST), a framework that integrates head-level diagnosis with <a class="glightbox" href="https://img.shields.io/badge/sparse-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/sparse-F08080" /></a> fine-tuning. CAST first constructs a pre-alignment conflict map by synthesizing Optimization Conflict and Functional Sensitivity, which then guides the selective update of parameters. Experiments reveal that alignment conflicts in <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s are not uniformly distributed. We find that the drop in general capabilities mainly comes from updating a small group of ``high-conflict'' heads. By simply skipping these heads during training, we significantly reduce this loss without compromising safety, offering an interpretable and parameter-efficient approach to improving the safety-utility trade-off.</p>
<h2 id="inhibitory-attacks-on-backdoor-based-fingerprinting-for-large-language-models">Inhibitory Attacks on Backdoor-based Fingerprinting for Large Language Models</h2>
<blockquote>
<p>Authors: Hang Fu, Wanli Peng, Yinghan Zhou, Jiaxuan Wu, Juan Wen, Yiming Xue</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.04261v1">http://arxiv.org/abs/2601.04261v1</a></p>
</blockquote>
<p>The widespread adoption of Large Language Model (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>) in commercial and research settings has intensified the need for robust intellectual property protection. Backdoor-based <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> fingerprinting has emerged as a promising solution for this challenge. In practical application, the low-cost multi-model collaborative technique, <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> ensemble, combines diverse <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s to leverage their complementary strengths, garnering significant attention and practical adoption. Unfortunately, the vulnerability of existing <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> fingerprinting for the ensemble scenario is unexplored. In order to comprehensively assess the robustness of <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> fingerprinting, in this paper, we propose two novel fingerprinting attack methods: token filter attack (TFA) and sentence verification attack (SVA). The TFA gets the next token from a unified set of tokens created by the token filter mechanism at each <a class="glightbox" href="https://img.shields.io/badge/decoding-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decoding-F08080" /></a> step. The SVA filters out fingerprint responses through a sentence verification mechanism based on perplexity and voting. Experimentally, the proposed methods effectively inhibit the fingerprint response while maintaining ensemble performance. Compared with state-of-the-art attack methods, the proposed method can achieve better performance. The findings necessitate enhanced robustness in <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> fingerprinting.</p>
<h2 id="physicsformer-an-efficient-and-fast-attention-based-physics-informed-neural-network-for-solving-incompressible-navier-stokes-equations">PhysicsFormer An Efficient and Fast Attention-Based Physics Informed Neural Network for Solving Incompressible Navier Stokes Equations</h2>
<blockquote>
<p>Authors: Biswanath Barman, Debdeep Chatterjee, Rajendra K. Ray</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03613v1">http://arxiv.org/abs/2601.03613v1</a></p>
</blockquote>
<p>Traditional experimental and numerical approaches for fluid dynamics problems often suffer from high computational cost, mesh sensitivity, and limited capability in capturing complex physical behaviors. Moreover, conventional physics-informed neural networks (PINNs) frequently struggle in chaotic and highly unsteady flow regimes. In this work, we propose \textit{PhysicsFormer}, a fast and efficient <a class="glightbox" href="https://img.shields.io/badge/transformer-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/transformer-FF8C00" /></a>-based physics-informed framework that incorporates multi-head encoder-<a class="glightbox" href="https://img.shields.io/badge/decode-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decode-F08080" /></a>r cross-attention. Unlike multilayer perceptron-based PINNs, PhysicsFormer operates on sequential representations constructed from spatio-temporal data, enabling effective learning of long-range temporal dependencies and improved propagation of initial condition information. A data-embedding strategy is employed to convert spatio-temporal points into pseudo-sequences, while a dynamics-weighted loss function replaces the standard PINNs formulation. Owing to its parallel learning structure, PhysicsFormer demonstrates superior computational efficiency compared to existing <a class="glightbox" href="https://img.shields.io/badge/transformer-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/transformer-FF8C00" /></a>-based approaches. The framework is validated on Burgers' equation and flow reconstruction governed by the Navier-Stokes equations, achieving mean squared errors on the order of <script type="math/tex">10^{-6}</script>. In addition, an inverse problem involving parameter identification in the two-dimensional incompressible Navier-Stokes equations is investigated. For clean data, PhysicsFormer achieves zero identification error for both <script type="math/tex">Î»_1</script> and <script type="math/tex">Î»_2</script>; under <script type="math/tex">1\%</script> Gaussian noise, the errors are <script type="math/tex">0.07\%</script> for <script type="math/tex">Î»_1</script> and <script type="math/tex">0\%</script> for <script type="math/tex">Î»_2</script>. These results demonstrate that PhysicsFormer provides a reliable and computationally efficient surrogate modeling framework for time-dependent fluid flow problems.</p>
<h2 id="jailbreaking-llms-vlms-mechanisms-evaluation-and-unified-defense">Jailbreaking LLMs &amp; VLMs Mechanisms, Evaluation, and Unified Defense</h2>
<blockquote>
<p>Authors: Zejian Chen, Chaozhuo Li, Chao Li, Xi Zhang, Litian Zhang, Yiming He</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03594v1">http://arxiv.org/abs/2601.03594v1</a></p>
</blockquote>
<p>This paper provides a systematic survey of jailbreak attacks and defenses on Large Language Models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) and Vision-Language Models (VLMs), emphasizing that jailbreak vulnerabilities stem from structural factors such as incomplete training data, linguistic ambiguity, and generative uncertainty. It further differentiates between hallucinations and jailbreaks in terms of intent and triggering mechanisms. We propose a three-dimensional survey framework: (1) Attack dimension-including template/encoding-based, in-context learning manipulation, reinforcement/adversarial learning, <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>-assisted and fine-tuned attacks, as well as prompt- and image-level perturbations and agent-based transfer in VLMs; (2) Defense dimension-encompassing prompt-level obfuscation, output evaluation, and model-level alignment or fine-tuning; and (3) Evaluation dimension-covering metrics such as Attack Success Rate (ASR), toxicity score, query/time cost, and multimodal Clean Accuracy and Attribute Success Rate. Compared with prior works, this survey spans the full spectrum from text-only to multimodal settings, consolidating shared mechanisms and proposing unified defense principles: variant-consistency and gradient-sensitivity detection at the perception layer, safety-aware <a class="glightbox" href="https://img.shields.io/badge/decoding-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decoding-F08080" /></a> and output review at the generation layer, and adversarially augmented preference alignment at the parameter layer. Additionally, we summarize existing multimodal safety benchmarks and discuss future directions, including automated red teaming, cross-modal collaborative defense, and standardized evaluation.</p>
<h2 id="diffcot-diffusion-styled-chain-of-thought-reasoning-in-llms">DiffCoT Diffusion-styled Chain-of-Thought Reasoning in LLMs</h2>
<blockquote>
<p>Authors: Shidong Cao, Hongzhan Lin, Yuxuan Gu, Ziyang Luo, Jing Ma</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03559v1">http://arxiv.org/abs/2601.03559v1</a></p>
</blockquote>
<p>Chain-of-Thought (CoT) reasoning improves multi-step mathematical problem solving in large language models but remains vulnerable to exposure bias and error accumulation, as early mistakes propagate irreversibly through autoregressive <a class="glightbox" href="https://img.shields.io/badge/decoding-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decoding-F08080" /></a>. In this work, we propose DiffCoT, a diffusion-styled CoT framework that reformulates CoT reasoning as an iterative denoising process. DiffCoT integrates diffusion principles at the reasoning-step level via a sliding-window mechanism, enabling unified generation and retrospective correction of intermediate steps while pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> token-level autoregression. To maintain causal consistency, we further introduce a causal diffusion noise schedule that respects the temporal structure of reasoning chains. Extensive experiments on three multi-step CoT reasoning benchmarks across diverse model backbones demonstrate that DiffCoT consistently outperforms existing CoT preference optimization methods, yielding improved robustness and error-correction capability in CoT reasoning.</p>
<h2 id="layer-order-inversion-rethinking-latent-multi-hop-reasoning-in-large-language-models">Layer-Order Inversion Rethinking Latent Multi-Hop Reasoning in Large Language Models</h2>
<blockquote>
<p>Authors: Xukai Liu, Ye Liu, Jipeng Zhang, Yanghai Zhang, Kai Zhang, Qi Liu</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03542v1">http://arxiv.org/abs/2601.03542v1</a></p>
</blockquote>
<p>Large language models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) perform well on multi-hop reasoning, yet how they internally compose multiple facts remains unclear. Recent work proposes \emph{hop-aligned circuit hypothesis}, suggesting that bridge entities are computed sequentially across layers before later-hop answers. Through systematic analyses on real-world multi-hop queries, we show that this hop-aligned assumption does not generalize: later-hop answer entities can become decodable earlier than bridge entities, a phenomenon we call \emph{layer-order inversion}, which strengthens with total hops. To explain this behavior, we propose a \emph{probabilistic recall-and-extract} framework that models multi-hop reasoning as broad probabilistic recall in shallow MLP layers followed by selective extraction in deeper attention layers. This framework is empirically validated through systematic probing analyses, reinterpreting prior layer-wise <a class="glightbox" href="https://img.shields.io/badge/decoding-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decoding-F08080" /></a> evidence, explaining chain-of-thought gains, and providing a mechanistic diagnosis of multi-hop failures despite correct single-hop knowledge. Code is available at https://github.com/laquabe/Layer-Order-Inversion.</p>
<h2 id="introlm-introspective-language-models-via-prefilling-time-self-evaluation">IntroLM Introspective Language Models via Prefilling-Time Self-Evaluation</h2>
<blockquote>
<p>Authors: Hossein Hosseini Kasnavieh, Gholamreza Haffari, Chris Leckie, Adel N. Toosi</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03511v1">http://arxiv.org/abs/2601.03511v1</a></p>
</blockquote>
<p>A major challenge for the operation of large language models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s) is how to predict whether a specific <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a> will produce sufficiently high-quality output for a given query. Existing approaches rely on external classifiers, most commonly BERT based models, which suffer from limited context windows, constrained representational capacity, and additional computational overhead. We propose IntroLM, a method that enables causal language models to predict their own output quality during the <a class="glightbox" href="https://img.shields.io/badge/prefill-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/prefill-F08080" /></a>ing phase without affecting generation using introspective tokens. By introducing token conditional LoRA that activates only for the introspective token, the model learns to predict the output quality for a given query while pre<a class="glightbox" href="https://img.shields.io/badge/serving-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/serving-FF8C00" /></a> the original backbone behavior and avoiding external evaluators. On question answering benchmarks, IntroLM applied to Qwen3 8B achieves a ROC AUC of 90 precent for success prediction, outperforming a DeBERTa classifier by 14 precent. When integrated into multi model routing systems, IntroLM achieves superior cost performance tradeoffs, reducing latency by up to 33 precent and large model usage by up to 50 precent at matched reliability.</p>
<h2 id="beyond-perplexity-a-lightweight-benchmark-for-knowledge-retention-in-supervised-fine-tuning">Beyond Perplexity A Lightweight Benchmark for Knowledge Retention in Supervised Fine-Tuning</h2>
<blockquote>
<p>Authors: Soheil Zibakhsh Shabgahi, Pedram Aghazadeh, Farinaz Koushanfar</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03505v1">http://arxiv.org/abs/2601.03505v1</a></p>
</blockquote>
<p>Supervised Fine-Tuning (SFT) is a standard approach for injecting domain knowledge into Large Language Models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s). However, relying on validation perplexity to monitor training is often insufficient, as it confounds stylistic mimicry with genuine factual internalization. To address this, we introduce the Knowledge Retention (KR) Test , a lightweight, corpus-grounded evaluation framework designed to distinguish factual learning from linguistics. KR-Test utilizes automatically generated contrastive examples to measure likelihood preferences for correct versus incorrect continuations, requiring no instruction tuning or generative <a class="glightbox" href="https://img.shields.io/badge/decoding-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/decoding-F08080" /></a>. We validate the framework's integrity through a "blind vs. oracle" baseline analysis. Furthermore, we demonstrate the diagnostic capabilities of KR-Test by analyzing the training dynamics of Low-Rank Adaptation (LoRA). By exposing the fine-grained dissociation between linguistic convergence and knowledge retention, KR-Test enhances the interpretability of fine-tuning dynamics.</p>
<h2 id="from-bits-to-chips-an-llm-based-hardware-aware-quantization-agent-for-streamlined-deployment-of-llms">From Bits to Chips An LLM-based Hardware-Aware Quantization Agent for Streamlined Deployment of LLMs</h2>
<blockquote>
<p>Authors: Kaiyuan Deng, Hangyu Zheng, Minghai Qing, Kunxiong Zhu, Gen Li, Yang Xiao, Lan Emily Zhang, Linke Guo, Bo Hui, Yanzhi Wang, Geng Yuan, Gagan Agrawal, Wei Niu, Xiaolong Ma</p>
<p>2026-01-07</p>
<p><a href="http://arxiv.org/abs/2601.03484v1">http://arxiv.org/abs/2601.03484v1</a></p>
</blockquote>
<p>Deploying models, especially large language models (<a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s), is becoming increasingly attractive to a broader user base, including those without specialized expertise. However, due to the resource constraints of certain hardware, maintaining high accuracy with larger model while meeting the hardware requirements remains a significant challenge. Model <a class="glightbox" href="https://img.shields.io/badge/quantization-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/quantization-F08080" /></a> technique helps mitigate memory and compute bottlenecks, yet the added complexities of tuning and deploying <a class="glightbox" href="https://img.shields.io/badge/quantize-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/quantize-F08080" /></a>d models further exacerbates these challenges, making the process unfriendly to most of the users. We introduce the Hardware-Aware Quantization Agent (HAQA), an automated framework that leverages <a class="glightbox" href="https://img.shields.io/badge/LLM-FF8C00" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/LLM-FF8C00" /></a>s to streamline the entire <a class="glightbox" href="https://img.shields.io/badge/quantization-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/quantization-F08080" /></a> and deployment process by enabling efficient hyperparameter tuning and hardware configuration, thereby simultaneously improving deployment quality and ease of use for a broad range of users. Our results demonstrate up to a 2.3x speedup in inference, along with increased throughput and improved accuracy compared to unoptimized models on Llama. Additionally, HAQA is designed to implement adaptive <a class="glightbox" href="https://img.shields.io/badge/quantization-F08080" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="key" src="https://img.shields.io/badge/quantization-F08080" /></a> strategies across diverse hardware platforms, as it automatically finds optimal settings even when they appear counterintuitive, thereby reducing extensive manual effort and demonstrating superior adaptability. Code will be released.</p>
              
  <!-- Giscus è¯„è®ºç³»ç»Ÿ - åªåœ¨ notes æ–‡ä»¶å¤¹ä¸‹æ˜¾ç¤º -->
<script>
  // ä½¿ç”¨ JavaScript æ¥åˆ¤æ–­ URL è·¯å¾„
  if (window.location.pathname.includes('/notes/')) {
    document.write(`
      <div id="giscus-container" style="margin-top: 2rem; padding-top: 1rem; border-top: 1px solid #e1e4e8;">
        <script src="https://giscus.app/client.js"
                data-repo="hustzxd/EfficientPaper"
                data-repo-id="R_kgDOKVYtOg"
                data-category="General"
                data-category-id="DIC_kwDOKVYtOs4CukCv"
                data-mapping="pathname"
                data-strict="0"
                data-reactions-enabled="1"
                data-emit-metadata="0"
                data-input-position="bottom"
                data-theme="light"
                data-lang="zh-CN"
                crossorigin="anonymous"
                async>
        <\/script>
      </div>
    `);
  }
</script>

            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../2025-12-31/" class="btn btn-neutral float-left" title="2025-12-31"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../legacy/2025-10-09/" class="btn btn-neutral float-right" title="2025-10-09">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../2025-12-31/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../legacy/2025-10-09/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-clike.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
      <script src="../../js/prism-prototxt.js"></script>
      <script src="../../js/preview.js"></script>
      <script src="../../js/back-to-top.js"></script>
      <script src="../../js/note-editor.js"></script>
      <script src="../../js/auto-reload.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
</script></body>
</html>
