# 2024-11-22

# Table of Contents
* [Unleashing the Power of Large Language Models for Group POI Recommendations](#Unleashing-the-Power-of-Large-Language-Models-for-Group-POI-Recommendations)
* [A Survey On Enhancing Reinforcement Learning in Complex Environments Insights from Human and LLM Feedback](#A-Survey-On-Enhancing-Reinforcement-Learning-in-Complex-Environments-Insights-from-Human-and-LLM-Feedback)
* [Upgrade of the Diagnostic Neutral Beam Injector for the RFX-mod2 experiment](#Upgrade-of-the-Diagnostic-Neutral-Beam-Injector-for-the-RFX-mod2-experiment)
* [Transformers with Sparse Attention for Granger Causality](#Transformers-with-Sparse-Attention-for-Granger-Causality)
* [Transforming the Hybrid Cloud for Emerging AI Workloads](#Transforming-the-Hybrid-Cloud-for-Emerging-AI-Workloads)
* [Unlocking Historical Clinical Trial Data with ALIGN A Compositional Large Language Model System for Medical Coding](#Unlocking-Historical-Clinical-Trial-Data-with-ALIGN-A-Compositional-Large-Language-Model-System-for-Medical-Coding)
* [IC Mechanisms for Risk-Averse Advertisers in the Online Advertising System](#IC-Mechanisms-for-Risk-Averse-Advertisers-in-the-Online-Advertising-System)
* [Compute Optimal Inference and Provable Amortisation Gap in Sparse Autoencoders](#Compute-Optimal-Inference-and-Provable-Amortisation-Gap-in-Sparse-Autoencoders)
* [Practical Compact Deep Compressed Sensing](#Practical-Compact-Deep-Compressed-Sensing)
* [Hardware Scaling Trends and Diminishing Returns in Large-Scale Distributed Training](#Hardware-Scaling-Trends-and-Diminishing-Returns-in-Large-Scale-Distributed-Training)
* [Topkima-Former Low-energy, Low-Latency Inference for Transformers using top-k In-memory ADC](#Topkima-Former-Low-energy,-Low-Latency-Inference-for-Transformers-using-top-k-In-memory-ADC)
* [A Theory for Compressibility of Graph Transformers for Transductive Learning](#A-Theory-for-Compressibility-of-Graph-Transformers-for-Transductive-Learning)
* [A toy model for $p$-form gauge symmetry](#A-toy-model-for-$p$-form-gauge-symmetry)
* [Machine learned reconstruction of tsunami dynamics from sparse observations](#Machine-learned-reconstruction-of-tsunami-dynamics-from-sparse-observations)
* [Selective Attention Enhancing Transformer through Principled Context Control](#Selective-Attention-Enhancing-Transformer-through-Principled-Context-Control)
* [ProSec Fortifying Code LLMs with Proactive Security Alignment](#ProSec-Fortifying-Code-LLMs-with-Proactive-Security-Alignment)
* [SparseInfer Training-free Prediction of Activation Sparsity for Fast LLM Inference](#SparseInfer-Training-free-Prediction-of-Activation-Sparsity-for-Fast-LLM-Inference)
* [Data-efficient Tactile Sensing with Electrical Impedance Tomography](#Data-efficient-Tactile-Sensing-with-Electrical-Impedance-Tomography)
* [STREAM A Universal State-Space Model for Sparse Geometric Data](#STREAM-A-Universal-State-Space-Model-for-Sparse-Geometric-Data)
* [S3TU-Net Structured Convolution and Superpixel Transformer for Lung Nodule Segmentation](#S3TU-Net-Structured-Convolution-and-Superpixel-Transformer-for-Lung-Nodule-Segmentation)
* [Ultra-Sparse Memory Network](#Ultra-Sparse-Memory-Network)
* [Faster Multi-GPU Training with PPLL A Pipeline Parallelism Framework Leveraging Local Learning](#Faster-Multi-GPU-Training-with-PPLL-A-Pipeline-Parallelism-Framework-Leveraging-Local-Learning)
* [Deep Learning VLBI Image Reconstruction with Closure Invariants](#Deep-Learning-VLBI-Image-Reconstruction-with-Closure-Invariants)
* [ITACLIP Boosting Training-Free Semantic Segmentation with Image, Text, and Architectural Enhancements](#ITACLIP-Boosting-Training-Free-Semantic-Segmentation-with-Image,-Text,-and-Architectural-Enhancements)
* [The Nahm transform of multi-fractional instantons](#The-Nahm-transform-of-multi-fractional-instantons)
* [BitMoD Bit-serial Mixture-of-Datatype LLM Acceleration](#BitMoD-Bit-serial-Mixture-of-Datatype-LLM-Acceleration)
* [Continuous Speculative Decoding for Autoregressive Image Generation](#Continuous-Speculative-Decoding-for-Autoregressive-Image-Generation)
* [SILVIA Automated Superword-Level Parallelism Exploitation via HLS-Specific LLVM Passes for Compute-Intensive FPGA Accelerators](#SILVIA-Automated-Superword-Level-Parallelism-Exploitation-via-HLS-Specific-LLVM-Passes-for-Compute-Intensive-FPGA-Accelerators)
* [Continual Task Learning through Adaptive Policy Self-Composition](#Continual-Task-Learning-through-Adaptive-Policy-Self-Composition)
* [GPS-Gaussian+ Generalizable Pixel-wise 3D Gaussian Splatting for Real-Time Human-Scene Rendering from Sparse Views](#GPS-Gaussian+-Generalizable-Pixel-wise-3D-Gaussian-Splatting-for-Real-Time-Human-Scene-Rendering-from-Sparse-Views)
* [LP Data Pipeline Lightweight, Purpose-driven Data Pipeline for Large Language Models](#LP-Data-Pipeline-Lightweight,-Purpose-driven-Data-Pipeline-for-Large-Language-Models)
* [ESTVocoder An Excitation-Spectral-Transformed Neural Vocoder Conditioned on Mel Spectrogram](#ESTVocoder-An-Excitation-Spectral-Transformed-Neural-Vocoder-Conditioned-on-Mel-Spectrogram)
* [AIGS Generating Science from AI-Powered Automated Falsification](#AIGS-Generating-Science-from-AI-Powered-Automated-Falsification)
* [FastDraft How to Train Your Draft](#FastDraft-How-to-Train-Your-Draft)
* [EfQAT An Efficient Framework for Quantization-Aware Training](#EfQAT-An-Efficient-Framework-for-Quantization-Aware-Training)
* [Schrödingerization based Quantum Circuits for Maxwell's Equation with time-dependent source terms](#Schrödingerization-based-Quantum-Circuits-for-Maxwell's-Equation-with-time-dependent-source-terms)
* [SageAttention2 Technical Report Accurate 4 Bit Attention for Plug-and-play Inference Acceleration](#SageAttention2-Technical-Report-Accurate-4-Bit-Attention-for-Plug-and-play-Inference-Acceleration)
* [Towards Accurate and Efficient Sub-8-Bit Integer Training](#Towards-Accurate-and-Efficient-Sub-8-Bit-Integer-Training)
* [MpoxVLM A Vision-Language Model for Diagnosing Skin Lesions from Mpox Virus Infection](#MpoxVLM-A-Vision-Language-Model-for-Diagnosing-Skin-Lesions-from-Mpox-Virus-Infection)
* [Adaptive Soft Actor-Critic Framework for RIS-Assisted and UAV-Aided Communication](#Adaptive-Soft-Actor-Critic-Framework-for-RIS-Assisted-and-UAV-Aided-Communication)
* [Conformation Generation using Transformer Flows](#Conformation-Generation-using-Transformer-Flows)
* [Multi-Stage Vision Token Dropping Towards Efficient Multimodal Large Language Model](#Multi-Stage-Vision-Token-Dropping-Towards-Efficient-Multimodal-Large-Language-Model)
* [Beyond Feature Mapping GAP Integrating Real HDRTV Priors for Superior SDRTV-to-HDRTV Conversion](#Beyond-Feature-Mapping-GAP-Integrating-Real-HDRTV-Priors-for-Superior-SDRTV-to-HDRTV-Conversion)
* [Hybrid Attention Model Using Feature Decomposition and Knowledge Distillation for Glucose Forecasting](#Hybrid-Attention-Model-Using-Feature-Decomposition-and-Knowledge-Distillation-for-Glucose-Forecasting)
* [Precision or Peril Evaluating Code Quality from Quantized Large Language Models](#Precision-or-Peril-Evaluating-Code-Quality-from-Quantized-Large-Language-Models)
* [BlueLM-V-3B Algorithm and System Co-Design for Multimodal Large Language Models on Mobile Devices](#BlueLM-V-3B-Algorithm-and-System-Co-Design-for-Multimodal-Large-Language-Models-on-Mobile-Devices)
* [Exascale Workflow Applications and Middleware An ExaWorks Retrospective](#Exascale-Workflow-Applications-and-Middleware-An-ExaWorks-Retrospective)
* [An exploration of the effect of quantisation on energy consumption and inference time of StarCoder2](#An-exploration-of-the-effect-of-quantisation-on-energy-consumption-and-inference-time-of-StarCoder2)
* [Subcritical annulus crossing in spatial random graphs](#Subcritical-annulus-crossing-in-spatial-random-graphs)
* [SmoothCache A Universal Inference Acceleration Technique for Diffusion Transformers](#SmoothCache-A-Universal-Inference-Acceleration-Technique-for-Diffusion-Transformers)
* [Systolic Arrays and Structured Pruning Co-design for Efficient Transformers in Edge Systems](#Systolic-Arrays-and-Structured-Pruning-Co-design-for-Efficient-Transformers-in-Edge-Systems)
* [Scaling Law for Post-training after Model Pruning](#Scaling-Law-for-Post-training-after-Model-Pruning)
* [Super-$\mathrm{Lie}_\infty$ T-Duality and M-Theory](#Super-$\mathrm{Lie}_\infty$-T-Duality-and-M-Theory)
* [Agentic LLMs in the Supply Chain Towards Autonomous Multi-Agent Consensus-Seeking](#Agentic-LLMs-in-the-Supply-Chain-Towards-Autonomous-Multi-Agent-Consensus-Seeking)
* [Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation](#Prompting-and-Fine-tuning-Large-Language-Models-for-Automated-Code-Review-Comment-Generation)
* [Layer Importance and Hallucination Analysis in Large Language Models via Enhanced Activation Variance-Sparsity](#Layer-Importance-and-Hallucination-Analysis-in-Large-Language-Models-via-Enhanced-Activation-Variance-Sparsity)
* [Seeing Clearly by Layer Two Enhancing Attention Heads to Alleviate Hallucination in LVLMs](#Seeing-Clearly-by-Layer-Two-Enhancing-Attention-Heads-to-Alleviate-Hallucination-in-LVLMs)
* [Stable Similarity Comparison of Persistent Homology Groups](#Stable-Similarity-Comparison-of-Persistent-Homology-Groups)
* [A Secure Estimator with Gaussian Bernoulli Mixture Model](#A-Secure-Estimator-with-Gaussian-Bernoulli-Mixture-Model)
* [DiffFNO Diffusion Fourier Neural Operator](#DiffFNO-Diffusion-Fourier-Neural-Operator)
* [AMXFP4 Taming Activation Outliers with Asymmetric Microscaling Floating-Point for 4-bit LLM Inference](#AMXFP4-Taming-Activation-Outliers-with-Asymmetric-Microscaling-Floating-Point-for-4-bit-LLM-Inference)
* [Phase Transitions with Structured Sparsity](#Phase-Transitions-with-Structured-Sparsity)


## Unleashing the Power of Large Language Models for Group POI Recommendations

>Authors: Jing Long, Liang Qu, Guanhua Ye, Tong Chen, Quoc Viet Hung Nguyen, Hongzhi Yin

>2024-11-20

> http://arxiv.org/abs/2411.13415v1

Group Point-of-Interest (POI) recommendations aim to predict the next POI
that satisfies the diverse preferences of a group of users. This task is more
challenging than traditional individual POI recommendations due to complex
group decision-making and extremely **sparse** group-level check-in data. Existing
methods for group POI recommendations primarily rely on single ID-based
features from check-in data, capturing only statistical correlations and
failing to fully utilize the rich semantic information contained in the
check-ins, resulting in suboptimal performance. To this end, we propose a
framework that unleashes the power of the Large Language Model (LLM) for
context-aware group POI recommendations (LLMGPR). Our approach first introduces
POI tokens alongside the original word tokens of the LLM, which are initialized
by applying the LLM to the rich information of each POI. We then propose a
novel sequencing adapter guided by Quantized Low-Rank Adaptation (QLORA) to
modify the LLM. The enhanced LLM can learn sequence representations by
combining semantic-enhanced POI tokens and rich contextual information
including positional encodings and spatio-temporal differences. This approach
can be adapted for learning either group or user representations depending on
the sequence type. Furthermore, we enhance group representations by aggregating
individual member representations with another QLORA-based aggregation adapter
and introducing a self-supervised learning task that predicts the purpose of
check-in sequences, alleviating the data **sparsity** issue. Our experimental
results demonstrate that LLMGPR outperforms existing methods, effectively
addressing group-level data **sparsity** and providing superior recommendations.


## A Survey On Enhancing Reinforcement Learning in Complex Environments Insights from Human and LLM Feedback

>Authors: Alireza Rashidi Laleh, Majid Nili Ahmadabadi

>2024-11-20

> http://arxiv.org/abs/2411.13410v1

Reinforcement learning (RL) is one of the active fields in machine learning,
demonstrating remarkable potential in tackling real-world challenges. Despite
its promising prospects, this methodology has encountered with issues and
challenges, hindering it from achieving the best performance. In particular,
these approaches lack decent performance when navigating environments and
solving tasks with large observation space, often resulting in
sample-inefficiency and prolonged learning times. This issue, commonly referred
to as the curse of dimensionality, complicates decision-making for RL agents,
necessitating a careful balance between attention and decision-making. RL
agents, when augmented with human or large language models' (LLMs) feedback,
may exhibit resilience and adaptability, leading to enhanced performance and
accelerated learning. Such feedback, conveyed through various modalities or
granularities including natural language, serves as a guide for RL agents,
aiding them in discerning relevant environmental cues and optimizing
decision-making processes. In this survey paper, we mainly focus on problems of
two-folds: firstly, we focus on humans or an LLMs assistance, investigating the
ways in which these entities may collaborate with the RL agent in order to
foster optimal behavior and expedite learning; secondly, we delve into the
research papers dedicated to addressing the intricacies of environments
characterized by large observation space.


## Upgrade of the Diagnostic Neutral Beam Injector for the RFX-mod2 experiment

>Authors: Marco Barbisan, Marco Boldrin, Luca Cinnirella, Bruno Laterza, Alberto Maistrello, Lionello Marrelli, Federico Molon, Simone Peruzzo, Cesare Taliercio, Marco Valisa, Enrico Zampiva

>2024-11-20

> http://arxiv.org/abs/2411.13373v1

Diagnostic Neutral Beam Injectors (DNBI), through the combined use of Charge
Exchange Recombination Spectroscopy (CHERS) and Motional Stark effect
diagnostics (MSE), are a well-known tool to access important information about
magnetically confined plasmas, such as radial profiles of ion temperature, ion
flow, impurity content and intensity and direction of the magnetic field. For
this purpose, a DNBI was installed and operated in the RFX-mod experiment,
which was designed to confine plasma mainly through the Reversed Field Pinch
configuration. The DNBI, designed and built by the Budker Institute of Plasma
Physics, was based on a source of positive hydrogen ions, accelerated to 50 keV
and for an equivalent neutral beam current of about 5 A at the source. The beam
could be modulated and the maximum overall duration was 50 ms. With the upgrade
of RFX-mod to the present RFX-mod2 machine, the DNBI is being renovated to
solve several plant faults and improve the overall reliability of the system.
The 50 kV power supply is being improved, as well as the power supplies in the
high voltage deck and its insulation transformer. The control system,
originally based on CAMAC technology, was redesigned to be fully replaced. This
contribution reviews the technical criticalities emerged in the DNBI check-up
and the new solutions adopted to make the DNBI operative and more reliable.


## Transformers with Sparse Attention for Granger Causality

>Authors: Riya Mahesh, Rahul Vashisht, Chandrashekar Lakshminarayanan

>2024-11-20

> http://arxiv.org/abs/2411.13264v1

Temporal causal analysis means understanding the underlying causes behind
observed variables over time. Deep learning based methods such as transformers
are increasingly used to capture temporal dynamics and causal relationships
beyond mere correlations. Recent works suggest self-attention weights of
transformers as a useful indicator of causal links. We leverage this to propose
a novel modification to the self-attention module to establish causal links
between the variables of multivariate time-series data with varying lag
dependencies. Our Sparse Attention Transformer captures causal relationships
using a two-fold approach - performing temporal attention first followed by
attention between the variables across the time steps masking them individually
to compute Granger Causality indices. The key novelty in our approach is the
ability of the model to assert importance and pick the most significant past
time instances for its prediction task against manually feeding a fixed time
lag value. We demonstrate the effectiveness of our approach via extensive
experimentation on several synthetic benchmark datasets. Furthermore, we
compare the performance of our model with the traditional Vector Autoregression
based Granger Causality method that assumes fixed lag length.


## Transforming the Hybrid Cloud for Emerging AI Workloads

>Authors: Deming Chen, Alaa Youssef, Ruchi Pendse, André Schleife, Bryan K. Clark, Hendrik Hamann, Jingrui He, Teodoro Laino, Lav Varshney, Yuxiong Wang, Avirup Sil, Reyhaneh Jabbarvand, Tianyin Xu, Volodymyr Kindratenko, Carlos Costa, Sarita Adve, Charith Mendis, Minjia Zhang, Santiago Núñez-Corrales, Raghu Ganti, Mudhakar Srivatsa, Nam Sung Kim, Josep Torrellas, Jian Huang, Seetharami Seelam, Klara Nahrstedt, Tarek Abdelzaher, Tamar Eilam, Huimin Zhao, Matteo Manica, Ravishankar Iyer, Martin Hirzel, Vikram Adve, Darko Marinov, Hubertus Franke, Hanghang Tong, Elizabeth Ainsworth, Han Zhao, Deepak Vasisht, Minh Do, Fabio Oliveira, Giovanni Pacifici, Ruchir Puri, Priya Nagpurkar

>2024-11-20

> http://arxiv.org/abs/2411.13239v1

This white paper, developed through close collaboration between IBM Research
and UIUC researchers within the IIDAI Institute, envisions transforming hybrid
cloud systems to meet the growing complexity of AI workloads through
innovative, full-stack co-design approaches, emphasizing usability,
manageability, affordability, adaptability, efficiency, and scalability. By
integrating cutting-edge technologies such as generative and agentic AI,
cross-layer automation and optimization, unified control plane, and composable
and adaptive system architecture, the proposed framework addresses critical
challenges in energy efficiency, performance, and cost-effectiveness.
Incorporating quantum computing as it matures will enable quantum-accelerated
simulations for materials science, climate modeling, and other high-impact
domains. Collaborative efforts between academia and industry are central to
this vision, driving advancements in foundation models for material design and
climate solutions, scalable multimodal data processing, and enhanced
physics-based AI emulators for applications like weather forecasting and carbon
sequestration. Research priorities include advancing AI agentic systems, LLM as
an Abstraction (LLMaaA), AI model optimization and unified abstractions across
heterogeneous infrastructure, end-to-end edge-cloud transformation, efficient
programming model, middleware and platform, secure infrastructure,
application-adaptive cloud systems, and new quantum-classical collaborative
workflows. These ideas and solutions encompass both theoretical and practical
research questions, requiring coordinated input and support from the research
community. This joint initiative aims to establish hybrid clouds as secure,
efficient, and sustainable platforms, fostering breakthroughs in AI-driven
applications and scientific discovery across academia, industry, and society.


## Unlocking Historical Clinical Trial Data with ALIGN A Compositional Large Language Model System for Medical Coding

>Authors: Nabeel Seedat, Caterina Tozzi, Andrea Hita Ardiaca, Mihaela van der Schaar, James Weatherall, Adam Taylor

>2024-11-20

> http://arxiv.org/abs/2411.13163v1

The reuse of historical clinical trial data has significant potential to
accelerate medical research and drug development. However, interoperability
challenges, particularly with missing medical codes, hinders effective data
integration across studies. While Large Language Models (LLMs) offer a
promising solution for automated coding without labeled data, current
approaches face challenges on complex coding tasks. We introduce ALIGN, a novel
compositional LLM-based system for automated, zero-shot medical coding. ALIGN
follows a three-step process: (1) diverse candidate code generation; (2)
self-evaluation of codes and (3) confidence scoring and uncertainty estimation
enabling human deferral to ensure reliability. We evaluate ALIGN on harmonizing
medication terms into Anatomical Therapeutic Chemical (ATC) and medical history
terms into Medical Dictionary for Regulatory Activities (MedDRA) codes
extracted from 22 immunology trials. ALIGN outperformed the LLM baselines,
while also providing capabilities for trustworthy deployment. For MedDRA
coding, ALIGN achieved high accuracy across all levels, matching RAG and
excelling at the most specific levels (87-90% for HLGT). For ATC coding, ALIGN
demonstrated superior performance, particularly at lower hierarchy levels (ATC
Level 4), with 72-73% overall accuracy and 86-89% accuracy for common
medications, outperforming baselines by 7-22%. ALIGN's uncertainty-based
deferral improved accuracy by 17% to 90% accuracy with 30% deferral, notably
enhancing performance on uncommon medications. ALIGN achieves this
cost-efficiently at \$0.0007 and \$0.02 per code for GPT-4o-mini and GPT-4o,
reducing barriers to clinical adoption. ALIGN advances automated medical coding
for clinical trial data, contributing to enhanced data interoperability and
reusability, positioning it as a promising tool to improve clinical research
and accelerate drug development.


## IC Mechanisms for Risk-Averse Advertisers in the Online Advertising System

>Authors: Bingzhe Wang, Ruohan Qian, Yuejia Dou, Qi Qi, Bo Shen, Changyuan Li, Yixuan Zhang, Yixin Su, Xin Yuan, Wenqiang liu, Bin Zou, Wen Yi, Zhi Guo, Shuanglong Li, Liu Lin

>2024-11-20

> http://arxiv.org/abs/2411.13162v1

The autobidding system generates huge revenue for advertising platforms,
garnering substantial research attention. Existing studies in autobidding
systems focus on designing Autobidding Incentive Compatible (AIC) mechanisms,
where the mechanism is Incentive Compatible (IC) under ex ante expectations.
However, upon deploying AIC mechanisms in advertising platforms, we observe a
notable deviation between the actual auction outcomes and these expectations
during runtime, particularly in the scene with few clicks (**sparse**-click). This
discrepancy undermines truthful bidding among advertisers in AIC mechanisms,
especially for risk-averse advertisers who are averse to outcomes that do not
align with the expectations. To address this issue, we propose a mechanism,
Decoupled First-Price Auction (DFP), that retains its IC property even during
runtime. DFP dynamically adjusts the payment based on real-time user conversion
outcomes, ensuring that advertisers' realized utilities closely approximate
their expected utilities during runtime. To realize the payment mechanism of
DFP, we propose a PPO-based RL algorithm, with a meticulously crafted reward
function. This algorithm dynamically adjusts the payment to fit DFP mechanism.
We conduct extensive experiments leveraging real-world data to validate our
findings.


## Compute Optimal Inference and Provable Amortisation Gap in Sparse Autoencoders

>Authors: Charles O'Neill, David Klindt

>2024-11-20

> http://arxiv.org/abs/2411.13117v1

A recent line of work has shown promise in using **sparse** autoencoders (SAEs)
to uncover interpretable features in neural network representations. However,
the simple linear-nonlinear encoding mechanism in SAEs limits their ability to
perform accurate **sparse** inference. In this paper, we investigate **sparse**
inference and learning in SAEs through the lens of **sparse** coding. Specifically,
we show that SAEs perform amortised **sparse** inference with a computationally
restricted encoder and, using compressed sensing theory, we prove that this
mapping is inherently insufficient for accurate **sparse** inference, even in
solvable cases. Building on this theory, we empirically explore conditions
where more sophisticated **sparse** inference methods outperform traditional SAE
encoders. Our key contribution is the decoupling of the encoding and decoding
processes, which allows for a comparison of various **sparse** encoding strategies.
We evaluate these strategies on two dimensions: alignment with true underlying
**sparse** features and correct inference of **sparse** codes, while also accounting
for computational costs during training and inference. Our results reveal that
substantial performance gains can be achieved with minimal increases in compute
cost. We demonstrate that this generalises to SAEs applied to large language
models (LLMs), where advanced encoders achieve similar interpretability. This
work opens new avenues for understanding neural network representations and
offers important implications for improving the tools we use to analyse the
activations of large language models.


## Practical Compact Deep Compressed Sensing

>Authors: Bin Chen, Jian Zhang

>2024-11-20

> http://arxiv.org/abs/2411.13081v1

Recent years have witnessed the success of deep networks in compressed
sensing (CS), which allows for a significant reduction in sampling cost and has
gained growing attention since its inception. In this paper, we propose a new
practical and compact network dubbed PCNet for general image CS. Specifically,
in PCNet, a novel collaborative sampling operator is designed, which consists
of a deep conditional filtering step and a dual-branch fast sampling step. The
former learns an implicit representation of a linear transformation matrix into
a few convolutions and first performs adaptive local filtering on the input
image, while the latter then uses a discrete cosine transform and a scrambled
block-diagonal Gaussian matrix to generate under-sampled measurements. Our
PCNet is equipped with an enhanced proximal gradient descent algorithm-unrolled
network for reconstruction. It offers flexibility, interpretability, and strong
recovery performance for arbitrary sampling rates once trained. Additionally,
we provide a deployment-oriented extraction scheme for single-pixel CS imaging
systems, which allows for the convenient conversion of any linear sampling
operator to its matrix form to be loaded onto hardware like digital
micro-mirror devices. Extensive experiments on natural image CS, **quantize**d CS,
and self-supervised CS demonstrate the superior reconstruction accuracy and
generalization ability of PCNet compared to existing state-of-the-art methods,
particularly for high-resolution images. Code is available at
https://github.com/Guaishou74851/PCNet.


## Hardware Scaling Trends and Diminishing Returns in Large-Scale Distributed Training

>Authors: Jared Fernandez, Luca Wehrstedt, Leonid Shamis, Mostafa Elhoushi, Kalyan Saladi, Yonatan Bisk, Emma Strubell, Jacob Kahn

>2024-11-20

> http://arxiv.org/abs/2411.13055v1

Dramatic increases in the capabilities of neural network models in recent
years are driven by scaling model size, training data, and corresponding
computational resources. To develop the exceedingly large networks required in
modern applications, such as large language models (LLMs), model training is
distributed across tens of thousands of hardware accelerators (e.g. GPUs),
requiring orchestration of computation and communication across large computing
clusters. In this work, we demonstrate that careful consideration of hardware
configuration and parallelization strategy is critical for effective (i.e.
compute- and cost-efficient) scaling of model size, training data, and total
computation. We conduct an extensive empirical study of the performance of
large-scale LLM training workloads across model size, hardware configurations,
and distributed parallelization strategies. We demonstrate that: (1) beyond
certain scales, overhead incurred from certain distributed communication
strategies leads parallelization strategies previously thought to be
sub-optimal in fact become preferable; and (2) scaling the total number of
accelerators for large model training quickly yields diminishing returns even
when hardware and parallelization strategies are properly optimized, implying
poor marginal performance per additional unit of power or GPU-hour.


## Topkima-Former Low-energy, Low-Latency Inference for Transformers using top-k In-memory ADC

>Authors: Shuai Dong, Junyi Yang, Xiaoqi Peng, Hongyang Shang, Ye Ke, Xiaofeng Yang, Hongjie Liu, Arindam Basu

>2024-11-20

> http://arxiv.org/abs/2411.13050v1

Transformer model has gained prominence as a popular deep neural network
architecture for neural language processing (NLP) and computer vision (CV)
applications. However, the extensive use of nonlinear operations, like softmax,
poses a performance bottleneck during transformer inference and comprises up to
40% of the total latency. Hence, we propose innovations at the circuit,
architecture, and algorithm levels to accelerate the transformer. At the
circuit level, we propose topkima-combining top-k activation selection with
in-memory ADC (IMA) to implement a low-energy and low-latency softmax without
any sorting latency. Only the k largest activations are sent to the softmax
calculation block, reducing the huge computational cost of softmax. Using a
modified training scheme with top-k only in the forward pass, experimental
results demonstrate only a 0.4% to 1.2% reduction in accuracy across ViT,
distilBERT, and BERT-base models when evaluated on CIFAR-10, CIFAR-100, and
SQuAD datasets with k=5. At the architecture level, an improved scale-free
technique is introduced to reduce the computational cost of attention. The
combined system, dubbed Topkima-Former, enhances 1.8x-84x speedup and 1.3x-35x
energy efficiency (EE) over prior In-memory computing (IMC) accelerators.
Compared to a conventional softmax macro and a digital top-k (Dtopk) softmax
macro, our proposed tokima softmax macro achieves about 15x and 8x faster speed
respectively.


## A Theory for Compressibility of Graph Transformers for Transductive Learning

>Authors: Hamed Shirzad, Honghao Lin, Ameya Velingker, Balaji Venkatachalam, David Woodruff, Danica Sutherland

>2024-11-20

> http://arxiv.org/abs/2411.13028v1

Transductive tasks on graphs differ fundamentally from typical supervised
machine learning tasks, as the independent and identically distributed (i.i.d.)
assumption does not hold among samples. Instead, all train/test/validation
samples are present during training, making them more akin to a semi-supervised
task. These differences make the analysis of the models substantially different
from other models. Recently, Graph Transformers have significantly improved
results on these datasets by overcoming long-range dependency problems.
However, the quadratic complexity of full Transformers has driven the community
to explore more efficient variants, such as those with **sparse**r attention
patterns. While the attention matrix has been extensively discussed, the hidden
dimension or width of the network has received less attention. In this work, we
establish some theoretical bounds on how and under what conditions the hidden
dimension of these networks can be compressed. Our results apply to both **sparse**
and dense variants of Graph Transformers.


## A toy model for $p$-form gauge symmetry

>Authors: Yi Yan, Zhao-Long Wang

>2024-11-20

> http://arxiv.org/abs/2411.13012v1

The abelian $(p+1)$-form gauge field is inherently coupled to the $p$-brane
worldvolume. After **quantization**, the corresponding $p$-form gauge
transformation is associated with the local phase ambiguity of the $p$-brane
wave functional. In essence, the $p$-form gauge symmetry can be realized as a
special construction of the generic 0-form gauge symmetry in the functional
space of $p$-brane configurations. The non-abelian generalization is
straightforward in the functional space language. To simplify the analysis, we
further introduce a toy model where the infinite dimensional functional space
of $p$-brane configurations is replaced by a finite dimensional matrix space.
After taking the symmetric trace in the matrix model, the original discussions
of the $p$-form gauge symmetry can be inherited by the toy model.


## Machine learned reconstruction of tsunami dynamics from sparse observations

>Authors: Edward McDugald, Arvind Mohan, Darren Engwirda, Agnese Marcato, Javier Santos

>2024-11-20

> http://arxiv.org/abs/2411.12948v1

We investigate the use of the Senseiver, a transformer neural network
designed for **sparse** sensing applications, to estimate full-field surface height
measurements of tsunami waves from **sparse** observations. The model is trained on
a large ensemble of simulated data generated via a shallow water equations
solver, which we show to be a faithful reproduction for the underlying dynamics
by comparison to historical events. We train the model on a dataset consisting
of 8 tsunami simulations whose epicenters correspond to historical USGS
earthquake records, and where the model inputs are restricted to measurements
obtained at actively deployed buoy locations. We test the Senseiver on a
dataset consisting of 8 simulations not included in training, demonstrating its
capability for extrapolation. The results show remarkable resolution of fine
scale phase and amplitude features from the true field, provided that at least
a few of the sensors have obtained a non-zero signal. Throughout, we discuss
which forecasting techniques can be improved by this method, and suggest ways
in which the flexibility of the architecture can be leveraged to incorporate
arbitrary remote sensing data (eg. HF Radar and satellite measurements) as well
as investigate optimal sensor placements.


## Selective Attention Enhancing Transformer through Principled Context Control

>Authors: Xuechen Zhang, Xiangyu Chang, Mingchen Li, Amit Roy-Chowdhury, Jiasi Chen, Samet Oymak

>2024-11-19

> http://arxiv.org/abs/2411.12892v1

The attention mechanism within the transformer architecture enables the model
to weigh and combine tokens based on their relevance to the query. While
self-attention has enjoyed major success, it notably treats all queries $q$ in
the same way by applying the mapping $V^\top\text{softmax}(Kq)$, where $V,K$
are the value and key embeddings respectively. In this work, we argue that this
uniform treatment hinders the ability to control contextual **sparsity** and
relevance. As a solution, we introduce the $\textit{Selective Self-Attention}$
(SSA) layer that augments the softmax nonlinearity with a principled
temperature scaling strategy. By controlling temperature, SSA adapts the
contextual **sparsity** of the attention map to the query embedding and its
position in the context window. Through theory and experiments, we demonstrate
that this alleviates attention dilution, aids the optimization process, and
enhances the model's ability to control softmax spikiness of individual
queries. We also incorporate temperature scaling for value embeddings and show
that it boosts the model's ability to suppress irrelevant/noisy tokens.
Notably, SSA is a lightweight method which introduces less than 0.5% new
parameters through a weight-sharing strategy and can be fine-tuned on existing
LLMs. Extensive empirical evaluations demonstrate that SSA-equipped models
achieve a noticeable and consistent accuracy improvement on language modeling
benchmarks.


## ProSec Fortifying Code LLMs with Proactive Security Alignment

>Authors: Xiangzhe Xu, Zian Su, Jinyao Guo, Kaiyuan Zhang, Zhenting Wang, Xiangyu Zhang

>2024-11-19

> http://arxiv.org/abs/2411.12882v1

Recent advances in code-specific large language models (LLMs) have greatly
enhanced code generation and refinement capabilities. However, the safety of
code LLMs remains under-explored, posing potential risks as insecure code
generated by these models may introduce vulnerabilities into real-world
systems. Previous work proposes to collect security-focused instruction-tuning
dataset from real-world vulnerabilities. It is constrained by the data **sparsity**
of vulnerable code, and has limited applicability in the iterative
post-training workflows of modern LLMs. In this paper, we propose ProSec, a
novel proactive security alignment approach designed to align code LLMs with
secure coding practices. ProSec systematically exposes the vulnerabilities in a
code LLM by synthesizing error-inducing coding scenarios from Common Weakness
Enumerations (CWEs), and generates fixes to vulnerable code snippets, allowing
the model to learn secure practices through advanced preference learning
objectives. The scenarios synthesized by ProSec triggers 25 times more
vulnerable code than a normal instruction-tuning dataset, resulting in a
security-focused alignment dataset 7 times larger than the previous work.
Experiments show that models trained with ProSec is 29.2% to 35.5% more secure
compared to previous work, with a marginal negative effect of less than 2
percentage points on model's utility.


## SparseInfer Training-free Prediction of Activation Sparsity for Fast LLM Inference

>Authors: Jiho Shin, Hoeseok Yang, Youngmin Yi

>2024-11-19

> http://arxiv.org/abs/2411.12692v1

Leveraging **sparsity** is crucial for optimizing large language model inference.
however, modern LLMs employing SiLU as their activation function exhibit
minimal activation **sparsity**. Recent research has proposed replacing SiLU with
ReLU to induce significant activation **sparsity** and showed no downstream task
accuracy degradation through fine tuning. However, taking full advantage of it
required training a predictor to estimate this **sparsity**. In this paper, we
introduce SparseInfer, a simple, light weight, and training free predictor for
activation **sparsity** of ReLU field LLMs, in which activation **sparsity** is
predicted by comparing only the sign bits of inputs and weights. To compensate
for possible prediction inaccuracy, an adaptive tuning of the predictor's
conservativeness is enabled, which can also serve as a control knob for
optimizing LLM inference. The proposed method achieves approximately faster
inference speed over the state of the art, with negligible accuracy loss of
within 1%p.


## Data-efficient Tactile Sensing with Electrical Impedance Tomography

>Authors: Huazhi Dong, Ronald B. Liu, Leo Micklem, Peisan Sharel E, Francesco Giorgio-Serchi, Yunjie Yang

>2024-11-19

> http://arxiv.org/abs/2411.12658v1

Electrical Impedance Tomography (EIT)-inspired tactile sensors are gaining
attention in robotic tactile sensing due to their cost-effectiveness, safety,
and scalability with **sparse** electrode configurations. This paper presents a
data augmentation strategy for learning-based tactile reconstruction that
amplifies the original single-frame signal measurement into 32 distinct,
effective signal data for training. This approach supplements uncollected
conditions of position information, resulting in more accurate and
high-resolution tactile reconstructions. Data augmentation for EIT
significantly reduces the required EIT measurements and achieves promising
performance with even limited samples. Simulation results show that the
proposed method improves the correlation coefficient by over 12% and reduces
the relative error by over 21% under various noise levels. Furthermore, we
demonstrate that a standard deep neural network (DNN) utilizing the proposed
data augmentation reduces the required data down to 1/31 while achieving a
similar tactile reconstruction quality. Real-world tests further validate the
approach's effectiveness on a flexible EIT-based tactile sensor. These results
could help address the challenge of training tactile sensing networks with
limited available measurements, improving the accuracy and applicability of
EIT-based tactile sensing systems.


## STREAM A Universal State-Space Model for Sparse Geometric Data

>Authors: Mark Schöne, Yash Bhisikar, Karan Bania, Khaleelulla Khan Nazeer, Christian Mayr, Anand Subramoney, David Kappel

>2024-11-19

> http://arxiv.org/abs/2411.12603v1

Handling **sparse** and unstructured geometric data, such as point clouds or
event-based vision, is a pressing challenge in the field of machine vision.
Recently, sequence models such as Transformers and state-space models entered
the domain of geometric data. These methods require specialized preprocessing
to create a sequential view of a set of points. Furthermore, prior works
involving sequence models iterate geometric data with either uniform or learned
step sizes, implicitly relying on the model to infer the underlying geometric
structure. In this work, we propose to encode geometric structure explicitly
into the parameterization of a state-space model. State-space models are based
on linear dynamics governed by a one-dimensional variable such as time or a
spatial coordinate. We exploit this dynamic variable to inject relative
differences of coordinates into the step size of the state-space model. The
resulting geometric operation computes interactions between all pairs of N
points in O(N) steps. Our model deploys the Mamba selective state-space model
with a modified CUDA kernel to efficiently map **sparse** geometric data to modern
hardware. The resulting sequence model, which we call STREAM, achieves
competitive results on a range of benchmarks from point-cloud classification to
event-based vision and audio classification. STREAM demonstrates a powerful
inductive bias for **sparse** geometric data by improving the PointMamba baseline
when trained from scratch on the ModelNet40 and ScanObjectNN point cloud
analysis datasets. It further achieves, for the first time, 100% test accuracy
on all 11 classes of the DVS128 Gestures dataset.


## S3TU-Net Structured Convolution and Superpixel Transformer for Lung Nodule Segmentation

>Authors: Yuke Wu, Xiang Liu, Yunyu Shi, Xinyi Chen, Zhenglei Wang, YuQing Xu, Shuo Hong Wang

>2024-11-19

> http://arxiv.org/abs/2411.12547v1

The irregular and challenging characteristics of lung adenocarcinoma nodules
in computed tomography (CT) images complicate staging diagnosis, making
accurate segmentation critical for clinicians to extract detailed lesion
information. In this study, we propose a segmentation model, S3TU-Net, which
integrates multi-dimensional spatial connectors and a superpixel-based visual
transformer. S3TU-Net is built on a multi-view CNN-Transformer hybrid
architecture, incorporating superpixel algorithms, structured weighting, and
spatial shifting techniques to achieve superior segmentation performance. The
model leverages structured convolution blocks (DWF-Conv/D2BR-Conv) to extract
multi-scale local features while mitigating overfitting. To enhance multi-scale
feature fusion, we introduce the S2-MLP Link, integrating spatial shifting and
attention mechanisms at the skip connections. Additionally, the residual-based
superpixel visual transformer (RM-SViT) effectively merges global and local
features by employing **sparse** correlation learning and multi-branch attention to
capture long-range dependencies, with residual connections enhancing stability
and computational efficiency. Experimental results on the LIDC-IDRI dataset
demonstrate that S3TU-Net achieves a DSC, precision, and IoU of 89.04%, 90.73%,
and 90.70%, respectively. Compared to recent methods, S3TU-Net improves DSC by
4.52% and sensitivity by 3.16%, with other metrics showing an approximate 2%
increase. In addition to comparison and ablation studies, we validated the
generalization ability of our model on the EPDB private dataset, achieving a
DSC of 86.40%.


## Ultra-Sparse Memory Network

>Authors: Zihao Huang, Qiyang Min, Hongzhi Huang, Defa Zhu, Yutao Zeng, Ran Guo, Xun Zhou

>2024-11-19

> http://arxiv.org/abs/2411.12364v1

It is widely acknowledged that the performance of Transformer models is
exponentially related to their number of parameters and computational
complexity. While approaches like Mixture of Experts (MoE) decouple parameter
count from computational complexity, they still face challenges in inference
due to high memory access costs. This work introduces UltraMem, incorporating
large-scale, ultra-**sparse** memory layer to address these limitations. Our
approach significantly reduces inference latency while maintaining model
performance. We also investigate the scaling laws of this new architecture,
demonstrating that it not only exhibits favorable scaling properties but
outperforms traditional models. In our experiments, we train networks with up
to 20 million memory slots. The results show that our method achieves
state-of-the-art inference speed and model performance within a given
computational budget.


## Faster Multi-GPU Training with PPLL A Pipeline Parallelism Framework Leveraging Local Learning

>Authors: Xiuyuan Guo, Chengqi Xu, Guinan Guo, Feiyu Zhu, Changpeng Cai, Peizhe Wang, Xiaoming Wei, Junhao Su, Jialin Gao

>2024-11-19

> http://arxiv.org/abs/2411.12780v1

Currently, training large-scale deep learning models is typically achieved
through parallel training across multiple GPUs. However, due to the inherent
communication overhead and synchronization delays in traditional model
parallelism methods, seamless parallel training cannot be achieved, which, to
some extent, affects overall training efficiency. To address this issue, we
present PPLL (Pipeline Parallelism based on Local Learning), a novel framework
that leverages local learning algorithms to enable effective parallel training
across multiple GPUs. PPLL divides the model into several distinct blocks, each
allocated to a separate GPU. By utilizing queues to manage data transfers
between GPUs, PPLL ensures seamless cross-GPU communication, allowing multiple
blocks to execute forward and backward passes in a pipelined manner. This
design minimizes idle times and prevents bottlenecks typically caused by
sequential gradient updates, thereby accelerating the overall training process.
We validate PPLL through extensive experiments using ResNet and Vision
Transformer (ViT) architectures on CIFAR-10, SVHN, and STL-10 datasets. Our
results demonstrate that PPLL significantly enhances the training speed of the
local learning method while achieving comparable or even superior training
speed to traditional pipeline parallelism (PP) without sacrificing model
performance. In a 4-GPU training setup, PPLL accelerated local learning
training on ViT and ResNet by 162% and 33%, respectively, achieving 1.25x and
0.85x the speed of traditional pipeline parallelism.


## Deep Learning VLBI Image Reconstruction with Closure Invariants

>Authors: Samuel Lai, Nithyanandan Thyagarajan, O. Ivy Wong, Foivos Diakogiannis, Lucas Hoefs

>2024-11-19

> http://arxiv.org/abs/2411.12233v1

Interferometric closure invariants, constructed from triangular loops of
mixed Fourier components, capture calibration-independent information on source
morphology. While a complete set of closure invariants is directly obtainable
from measured visibilities, the inverse transformation from closure invariants
to the source intensity distribution is not established. In this work, we
demonstrate a deep learning approach, Deep learning Image Reconstruction with
Closure Terms (DIReCT), to directly reconstruct the image from closure
invariants. Trained on both well-defined mathematical shapes (two-dimensional
gaussians, disks, ellipses, $m$-rings) and natural images (CIFAR-10), the
results from our specially designed model are insensitive to station-based
corruptions and thermal noise. The median fidelity score between the
reconstruction and the blurred ground truth achieved is $\gtrsim 0.9$ even for
untrained morphologies, where a unit score denotes perfect reconstruction. In
our validation tests, DIReCT's results are comparable to other state-of-the-art
deconvolution and regularised maximum-likelihood image reconstruction
algorithms, with the advantage that DIReCT does not require hand-tuned
hyperparameters for each individual prediction. This independent approach shows
promising results and offers a calibration-independent constraint on source
morphology, ultimately complementing and improving the reliability of **sparse**
VLBI imaging results.


## ITACLIP Boosting Training-Free Semantic Segmentation with Image, Text, and Architectural Enhancements

>Authors: M. Arda Aydın, Efe Mert Çırpar, Elvin Abdinli, Gozde Unal, Yusuf H. Sahin

>2024-11-18

> http://arxiv.org/abs/2411.12044v1

Recent advances in foundational Vision Language Models (VLMs) have reshaped
the evaluation paradigm in computer vision tasks. These foundational models,
especially CLIP, have accelerated research in open-vocabulary computer vision
tasks, including Open-Vocabulary Semantic Segmentation (OVSS). Although the
initial results are promising, the dense prediction capabilities of VLMs still
require further improvement. In this study, we enhance the semantic
segmentation performance of CLIP by introducing new modules and modifications:
1) architectural changes in the last layer of ViT and the incorporation of
attention maps from the middle layers with the last layer, 2) Image
Engineering: applying data augmentations to enrich input image representations,
and 3) using Large Language Models (LLMs) to generate definitions and synonyms
for each class name to leverage CLIP's open-vocabulary capabilities. Our
training-free method, ITACLIP, outperforms current state-of-the-art approaches
on segmentation benchmarks such as COCO-Stuff, COCO-Object, Pascal Context, and
Pascal VOC. Our code is available at https://github.com/m-arda-aydn/ITACLIP.


## The Nahm transform of multi-fractional instantons

>Authors: Mohamed M. Anber, Erich Poppitz

>2024-11-18

> http://arxiv.org/abs/2411.11962v1

We embed the multi-fractional instantons of $SU(N)$ gauge theories on
$\mathbb T^4$ with 't Hooft twisted boundary conditions into $U(N)$ bundles and
use the Nahm transform to study the corresponding configurations on the dual
$\widehat{\mathbb T}^4$. We first show that $SU(N)$ fractional instantons of
topological charge $Q={r \over N}$, $r \in \{1, 2,...,N-1\}$, are mapped to
fractional instantons of $SU(\widehat N)$ of charge $\widehat Q = {r \over
\widehat N}$, where $\widehat N = N q_1 q_3 - r q_3 + q_1$ and $q_{1,3}$ are
integer-**quantize**d $U(1)$ fluxes. We then explicitly construct the Nahm
transform of constant field strength fractional instantons of $SU(N)$ and find
the $SU(\widehat N)$ configurations they map to. Both the $\mathbb T^4$
instantons and their $\widehat {\mathbb T}^4$ images are self-dual for
appropriately tuned torus periods. The Nahm duality can be extended to tori
with detuned periods, with detuning parameter $\Delta$, mapping solutions with
$\Delta >0$ on $\mathbb T^4$ to ones with $\widehat\Delta <0$ on
$\widehat{\mathbb T}^4$. We also recall that fractional instantons appear in
string theory precisely via the $U(N)$ embedding, suggesting that studying the
end point of tachyon condensation for $\Delta \ne 0$ is needed -- and is
perhaps feasible in a small-$\Delta$ expansion, as in field theory studies --
in order to understand the appearance and role of fractional instantons in
$D$-brane constructions.


## BitMoD Bit-serial Mixture-of-Datatype LLM Acceleration

>Authors: Yuzong Chen, Ahmed F. AbouElhamayed, Xilai Dai, Yang Wang, Marta Andronic, George A. Constantinides, Mohamed S. Abdelfattah

>2024-11-18

> http://arxiv.org/abs/2411.11745v1

Large language models (LLMs) have demonstrated remarkable performance across
various machine learning tasks. Yet the substantial memory footprint of LLMs
significantly hinders their deployment. In this paper, we improve the
accessibility of LLMs through BitMoD, an algorithm-hardware co-design solution
that enables efficient LLM **acceleration** at low weight precision. On the
algorithm side, BitMoD introduces fine-grained data type adaptation that uses a
different numerical data type to **quantize** a group of (e.g., 128) weights.
Through the careful design of these new data types, BitMoD is able to **quantize**
LLM weights to very low precision (e.g., 4 bits and 3 bits) while maintaining
high accuracy. On the hardware side, BitMoD employs a bit-serial processing
element to easily support multiple numerical precisions and data types; our
hardware design includes two key innovations: First, it employs a unified
representation to process different weight data types, thus reducing the
hardware cost. Second, it adopts a bit-serial de**quantization** unit to rescale
the per-group partial sum with minimal hardware overhead. Our evaluation on six
representative LLMs demonstrates that BitMoD significantly outperforms
state-of-the-art LLM **quantization** and **acceleration** methods. For discriminative
tasks, BitMoD can **quantize** LLM weights to 4-bit with $<\!0.5\%$ accuracy loss
on average. For generative tasks, BitMoD is able to **quantize** LLM weights to
3-bit while achieving better perplexity than prior LLM **quantization** scheme.
Combining the superior model performance with an efficient accelerator design,
BitMoD achieves an average of $1.69\times$ and $1.48\times$ speedups compared
to prior LLM accelerators ANT and OliVe, respectively.


## Continuous Speculative Decoding for Autoregressive Image Generation

>Authors: Zili Wang, Robert Zhang, Kun Ding, Qi Yang, Fei Li, Shiming Xiang

>2024-11-18

> http://arxiv.org/abs/2411.11925v1

Continuous-valued Autoregressive (AR) image generation models have
demonstrated notable superiority over their discrete-token counterparts,
showcasing considerable reconstruction quality and higher generation fidelity.
However, the computational demands of the autoregressive framework result in
significant inference overhead. While speculative decoding has proven effective
in accelerating Large Language Models (LLMs), their adaptation to
continuous-valued visual autoregressive models remains unexplored. This work
generalizes the speculative decoding algorithm from discrete tokens to
continuous space. By analyzing the intrinsic properties of output distribution,
we establish a tailored acceptance criterion for the diffusion distributions
prevalent in such models. To overcome the inconsistency that occurred in
speculative decoding output distributions, we introduce denoising trajectory
alignment and token pre-filling methods. Additionally, we identify the
hard-to-sample distribution in the rejection phase. To mitigate this issue, we
propose a meticulous acceptance-rejection sampling method with a proper upper
bound, thereby circumventing complex integration. Experimental results show
that our continuous speculative decoding achieves a remarkable $2.33\times$
speed-up on off-the-shelf models while maintaining the output distribution.
Codes will be available at https://github.com/MarkXCloud/CSpD


## SILVIA Automated Superword-Level Parallelism Exploitation via HLS-Specific LLVM Passes for Compute-Intensive FPGA Accelerators

>Authors: Giovanni Brignone, Roberto Bosio, Fabrizio Ottati, Claudio Sansoè, Luciano Lavagno

>2024-11-18

> http://arxiv.org/abs/2411.11384v1

High-level synthesis (HLS) aims at democratizing custom hardware **acceleration**
with highly abstracted software-like descriptions. However, efficient
accelerators still require substantial low-level hardware optimizations,
defeating the HLS intent. In the context of field-programmable gate arrays,
digital signal processors (DSPs) are a crucial resource that typically requires
a significant optimization effort for its efficient utilization, especially
when used for sub-word vectorization. This work proposes SILVIA, an open-source
LLVM transformation pass that automatically identifies superword-level
parallelism within an HLS design and exploits it by packing multiple
operations, such as additions, multiplications, and multiply-and-adds, into a
single DSP. SILVIA is integrated in the flow of the commercial AMD Vitis HLS
tool and proves its effectiveness by packing multiple operations on the DSPs
without any manual source-code modifications on several diverse
state-of-the-art HLS designs such as convolutional neural networks and basic
linear algebra subprograms accelerators, reducing the DSP utilization for
additions by 70 % and for multiplications and multiply-and-adds by 50 % on
average.


## Continual Task Learning through Adaptive Policy Self-Composition

>Authors: Shengchao Hu, Yuhang Zhou, Ziqing Fan, Jifeng Hu, Li Shen, Ya Zhang, Dacheng Tao

>2024-11-18

> http://arxiv.org/abs/2411.11364v1

Training a generalizable agent to continually learn a sequence of tasks from
offline trajectories is a natural requirement for long-lived agents, yet
remains a significant challenge for current offline reinforcement learning (RL)
algorithms. Specifically, an agent must be able to rapidly adapt to new tasks
using newly collected trajectories (plasticity), while retaining knowledge from
previously learned tasks (stability). However, systematic analyses of this
setting are scarce, and it remains unclear whether conventional continual
learning (CL) methods are effective in continual offline RL (CORL) scenarios.
In this study, we develop the Offline Continual World benchmark and demonstrate
that traditional CL methods struggle with catastrophic forgetting, primarily
due to the unique distribution shifts inherent to CORL scenarios. To address
this challenge, we introduce CompoFormer, a structure-based continual
transformer model that adaptively composes previous policies via a meta-policy
network. Upon encountering a new task, CompoFormer leverages semantic
correlations to selectively integrate relevant prior policies alongside newly
trained parameters, thereby enhancing knowledge sharing and accelerating the
learning process. Our experiments reveal that CompoFormer outperforms
conventional CL methods, particularly in longer task sequences, showcasing a
promising balance between plasticity and stability.


## GPS-Gaussian+ Generalizable Pixel-wise 3D Gaussian Splatting for Real-Time Human-Scene Rendering from Sparse Views

>Authors: Boyao Zhou, Shunyuan Zheng, Hanzhang Tu, Ruizhi Shao, Boning Liu, Shengping Zhang, Liqiang Nie, Yebin Liu

>2024-11-18

> http://arxiv.org/abs/2411.11363v1

Differentiable rendering techniques have recently shown promising results for
free-viewpoint video synthesis of characters. However, such methods, either
Gaussian Splatting or neural implicit rendering, typically necessitate
per-subject optimization which does not meet the requirement of real-time
rendering in an interactive application. We propose a generalizable Gaussian
Splatting approach for high-resolution image rendering under a **sparse**-view
camera setting. To this end, we introduce Gaussian parameter maps defined on
the source views and directly regress Gaussian properties for instant novel
view synthesis without any fine-tuning or optimization. We train our Gaussian
parameter regression module on human-only data or human-scene data, jointly
with a depth estimation module to lift 2D parameter maps to 3D space. The
proposed framework is fully differentiable with both depth and rendering
supervision or with only rendering supervision. We further introduce a
regularization term and an epipolar attention mechanism to preserve geometry
consistency between two source views, especially when neglecting depth
supervision. Experiments on several datasets demonstrate that our method
outperforms state-of-the-art methods while achieving an exceeding rendering
speed.


## LP Data Pipeline Lightweight, Purpose-driven Data Pipeline for Large Language Models

>Authors: Yungi Kim, Hyunsoo Ha, Seonghoon Yang, Sukyung Lee, Jihoo Kim, Chanjun Park

>2024-11-18

> http://arxiv.org/abs/2411.11289v1

Creating high-quality, large-scale datasets for large language models (LLMs)
often relies on resource-intensive, GPU-accelerated models for quality
filtering, making the process time-consuming and costly. This dependence on
GPUs limits accessibility for organizations lacking significant computational
infrastructure. To address this issue, we introduce the Lightweight,
Purpose-driven (LP) Data Pipeline, a framework that operates entirely on CPUs
to streamline the processes of dataset extraction, filtering, and curation.
Based on our four core principles, the LP Data Pipeline significantly reduces
preparation time and cost while maintaining high data quality. Importantly, our
pipeline enables the creation of purpose-driven datasets tailored to specific
domains and languages, enhancing the applicability of LLMs in specialized
contexts. We anticipate that our pipeline will lower the barriers to LLM
development, enabling a wide range of organizations to access LLMs more easily.


## ESTVocoder An Excitation-Spectral-Transformed Neural Vocoder Conditioned on Mel Spectrogram

>Authors: Xiao-Hang Jiang, Hui-Peng Du, Yang Ai, Ye-Xin Lu, Zhen-Hua Ling

>2024-11-18

> http://arxiv.org/abs/2411.11258v1

This paper proposes ESTVocoder, a novel excitation-spectral-transformed
neural vocoder within the framework of source-filter theory. The ESTVocoder
transforms the amplitude and phase spectra of the excitation into the
corresponding speech amplitude and phase spectra using a neural filter whose
backbone is ConvNeXt v2 blocks. Finally, the speech waveform is reconstructed
through the inverse short-time Fourier transform (ISTFT). The excitation is
constructed based on the F0: for voiced segments, it contains full harmonic
information, while for unvoiced segments, it is represented by noise. The
excitation provides the filter with prior knowledge of the amplitude and phase
patterns, expecting to reduce the modeling difficulty compared to conventional
neural vocoders. To ensure the fidelity of the synthesized speech, an
adversarial training strategy is applied to ESTVocoder with multi-scale and
multi-resolution discriminators. Analysis-synthesis and text-to-speech
experiments both confirm that our proposed ESTVocoder outperforms or is
comparable to other baseline neural vocoders, e.g., HiFi-GAN, SiFi-GAN, and
Vocos, in terms of synthesized speech quality, with a reasonable model
complexity and generation speed. Additional analysis experiments also
demonstrate that the introduced excitation effectively accelerates the model's
convergence process, thanks to the speech spectral prior information contained
in the excitation.


## AIGS Generating Science from AI-Powered Automated Falsification

>Authors: Zijun Liu, Kaiming Liu, Yiqi Zhu, Xuanyu Lei, Zonghan Yang, Zhenhe Zhang, Peng Li, Yang Liu

>2024-11-17

> http://arxiv.org/abs/2411.11910v1

Rapid development of artificial intelligence has drastically accelerated the
development of scientific discovery. Trained with large-scale observation data,
deep neural networks extract the underlying patterns in an end-to-end manner
and assist human researchers with highly-precised predictions in unseen
scenarios. The recent rise of Large Language Models (LLMs) and the empowered
autonomous agents enable scientists to gain help through interaction in
different stages of their research, including but not limited to literature
review, research ideation, idea implementation, and academic writing. However,
AI researchers instantiated by foundation model empowered agents with
full-process autonomy are still in their infancy. In this paper, we study
$\textbf{AI-Generated Science}$ (AIGS), where agents independently and
autonomously complete the entire research process and discover scientific laws.
By revisiting the definition of scientific research, we argue that
$\textit{falsification}$ is the essence of both human research process and the
design of an AIGS system. Through the lens of falsification, prior systems
attempting towards AI-Generated Science either lack the part in their design,
or rely heavily on existing verification engines that narrow the use in
specialized domains. In this work, we propose Baby-AIGS as a baby-step
demonstration of a full-process AIGS system, which is a multi-agent system with
agents in roles representing key research process. By introducing
FalsificationAgent, which identify and then verify possible scientific
discoveries, we empower the system with explicit falsification. Experiments on
three tasks preliminarily show that Baby-AIGS could produce meaningful
scientific discoveries, though not on par with experienced human researchers.
Finally, we discuss on the limitations of current Baby-AIGS, actionable
insights, and related ethical issues in detail.


## FastDraft How to Train Your Draft

>Authors: Ofir Zafrir, Igor Margulis, Dorin Shteyman, Guy Boudoukh

>2024-11-17

> http://arxiv.org/abs/2411.11055v1

Speculative Decoding has gained popularity as an effective technique for
accelerating the auto-regressive inference process of Large Language Models
(LLMs). However, Speculative Decoding entirely relies on the availability of
efficient draft models, which are often lacking for many existing language
models due to a stringent constraint of vocabulary incompatibility. In this
work we introduce FastDraft, a novel and efficient approach for pre-training
and aligning a draft model to any large language model by incorporating
efficient pre-training, followed by fine-tuning over synthetic datasets
generated by the target model. We demonstrate FastDraft by training two highly
parameter efficient drafts for the popular Phi-3-mini and Llama-3.1-8B models.
Using FastDraft, we were able to produce a draft with approximately 10 billion
tokens on a single server with 8 Intel$^\circledR$ Gaudi$^\circledR$ 2
accelerators in under 24 hours. Our results show that the draft model achieves
impressive results in key metrics of acceptance rate, block efficiency and up
to 3x memory bound speed up when evaluated on code completion and up to 2x in
summarization, text completion and instruction tasks. We validate our
theoretical findings through benchmarking on the latest Intel$^\circledR$
Core$^{\tiny \text{TM}}$ Ultra, achieving a wall-clock time speedup of up to
2x, indicating a significant reduction in runtime. Due to its high quality,
FastDraft unlocks large language models inference on AI-PC and other
edge-devices.


## EfQAT An Efficient Framework for Quantization-Aware Training

>Authors: Saleh Ashkboos, Bram Verhoef, Torsten Hoefler, Evangelos Eleftheriou, Martino Dazzi

>2024-11-17

> http://arxiv.org/abs/2411.11038v1

Quantization-aware training (QAT) schemes have been shown to achieve
near-full precision accuracy. They accomplish this by training a **quantize**d
model for multiple epochs. This is computationally expensive, mainly because of
the full precision backward pass. On the other hand, post-training **quantization**
(PTQ) schemes do not involve training and are therefore computationally cheap,
but they usually result in a significant accuracy drop. We address these
challenges by proposing EfQAT, which generalizes both schemes by optimizing
only a subset of the parameters of a **quantize**d model. EfQAT starts by applying
a PTQ scheme to a pre-trained model and only updates the most critical network
parameters while freezing the rest, accelerating the backward pass. We
demonstrate the effectiveness of EfQAT on various CNNs and Transformer-based
models using different GPUs. Specifically, we show that EfQAT is significantly
more accurate than PTQ with little extra compute. Furthermore, EfQAT can
accelerate the QAT backward pass between 1.44-1.64x while retaining most
accuracy.


## Schrödingerization based Quantum Circuits for Maxwell's Equation with time-dependent source terms

>Authors: Chuwen Ma, Shi Jin, Nana Liu, Kezhen Wang, Lei Zhang

>2024-11-17

> http://arxiv.org/abs/2411.10999v1

The Schr\"odingerisation method combined with the autonomozation technique in
\cite{cjL23} converts general non-autonomous linear differential equations with
non-unitary dynamics into systems of autonomous Schr\"odinger-type equations,
via the so-called warped phase transformation that maps the equation into two
higher dimension. Despite the success of Schr\"odingerisation techniques, they
typically require the black box of the **sparse** Hamiltonian simulation, suitable
for continuous-variable based analog quantum simulation. For qubit-based
general quantum computing one needs to design the quantum circuits for
practical implementation.
  This paper explicitly constructs a quantum circuit for Maxwell's equations
with perfect electric conductor (PEC) boundary conditions and time-dependent
source terms, based on Schr\"odingerization and autonomozation, with
corresponding computational complexity analysis. Through initial value
smoothing and high-order approximation to the delta function, the increase in
qubits from the extra dimensions only requires minor rise in computational
complexity, almost $\log\log {1/\varepsilon}$ where $\varepsilon$ is the
desired precision. Our analysis demonstrates that quantum algorithms
constructed using Schr\"odingerisation exhibit polynomial **acceleration** in
computational complexity compared to the classical Finite Difference Time
Domain (FDTD) format.


## SageAttention2 Technical Report Accurate 4 Bit Attention for Plug-and-play Inference Acceleration

>Authors: Jintao Zhang, Haofeng Huang, Pengle Zhang, Jia Wei, Jun Zhu, Jianfei Chen

>2024-11-17

> http://arxiv.org/abs/2411.10958v1

Although **quantization** for linear layers has been widely used, its application
to accelerate the attention process remains limited. SageAttention utilizes
8-bit matrix multiplication, 16-bit matrix multiplication with 16-bit
accumulator, and precision-enhancing methods, implementing an accurate and 2x
speedup kernel compared to FlashAttention2. To further enhance the efficiency
of attention computation while maintaining precision, we propose
SageAttention2, which utilizes significantly faster 4-bit matrix multiplication
(Matmul) alongside additional precision-enhancing techniques. First, we propose
to **quantize** matrixes $(Q, K)$ to INT4 in a warp-level granularity and **quantize**
matrixes $(\widetilde P, V)$ to FP8. Second, we propose a method to smooth $Q$
and $V$, enhancing the accuracy of attention with INT4 $QK$ and FP8 $PV$.
Third, we analyze the **quantization** accuracy across timesteps and layers, then
propose an adaptive **quantization** method to ensure the end-to-end metrics over
various models. The operations per second (OPS) of SageAttention2 surpass
FlashAttention2 and xformers by about 3x and 5x on RTX4090, respectively.
Comprehensive experiments confirm that our approach incurs negligible
end-to-end metrics loss across diverse models, including those for large
language processing, image generation, and video generation. The codes are
available at https://github.com/thu-ml/SageAttention.


## Towards Accurate and Efficient Sub-8-Bit Integer Training

>Authors: Wenjin Guo, Donglai Liu, Weiying Xie, Yunsong Li, Xuefei Ning, Zihan Meng, Shulin Zeng, Jie Lei, Zhenman Fang, Yu Wang

>2024-11-17

> http://arxiv.org/abs/2411.10948v1

Neural network training is a memory- and compute-intensive task.
Quantization, which enables **low-bit**width formats in training, can significantly
mitigate the workload. To reduce **quantization** error, recent methods have
developed new data formats and additional pre-processing operations on
**quantize**rs. However, it remains quite challenging to achieve high accuracy and
efficiency simultaneously. In this paper, we explore sub-8-bit integer training
from its essence of gradient descent optimization. Our integer training
framework includes two components: ShiftQuant to realize accurate gradient
estimation, and L1 normalization to smoothen the loss landscape. ShiftQuant
attains performance that approaches the theoretical upper bound of group
**quantization**. Furthermore, it liberates group **quantization** from inefficient
memory rearrangement. The L1 normalization facilitates the implementation of
fully **quantize**d normalization layers with impressive convergence accuracy. Our
method frees sub-8-bit integer training from pre-processing and supports
general devices. This framework achieves negligible accuracy loss across
various neural networks and tasks ($0.92\%$ on 4-bit ResNets, $0.61\%$ on 6-bit
Transformers). The prototypical implementation of ShiftQuant achieves more than
$1.85\times/15.3\%$ performance improvement on CPU/GPU compared to its FP16
counterparts, and $33.9\%$ resource consumption reduction on FPGA than the FP16
counterparts. The proposed fully-**quantize**d L1 normalization layers achieve more
than $35.54\%$ improvement in throughout on CPU compared to traditional L2
normalization layers. Moreover, theoretical analysis verifies the advancement
of our method.


## MpoxVLM A Vision-Language Model for Diagnosing Skin Lesions from Mpox Virus Infection

>Authors: Xu Cao, Wenqian Ye, Kenny Moise, Megan Coffee

>2024-11-16

> http://arxiv.org/abs/2411.10888v1

In the aftermath of the COVID-19 pandemic and amid accelerating climate
change, emerging infectious diseases, particularly those arising from zoonotic
spillover, remain a global threat. Mpox (caused by the monkeypox virus) is a
notable example of a zoonotic infection that often goes undiagnosed, especially
as its rash progresses through stages, complicating detection across diverse
populations with different presentations. In August 2024, the WHO
Director-General declared the mpox outbreak a public health emergency of
international concern for a second time. Despite the deployment of deep
learning techniques for detecting diseases from skin lesion images, a robust
and publicly accessible foundation model for mpox diagnosis is still lacking
due to the unavailability of open-source mpox skin lesion images, multimodal
clinical data, and specialized training pipelines. To address this gap, we
propose MpoxVLM, a vision-language model (VLM) designed to detect mpox by
analyzing both skin lesion images and patient clinical information. MpoxVLM
integrates the CLIP visual encoder, an enhanced Vision Transformer (ViT)
classifier for skin lesions, and LLaMA-2-7B models, pre-trained and fine-tuned
on visual instruction-following question-answer pairs from our newly released
mpox skin lesion dataset. Our work achieves 90.38% accuracy for mpox detection,
offering a promising pathway to improve early diagnostic accuracy in combating
mpox.


## Adaptive Soft Actor-Critic Framework for RIS-Assisted and UAV-Aided Communication

>Authors: Abuzar B. M. Adam, Elhadj Moustapha Diallo, Mohammed A. M. Elhassan

>2024-11-16

> http://arxiv.org/abs/2411.10882v1

In this work, we explore UAV-assisted reconfigurable intelligent surface
(RIS) technology to enhance downlink communications in wireless networks. By
integrating RIS on both UAVs and ground infrastructure, we aim to boost network
coverage, fairness, and resilience against challenges such as UAV jitter. To
maximize the minimum achievable user rate, we formulate a joint optimization
problem involving beamforming, phase shifts, and UAV trajectory. To address
this problem, we propose an adaptive soft actor-critic (ASAC) framework. In
this approach, agents are built using adaptive **sparse** transformers with
attentive feature refinement (ASTAFER), enabling dynamic feature processing
that adapts to real-time network conditions. The ASAC model learns optimal
solutions to the coupled subproblems in real time, delivering an end-to-end
solution without relying on iterative or relaxation-based methods. Simulation
results demonstrate that our ASAC-based approach achieves better performance
compared to the conventional SAC. This makes it a robust, adaptable solution
for real-time, fair, and efficient downlink communication in UAV-RIS networks.


## Conformation Generation using Transformer Flows

>Authors: Sohil Atul Shah, Vladlen Koltun

>2024-11-16

> http://arxiv.org/abs/2411.10817v1

Estimating three-dimensional conformations of a molecular graph allows
insight into the molecule's biological and chemical functions. Fast generation
of valid conformations is thus central to molecular modeling. Recent advances
in graph-based deep networks have accelerated conformation generation from
hours to seconds. However, current network architectures do not scale well to
large molecules. Here we present ConfFlow, a flow-based model for conformation
generation based on transformer networks. In contrast with existing approaches,
ConfFlow directly samples in the coordinate space without enforcing any
explicit physical constraints. The generative procedure is highly interpretable
and is akin to force field updates in molecular dynamics simulation. When
applied to the generation of large molecule conformations, ConfFlow improve
accuracy by up to $40\%$ relative to state-of-the-art learning-based methods.
The source code is made available at https://github.com/IntelLabs/ConfFlow.


## Multi-Stage Vision Token Dropping Towards Efficient Multimodal Large Language Model

>Authors: Ting Liu, Liangtao Shi, Richang Hong, Yue Hu, Quanjun Yin, Linfeng Zhang

>2024-11-16

> http://arxiv.org/abs/2411.10803v1

The vision tokens in multimodal large language models usually exhibit
significant spatial and temporal redundancy and take up most of the input
tokens, which harms their inference efficiency. To solve this problem, some
recent works were introduced to drop the unimportant tokens during inference
where the importance of each token is decided only by the information in either
the vision encoding stage or the prefilling stage. In this paper, we propose
Multi-stage Token Dropping (MustDrop) to measure the importance of each token
from the whole lifecycle, including the vision encoding stage, prefilling
stage, and decoding stage. Concretely, in the visual encoding stage, MustDrop
merges spatially adjacent tokens with high similarity, and establishes a key
token set to retain the most vision-critical tokens, preventing them from being
discarded in later stages. In the prefilling stage, MustDrop further compresses
vision tokens by the guidance of text semantics, with a dual-attention
filtering strategy. In the decoding stage, an output-aware cache policy is
proposed to further reduce the size of the **KV** cache. By leveraging tailored
strategies in the multi-stage process, MustDrop can more precisely recognize
the important and redundant tokens, thus achieving an optimal balance between
performance and efficiency. For instance, MustDrop reduces about 88.5\% FLOPs
on LLaVA with a compression ratio of 92.2\% while maintaining comparable
accuracy. Our codes are available at
\url{https://github.com/liuting20/MustDrop}.


## Beyond Feature Mapping GAP Integrating Real HDRTV Priors for Superior SDRTV-to-HDRTV Conversion

>Authors: Kepeng Xu, Li Xu, Gang He, Zhiqiang Zhang, Wenxin Yu, Shihao Wang, Dajiang Zhou, Yunsong Li

>2024-11-16

> http://arxiv.org/abs/2411.10775v1

The rise of HDR-WCG display devices has highlighted the need to convert SDRTV
to HDRTV, as most video sources are still in SDR. Existing methods primarily
focus on designing neural networks to learn a single-style mapping from SDRTV
to HDRTV. However, the limited information in SDRTV and the diversity of styles
in real-world conversions render this process an ill-posed problem, thereby
constraining the performance and generalization of these methods. Inspired by
generative approaches, we propose a novel method for SDRTV to HDRTV conversion
guided by real HDRTV priors. Despite the limited information in SDRTV,
introducing real HDRTV as reference priors significantly constrains the
solution space of the originally high-dimensional ill-posed problem. This shift
transforms the task from solving an unreferenced prediction problem to making a
referenced selection, thereby markedly enhancing the accuracy and reliability
of the conversion process. Specifically, our approach comprises two stages: the
first stage employs a Vector Quantized Generative Adversarial Network to
capture HDRTV priors, while the second stage matches these priors to the input
SDRTV content to recover realistic HDRTV outputs. We evaluate our method on
public datasets, demonstrating its effectiveness with significant improvements
in both objective and subjective metrics across real and synthetic datasets.


## Hybrid Attention Model Using Feature Decomposition and Knowledge Distillation for Glucose Forecasting

>Authors: Ebrahim Farahmand, Shovito Barua Soumma, Nooshin Taheri Chatrudi, Hassan Ghasemzadeh

>2024-11-16

> http://arxiv.org/abs/2411.10703v1

The availability of continuous glucose monitors as over-the-counter
commodities have created a unique opportunity to monitor a person's blood
glucose levels, forecast blood glucose trajectories and provide automated
interventions to prevent devastating chronic complications that arise from poor
glucose control. However, forecasting blood glucose levels is challenging
because blood glucose changes consistently in response to food intake,
medication intake, physical activity, sleep, and stress. It is particularly
difficult to accurately predict BGL from multimodal and irregularly sampled
data and over long prediction horizons. Furthermore, these forecasting models
must operate in real-time on edge devices to provide in-the-moment
interventions. To address these challenges, we propose GlucoNet, an AI-powered
sensor system for continuously monitoring behavioral and physiological health
and robust forecasting of blood glucose patterns. GlucoNet devises a feature
decomposition-based transformer model that incorporates patients' behavioral
and physiological data and transforms **sparse** and irregular patient data (e.g.,
diet and medication intake data) into continuous features using a mathematical
model, facilitating better integration with the BGL data. Given the non-linear
and non-stationary nature of BG signals, we propose a decomposition method to
extract both low and high-frequency components from the BGL signals, thus
providing accurate forecasting. To reduce the computational complexity, we also
propose to employ knowledge distillation to compress the transformer model.
GlucoNet achieves a 60% improvement in RMSE and a 21% reduction in the number
of parameters, using data obtained involving 12 participants with T1-Diabetes.
These results underscore GlucoNet's potential as a compact and reliable tool
for real-world diabetes prevention and management.


## Precision or Peril Evaluating Code Quality from Quantized Large Language Models

>Authors: Eric L. Melin, Adam J. Torek, Nasir U. Eisty, Casey Kennington

>2024-11-16

> http://arxiv.org/abs/2411.10656v1

When scaled to hundreds of billions of parameters, Large Language Models
(LLMs) such as GPT-4 and LLaMA-405b have demonstrated remarkable capabilities
in tasks such as code generation, code completion, and writing test cases.
However, scaling up model sizes results in exponentially higher computational
cost and energy consumption, leaving a large carbon footprint and making these
models difficult to use by academic researchers and small businesses.
Quantization has emerged as a way to mitigate the memory overhead of LLMs,
allowing them to run on smaller hardware for lower prices. Quantization,
however, may have detrimental effects on a model's output and it's effects on
LLM generated code quality remains understudied and requires constant
evaluation as LLMs are improved. This study aims to evaluate the current code
generation capabilities of smaller LLMs using various metrics, exploring the
impact of **quantization** on code quality, and identifying prevalent quality
issues in the generated code. Method: We conducted a comprehensive evaluation
of four smaller open-source LLMs across two benchmarks and code similarity
scores. The impact of 8-bit and 4-bit **quantization** was analyzed, and a static
analysis tool was utilized to scrutinize the generated code's quality. Our
findings reveal that while the tested LLMs exhibit potential, these smaller
LLMs produce code with subpar performance on established benchmarks. The
effects of **quantization** on code quality are inconsistent, and the generated
code frequently exhibits recurring quality and maintainability issues. This
study underscores the necessity for careful scrutiny and validation of
LLM-generated code before its adoption in software projects. While smaller LLMs
can generate code, their output requires careful monitoring and validation by
practitioners before integration into software projects.


## BlueLM-V-3B Algorithm and System Co-Design for Multimodal Large Language Models on Mobile Devices

>Authors: Xudong Lu, Yinghao Chen, Cheng Chen, Hui Tan, Boheng Chen, Yina Xie, Rui Hu, Guanxin Tan, Renshou Wu, Yan Hu, Yi Zeng, Lei Wu, Liuyang Bian, Zhaoxiong Wang, Long Liu, Yanzhou Yang, Han Xiao, Aojun Zhou, Yafei Wen, Xiaoxin Chen, Shuai Ren, Hongsheng Li

>2024-11-16

> http://arxiv.org/abs/2411.10640v1

The emergence and growing popularity of multimodal large language models
(MLLMs) have significant potential to enhance various aspects of daily life,
from improving communication to facilitating learning and problem-solving.
Mobile phones, as essential daily companions, represent the most effective and
accessible deployment platform for MLLMs, enabling seamless integration into
everyday tasks. However, deploying MLLMs on mobile phones presents challenges
due to limitations in memory size and computational capability, making it
difficult to achieve smooth and real-time processing without extensive
optimization. In this paper, we present BlueLM-V-3B, an algorithm and system
co-design approach specifically tailored for the efficient deployment of MLLMs
on mobile platforms. To be specific, we redesign the dynamic resolution scheme
adopted by mainstream MLLMs and implement system optimization for
hardware-aware deployment to optimize model inference on mobile phones.
BlueLM-V-3B boasts the following key highlights: (1) Small Size: BlueLM-V-3B
features a language model with 2.7B parameters and a vision encoder with 400M
parameters. (2) Fast Speed: BlueLM-V-3B achieves a generation speed of 24.4
token/s on the MediaTek Dimensity 9300 processor with 4-bit LLM weight
**quantization**. (3) Strong Performance: BlueLM-V-3B has attained the highest
average score of 66.1 on the OpenCompass benchmark among models with $\leq$ 4B
parameters and surpassed a series of models with much larger parameter sizes
(e.g., MiniCPM-V-2.6, InternVL2-8B).


## Exascale Workflow Applications and Middleware An ExaWorks Retrospective

>Authors: Aymen Alsaadi, Mihael Hategan-Marandiuc, Ketan Maheshwari, Andre Merzky, Mikhail Titov, Matteo Turilli, Andreas Wilke, Justin M. Wozniak, Kyle Chard, Rafael Ferreira da Silva, Shantenu Jha, Daniel Laney

>2024-11-16

> http://arxiv.org/abs/2411.10637v1

Exascale computers offer transformative capabilities to combine data-driven
and learning-based approaches with traditional simulation applications to
accelerate scientific discovery and insight. However, these software
combinations and integrations are difficult to achieve due to the challenges of
coordinating and deploying heterogeneous software components on diverse and
massive platforms. We present the ExaWorks project, which addresses many of
these challenges. We developed a workflow Software Development Toolkit (SDK), a
curated collection of workflow technologies that can be composed and
interoperated through a common interface, engineered following current best
practices, and specifically designed to work on HPC platforms. ExaWorks also
developed PSI/J, a job management abstraction API, to simplify the construction
of portable software components and applications that can be used over various
HPC schedulers. The PSI/J API is a minimal interface for submitting and
monitoring jobs and their execution state across multiple and commonly used HPC
schedulers. We also describe several leading and innovative workflow examples
of ExaWorks tools used on DOE leadership platforms. Furthermore, we discuss how
our project is working with the workflow community, large computing facilities,
and HPC platform vendors to address the requirements of workflows sustainably
at the exascale.


## An exploration of the effect of quantisation on energy consumption and inference time of StarCoder2

>Authors: Pepijn de Reus, Ana Oprescu, Jelle Zuidema

>2024-11-15

> http://arxiv.org/abs/2411.12758v1

This study examines quantisation and **pruning** strategies to reduce energy
consumption in code Large Language Models (LLMs) inference. Using StarCoder2,
we observe increased energy demands with **quantization** due to lower throughput
and some accuracy losses. Conversely, **pruning** reduces energy usage but impairs
performance. The results highlight challenges and trade-offs in LLM model
compression. We suggest future work on hardware-optimized **quantization** to
enhance efficiency with minimal loss in accuracy.


## Subcritical annulus crossing in spatial random graphs

>Authors: Emmanuel Jacob, Benedikt Jahnel, Lukas Lüchtrath

>2024-11-15

> http://arxiv.org/abs/2411.10333v1

We consider general continuum percolation models obeying **sparse**ness,
translation invariance, and spatial decorrelation. In particular, this includes
models constructed on general point sets other than the standard Poisson point
process or the Bernoulli-percolated lattice. Moreover, in our setting the
existence of an edge may depend not only on the two end vertices but also on a
surrounding vertex set and models are included that are not monotone in some of
their parameters. We study the critical annulus-crossing intensity
$\widehat{\lambda}_{c}$, which is smaller or equal to the classical critical
percolation intensity $\lambda_{c}$ and derive a condition for
$\widehat{\lambda}_{c}>0$ by relating the crossing of annuli to the occurrence
of long edges. This condition is sharp for models that have a modicum of
independence. In a nutshell, our result states that annuli are either not
crossed for small intensities or crossed by a single edge. Our proof rests on a
multiscale argument that further allows us to directly describe the decay of
the annulus-crossing probability with the decay of long edges probabilities.
  We apply our result to a number of examples from the literature. Most
importantly, we extensively discuss the weight-dependent random connection
model in a generalised version, for which we derive sufficient conditions for
the presence or absence of long edges that are typically easy to check. These
conditions are built on a decay coefficient $\zeta$ that has recently seen some
attention due to its importance for various proofs of global graph properties.


## SmoothCache A Universal Inference Acceleration Technique for Diffusion Transformers

>Authors: Joseph Liu, Joshua Geddes, Ziyu Guo, Haomiao Jiang, Mahesh Kumar Nandwana

>2024-11-15

> http://arxiv.org/abs/2411.10510v1

Diffusion Transformers (DiT) have emerged as powerful generative models for
various tasks, including image, video, and speech synthesis. However, their
inference process remains computationally expensive due to the repeated
evaluation of resource-intensive attention and feed-forward modules. To address
this, we introduce SmoothCache, a model-agnostic inference **acceleration**
technique for DiT architectures. SmoothCache leverages the observed high
similarity between layer outputs across adjacent diffusion timesteps. By
analyzing layer-wise representation errors from a small calibration set,
SmoothCache adaptively caches and reuses key features during inference. Our
experiments demonstrate that SmoothCache achieves 8% to 71% speed up while
maintaining or even improving generation quality across diverse modalities. We
showcase its effectiveness on DiT-XL for image generation, Open-Sora for
text-to-video, and Stable Audio Open for text-to-audio, highlighting its
potential to enable real-time applications and broaden the accessibility of
powerful DiT models.


## Systolic Arrays and Structured Pruning Co-design for Efficient Transformers in Edge Systems

>Authors: Pedro Palacios, Rafael Medina, Jean-Luc Rouas, Giovanni Ansaloni, David Atienza

>2024-11-15

> http://arxiv.org/abs/2411.10285v1

Efficient deployment of resource-intensive transformers on edge devices
necessitates cross-stack optimization. We thus study the interrelation between
structured **pruning** and systolic **acceleration**, matching the size of pruned
blocks with the systolic array dimensions. In this setting, computations of
pruned weight blocks can be skipped, reducing run-time and energy consumption,
but potentially impacting quality of service (QoS). To evaluate the trade-offs
between systolic array size and **sparsity** opportunities, we present a novel
co-design framework that integrates algorithmic optimization, system
simulation, and hardware design. Targeting speech recognition using
transformers as a case study, we analyze how configuration choices across the
stack affect performance metrics. Results demonstrate that structured **pruning**
on systems featuring systolic array **acceleration** can effectively increase
performance, while maintaining high QoS levels. Up to 26% system-wide speedups
due to structured **pruning** were measured, with only 1.4% word error rate
degradation on the standard Librispeech dataset.


## Scaling Law for Post-training after Model Pruning

>Authors: Xiaodong Chen, Yuxuan Hu, Jing Zhang, Xiaokang Zhang, Cuiping Li, Hong Chen

>2024-11-15

> http://arxiv.org/abs/2411.10272v1

Large language models (LLMs) based on the Transformer architecture are widely
employed across various domains and tasks. However, their increasing size
imposes significant hardware demands, limiting practical deployment. To
mitigate this, model **pruning** techniques have been developed to create more
efficient models while maintaining high performance. Despite this,
post-training after **pruning** is crucial for performance recovery and can be
resource-intensive. This paper investigates the post-training requirements of
pruned LLMs and introduces a scaling law to determine the optimal amount of
post-training data. Post-training experiments with the Llama-3 and Qwen-2.5
series models, pruned using depth **pruning**, width **pruning**, and 2:4
semi-structured **pruning**, show that higher **pruning** ratios necessitate more
post-training data for performance recovery, whereas larger LLMs require less.
The proposed scaling law predicts a model's loss based on its parameter counts
before and after **pruning**, as well as the post-training token counts.
Furthermore, we find that the scaling law established from smaller LLMs can be
reliably extrapolated to larger LLMs. This work provides valuable insights into
the post-training of pruned LLMs and offers a practical scaling law for
optimizing post-training data usage.


## Super-$\mathrm{Lie}_\infty$ T-Duality and M-Theory

>Authors: Grigorios Giotopoulos, Hisham Sati, Urs Schreiber

>2024-11-15

> http://arxiv.org/abs/2411.10260v1

Super $L_\infty$-algebras unify extended super-symmetry with rational
classifying spaces for higher flux densities: The super-invariant super-fluxes
which control super $p$-branes and their supergravity target super-spaces are,
together with their (non-linear) Bianchi identities, neatly encoded in
(non-abelian) super-$L_\infty$ cocycles. These are the rational shadows of
flux-**quantization** laws (in ordinary cohomology, K-theory, Cohomotopy, iterated
K-theory, etc).
  We first review, in streamlined form while filling some previous gaps,
double-dimensional reduction/oxidation and 10D superspace T-duality along
higher-dimensional super-tori. We do so tangent super-space wise, by viewing it
as an instance of adjunctions (dualities) between super-$L_\infty$-extensions
and -cyclifications, applied to the avatar super-flux densities of 10D
supergravity. In particular, this yields a derivation, at the rational level,
of the traditional laws of "topological T-duality" from the super-$L_\infty$
structure of type II superspace. At this level, we also discuss a higher
categorical analog of T-duality involving M-branes.
  Then, by considering super-space T-duality along all 1+9 spacetime dimensions
while retaining the 11th dimension as in F-theory, we find the M-algebra
appearing as the complete brane-charge extension of the fully
T-doubled/correspondence super-spacetime. On this backdrop, we recognize the
"decomposed" M-theory 3-form on the "hidden M-algebra" as an M-theoretic lift
of the Poincar\'e super 2-form that controls superspace T-duality as the
integral kernel of the super Fourier-Mukai transform. This provides the
super-space structure of an M-theory lift of the doubled/correspondence space
geometry, which controls T-duality.


## Agentic LLMs in the Supply Chain Towards Autonomous Multi-Agent Consensus-Seeking

>Authors: Valeria Jannelli, Stefan Schoepf, Matthias Bickel, Torbjørn Netland, Alexandra Brintrup

>2024-11-15

> http://arxiv.org/abs/2411.10184v1

This paper explores how Large Language Models (LLMs) can automate
consensus-seeking in supply chain management (SCM), where frequent decisions on
problems such as inventory levels and delivery times require coordination among
companies. Traditional SCM relies on human consensus in decision-making to
avoid emergent problems like the bullwhip effect. Some routine consensus
processes, especially those that are time-intensive and costly, can be
automated. Existing solutions for automated coordination have faced challenges
due to high entry barriers locking out SMEs, limited capabilities, and limited
adaptability in complex scenarios. However, recent advances in Generative AI,
particularly LLMs, show promise in overcoming these barriers. LLMs, trained on
vast datasets can negotiate, reason, and plan, facilitating near-human-level
consensus at scale with minimal entry barriers. In this work, we identify key
limitations in existing approaches and propose autonomous LLM agents to address
these gaps. We introduce a series of novel, supply chain-specific
consensus-seeking frameworks tailored for LLM agents and validate the
effectiveness of our approach through a case study in inventory management. To
accelerate progress within the SCM community, we open-source our code,
providing a foundation for further advancements in LLM-powered autonomous
supply chain solutions.


## Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation

>Authors: Md. Asif Haider, Ayesha Binte Mostofa, Sk. Sabit Bin Mosaddek, Anindya Iqbal, Toufique Ahmed

>2024-11-15

> http://arxiv.org/abs/2411.10129v1

Generating accurate code review comments remains a significant challenge due
to the inherently diverse and non-unique nature of the task output. Large
language models pretrained on both programming and natural language data tend
to perform well in code-oriented tasks. However, large-scale pretraining is not
always feasible due to its environmental impact and project-specific
generalizability issues. In this work, first we fine-tune open-source Large
language models (LLM) in parameter-efficient, **quantize**d low-rank (QLoRA)
fashion on consumer-grade hardware to improve review comment generation. Recent
studies demonstrate the efficacy of augmenting semantic metadata information
into prompts to boost performance in other code-related tasks. To explore this
in code review activities, we also prompt proprietary, closed-source LLMs
augmenting the input code patch with function call graphs and code summaries.
Both of our strategies improve the review comment generation performance, with
function call graph augmented few-shot prompting on the GPT-3.5 model
surpassing the pretrained baseline by around 90% BLEU-4 score on the
CodeReviewer dataset. Moreover, few-shot prompted Gemini-1.0 Pro, QLoRA
fine-tuned Code Llama and Llama 3.1 models achieve competitive results (ranging
from 25% to 83% performance improvement) on this task. An additional human
evaluation study further validates our experimental findings, reflecting
real-world developers' perceptions of LLM-generated code review comments based
on relevant qualitative metrics.


## Layer Importance and Hallucination Analysis in Large Language Models via Enhanced Activation Variance-Sparsity

>Authors: Zichen Song, Sitan Huang, Yuxin Wu, Zhongfeng Kang

>2024-11-15

> http://arxiv.org/abs/2411.10069v1

Evaluating the importance of different layers in large language models (LLMs)
is crucial for optimizing model performance and interpretability. This paper
first explores layer importance using the Activation Variance-Sparsity Score
(AVSS), which combines normalized activation variance and **sparsity** to quantify
each layer's contribution to overall model performance. By ranking layers based
on AVSS and **pruning** the least impactful 25\%, our experiments on tasks such as
question answering, language modeling, and sentiment classification show that
over 90\% of the original performance is retained, highlighting potential
redundancies in LLM architectures. Building on AVSS, we propose an enhanced
version tailored to assess hallucination propensity across layers (EAVSS). This
improved approach introduces Hallucination-Specific Activation Variance (HSAV)
and Hallucination-Specific Sparsity (HSS) metrics, allowing precise
identification of hallucination-prone layers. By incorporating contrastive
learning on these layers, we effectively mitigate hallucination generation,
contributing to more robust and efficient LLMs(The maximum performance
improvement is 12\%). Our results on the NQ, SciQ, TriviaQA, TruthfulQA, and
WikiQA datasets demonstrate the efficacy of this method, offering a
comprehensive framework for both layer importance evaluation and hallucination
mitigation in LLMs.


## Seeing Clearly by Layer Two Enhancing Attention Heads to Alleviate Hallucination in LVLMs

>Authors: Xiaofeng Zhang, Yihao Quan, Chaochen Gu, Chen Shen, Xiaosong Yuan, Shaotian Yan, Hao Cheng, Kaijie Wu, Jieping Ye

>2024-11-15

> http://arxiv.org/abs/2411.09968v1

The hallucination problem in multimodal large language models (MLLMs) remains
a common issue. Although image tokens occupy a majority of the input sequence
of MLLMs, there is limited research to explore the relationship between image
tokens and hallucinations. In this paper, we analyze the distribution of
attention scores for image tokens across each layer and head of the model,
revealing an intriguing and common phenomenon: most hallucinations are closely
linked to the pattern of attention sinks in the self-attention matrix of image
tokens, where shallow layers exhibit dense attention sinks and deeper layers
show **sparse** attention sinks. We further analyze the attention heads of
different layers and find that heads with high-density attention sink in the
image part play a positive role in alleviating hallucinations. In this paper,
we propose a training-free method named \textcolor{red}{\textbf{E}}nhancing
\textcolor{red}{\textbf{A}}ttention \textcolor{red}{\textbf{H}}eads (EAH), an
approach designed to enhance the convergence of image tokens attention sinks in
the shallow layers. EAH identifies the attention head that shows the vision
sink in a shallow layer and extracts its attention matrix. This attention map
is then broadcast to other heads in the layer, thereby strengthening the layer
to pay more attention to the image itself. With extensive experiments, EAH
shows significant hallucination-mitigating performance on different MLLMs and
metrics, proving its effectiveness and generality.


## Stable Similarity Comparison of Persistent Homology Groups

>Authors: Jiaxing He, Bingzhe Hou, Tieru Wu, Yang Cao

>2024-11-15

> http://arxiv.org/abs/2411.09960v1

Classification in the sense of similarity is an important issue. In this
paper, we study similarity classification in Topological Data Analysis. We
define a pseudometric $d_{S}^{(p)}$ to measure the distance between barcodes
generated by persistent homology groups of topological spaces, and we provide
that our pseudometric $d_{S}^{(2)}$ is a similarity invariant. Thereby, we
establish a connection between Operator Theory and Topological Data Analysis.
We give the calculation formula of the pseudometric $d_{S}^{(2)}$
$(d_{S}^{(1)})$ by arranging all eigenvalues of matrices determined by barcodes
in descending order to get the infimum over all matchings. Since conformal
linear transformation is one representative type of similarity transformations,
we construct comparative experiments on both synthetic datasets and waves from
an online platform to demonstrate that our pseudometric $d_{S}^{(2)}$
$(d_{S}^{(1)})$ is stable under conformal linear transformations, whereas the
bottleneck and Wasserstein distances are not. In particular, our pseudometric
on waves is only related to the waveform but is independent on the frequency
and amplitude. Furthermore, the computation time for $d_{S}^{(2)}$
$(d_{S}^{(1)})$ is significantly less than the computation time for bottleneck
distance and is comparable to the computation time for accelerated Wasserstein
distance between barcodes.


## A Secure Estimator with Gaussian Bernoulli Mixture Model

>Authors: Xingzhou Chen, Nachuan Yang, Peihu Duan, Shilei Li, Ling Shi

>2024-11-15

> http://arxiv.org/abs/2411.09956v1

The implementation of cyber-physical systems in real-world applications is
challenged by safety requirements in the presence of sensor threats. Most
cyber-physical systems, in particular the vulnerable multi-sensor systems,
struggle to detect the attack in observation signals. In this paper, we tackle
this issue by proposing a Gaussian-Bernoulli Secure (GBS) estimator, which
effectively transforms the assessment of sensor status into an optimal
estimation problem concerning the system state and observation indicators. It
encompasses two theoretical sub-problems: sequential state estimation with
partial observations and estimation updates with disordered new observations.
Within the framework of Kalman filter, we derive closed-form solutions for
these two issues. However, due to their computational inefficiency, we propose
the iterative approach employing proximal gradient descent to accelerate the
estimation update. We conduct comprehensive experiments from three
perspectives: computational efficiency, detection and estimation performance,
and characterization of observation error. Our GBS estimator shows the
improvements compared to other methods.


## DiffFNO Diffusion Fourier Neural Operator

>Authors: Xiaoyi Liu, Hao Tang

>2024-11-15

> http://arxiv.org/abs/2411.09911v1

We introduce DiffFNO, a novel diffusion framework for arbitrary-scale
super-resolution strengthened by a Weighted Fourier Neural Operator (WFNO).
Mode Re-balancing in WFNO effectively captures critical frequency components,
significantly improving the reconstruction of high-frequency image details that
are crucial for super-resolution tasks. Gated Fusion Mechanism (GFM) adaptively
complements WFNO's spectral features with spatial features from an
Attention-based Neural Operator (AttnNO). This enhances the network's
capability to capture both global structures and local details. Adaptive
Time-Step (ATS) ODE solver, a deterministic sampling strategy, accelerates
inference without sacrificing output quality by dynamically adjusting
integration step sizes ATS. Extensive experiments demonstrate that DiffFNO
achieves state-of-the-art (SOTA) results, outperforming existing methods across
various scaling factors by a margin of 2 to 4 dB in PSNR, including those
beyond the training distribution. It also achieves this at lower inference
time. Our approach sets a new standard in super-resolution, delivering both
superior accuracy and computational efficiency.


## AMXFP4 Taming Activation Outliers with Asymmetric Microscaling Floating-Point for 4-bit LLM Inference

>Authors: Janghwan Lee, Jiwoong Park, Jinseok Kim, Yongjik Kim, Jungju Oh, Jinwook Oh, Jungwook Choi

>2024-11-15

> http://arxiv.org/abs/2411.09909v1

Scaling Large Language Models (LLMs) with extended context lengths has
increased the need for efficient **low-bit** **quantization** to manage their
substantial computational demands. However, reducing precision to 4 bits
frequently degrades performance due to activation outliers. To address this, we
propose Asymmetric Microscaling 4-bit Floating-Point (AMXFP4) for efficient LLM
inference. This novel data format leverages asymmetric shared scales to
mitigate outliers while naturally capturing the asymmetry introduced by
group-wise **quantization**. Unlike conventional 4-bit **quantization** methods that
rely on data rotation and costly calibration, AMXFP4 uses asymmetric shared
scales for direct 4-bit casting, achieving near-ideal **quantization** accuracy
across various LLM tasks, including multi-turn conversations, long-context
reasoning, and visual question answering. Our AMXFP4 format significantly
outperforms MXFP4 and other leading **quantization** techniques, enabling robust,
calibration-free 4-bit inference.


## Phase Transitions with Structured Sparsity

>Authors: Huiguang Zhang, Baoguo Liu

>2024-11-15

> http://arxiv.org/abs/2411.09868v1

In the field of signal processing, phase transition phenomena have recently
attracted great attention. Donoho's work established the signal recovery
threshold using indicators such as restricted isotropy (RIP) and incoherence
and proved that phase transition phenomena occur in compressed sampling.
Nevertheless, the phase transition phenomenon of structured **sparse** signals
remains unclear, and these studies mainly focused on simple **sparse** signals.
Signals with a specific structure, such as the block or tree structures common
in real-world applications, are called structured **sparse** signals. The
objectives of this article are to study the phase transition phenomenon of
structured **sparse** signals and to investigate how structured **sparse** signals
affect the phase transition threshold. It begins with a summary of the common
subspace of structured **sparse** signals and the theory of high-dimensional convex
polytope random projections. Next, the strong threshold expression of
block-structured and tree-structured **sparse** signals is derived after examining
the weak and strong thresholds of structured **sparse** signals.

