# 2025-05-09

# Table of Contents
* [On Path to Multimodal Generalist General-Level and General-Bench](#On-Path-to-Multimodal-Generalist-General-Level-and-General-Bench)
* [Pangu Ultra MoE How to Train Your Big MoE on Ascend NPUs](#Pangu-Ultra-MoE-How-to-Train-Your-Big-MoE-on-Ascend-NPUs)
* [M2Rec Multi-scale Mamba for Efficient Sequential Recommendation](#M2Rec-Multi-scale-Mamba-for-Efficient-Sequential-Recommendation)
* [LONGER Scaling Up Long Sequence Modeling in Industrial Recommenders](#LONGER-Scaling-Up-Long-Sequence-Modeling-in-Industrial-Recommenders)
* [Deep Learning Innovations for Energy Efficiency Advances in Non-Intrusive Load Monitoring and EV Charging Optimization for a Sustainable Grid](#Deep-Learning-Innovations-for-Energy-Efficiency-Advances-in-Non-Intrusive-Load-Monitoring-and-EV-Charging-Optimization-for-a-Sustainable-Grid)
* [RGB-Event Fusion with Self-Attention for Collision Prediction](#RGB-Event-Fusion-with-Self-Attention-for-Collision-Prediction)
* [Neural-network-based longitudinal electric field prediction in nonlinear plasma wakefield accelerators](#Neural-network-based-longitudinal-electric-field-prediction-in-nonlinear-plasma-wakefield-accelerators)
* [The stability of generalized phase retrieval problem over compact groups](#The-stability-of-generalized-phase-retrieval-problem-over-compact-groups)
* [On-Device LLM for Context-Aware Wi-Fi Roaming](#On-Device-LLM-for-Context-Aware-Wi-Fi-Roaming)
* [NC-smooth thickenings and Jacobians](#NC-smooth-thickenings-and-Jacobians)
* [Modal Decomposition and Identification for a Population of Structures Using Physics-Informed Graph Neural Networks and Transformers](#Modal-Decomposition-and-Identification-for-a-Population-of-Structures-Using-Physics-Informed-Graph-Neural-Networks-and-Transformers)
* [A Graphical Global Optimization Framework for Parameter Estimation of Statistical Models with Nonconvex Regularization Functions](#A-Graphical-Global-Optimization-Framework-for-Parameter-Estimation-of-Statistical-Models-with-Nonconvex-Regularization-Functions)
* [VITA-Audio Fast Interleaved Cross-Modal Token Generation for Efficient Large Speech-Language Model](#VITA-Audio-Fast-Interleaved-Cross-Modal-Token-Generation-for-Efficient-Large-Speech-Language-Model)
* [Matching Distance and Geometric Distribution Aided Learning Multiview Point Cloud Registration](#Matching-Distance-and-Geometric-Distribution-Aided-Learning-Multiview-Point-Cloud-Registration)
* [Faster MoE LLM Inference for Extremely Large Models](#Faster-MoE-LLM-Inference-for-Extremely-Large-Models)
* [High-order exponential solver method for particle-in-cell simulations](#High-order-exponential-solver-method-for-particle-in-cell-simulations)
* [Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs and Retrieval-Augmented Generation](#Lightweight-Clinical-Decision-Support-System-using-QLoRA-Fine-Tuned-LLMs-and-Retrieval-Augmented-Generation)
* [SPAP Structured Pruning via Alternating Optimization and Penalty Methods](#SPAP-Structured-Pruning-via-Alternating-Optimization-and-Penalty-Methods)
* [Geospatial Mechanistic Interpretability of Large Language Models](#Geospatial-Mechanistic-Interpretability-of-Large-Language-Models)
* [Physics-Informed Neural Networks in Electromagnetic and Nanophotonic Design](#Physics-Informed-Neural-Networks-in-Electromagnetic-and-Nanophotonic-Design)
* [Accelerated inverse design of passive Si Photonics](#Accelerated-inverse-design-of-passive-Si-Photonics)
* [IAFormer Interaction-Aware Transformer network for collider data analysis](#IAFormer-Interaction-Aware-Transformer-network-for-collider-data-analysis)
* [PROM Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs](#PROM-Prioritize-Reduction-of-Multiplications-Over-Lower-Bit-Widths-for-Efficient-CNNs)
* [QiMeng-CPU-v2 Automated Superscalar Processor Design by Learning Data Dependencies](#QiMeng-CPU-v2-Automated-Superscalar-Processor-Design-by-Learning-Data-Dependencies)
* [Holmes Automated Fact Check with Large Language Models](#Holmes-Automated-Fact-Check-with-Large-Language-Models)


## On Path to Multimodal Generalist General-Level and General-Bench

>Authors: Hao Fei, Yuan Zhou, Juncheng Li, Xiangtai Li, Qingshan Xu, Bobo Li, Shengqiong Wu, Yaoting Wang, Junbao Zhou, Jiahao Meng, Qingyu Shi, Zhiyuan Zhou, Liangtao Shi, Minghe Gao, Daoan Zhang, Zhiqi Ge, Weiming Wu, Siliang Tang, Kaihang Pan, Yaobo Ye, Haobo Yuan, Tao Zhang, Tianjie Ju, Zixiang Meng, Shilin Xu, Liyu Jia, Wentao Hu, Meng Luo, Jiebo Luo, Tat-Seng Chua, Shuicheng Yan, Hanwang Zhang

>2025-05-07

> http://arxiv.org/abs/2505.04620v1

The Multimodal Large Language Model (MLLM) is currently experiencing rapid
growth, driven by the advanced capabilities of LLMs. Unlike earlier
specialists, existing MLLMs are evolving towards a Multimodal Generalist
paradigm. Initially limited to understanding multiple modalities, these models
have advanced to not only comprehend but also generate across modalities. Their
capabilities have expanded from coarse-grained to fine-grained multimodal
understanding and from supporting limited modalities to arbitrary ones. While
many benchmarks exist to assess MLLMs, a critical question arises: Can we
simply assume that higher performance across tasks indicates a stronger MLLM
capability, bringing us closer to human-level AI? We argue that the answer is
not as straightforward as it seems. This project introduces General-Level, an
evaluation framework that defines 5-scale levels of MLLM performance and
generality, offering a methodology to compare MLLMs and gauge the progress of
existing systems towards more robust multimodal generalists and, ultimately,
towards AGI. At the core of the framework is the concept of Synergy, which
measures whether models maintain consistent capabilities across comprehension
and generation, and across multiple modalities. To support this evaluation, we
present General-Bench, which encompasses a broader spectrum of skills,
modalities, formats, and capabilities, including over 700 tasks and 325,800
instances. The evaluation results that involve over 100 existing
state-of-the-art MLLMs uncover the capability rankings of generalists,
highlighting the challenges in reaching genuine AI. We expect this project to
pave the way for future research on next-generation multimodal foundation
models, providing a robust infrastructure to accelerate the realization of AGI.
Project page: https://generalist.top/


## Pangu Ultra MoE How to Train Your Big MoE on Ascend NPUs

>Authors: Yehui Tang, Yichun Yin, Yaoyuan Wang, Hang Zhou, Yu Pan, Wei Guo, Ziyang Zhang, Miao Rang, Fangcheng Liu, Naifu Zhang, Binghan Li, Yonghan Dong, Xiaojun Meng, Yasheng Wang, Dong Li, Yin Li, Dandan Tu, Can Chen, Youliang Yan, Fisher Yu, Ruiming Tang, Yunhe Wang, Botian Huang, Bo Wang, Boxiao Liu, Changzheng Zhang, Da Kuang, Fei Liu, Gang Huang, Jiansheng Wei, Jiarui Qin, Jie Ran, Jinpeng Li, Jun Zhao, Liang Dai, Lin Li, Liqun Deng, Peifeng Qin, Pengyuan Zeng, Qiang Gu, Shaohua Tang, Shengjun Cheng, Tao Gao, Tao Yu, Tianshu Li, Tianyu Bi, Wei He, Weikai Mao, Wenyong Huang, Wulong Liu, Xiabing Li, Xianzhi Yu, Xueyu Wu, Xu He, Yangkai Du, Yan Xu, Ye Tian, Yimeng Wu, Yongbing Huang, Yong Tian, Yong Zhu, Yue Li, Yufei Wang, Yuhang Gai, Yujun Li, Yu Luo, Yunsheng Ni, Yusen Sun, Zelin Chen, Zhe Liu, Zhicheng Liu, Zhipeng Tu, Zilin Ding, Zongyuan Zhan

>2025-05-07

> http://arxiv.org/abs/2505.04519v1

Sparse large language models (LLMs) with Mixture of Experts (MoE) and close
to a trillion parameters are dominating the realm of most capable language
models. However, the massive model scale poses significant challenges for the
underlying software and hardware systems. In this paper, we aim to uncover a
recipe to harness such scale on Ascend NPUs. The key goals are better usage of
the computing resources under the dynamic **sparse** model structures and
materializing the expected performance gain on the actual hardware. To select
model configurations suitable for Ascend NPUs without repeatedly running the
expensive experiments, we leverage simulation to compare the trade-off of
various model hyperparameters. This study led to Pangu Ultra MoE, a **sparse** LLM
with 718 billion parameters, and we conducted experiments on the model to
verify the simulation results. On the system side, we dig into Expert
Parallelism to optimize the communication between NPU devices to reduce the
synchronization overhead. We also optimize the memory efficiency within the
devices to further reduce the parameter and activation management overhead. In
the end, we achieve an MFU of 30.0% when training Pangu Ultra MoE, with
performance comparable to that of DeepSeek R1, on 6K Ascend NPUs, and
demonstrate that the Ascend system is capable of harnessing all the training
stages of the state-of-the-art language models. Extensive experiments indicate
that our recipe can lead to efficient training of large-scale **sparse** language
models with MoE. We also study the behaviors of such models for future
reference.


## M2Rec Multi-scale Mamba for Efficient Sequential Recommendation

>Authors: Qianru Zhang, Liang Qu, Honggang Wen, Dong Huang, Siu-Ming Yiu, Nguyen Quoc Viet Hung, Hongzhi Yin

>2025-05-07

> http://arxiv.org/abs/2505.04445v1

Sequential recommendation systems aim to predict users' next preferences
based on their interaction histories, but existing approaches face critical
limitations in efficiency and multi-scale pattern recognition. While
Transformer-based methods struggle with quadratic computational complexity,
recent Mamba-based models improve efficiency but fail to capture periodic user
behaviors, leverage rich semantic information, or effectively fuse multimodal
features. To address these challenges, we propose \model, a novel sequential
recommendation framework that integrates multi-scale Mamba with Fourier
analysis, Large Language Models (LLMs), and adaptive gating. First, we enhance
Mamba with Fast Fourier Transform (FFT) to explicitly model periodic patterns
in the frequency domain, separating meaningful trends from noise. Second, we
incorporate LLM-based text embeddings to enrich **sparse** interaction data with
semantic context from item descriptions. Finally, we introduce a learnable gate
mechanism to dynamically balance temporal (Mamba), frequency (FFT), and
semantic (LLM) features, ensuring harmonious multimodal fusion. Extensive
experiments demonstrate that \model\ achieves state-of-the-art performance,
improving Hit Rate@10 by 3.2\% over existing Mamba-based models while
maintaining 20\% faster inference than Transformer baselines. Our results
highlight the effectiveness of combining frequency analysis, semantic
understanding, and adaptive fusion for sequential recommendation. Code and
datasets are available at: https://anonymous.4open.science/r/M2Rec.


## LONGER Scaling Up Long Sequence Modeling in Industrial Recommenders

>Authors: Zheng Chai, Qin Ren, Xijun Xiao, Huizhi Yang, Bo Han, Sijun Zhang, Di Chen, Hui Lu, Wenlin Zhao, Lele Yu, Xionghang Xie, Shiru Ren, Xiang Sun, Yaocheng Tan, Peng Xu, Yuchao Zheng, Di Wu

>2025-05-07

> http://arxiv.org/abs/2505.04421v1

Modeling ultra-long user behavior sequences is critical for capturing both
long- and short-term preferences in industrial recommender systems. Existing
solutions typically rely on two-stage retrieval or indirect modeling paradigms,
incuring upstream-downstream inconsistency and computational inefficiency. In
this paper, we present LONGER, a Long-sequence Optimized traNsformer for
GPU-Efficient Recommenders. LONGER incorporates (i) a global token mechanism
for stabilizing attention over long contexts, (ii) a token merge module with
lightweight InnerTransformers and hybrid attention strategy to reduce quadratic
complexity, and (iii) a series of engineering optimizations, including training
with mixed-precision and activation recomputation, **KV** cache serving, and the
fully synchronous model training and serving framework for unified GPU-based
dense and **sparse** parameter updates. LONGER consistently outperforms strong
baselines in both offline metrics and online A/B testing in both advertising
and e-commerce services at ByteDance, validating its consistent effectiveness
and industrial-level scaling laws. Currently, LONGER has been fully deployed at
more than 10 influential scenarios at ByteDance, serving billion users.


## Deep Learning Innovations for Energy Efficiency Advances in Non-Intrusive Load Monitoring and EV Charging Optimization for a Sustainable Grid

>Authors: Stavros Sykiotis

>2025-05-07

> http://arxiv.org/abs/2505.04367v1

The global energy landscape is undergoing a profound transformation, often
referred to as the energy transition, driven by the urgent need to mitigate
climate change, reduce greenhouse gas emissions, and ensure sustainable energy
supplies. However, the undoubted complexity of new investments in renewables,
as well as the phase out of high CO2-emission energy sources, hampers the pace
of the energy transition and raises doubts as to whether new renewable energy
sources are capable of solely meeting the climate target goals. This highlights
the need to investigate alternative pathways to accelerate the energy
transition, by identifying human activity domains with higher/excessive energy
demands. Two notable examples where there is room for improvement, in the sense
of reducing energy consumption and consequently CO2 emissions, are residential
energy consumption and road transport. This dissertation investigates the
development of novel Deep Learning techniques to create tools which solve
limitations in these two key energy domains. Reduction of residential energy
consumption can be achieved by empowering end-users with the user of
Non-Intrusive Load Monitoring, whereas optimization of EV charging with Deep
Reinforcement Learning can tackle road transport decarbonization.


## RGB-Event Fusion with Self-Attention for Collision Prediction

>Authors: Pietro Bonazzi, Christian Vogt, Michael Jost, Haotong Qin, Lyes Khacef, Federico Paredes-Valles, Michele Magno

>2025-05-07

> http://arxiv.org/abs/2505.04258v1

Ensuring robust and real-time obstacle avoidance is critical for the safe
operation of autonomous robots in dynamic, real-world environments. This paper
proposes a neural network framework for predicting the time and collision
position of an unmanned aerial vehicle with a dynamic object, using RGB and
event-based vision sensors. The proposed architecture consists of two separate
encoder branches, one for each modality, followed by fusion by self-attention
to improve prediction accuracy. To facilitate benchmarking, we leverage the
ABCD [8] dataset collected that enables detailed comparisons of single-modality
and fusion-based approaches. At the same prediction throughput of 50Hz, the
experimental results show that the fusion-based model offers an improvement in
prediction accuracy over single-modality approaches of 1% on average and 10%
for distances beyond 0.5m, but comes at the cost of +71% in memory and + 105%
in FLOPs. Notably, the event-based model outperforms the RGB model by 4% for
position and 26% for time error at a similar computational cost, making it a
competitive alternative. Additionally, we evaluate **quantize**d versions of the
event-based models, applying 1- to 8-bit **quantization** to assess the trade-offs
between predictive performance and computational efficiency. These findings
highlight the trade-offs of multi-modal perception using RGB and event-based
cameras in robotic applications.


## Neural-network-based longitudinal electric field prediction in nonlinear plasma wakefield accelerators

>Authors: Xiaoning Wang, Ming Zeng, Dazhang Li, Weiming An, Wei Lu

>2025-05-07

> http://arxiv.org/abs/2505.04236v1

Plasma wakefield **acceleration** holds remarkable promise for future advanced
accelerators. The design and optimization of plasma-based accelerators
typically require particle-in-cell simulations, which can be computationally
intensive and time consuming. In this study, we train a neural network model to
obtain the on-axis longitudinal electric field distribution directly without
conducting particle-in-cell simulations for designing a two-bunch plasma
wakefield **acceleration** stage. By combining the neural network model with an
advanced algorithm for achieving the minimal energy spread, the optimal
normalized charge per unit length of a trailing beam leading to the optimal
beam-loading can be quickly identified. This approach can reduce computation
time from around 7.6 minutes in the case of using particle-in-cell simulations
to under 0.1 seconds. Moreover, the longitudinal electric field distribution
under the optimal beam-loading can be visually observed. Utilizing this model
with the beam current profile also enables the direct extraction of design
parameters under the optimal beam-loading, including the maximum decelerating
electric field within the drive beam, the average accelerating electric field
within the trailing beam and the transformer ratio. This model has the
potential to significantly improve the efficiency of designing and optimizing
the beam-driven plasma wakefield accelerators.


## The stability of generalized phase retrieval problem over compact groups

>Authors: Tal Amir, Tamir Bendory, Nadav Dym, Dan Edidin

>2025-05-07

> http://arxiv.org/abs/2505.04190v1

The generalized phase retrieval problem over compact groups aims to recover a
set of matrices, representing an unknown signal, from their associated Gram
matrices, leveraging prior structural knowledge about the signal. This
framework generalizes the classical phase retrieval problem, which reconstructs
a signal from the magnitudes of its Fourier transform, to a richer setting
involving non-abelian compact groups. In this broader context, the unknown
phases in Fourier space are replaced by unknown orthogonal matrices that arise
from the action of a compact group on a finite-dimensional vector space. This
problem is primarily motivated by advances in electron microscopy to
determining the 3D structure of biological macromolecules from highly noisy
observations. To capture realistic assumptions from machine learning and signal
processing, we model the signal as belonging to one of several broad structural
families: a generic linear subspace, a **sparse** representation in a generic
basis, the output of a generic ReLU neural network, or a generic
low-dimensional manifold. Our main result shows that, under mild conditions,
the generalized phase retrieval problem not only admits a unique solution (up
to inherent group symmetries), but also satisfies a bi-Lipschitz property. This
implies robustness to both noise and model mismatch, an essential requirement
for practical use, especially when measurements are severely corrupted by
noise. These findings provide theoretical support for a wide class of
scientific problems under modern structural assumptions, and they offer strong
foundations for developing robust algorithms in high-noise regimes.


## On-Device LLM for Context-Aware Wi-Fi Roaming

>Authors: Ju-Hyung Lee, Yanqing Lu

>2025-05-07

> http://arxiv.org/abs/2505.04174v1

Wireless roaming is a critical yet challenging task for maintaining seamless
connectivity in dynamic mobile environments. Conventional threshold-based or
heuristic schemes often fail, leading to either sticky or excessive handovers.
We introduce the first cross-layer use of an on-device large language model
(LLM): high-level reasoning in the application layer that issues real-time
actions executed in the PHY/MAC stack. The LLM addresses two tasks: (i)
context-aware AP selection, where structured prompts fuse environmental cues
(e.g., location, time) to choose the best BSSID; and (ii) dynamic threshold
adjustment, where the model adaptively decides when to roam. To satisfy the
tight latency and resource budgets of edge hardware, we apply a suite of
optimizations-chain-of-thought prompting, parameter-efficient fine-tuning, and
**quantization**. Experiments on indoor and outdoor datasets show that our approach
surpasses legacy heuristics and DRL baselines, achieving a strong balance
between roaming stability and signal quality. These findings underscore the
promise of application-layer LLM reasoning for lower-layer wireless control in
future edge systems.


## NC-smooth thickenings and Jacobians

>Authors: Alexander Polishchuk

>2025-05-06

> http://arxiv.org/abs/2505.04023v1

We prove that a bounded complex of coherent sheaves on an abelian variety A,
whose Fourier-Mukai transform has support of dimension at most 1, extends to a
perfect complex on the standard NC-smooth thickening of A and on the
deformation **quantization** of any constant Poisson bracket on A. We discuss a
related conjectural characterization of Jacobians in terms of NC-smooth
thickenings.


## Modal Decomposition and Identification for a Population of Structures Using Physics-Informed Graph Neural Networks and Transformers

>Authors: Xudong Jian, Kiran Bacsa, Gregory Duthé, Eleni Chatzi

>2025-05-06

> http://arxiv.org/abs/2505.04018v1

Modal identification is crucial for structural health monitoring and
structural control, providing critical insights into structural dynamics and
performance. This study presents a novel deep learning framework that
integrates graph neural networks (GNNs), transformers, and a physics-informed
loss function to achieve modal decomposition and identification across a
population of structures. The transformer module decomposes
multi-degrees-of-freedom (MDOF) structural dynamic measurements into
single-degree-of-freedom (SDOF) modal responses, facilitating the
identification of natural frequencies and damping ratios. Concurrently, the GNN
captures the structural configurations and identifies mode shapes corresponding
to the decomposed SDOF modal responses. The proposed model is trained in a
purely physics-informed and unsupervised manner, leveraging modal decomposition
theory and the independence of structural modes to guide learning without the
need for labeled data. Validation through numerical simulations and laboratory
experiments demonstrates its effectiveness in accurately decomposing dynamic
responses and identifying modal properties from **sparse** structural dynamic
measurements, regardless of variations in external loads or structural
configurations. Comparative analyses against established modal identification
techniques and model variations further underscore its superior performance,
positioning it as a favorable approach for population-based structural health
monitoring.


## A Graphical Global Optimization Framework for Parameter Estimation of Statistical Models with Nonconvex Regularization Functions

>Authors: Danial Davarnia, Mohammadreza Kiaghadi

>2025-05-06

> http://arxiv.org/abs/2505.03899v1

Optimization problems with norm-bounding constraints arise in a variety of
applications, including portfolio optimization, machine learning, and feature
selection. A common approach to these problems involves relaxing the norm
constraint via Lagrangian relaxation, transforming it into a regularization
term in the objective function. A particularly challenging class includes the
zero-norm function, which promotes **sparsity** in statistical parameter
estimation. Most existing exact methods for solving these problems introduce
binary variables and artificial bounds to reformulate them as
higher-dimensional mixed-integer programs, solvable by standard solvers. Other
exact approaches exploit specific structural properties of the objective,
making them difficult to generalize across different problem types. Alternative
methods employ nonconvex penalties with favorable statistical characteristics,
but these are typically addressed using heuristic or local optimization
techniques due to their structural complexity. In this paper, we propose a
novel graph-based method to globally solve optimization problems involving
generalized norm-bounding constraints. Our approach encompasses standard
$\ell_p$-norms for $p \in [0, \infty)$ and nonconvex penalties such as SCAD and
MCP. We leverage decision diagrams to construct strong convex relaxations
directly in the original variable space, eliminating the need for auxiliary
variables or artificial bounds. Integrated into a spatial branch-and-cut
framework, our method guarantees convergence to the global optimum. We
demonstrate its effectiveness through preliminary computational experiments on
benchmark **sparse** linear regression problems involving complex nonconvex
penalties, which are not tractable using existing global optimization
techniques.


## VITA-Audio Fast Interleaved Cross-Modal Token Generation for Efficient Large Speech-Language Model

>Authors: Zuwei Long, Yunhang Shen, Chaoyou Fu, Heting Gao, Lijiang Li, Peixian Chen, Mengdan Zhang, Hang Shao, Jian Li, Jinlong Peng, Haoyu Cao, Ke Li, Rongrong Ji, Xing Sun

>2025-05-06

> http://arxiv.org/abs/2505.03739v1

With the growing requirement for natural human-computer interaction,
speech-based systems receive increasing attention as speech is one of the most
common forms of daily communication. However, the existing speech models still
experience high latency when generating the first audio token during streaming,
which poses a significant bottleneck for deployment. To address this issue, we
propose VITA-Audio, an end-to-end large speech model with fast audio-text token
generation. Specifically, we introduce a lightweight Multiple Cross-modal Token
Prediction (MCTP) module that efficiently generates multiple audio tokens
within a single model forward pass, which not only accelerates the inference
but also significantly reduces the latency for generating the first audio in
streaming scenarios. In addition, a four-stage progressive training strategy is
explored to achieve model **acceleration** with minimal loss of speech quality. To
our knowledge, VITA-Audio is the first multi-modal large language model capable
of generating audio output during the first forward pass, enabling real-time
conversational capabilities with minimal latency. VITA-Audio is fully
reproducible and is trained on open-source data only. Experimental results
demonstrate that our model achieves an inference speedup of 3~5x at the 7B
parameter scale, but also significantly outperforms open-source models of
similar model size on multiple benchmarks for automatic speech recognition
(ASR), text-to-speech (TTS), and spoken question answering (SQA) tasks.


## Matching Distance and Geometric Distribution Aided Learning Multiview Point Cloud Registration

>Authors: Shiqi Li, Jihua Zhu, Yifan Xie, Naiwen Hu, Di Wang

>2025-05-06

> http://arxiv.org/abs/2505.03692v1

Multiview point cloud registration plays a crucial role in robotics,
automation, and computer vision fields. This paper concentrates on pose graph
construction and motion synchronization within multiview registration. Previous
methods for pose graph construction often pruned fully connected graphs or
constructed **sparse** graph using global feature aggregated from local
descriptors, which may not consistently yield reliable results. To identify
dependable pairs for pose graph construction, we design a network model that
extracts information from the matching distance between point cloud pairs. For
motion synchronization, we propose another neural network model to calculate
the absolute pose in a data-driven manner, rather than optimizing inaccurate
handcrafted loss functions. Our model takes into account geometric distribution
information and employs a modified attention mechanism to facilitate flexible
and reliable feature interaction. Experimental results on diverse indoor and
outdoor datasets confirm the effectiveness and generalizability of our
approach. The source code is available at https://github.com/Shi-Qi-Li/MDGD.


## Faster MoE LLM Inference for Extremely Large Models

>Authors: Haoqi Yang, Luohe Shi, Qiwei Li, Zuchao Li, Ping Wang, Bo Du, Mengjia Shen, Hai Zhao

>2025-05-06

> http://arxiv.org/abs/2505.03531v1

Sparse Mixture of Experts (MoE) large language models (LLMs) are gradually
becoming the mainstream approach for ultra-large-scale models. Existing
optimization efforts for MoE models have focused primarily on coarse-grained
MoE architectures. With the emergence of DeepSeek Models, fine-grained MoE
models are gaining popularity, yet research on them remains limited. Therefore,
we want to discuss the efficiency dynamic under different service loads.
Additionally, fine-grained models allow deployers to reduce the number of
routed experts, both activated counts and total counts, raising the question of
how this reduction affects the trade-off between MoE efficiency and
performance. Our findings indicate that while deploying MoE models presents
greater challenges, it also offers significant optimization opportunities.
Reducing the number of activated experts can lead to substantial efficiency
improvements in certain scenarios, with only minor performance degradation.
Reducing the total number of experts provides limited efficiency gains but
results in severe performance degradation. Our method can increase throughput
by at least 10\% without any performance degradation. Overall, we conclude that
MoE inference optimization remains an area with substantial potential for
exploration and improvement.


## High-order exponential solver method for particle-in-cell simulations

>Authors: Szilárd Majorosi, Nasr Hafz, Zsolt Lécz

>2025-05-06

> http://arxiv.org/abs/2505.03518v1

Outstanding advances in solid-state laser technology, employing the optical
parametric chirped-pulse-amplification (OPCPA) technique, have led physicists
to focus laser pulses to highly-relativistic intensities which led to novel
schemes for charged-particle **acceleration** and radiation generation in
laser-driven plasmas. Microscopic understanding of these highly nonlinear
processes is possible via accurate modeling of the laser-plasma interaction
using particle-in-cell (PIC) simulations. Numerous codes are available and they
rely on finite difference time domain methods on Yee-grids or on the analytical
solution of the Maxwell-equations in spectral space. In this work, we present a
solution bridging these two methods, which we call finite difference
exponential time domain solution. This method could provide a very high
accuracy even in 3D, but with improved locality, similar to the pseudospectral
analytical methods without relying on transformation to special basis
functions. We verified the accuracy and the convergence of the method in
various benchmarks, including laser propagation in vacuum and in underdense
plasma. We also simulated electron injection in a non-linear laser-plasma
wakefield **acceleration** and surface high-harmonic generation in the overdense
regime. The results are then compared with those obtained from standard PIC
codes.


## Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs and Retrieval-Augmented Generation

>Authors: Mohammad Shoaib Ansari, Mohd Sohail Ali Khan, Shubham Revankar, Aditya Varma, Anil S. Mokhade

>2025-05-06

> http://arxiv.org/abs/2505.03406v1

This research paper investigates the application of Large Language Models
(LLMs) in healthcare, specifically focusing on enhancing medical decision
support through Retrieval-Augmented Generation (RAG) integrated with
hospital-specific data and fine-tuning using Quantized Low-Rank Adaptation
(QLoRA). The system utilizes Llama 3.2-3B-Instruct as its foundation model. By
embedding and retrieving context-relevant healthcare information, the system
significantly improves response accuracy. QLoRA facilitates notable parameter
efficiency and memory optimization, preserving the integrity of medical
information through specialized **quantization** techniques. Our research also
shows that our model performs relatively well on various medical benchmarks,
indicating that it can be used to make basic medical suggestions. This paper
details the system's technical components, including its architecture,
**quantization** methods, and key healthcare applications such as enhanced disease
prediction from patient symptoms and medical history, treatment suggestions,
and efficient summarization of complex medical reports. We touch on the ethical
considerations-patient privacy, data security, and the need for rigorous
clinical validation-as well as the practical challenges of integrating such
systems into real-world healthcare workflows. Furthermore, the lightweight
**quantize**d weights ensure scalability and ease of deployment even in
low-resource hospital environments. Finally, the paper concludes with an
analysis of the broader impact of LLMs on healthcare and outlines future
directions for LLMs in medical settings.


## SPAP Structured Pruning via Alternating Optimization and Penalty Methods

>Authors: Hanyu Hu, Xiaoming Yuan

>2025-05-06

> http://arxiv.org/abs/2505.03373v1

The deployment of large language models (LLMs) is often constrained by their
substantial computational and memory demands. While structured **pruning** presents
a viable approach by eliminating entire network components, existing methods
suffer from performance degradation, reliance on heuristic metrics, or
expensive finetuning. To address these challenges, we propose SPAP (Structured
Pruning via Alternating Optimization and Penalty Methods), a novel and
efficient structured **pruning** framework for LLMs grounded in optimization
theory. SPAP formulates the **pruning** problem through a mixed-integer
optimization model, employs a penalty method that effectively makes **pruning**
decisions to minimize **pruning** errors, and introduces an alternating
minimization algorithm tailored to the splittable problem structure for
efficient weight updates and performance recovery. Extensive experiments on
OPT, LLaMA-3/3.1/3.2, and Qwen2.5 models demonstrate SPAP's superiority over
state-of-the-art methods, delivering linear inference speedups (1.29$\times$ at
30% **sparsity**) and proportional memory reductions. Our work offers a practical,
optimization-driven solution for **pruning** LLMs while preserving model
performance.


## Geospatial Mechanistic Interpretability of Large Language Models

>Authors: Stef De Sabbata, Stefano Mizzaro, Kevin Roitero

>2025-05-06

> http://arxiv.org/abs/2505.03368v1

Large Language Models (LLMs) have demonstrated unprecedented capabilities
across various natural language processing tasks. Their ability to process and
generate viable text and code has made them ubiquitous in many fields, while
their deployment as knowledge bases and "reasoning" tools remains an area of
ongoing research. In geography, a growing body of literature has been focusing
on evaluating LLMs' geographical knowledge and their ability to perform spatial
reasoning. However, very little is still known about the internal functioning
of these models, especially about how they process geographical information.
  In this chapter, we establish a novel framework for the study of geospatial
mechanistic interpretability - using spatial analysis to reverse engineer how
LLMs handle geographical information. Our aim is to advance our understanding
of the internal representations that these complex models generate while
processing geographical information - what one might call "how LLMs think about
geographic information" if such phrasing was not an undue anthropomorphism.
  We first outline the use of probing in revealing internal structures within
LLMs. We then introduce the field of mechanistic interpretability, discussing
the superposition hypothesis and the role of **sparse** autoencoders in
disentangling polysemantic internal representations of LLMs into more
interpretable, monosemantic features. In our experiments, we use spatial
autocorrelation to show how features obtained for placenames display spatial
patterns related to their geographic location and can thus be interpreted
geospatially, providing insights into how these models process geographical
information. We conclude by discussing how our framework can help shape the
study and use of foundation models in geography.


## Physics-Informed Neural Networks in Electromagnetic and Nanophotonic Design

>Authors: Omar A. M. Abdelraouf, Abdulrahman M. A. Ahmed, Emadeldeen Eldele, Ahmed A. Omar

>2025-05-06

> http://arxiv.org/abs/2505.03354v1

The fusion of artificial intelligence (AI) with physics-guided frameworks has
opened transformative avenues for advancing the design and optimization of
electromagnetic and nanophotonic systems. Innovations in deep neural networks
(DNNs) and physics-informed neural networks (PINNs) now provide robust tools to
tackle longstanding challenges in light scattering engineering, meta-optics,
and nonlinear photonics. This review outlines recent progress in leveraging
these computational methodologies to enhance device performance across domains
such as dynamic light modulation, antenna design, and nonlinear optical
phenomena. We systematically survey advancements in AI-driven forward and
inverse design strategies, which bypass conventional trial-and-error approaches
by embedding physical laws directly into optimization workflows. Furthermore,
the integration of AI accelerates electromagnetic simulations and enables
precise modelling of complex optical effects, including topological photonic
states and nonlinear interactions. A comparative evaluation of algorithmic
frameworks highlights their strengths in balancing computational efficiency,
multi-objective optimization, and fabrication feasibility. Challenges such as
limited interpretability of AI models and data scarcity for unconventional
optical modes are critically addressed. Finally, we emphasize future
opportunities in scalable multi-physics modelling, adaptive architectures, and
practical deployment of AI-optimized photonic devices. This work underscores
the pivotal role of AI in transcending traditional design limitations, thereby
propelling the development of next-generation photonic technologies with
unprecedented functionality and efficiency.


## Accelerated inverse design of passive Si Photonics

>Authors: Anton Sofronov, Dina Yakovleva, Alexander Yakubovich

>2025-05-06

> http://arxiv.org/abs/2505.03352v1

We present an accurate differentiable parametrization scheme for topological
optimization and inverse design of passive components of integrated Si
photonics. We show that the most of operations in the transformation chain from
control variables to effective anisotropic dielectric tensor discretized on the
Yee grid are expressible in terms of generalized convolutions that can be
computed efficiently on GPU accelerators. Combined with the recent open-source
GPU FDTD code and custom gradient-descent optimizer with dynamic control of
final design manufacturability, it results in fast inverse design tool capable
of producing reliable Si photonic component layouts in minutes/hours instead of
days. The final designs, although not globally optimal, are generally
physically meaningful since they reflect how fields themselves tend to
propagate through the device in the most efficient way.


## IAFormer Interaction-Aware Transformer network for collider data analysis

>Authors: W. Esmail, A. Hammad, M. Nojiri

>2025-05-06

> http://arxiv.org/abs/2505.03258v1

In this paper, we introduce IAFormer, a novel Transformer-based architecture
that efficiently integrates pairwise particle interactions through a dynamic
**sparse** attention mechanism. The IAformer has two new mechanisms within the
model. First, the attention matrix depends on predefined boost invariant
pairwise quantities, reducing the network parameter significantly from the
original particle transformer models. Second, IAformer incorporate the **sparse**
attention mechanism by utilizing the ``differential attention'', so that it can
dynamically prioritizes relevant particle tokens while reducing computational
overhead associated with less informative ones. This approach significantly
lowers the model complexity without compromising performance. Despite being
computationally efficient by more than an order of magnitude than the Particle
Transformer network, IAFormer achieves state-of-the-art performance in
classification tasks on the Top and quark-gluon datasets. Furthermore, we
employ AI interpretability techniques, verifying that the model effectively
captures physically meaningful information layer by layer through its **sparse**
attention mechanism, building an efficient network output that is resistant to
statistical fluctuations. IAformer highlights the need to **sparse** attention in
any Transformer analysis to reduce the network size while improving its
performance.


## PROM Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs

>Authors: Lukas Meiner, Jens Mehnert, Alexandru Paul Condurache

>2025-05-06

> http://arxiv.org/abs/2505.03254v1

Convolutional neural networks (CNNs) are crucial for computer vision tasks on
resource-constrained devices. Quantization effectively compresses these models,
reducing storage size and energy cost. However, in modern depthwise-separable
architectures, the computational cost is distributed unevenly across its
components, with pointwise operations being the most expensive. By applying a
general **quantization** scheme to this imbalanced cost distribution, existing
**quantization** approaches fail to fully exploit potential efficiency gains. To
this end, we introduce PROM, a straightforward approach for quantizing modern
depthwise-separable convolutional networks by selectively using two distinct
bit-widths. Specifically, pointwise convolutions are **quantize**d to ternary
weights, while the remaining modules use 8-bit weights, which is achieved
through a simple **quantization**-aware training procedure. Additionally, by
quantizing activations to 8-bit, our method transforms pointwise convolutions
with ternary weights into int8 additions, which enjoy broad support across
hardware platforms and effectively eliminates the need for expensive
multiplications. Applying PROM to MobileNetV2 reduces the model's energy cost
by more than an order of magnitude (23.9x) and its storage size by 2.7x
compared to the float16 baseline while retaining similar classification
performance on ImageNet. Our method advances the Pareto frontier for energy
consumption vs. top-1 accuracy for **quantize**d convolutional models on ImageNet.
PROM addresses the challenges of quantizing depthwise-separable convolutional
networks to both ternary and 8-bit weights, offering a simple way to reduce
energy cost and storage size.


## QiMeng-CPU-v2 Automated Superscalar Processor Design by Learning Data Dependencies

>Authors: Shuyao Cheng, Rui Zhang, Wenkai He, Pengwei Jin, Chongxiao Li, Zidong Du, Xing Hu, Yifan Hao, Guanglin Xu, Yuanbo Wen, Ling Li, Qi Guo, Yunji Chen

>2025-05-06

> http://arxiv.org/abs/2505.03195v1

Automated processor design, which can significantly reduce human efforts and
accelerate design cycles, has received considerable attention. While recent
advancements have automatically designed single-cycle processors that execute
one instruction per cycle, their performance cannot compete with modern
superscalar processors that execute multiple instructions per cycle. Previous
methods fail on superscalar processor design because they cannot address
inter-instruction data dependencies, leading to inefficient sequential
instruction execution.
  This paper proposes a novel approach to automatically designing superscalar
processors using a hardware-friendly model called the Stateful Binary
Speculation Diagram (State-BSD). We observe that processor parallelism can be
enhanced through on-the-fly inter-instruction dependent data predictors,
reusing the processor's internal states to learn the data dependency. To meet
the challenge of both hardware-resource limitation and design functional
correctness, State-BSD consists of two components: 1) a lightweight
state-selector trained by the simulated annealing method to detect the most
reusable processor states and store them in a small buffer; and 2) a highly
precise state-speculator trained by the BSD expansion method to predict the
inter-instruction dependent data using the selected states. It is the first
work to achieve the automated superscalar processor design, i.e. QiMeng-CPU-v2,
which improves the performance by about $380\times$ than the state-of-the-art
automated design and is comparable to human-designed superscalar processors
such as ARM Cortex A53.


## Holmes Automated Fact Check with Large Language Models

>Authors: Haoran Ou, Gelei Deng, Xingshuo Han, Jie Zhang, Xinlei He, Han Qiu, Shangwei Guo, Tianwei Zhang

>2025-05-06

> http://arxiv.org/abs/2505.03135v1

The rise of Internet connectivity has accelerated the spread of
disinformation, threatening societal trust, decision-making, and national
security. Disinformation has evolved from simple text to complex multimodal
forms combining images and text, challenging existing detection methods.
Traditional deep learning models struggle to capture the complexity of
multimodal disinformation. Inspired by advances in AI, this study explores
using Large Language Models (LLMs) for automated disinformation detection. The
empirical study shows that (1) LLMs alone cannot reliably assess the
truthfulness of claims; (2) providing relevant evidence significantly improves
their performance; (3) however, LLMs cannot autonomously search for accurate
evidence. To address this, we propose Holmes, an end-to-end framework featuring
a novel evidence retrieval method that assists LLMs in collecting high-quality
evidence. Our approach uses (1) LLM-powered summarization to extract key
information from open sources and (2) a new algorithm and metrics to evaluate
evidence quality. Holmes enables LLMs to verify claims and generate
justifications effectively. Experiments show Holmes achieves 88.3% accuracy on
two open-source datasets and 90.2% in real-time verification tasks. Notably,
our improved evidence retrieval boosts fact-checking accuracy by 30.8% over
existing methods

