# 2025-07-11

# Table of Contents
* [4KAgent Agentic Any Image to 4K Super-Resolution](#4KAgent-Agentic-Any-Image-to-4K-Super-Resolution)
* [Boosting Parameter Efficiency in LLM-Based Recommendation through Sophisticated Pruning](#Boosting-Parameter-Efficiency-in-LLM-Based-Recommendation-through-Sophisticated-Pruning)
* [Opto-ViT Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics](#Opto-ViT-Architecting-a-Near-Sensor-Region-of-Interest-Aware-Vision-Transformer-Accelerator-with-Silicon-Photonics)
* [SimCortex Collision-free Simultaneous Cortical Surfaces Reconstruction](#SimCortex-Collision-free-Simultaneous-Cortical-Surfaces-Reconstruction)
* [Know Your Attention Maps Class-specific Token Masking for Weakly Supervised Semantic Segmentation](#Know-Your-Attention-Maps-Class-specific-Token-Masking-for-Weakly-Supervised-Semantic-Segmentation)
* [Adaptive Termination for Multi-round Parallel Reasoning An Universal Semantic Entropy-Guided Framework](#Adaptive-Termination-for-Multi-round-Parallel-Reasoning-An-Universal-Semantic-Entropy-Guided-Framework)
* [QoE Optimization for Semantic Self-Correcting Video Transmission in Multi-UAV Networks](#QoE-Optimization-for-Semantic-Self-Correcting-Video-Transmission-in-Multi-UAV-Networks)
* [Text-promptable Object Counting via Quantity Awareness Enhancement](#Text-promptable-Object-Counting-via-Quantity-Awareness-Enhancement)
* [Graph Learning for Cooperative Cell-Free ISAC Systems From Optimization to Estimation](#Graph-Learning-for-Cooperative-Cell-Free-ISAC-Systems-From-Optimization-to-Estimation)
* [SlimCaching Edge Caching of Mixture-of-Experts for Distributed Inference](#SlimCaching-Edge-Caching-of-Mixture-of-Experts-for-Distributed-Inference)
* [Direct Regret Optimization in Bayesian Optimization](#Direct-Regret-Optimization-in-Bayesian-Optimization)
* [SpindleKV A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers](#SpindleKV-A-Novel-KV-Cache-Reduction-Method-Balancing-Both-Shallow-and-Deep-Layers)
* [MoFE-Time Mixture of Frequency Domain Experts for Time-Series Forecasting Models](#MoFE-Time-Mixture-of-Frequency-Domain-Experts-for-Time-Series-Forecasting-Models)
* [Video-RTS Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning](#Video-RTS-Rethinking-Reinforcement-Learning-and-Test-Time-Scaling-for-Efficient-and-Enhanced-Video-Reasoning)
* [IMPACT Industrial Machine Perception via Acoustic Cognitive Transformer](#IMPACT-Industrial-Machine-Perception-via-Acoustic-Cognitive-Transformer)
* [Expressive and Unclonable Photonic Circuits Based on Disordered Moiré Quasicrystals](#Expressive-and-Unclonable-Photonic-Circuits-Based-on-Disordered-Moiré-Quasicrystals)
* [Energy-Efficient Supervised Learning with a Binary Stochastic Forward-Forward Algorithm](#Energy-Efficient-Supervised-Learning-with-a-Binary-Stochastic-Forward-Forward-Algorithm)
* [FedPhD Federated Pruning with Hierarchical Learning of Diffusion Models](#FedPhD-Federated-Pruning-with-Hierarchical-Learning-of-Diffusion-Models)
* [Exploring Task Performance with Interpretable Models via Sparse Auto-Encoders](#Exploring-Task-Performance-with-Interpretable-Models-via-Sparse-Auto-Encoders)
* [SLDB An End-To-End Heterogeneous System-on-Chip Benchmark Suite for LLM-Aided Design](#SLDB-An-End-To-End-Heterogeneous-System-on-Chip-Benchmark-Suite-for-LLM-Aided-Design)
* [ETT Expanding the Long Context Understanding Capability of LLMs at Test-Time](#ETT-Expanding-the-Long-Context-Understanding-Capability-of-LLMs-at-Test-Time)
* [Efficiency-Effectiveness Reranking FLOPs for LLM-based Rerankers](#Efficiency-Effectiveness-Reranking-FLOPs-for-LLM-based-Rerankers)
* [SQLBarber A System Leveraging Large Language Models to Generate Customized and Realistic SQL Workloads](#SQLBarber-A-System-Leveraging-Large-Language-Models-to-Generate-Customized-and-Realistic-SQL-Workloads)
* [Reference compositions for bismuth telluride thermoelectric materials for low-temperature power generation](#Reference-compositions-for-bismuth-telluride-thermoelectric-materials-for-low-temperature-power-generation)
* [Taming Data Challenges in ML-based Security Tasks Lessons from Integrating Generative AI](#Taming-Data-Challenges-in-ML-based-Security-Tasks-Lessons-from-Integrating-Generative-AI)
* [QS4D Quantization-aware training for efficient hardware deployment of structured state-space sequential models](#QS4D-Quantization-aware-training-for-efficient-hardware-deployment-of-structured-state-space-sequential-models)
* [Hierarchical Interaction Summarization and Contrastive Prompting for Explainable Recommendations](#Hierarchical-Interaction-Summarization-and-Contrastive-Prompting-for-Explainable-Recommendations)
* [Evaluation of Large Language Model-Driven AutoML in Data and Model Management from Human-Centered Perspective](#Evaluation-of-Large-Language-Model-Driven-AutoML-in-Data-and-Model-Management-from-Human-Centered-Perspective)
* [Chat-Ghosting A Comparative Study of Methods for Auto-Completion in Dialog Systems](#Chat-Ghosting-A-Comparative-Study-of-Methods-for-Auto-Completion-in-Dialog-Systems)
* [A Wireless Foundation Model for Multi-Task Prediction](#A-Wireless-Foundation-Model-for-Multi-Task-Prediction)
* [Constella Supporting Storywriters' Interconnected Character Creation through LLM-based Multi-Agents](#Constella-Supporting-Storywriters'-Interconnected-Character-Creation-through-LLM-based-Multi-Agents)
* [Text-Guided Token Communication for Wireless Image Transmission](#Text-Guided-Token-Communication-for-Wireless-Image-Transmission)
* [A Satellite-Ground Synergistic Large Vision-Language Model System for Earth Observation](#A-Satellite-Ground-Synergistic-Large-Vision-Language-Model-System-for-Earth-Observation)
* [Multi-patch/multiple-scattering frequency-time hybrid solver for interior and exterior wave equation problems](#Multi-patch/multiple-scattering-frequency-time-hybrid-solver-for-interior-and-exterior-wave-equation-problems)
* [Large Language Models for Agent-Based Modelling Current and possible uses across the modelling cycle](#Large-Language-Models-for-Agent-Based-Modelling-Current-and-possible-uses-across-the-modelling-cycle)
* [DRAGON Dynamic RAG Benchmark On News](#DRAGON-Dynamic-RAG-Benchmark-On-News)
* [LLMs are Introvert](#LLMs-are-Introvert)
* [Domain adaptation of large language models for geotechnical applications](#Domain-adaptation-of-large-language-models-for-geotechnical-applications)
* [Baton Compensate for Missing Wi-Fi Features for Practical Device-free Tracking](#Baton-Compensate-for-Missing-Wi-Fi-Features-for-Practical-Device-free-Tracking)
* [GTRSS Graph-based Top-$k$ Representative Similar Subtrajectory Query](#GTRSS-Graph-based-Top-$k$-Representative-Similar-Subtrajectory-Query)
* [SenseCF LLM-Prompted Counterfactuals for Intervention and Sensor Data Augmentation](#SenseCF-LLM-Prompted-Counterfactuals-for-Intervention-and-Sensor-Data-Augmentation)
* [Assessing Methodological Variability in Wastewater Surveillance A Wavelet Decomposition Approach](#Assessing-Methodological-Variability-in-Wastewater-Surveillance-A-Wavelet-Decomposition-Approach)
* [Hybrid Quantum Cryptosystems Integration of Entanglement-Assisted Decryption and Physical Phase Obfuscation](#Hybrid-Quantum-Cryptosystems-Integration-of-Entanglement-Assisted-Decryption-and-Physical-Phase-Obfuscation)
* [GLOSS Group of LLMs for Open-Ended Sensemaking of Passive Sensing Data for Health and Wellbeing](#GLOSS-Group-of-LLMs-for-Open-Ended-Sensemaking-of-Passive-Sensing-Data-for-Health-and-Wellbeing)
* [ModelCitizens Representing Community Voices in Online Safety](#ModelCitizens-Representing-Community-Voices-in-Online-Safety)
* [StreamVLN Streaming Vision-and-Language Navigation via SlowFast Context Modeling](#StreamVLN-Streaming-Vision-and-Language-Navigation-via-SlowFast-Context-Modeling)
* [Cascade Token-Sharded Private LLM Inference](#Cascade-Token-Sharded-Private-LLM-Inference)
* [All in One Visual-Description-Guided Unified Point Cloud Segmentation](#All-in-One-Visual-Description-Guided-Unified-Point-Cloud-Segmentation)
* [CREW-WILDFIRE Benchmarking Agentic Multi-Agent Collaborations at Scale](#CREW-WILDFIRE-Benchmarking-Agentic-Multi-Agent-Collaborations-at-Scale)
* [LVM4CSI Enabling Direct Application of Pre-Trained Large Vision Models for Wireless Channel Tasks](#LVM4CSI-Enabling-Direct-Application-of-Pre-Trained-Large-Vision-Models-for-Wireless-Channel-Tasks)
* [Sequential Attention-based Sampling for Histopathological Analysis](#Sequential-Attention-based-Sampling-for-Histopathological-Analysis)
* [Scale Dilation Dynamics in Flexible Bandwidth Needlet Constructions](#Scale-Dilation-Dynamics-in-Flexible-Bandwidth-Needlet-Constructions)
* [From Autonomy to Agency Agentic Vehicles for Human-Centered Mobility Systems](#From-Autonomy-to-Agency-Agentic-Vehicles-for-Human-Centered-Mobility-Systems)
* [Classification of autoimmune diseases from Peripheral blood TCR repertoires by multimodal multi-instance learning](#Classification-of-autoimmune-diseases-from-Peripheral-blood-TCR-repertoires-by-multimodal-multi-instance-learning)
* [The Case for Instance-Optimized LLMs in OLAP Databases](#The-Case-for-Instance-Optimized-LLMs-in-OLAP-Databases)
* [ArtifactsBench Bridging the Visual-Interactive Gap in LLM Code Generation Evaluation](#ArtifactsBench-Bridging-the-Visual-Interactive-Gap-in-LLM-Code-Generation-Evaluation)
* [LIFT Automating Symbolic Execution Optimization with Large Language Models for AI Networks](#LIFT-Automating-Symbolic-Execution-Optimization-with-Large-Language-Models-for-AI-Networks)
* [DoPI Doctor-like Proactive Interrogation LLM for Traditional Chinese Medicine](#DoPI-Doctor-like-Proactive-Interrogation-LLM-for-Traditional-Chinese-Medicine)
* [From Imitation to Innovation The Emergence of AI Unique Artistic Styles and the Challenge of Copyright Protection](#From-Imitation-to-Innovation-The-Emergence-of-AI-Unique-Artistic-Styles-and-the-Challenge-of-Copyright-Protection)
* [FurniMAS Language-Guided Furniture Decoration using Multi-Agent System](#FurniMAS-Language-Guided-Furniture-Decoration-using-Multi-Agent-System)
* [A Tale of Two Scripts Transliteration and Post-Correction for Judeo-Arabic](#A-Tale-of-Two-Scripts-Transliteration-and-Post-Correction-for-Judeo-Arabic)
* [Who's the Mole? Modeling and Detecting Intention-Hiding Malicious Agents in LLM-Based Multi-Agent Systems](#Who's-the-Mole?-Modeling-and-Detecting-Intention-Hiding-Malicious-Agents-in-LLM-Based-Multi-Agent-Systems)
* [LOOM-Scope a comprehensive and efficient LOng-cOntext Model evaluation framework](#LOOM-Scope-a-comprehensive-and-efficient-LOng-cOntext-Model-evaluation-framework)
* [LumiCRS Asymmetric Contrastive Prototype Learning for Long-Tail Conversational Movie Recommendation](#LumiCRS-Asymmetric-Contrastive-Prototype-Learning-for-Long-Tail-Conversational-Movie-Recommendation)
* [VectorLLM Human-like Extraction of Structured Building Contours vis Multimodal LLMs](#VectorLLM-Human-like-Extraction-of-Structured-Building-Contours-vis-Multimodal-LLMs)
* [Simultaneous Localization and Mapping Using Active mmWave Sensing in 5G NR](#Simultaneous-Localization-and-Mapping-Using-Active-mmWave-Sensing-in-5G-NR)
* [Enhancing Data Processing Efficiency in Blockchain Enabled Metaverse over Wireless Communications](#Enhancing-Data-Processing-Efficiency-in-Blockchain-Enabled-Metaverse-over-Wireless-Communications)
* [LTMSformer A Local Trend-Aware Attention and Motion State Encoding Transformer for Multi-Agent Trajectory Prediction](#LTMSformer-A-Local-Trend-Aware-Attention-and-Motion-State-Encoding-Transformer-for-Multi-Agent-Trajectory-Prediction)
* [Can Prompt Difficulty be Online Predicted for Accelerating RL Finetuning of Reasoning Models?](#Can-Prompt-Difficulty-be-Online-Predicted-for-Accelerating-RL-Finetuning-of-Reasoning-Models?)
* [Multimodal LLM Integrated Semantic Communications for 6G Immersive Experiences](#Multimodal-LLM-Integrated-Semantic-Communications-for-6G-Immersive-Experiences)


## 4KAgent Agentic Any Image to 4K Super-Resolution

>Authors: Yushen Zuo, Qi Zheng, Mingyang Wu, Xinrui Jiang, Renjie Li, Jian Wang, Yide Zhang, Gengchen Mai, Lihong V. Wang, James Zou, Xiaoyu Wang, Ming-Hsuan Yang, Zhengzhong Tu

>2025-07-09

> http://arxiv.org/abs/2507.07105v1

We present 4KAgent, a unified agentic super-resolution generalist system
designed to universally upscale any image to 4K resolution (and even higher, if
applied iteratively). Our system can transform images from extremely low
resolutions with severe degradations, for example, highly distorted inputs at
256x256, into crystal-clear, photorealistic 4K outputs. 4KAgent comprises three
core components: (1) Profiling, a module that customizes the 4KAgent pipeline
based on bespoke use cases; (2) A Perception Agent, which leverages
vision-language models alongside image quality assessment experts to analyze
the input image and make a tailored restoration plan; and (3) A Restoration
Agent, which executes the plan, following a recursive execution-reflection
paradigm, guided by a quality-driven mixture-of-expert policy to select the
optimal output for each step. Additionally, 4KAgent embeds a specialized face
restoration pipeline, significantly enhancing facial details in portrait and
selfie photos. We rigorously evaluate our 4KAgent across 11 distinct task
categories encompassing a total of 26 diverse benchmarks, setting new
state-of-the-art on a broad spectrum of imaging domains. Our evaluations cover
natural images, portrait photos, AI-generated content, satellite imagery,
fluorescence microscopy, and medical imaging like fundoscopy, ultrasound, and
X-ray, demonstrating superior performance in terms of both perceptual (e.g.,
NIQE, MUSIQ) and fidelity (e.g., PSNR) metrics. By establishing a novel agentic
paradigm for low-level vision tasks, we aim to catalyze broader interest and
innovation within vision-centric autonomous agents across diverse research
communities. We will release all the code, models, and results at:
https://4kagent.github.io.


## Boosting Parameter Efficiency in LLM-Based Recommendation through Sophisticated Pruning

>Authors: Shanle Zheng, Keqin Bao, Jizhi Zhang, Yang Zhang, Fuli Feng, Xiangnan He

>2025-07-09

> http://arxiv.org/abs/2507.07064v1

LLM-based recommender systems have made significant progress; however, the
deployment cost associated with the large parameter volume of LLMs still
hinders their real-world applications. This work explores parameter **pruning** to
improve parameter efficiency while maintaining recommendation quality, thereby
enabling easier deployment. Unlike existing approaches that focus primarily on
inter-layer redundancy, we uncover intra-layer redundancy within components
such as self-attention and MLP modules. Building on this analysis, we propose a
more fine-grained **pruning** approach that integrates both intra-layer and
layer-wise **pruning**. Specifically, we introduce a three-stage **pruning** strategy
that progressively prunes parameters at different levels and parts of the
model, moving from intra-layer to layer-wise **pruning**, or from width to depth.
Each stage also includes a performance restoration step using distillation
techniques, helping to strike a balance between performance and parameter
efficiency. Empirical results demonstrate the effectiveness of our approach:
across three datasets, our models achieve an average of 88% of the original
model's performance while **pruning** more than 95% of the non-embedding
parameters. This underscores the potential of our method to significantly
reduce resource requirements without greatly compromising recommendation
quality. Our code will be available at: https://github.com/zheng-sl/PruneRec


## Opto-ViT Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics

>Authors: Mehrdad Morsali, Chengwei Zhou, Deniz Najafi, Sreetama Sarkar, Pietro Mercati, Navid Khoshavi, Peter Beerel, Mahdi Nikdast, Gourav Datta, Shaahin Angizi

>2025-07-09

> http://arxiv.org/abs/2507.07044v1

Vision Transformers (ViTs) have emerged as a powerful architecture for
computer vision tasks due to their ability to model long-range dependencies and
global contextual relationships. However, their substantial compute and memory
demands hinder efficient deployment in scenarios with strict energy and
bandwidth limitations. In this work, we propose OptoViT, the first near-sensor,
region-aware ViT accelerator leveraging silicon photonics (SiPh) for real-time
and energy-efficient vision processing. Opto-ViT features a hybrid
electronic-photonic architecture, where the optical core handles
compute-intensive matrix multiplications using Vertical-Cavity Surface-Emitting
Lasers (VCSELs) and Microring Resonators (MRs), while nonlinear functions and
normalization are executed electronically. To reduce redundant computation and
patch processing, we introduce a lightweight Mask Generation Network (MGNet)
that identifies regions of interest in the current frame and prunes irrelevant
patches before ViT encoding. We further co-optimize the ViT backbone using
quantization-aware training and matrix decomposition tailored for photonic
constraints. Experiments across device fabrication, circuit and architecture
co-design, to classification, detection, and video tasks demonstrate that
OptoViT achieves 100.4 KFPS/W with up to 84% energy savings with less than 1.6%
accuracy loss, while enabling scalable and efficient ViT deployment at the
edge.


## SimCortex Collision-free Simultaneous Cortical Surfaces Reconstruction

>Authors: Kaveh Moradkhani, R Jarrett Rushmore, Sylvain Bouix

>2025-07-09

> http://arxiv.org/abs/2507.06955v1

Accurate cortical surface reconstruction from magnetic resonance imaging
(MRI) data is crucial for reliable neuroanatomical analyses. Current methods
have to contend with complex cortical geometries, strict topological
requirements, and often produce surfaces with **overlap**s, self-intersections, and
topological defects. To overcome these shortcomings, we introduce SimCortex, a
deep learning framework that simultaneously reconstructs all brain surfaces
(left/right white-matter and pial) from T1-weighted(T1w) MRI volumes while
preserving topological properties. Our method first segments the T1w image into
a nine-class tissue label map. From these segmentations, we generate
subject-specific, collision-free initial surface meshes. These surfaces serve
as precise initializations for subsequent multiscale diffeomorphic
deformations. Employing stationary velocity fields (SVFs) integrated via
scaling-and-squaring, our approach ensures smooth, topology-preserving
transformations with significantly reduced surface collisions and
self-intersections. Evaluations on standard datasets demonstrate that SimCortex
dramatically reduces surface **overlap**s and self-intersections, surpassing
current methods while maintaining state-of-the-art geometric accuracy.


## Know Your Attention Maps Class-specific Token Masking for Weakly Supervised Semantic Segmentation

>Authors: Joelle Hanna, Damian Borth

>2025-07-09

> http://arxiv.org/abs/2507.06848v1

Weakly Supervised Semantic Segmentation (WSSS) is a challenging problem that
has been extensively studied in recent years. Traditional approaches often rely
on external modules like Class Activation Maps to highlight regions of interest
and generate pseudo segmentation masks. In this work, we propose an end-to-end
method that directly utilizes the attention maps learned by a Vision
Transformer (ViT) for WSSS. We propose training a **sparse** ViT with multiple
[CLS] tokens (one for each class), using a random masking strategy to promote
[CLS] token - class assignment. At inference time, we aggregate the different
self-attention maps of each [CLS] token corresponding to the predicted labels
to generate pseudo segmentation masks. Our proposed approach enhances the
interpretability of self-attention maps and ensures accurate class assignments.
Extensive experiments on two standard benchmarks and three specialized datasets
demonstrate that our method generates accurate pseudo-masks, outperforming
related works. Those pseudo-masks can be used to train a segmentation model
which achieves results comparable to fully-supervised models, significantly
reducing the need for fine-grained labeled data.


## Adaptive Termination for Multi-round Parallel Reasoning An Universal Semantic Entropy-Guided Framework

>Authors: Zenan Xu, Zexuan Qiu, Guanhua Huang, Kun Li, Siheng Li, Chenchen Zhang, Kejiao Li, Qi Yi, Yuhao Jiang, Bo Zhou, Fengzong Lian, Zhanhui Kang

>2025-07-09

> http://arxiv.org/abs/2507.06829v1

Recent advances in large language models (LLMs) have accelerated progress
toward artificial general intelligence, with inference-time scaling emerging as
a key technique. Contemporary approaches leverage either sequential reasoning
(iteratively extending chains of thought) or parallel reasoning (generating
multiple solutions simultaneously) to scale inference. However, both paradigms
face fundamental limitations: sequential scaling typically relies on arbitrary
token budgets for termination, leading to inefficiency or premature cutoff;
while parallel scaling often lacks coordination among parallel branches and
requires intrusive fine-tuning to perform effectively. In light of these
challenges, we aim to design a flexible test-time collaborative inference
framework that exploits the complementary strengths of both sequential and
parallel reasoning paradigms. Towards this goal, the core challenge lies in
developing an efficient and accurate intrinsic quality metric to assess model
responses during collaborative inference, enabling dynamic control and early
termination of the reasoning trace. To address this challenge, we introduce
semantic entropy (SE), which quantifies the semantic diversity of parallel
model responses and serves as a robust indicator of reasoning quality due to
its strong negative correlation with accuracy...


## QoE Optimization for Semantic Self-Correcting Video Transmission in Multi-UAV Networks

>Authors: Xuyang Chen, Chong Huang, Daquan Feng, Lei Luo, Yao Sun, Xiang-Gen Xia

>2025-07-09

> http://arxiv.org/abs/2507.06717v1

Real-time unmanned aerial vehicle (UAV) video streaming is essential for
time-sensitive applications, including remote surveillance, emergency response,
and environmental monitoring. However, it faces challenges such as limited
bandwidth, latency fluctuations, and high packet loss. To address these issues,
we propose a novel semantic self-correcting video transmission framework with
ultra-fine bitrate granularity (SSCV-G). In SSCV-G, video frames are encoded
into a compact semantic codebook space, and the transmitter adaptively sends a
subset of semantic indices based on bandwidth availability, enabling
fine-grained bitrate control for improved bandwidth efficiency. At the
receiver, a spatio-temporal vision transformer (ST-ViT) performs multi-frame
joint decoding to reconstruct dropped semantic indices by modeling intra- and
inter-frame dependencies. To further improve performance under dynamic network
conditions, we integrate a multi-user proximal policy optimization (MUPPO)
reinforcement learning scheme that jointly optimizes **communication** resource
allocation and semantic bitrate selection to maximize user Quality of
Experience (QoE). Extensive experiments demonstrate that the proposed SSCV-G
significantly outperforms state-of-the-art video codecs in coding efficiency,
bandwidth adaptability, and packet loss robustness. Moreover, the proposed
MUPPO-based QoE optimization consistently surpasses existing benchmarks.


## Text-promptable Object Counting via Quantity Awareness Enhancement

>Authors: Miaojing Shi, Xiaowen Zhang, Zijie Yue, Yong Luo, Cairong Zhao, Li Li

>2025-07-09

> http://arxiv.org/abs/2507.06679v1

Recent advances in large vision-language models (VLMs) have shown remarkable
progress in solving the text-promptable object counting problem. Representative
methods typically specify text prompts with object category information in
images. This however is insufficient for training the model to accurately
distinguish the number of objects in the counting task. To this end, we propose
QUANet, which introduces novel quantity-oriented text prompts with a
vision-text quantity alignment loss to enhance the model's quantity awareness.
Moreover, we propose a dual-stream adaptive counting decoder consisting of a
Transformer stream, a CNN stream, and a number of Transformer-to-CNN
enhancement adapters (T2C-adapters) for density map prediction. The
T2C-adapters facilitate the effective knowledge **communication** and aggregation
between the Transformer and CNN streams. A cross-stream quantity ranking loss
is proposed in the end to optimize the ranking orders of predictions from the
two streams. Extensive experiments on standard benchmarks such as FSC-147,
CARPK, PUCPR+, and ShanghaiTech demonstrate our model's strong generalizability
for zero-shot class-agnostic counting. Code is available at
https://github.com/viscom-tongji/QUANet


## Graph Learning for Cooperative Cell-Free ISAC Systems From Optimization to Estimation

>Authors: Peng Jiang, Ming Li, Rang Liu, Qian Liu

>2025-07-09

> http://arxiv.org/abs/2507.06612v1

Cell-free integrated sensing and **communication** (ISAC) systems have emerged as
a promising paradigm for sixth-generation (6G) networks, enabling simultaneous
high-rate data transmission and high-precision radar sensing through
cooperative distributed access points (APs). Fully exploiting these
capabilities requires a unified design that bridges system-level optimization
with multi-target parameter estimation. This paper proposes an end-to-end graph
learning approach to close this gap, modeling the entire cell-free ISAC network
as a heterogeneous graph to jointly design the AP mode selection, user
association, precoding, and echo signal processing for multi-target position
and velocity estimation. In particular, we propose two novel heterogeneous
graph learning frameworks: a dynamic graph learning framework and a lightweight
mirror-based graph attention network (mirror-GAT) framework. The dynamic graph
learning framework employs structural and temporal attention mechanisms
integrated with a three-dimensional convolutional neural network (3D-CNN),
enabling superior performance and robustness in cell-free ISAC environments.
Conversely, the mirror-GAT framework significantly reduces computational
complexity and signaling overhead through a bi-level iterative structure with
share adjacency. Simulation results validate that both proposed
graph-learning-based frameworks achieve significant improvements in
multi-target position and velocity estimation accuracy compared to conventional
heuristic and optimization-based designs. Particularly, the mirror-GAT
framework demonstrates substantial reductions in computational time and
signaling overhead, underscoring its suitability for practical deployments.


## SlimCaching Edge Caching of Mixture-of-Experts for Distributed Inference

>Authors: Qian Chen, Xianhao Chen, Kaibin Huang

>2025-07-09

> http://arxiv.org/abs/2507.06567v1

Mixture-of-Experts (MoE) models improve the scalability of large language
models (LLMs) by activating only a small subset of relevant experts per input.
However, the sheer number of expert networks in an MoE model introduces a
significant storage burden for an edge device. To address this challenge, we
consider a scenario where experts are dispersed within an edge network for
distributed inference. Based on the popular Top-$K$ expert selection strategy,
we formulate a latency minimization problem by optimizing expert caching on
edge servers under storage constraints. When $K=1$, the problem reduces to a
monotone submodular maximization problem with knapsack constraints, for which
we design a greedy-based algorithm with a $(1 - 1/e)$-approximation guarantee.
For the general case where $K\geq1$, expert co-activation within the same MoE
layer introduces non-submodularity, causing greedy methods to be ineffective.
To tackle this issue, we propose a successive greedy decomposition method to
decompose the original problem into a series of subproblems, with each being
solved by a dynamic programming approach. Furthermore, we design an accelerated
algorithm based on the max-convolution technique to obtain the approximate
solution with a provable guarantee in polynomial time. Simulation results on
various MoE models demonstrate that our method significantly reduces inference
latency compared to existing baselines.


## Direct Regret Optimization in Bayesian Optimization

>Authors: Fengxue Zhang, Yuxin Chen

>2025-07-09

> http://arxiv.org/abs/2507.06529v1

Bayesian optimization (BO) is a powerful paradigm for optimizing expensive
black-box functions. Traditional BO methods typically rely on separate
hand-crafted acquisition functions and surrogate models for the underlying
function, and often operate in a myopic manner. In this paper, we propose a
novel direct regret optimization approach that jointly learns the optimal model
and non-myopic acquisition by distilling from a set of candidate models and
acquisitions, and explicitly targets minimizing the multi-step regret. Our
framework leverages an ensemble of Gaussian Processes (GPs) with varying
hyperparameters to generate simulated BO trajectories, each guided by an
acquisition function chosen from a pool of conventional choices, until a
Bayesian early stop criterion is met. These simulated trajectories, capturing
multi-step exploration strategies, are used to train an end-to-end decision
transformer that directly learns to select next query points aimed at improving
the ultimate objective. We further adopt a dense training--**sparse** learning
paradigm: The decision transformer is trained offline with abundant simulated
data sampled from ensemble GPs and acquisitions, while a limited number of real
evaluations refine the GPs online. Experimental results on synthetic and
real-world benchmarks suggest that our method consistently outperforms BO
baselines, achieving lower simple regret and demonstrating more robust
exploration in high-dimensional or noisy settings.


## SpindleKV A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers

>Authors: Zicong Tang, Shi Luohe, Zuchao Li, Baoyuan Qi, Guoming Liu, Lefei Zhang, Ping Wang

>2025-07-09

> http://arxiv.org/abs/2507.06517v1

Large Language Models (LLMs) have achieved impressive accomplishments in
recent years. However, the increasing memory consumption of **KV** cache has
possessed a significant challenge to the inference system. Eviction methods
have revealed the inherent redundancy within the **KV** cache, demonstrating its
potential for reduction, particularly in deeper layers. However, **KV** cache
reduction for shallower layers has been found to be insufficient. Based on our
observation that, the **KV** cache exhibits a high degree of similarity. Based on
this observation, we proposed a novel **KV** cache reduction method, Spindle**KV**,
which balances both shallow and deep layers. For deep layers, we employ an
attention weight based eviction method, while for shallow layers, we apply a
codebook based replacement approach which is learnt by similarity and merging
policy. Moreover, Spindle**KV** addressed the Grouped-Query Attention (GQA) dilemma
faced by other attention based eviction methods. Experiments on two common
benchmarks with three different LLMs shown that Spindle**KV** obtained better **KV**
cache reduction effect compared to baseline methods, while preserving similar
or even better model performance.


## MoFE-Time Mixture of Frequency Domain Experts for Time-Series Forecasting Models

>Authors: Yiwen Liu, Chenyu Zhang, Junjie Song, Siqi Chen, Sun Yin, Zihan Wang, Lingming Zeng, Yuji Cao, Junming Jiao

>2025-07-09

> http://arxiv.org/abs/2507.06502v1

As a prominent data modality task, time series forecasting plays a pivotal
role in diverse applications. With the remarkable advancements in Large
Language Models (LLMs), the adoption of LLMs as the foundational architecture
for time series modeling has gained significant attention. Although existing
models achieve some success, they rarely both model time and frequency
characteristics in a pretraining-finetuning paradigm leading to suboptimal
performance in predictions of complex time series, which requires both modeling
periodicity and prior pattern knowledge of signals. We propose MoFE-Time, an
innovative time series forecasting model that integrates time and frequency
domain features within a Mixture of Experts (MoE) network. Moreover, we use the
pretraining-finetuning paradigm as our training framework to effectively
transfer prior pattern knowledge across pretraining and finetuning datasets
with different periodicity distributions. Our method introduces both frequency
and time cells as experts after attention modules and leverages the MoE routing
mechanism to construct multidimensional **sparse** representations of input
signals. In experiments on six public benchmarks, MoFE-Time has achieved new
state-of-the-art performance, reducing MSE and MAE by 6.95% and 6.02% compared
to the representative methods Time-MoE. Beyond the existing evaluation
benchmarks, we have developed a proprietary dataset, NEV-sales, derived from
real-world business scenarios. Our method achieves outstanding results on this
dataset, underscoring the effectiveness of the MoFE-Time model in practical
commercial applications.


## Video-RTS Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning

>Authors: Ziyang Wang, Jaehong Yoon, Shoubin Yu, Md Mohaiminul Islam, Gedas Bertasius, Mohit Bansal

>2025-07-09

> http://arxiv.org/abs/2507.06485v1

Despite advances in reinforcement learning (RL)-based video reasoning with
large language models (LLMs), data collection and finetuning remain significant
challenges. These methods often rely on large-scale supervised fine-tuning
(SFT) with extensive video data and long Chain-of-Thought (CoT) annotations,
making them costly and hard to scale. To address this, we present Video-RTS, a
new approach to improve video reasoning capability with drastically improved
data efficiency by combining data-efficient RL with a video-adaptive test-time
scaling (TTS) strategy. Based on observations about the data scaling of RL
samples, we skip the resource-intensive SFT step and employ efficient pure-RL
training with output-based rewards, requiring no additional annotations or
extensive fine-tuning. Furthermore, to utilize computational resources more
efficiently, we introduce a **sparse**-to-dense video TTS strategy that improves
inference by iteratively adding frames based on output consistency. We validate
our approach on multiple video reasoning benchmarks, showing that Video-RTS
surpasses existing video reasoning models by an average of 2.4% in accuracy
using only 3.6% training samples. For example, Video-RTS achieves a 4.2%
improvement on Video-Holmes, a recent and challenging video reasoning
benchmark, and a 2.6% improvement on MMVU. Notably, our pure RL training and
adaptive video TTS offer complementary strengths, enabling Video-RTS's strong
reasoning performance.


## IMPACT Industrial Machine Perception via Acoustic Cognitive Transformer

>Authors: Changheon Han, Yuseop Sim, Hoin Jung, Jiho Lee, Hojun Lee, Yun Seok Kang, Sucheol Woo, Garam Kim, Hyung Wook Park, Martin Byung-Guk Jun

>2025-07-09

> http://arxiv.org/abs/2507.06481v1

Acoustic signals from industrial machines offer valuable insights for anomaly
detection, predictive maintenance, and operational efficiency enhancement.
However, existing task-specific, supervised learning methods often scale poorly
and fail to generalize across diverse industrial scenarios, whose acoustic
characteristics are distinct from general audio. Furthermore, the scarcity of
accessible, large-scale datasets and pretrained models tailored for industrial
audio impedes community-driven research and benchmarking. To address these
challenges, we introduce DINOS (Diverse INdustrial Operation Sounds), a
large-scale open-access dataset. DINOS comprises over 74,149 audio samples
(exceeding 1,093 hours) collected from various industrial acoustic scenarios.
We also present IMPACT (Industrial Machine Perception via Acoustic Cognitive
Transformer), a novel foundation model for industrial machine sound analysis.
IMPACT is pretrained on DINOS in a self-supervised manner. By jointly
optimizing utterance and frame-level losses, it captures both global semantics
and fine-grained temporal structures. This makes its representations suitable
for efficient fine-tuning on various industrial downstream tasks with minimal
labeled data. Comprehensive benchmarking across 30 distinct downstream tasks
(spanning four machine types) demonstrates that IMPACT outperforms existing
models on 24 tasks, establishing its superior effectiveness and robustness,
while providing a new performance benchmark for future research.


## Expressive and Unclonable Photonic Circuits Based on Disordered Moiré Quasicrystals

>Authors: Farhan Bin Tarik, Yingjie Lao, Mustafa Hammood, Jonathan Barnes, Madeline Mahanloo, Lukas Chrostowski, Taufiquar Khan, Judson D. Ryckman

>2025-07-09

> http://arxiv.org/abs/2507.06473v1

Structural symmetry in photonics has long been exploited to engineer devices
with predictable, analytically describable behaviors. Yet this predictability
often limits their expressivity, constraining complex interactions essential
for advanced functionalities in computing, sensing, and security. Here we
demonstrate how low symmetry integrated photonic circuits can unlock enhanced
mode diversity and rich spectral complexity, enabling highly non-linear
transformations of input signals into outputs. Our devices, physically
unclonable moir\'e quasicrystal interferometers integrated on a silicon
photonics platform, exhibit aperiodic and reconfigurable spectral responses and
are characterized by analyticity breaking and erasable mutual information.
Using dynamic thermo-optic control to drive their complex spectral dynamics, we
demonstrate that these devices function as reconfigurable physical unclonable
functions (rPUFs). We also highlight their ability to perform high-dimensional
input--output transformations, emulating reservoir-inspired information
processing in a compact photonic platform. This work bridges the gap between
engineered and natural complexity in photonic systems, revealing new
opportunities for scalable, energy-efficient, and information-dense
opto-electronics with applications in secure **communication**s, hardware security,
advanced sensing, and optical information processing. Our results establish
low-symmetry integrated photonics as a powerful resource for complex signal
manipulation in photonic systems.


## Energy-Efficient Supervised Learning with a Binary Stochastic Forward-Forward Algorithm

>Authors: Risi Jaiswal, Supriyo Datta, Joseph G. Makin

>2025-07-09

> http://arxiv.org/abs/2507.06461v1

Reducing energy consumption has become a pressing need for modern machine
learning, which has achieved many of its most impressive results by scaling to
larger and more energy-consumptive neural networks. Unfortunately, the main
algorithm for training such networks, backpropagation, poses significant
challenges for custom hardware accelerators, due to both its serial
dependencies and the memory footprint needed to store forward activations for
the backward pass. Alternatives to backprop, although less effective, do exist;
here the main computational bottleneck becomes matrix multiplication. In this
study, we derive forward-forward algorithms for binary, stochastic units.
Binarization of the activations transforms matrix multiplications into indexing
operations, which can be executed efficiently in hardware. Stochasticity,
combined with tied weights across units with different biases, bypasses the
information bottleneck imposed by binary units. Furthermore, although slow and
expensive in traditional hardware, binary sampling that is very fast can be
implemented cheaply with p-bits (probabilistic bits), novel devices made up of
unstable magnets. We evaluate our proposed algorithms on the MNIST,
Fashion-MNIST, and CIFAR-10 datasets, showing that its performance is close to
real-valued forward-forward, but with an estimated energy savings of about one
order of magnitude.


## FedPhD Federated Pruning with Hierarchical Learning of Diffusion Models

>Authors: Qianyu Long, Qiyuan Wang, Christos Anagnostopoulos, Daning Bi

>2025-07-08

> http://arxiv.org/abs/2507.06449v1

Federated Learning (FL), as a distributed learning paradigm, trains models
over distributed clients' data. FL is particularly beneficial for distributed
training of Diffusion Models (DMs), which are high-quality image generators
that require diverse data. However, challenges such as high **communication** costs
and data heterogeneity persist in training DMs similar to training Transformers
and Convolutional Neural Networks. Limited research has addressed these issues
in FL environments. To address this gap and challenges, we introduce a novel
approach, FedPhD, designed to efficiently train DMs in FL environments. FedPhD
leverages Hierarchical FL with homogeneity-aware model aggregation and
selection policy to tackle data heterogeneity while reducing **communication**
costs. The distributed structured **pruning** of FedPhD enhances computational
efficiency and reduces model storage requirements in clients. Our experiments
across multiple datasets demonstrate that FedPhD achieves high model
performance regarding Fr\'echet Inception Distance (FID) scores while reducing
**communication** costs by up to $88\%$. FedPhD outperforms baseline methods
achieving at least a $34\%$ improvement in FID, while utilizing only $56\%$ of
the total computation and **communication** resources.


## Exploring Task Performance with Interpretable Models via Sparse Auto-Encoders

>Authors: Shun Wang, Tyler Loakman, Youbo Lei, Yi Liu, Bohao Yang, Yuting Zhao, Dong Yang, Chenghua Lin

>2025-07-08

> http://arxiv.org/abs/2507.06427v1

Large Language Models (LLMs) are traditionally viewed as black-box
algorithms, therefore reducing trustworthiness and obscuring potential
approaches to increasing performance on downstream tasks. In this work, we
apply an effective LLM decomposition method using a dictionary-learning
approach with **sparse** autoencoders. This helps extract monosemantic features
from polysemantic LLM neurons. Remarkably, our work identifies model-internal
misunderstanding, allowing the automatic reformulation of the prompts with
additional annotations to improve the interpretation by LLMs. Moreover, this
approach demonstrates a significant performance improvement in downstream
tasks, such as mathematical reasoning and metaphor detection.


## SLDB An End-To-End Heterogeneous System-on-Chip Benchmark Suite for LLM-Aided Design

>Authors: Elisavet Lydia Alvanaki, Kevin Lee, Luca P. Carloni

>2025-07-08

> http://arxiv.org/abs/2507.06376v1

Over the last few years, Large Language Models (LLMs) have emerged as a
valuable tool for Electronic Design Automation (EDA). State-of-the-art research
in LLM-aided design has demonstrated the ability of LLMs to generate
syntactically correct RTL code, showcasing encouraging prospects for
integrating AI into the hardware design process. A key enabler of these
advancements is the availability of high-quality benchmarks to evaluate new
approaches. However, existing datasets and benchmarks fall short of
system-level design, as they focus primarily on component-level information and
low-complexity designs. To address this gap, we introduce the System-Level
Design Benchmark (SLDB), a dataset tailored for evaluating LLMs in system-level
integration and configuration tasks. SLDB includes a curated benchmark suite of
10 baseline SoC designs, whose components can be combined into an exponential
number of distinct tile-based SoCs through a synthetic library. The dataset
provides full SoC configurations, accelerator integration code, **communication**
parameters, and accelerator-aware system configurations, along with
testing-application code, compatible with the ESP platform[1].


## ETT Expanding the Long Context Understanding Capability of LLMs at Test-Time

>Authors: Kiarash Zahirnia, Zahra Golpayegani, Walid Ahmad, Yang Liu

>2025-07-08

> http://arxiv.org/abs/2507.06313v1

Transformer-based Language Models' computation and memory overhead increase
quadratically as a function of sequence length. The quadratic cost poses
challenges when employing LLMs for processing long sequences. In this work, we
introduce \ourmodelacronym~(Extend at Test-Time), method for extending the
context length of short context Transformer-based LLMs, with constant memory
requirement and linear computation overhead. ETT enable the extension of the
context length at test-time by efficient fine-tuning the model's parameters on
the input context, chunked into **overlap**ping small subsequences. We evaluate ETT
on LongBench by extending the context length of GPT-Large and Phi-2 up to 32
times, increasing from 1k to 32k tokens. This results in up to a 30 percent
improvement in the model's accuracy. We also study how context can be stored in
LLM's weights effectively and efficiently. Through a detailed ablation study,
we examine which Transformer modules are most beneficial to fine-tune at
test-time. Interestingly, we find that fine-tuning the second layer of the FFNs
is more effective than full fine-tuning, leading to a further improvement in
the models' accuracy.


## Efficiency-Effectiveness Reranking FLOPs for LLM-based Rerankers

>Authors: Zhiyuan Peng, Ting-ruen Wei, Tingyu Song, Yilun Zhao, Yi Fang

>2025-07-08

> http://arxiv.org/abs/2507.06223v1

Large Language Models (LLMs) have recently been applied to reranking tasks in
information retrieval, achieving strong performance. However, their high
computational demands often hinder practical deployment. Existing studies
evaluate the efficiency of LLM-based rerankers using proxy metrics such as
latency, the number of forward passes, input tokens, and output tokens.
However, these metrics depend on hardware and running-time choices (\eg
parallel or not, batch size, etc), and often fail to account for model size,
making it difficult to interpret and obscuring the evaluation of the
efficiency-effectiveness tradeoff. To address this issue, we propose
E\textsuperscript{2}R-FLOPs, for LLM-based rerankers: ranking metrics per
PetaFLOP (RPP) for relevance per compute and queries per PetaFLOP (QPP) for
hardware-agnostic throughput. Companied with the new metrics, an interpretable
FLOPs estimator is built to estimate the FLOPs of an LLM-based reranker even
without running any experiments. Based on the proposed metrics, we conduct
comprehensive experiments to evaluate a wide range of LLM-based rerankers with
different architecture, studying the efficiency-effectiveness trade-off and
bringing this issue to the attention of the research community.


## SQLBarber A System Leveraging Large Language Models to Generate Customized and Realistic SQL Workloads

>Authors: Jiale Lao, Immanuel Trummer

>2025-07-08

> http://arxiv.org/abs/2507.06192v1

Database research and development often require a large number of SQL queries
for benchmarking purposes. However, acquiring real-world SQL queries is
challenging due to privacy concerns, and existing SQL generation methods are
limited in customization and in satisfying realistic constraints. To address
this issue, we present SQLBarber, a system based on Large Language Models
(LLMs) to generate customized and realistic SQL workloads. SQLBarber (i)
eliminates the need for users to manually craft SQL templates in advance, while
providing the flexibility to accept natural language specifications to
constrain SQL templates, (ii) scales efficiently to generate large volumes of
queries matching any user-defined cost distribution (e.g., cardinality and
execution plan cost), and (iii) uses execution statistics from Amazon Redshift
and Snowflake to derive SQL template specifications and query cost
distributions that reflect real-world query characteristics. SQLBarber
introduces (i) a declarative interface for users to effortlessly generate
customized SQL templates, (ii) an LLM-powered pipeline augmented with a
self-correction module that profiles, refines, and prunes SQL templates based
on query costs, and (iii) a Bayesian Optimizer to efficiently explore different
predicate values and identify a set of queries that satisfy the target cost
distribution. We construct and open-source ten benchmarks of varying difficulty
levels and target query cost distributions based on real-world statistics from
Snowflake and Amazon Redshift. Extensive experiments on these benchmarks show
that SQLBarber is the only system that can generate customized SQL templates.
It reduces query generation time by one to three orders of magnitude, and
significantly improves alignment with the target cost distribution, compared
with existing methods.


## Reference compositions for bismuth telluride thermoelectric materials for low-temperature power generation

>Authors: Nirma Kumari, Jaywan Chung, Seunghyun Oh, Jeongin Jang, Jongho Park, Ji Hui Son, SuDong Park, Byungki Ryu

>2025-07-08

> http://arxiv.org/abs/2507.06101v2

Thermoelectric (TE) technology enables direct heat-to-electricity conversion
and is gaining attention as a clean, fuel-saving, and carbon-neutral solution
for industrial, automotive, and marine applications. Despite nearly a century
of research, apart from successes in deep-space power sources and solid-state
cooling modules, the industrialization and commercialization of TE power
generation remain limited. Since the new millennium, nanostructured bulk
materials have accelerated the discovery of new TE systems. However, due to
limited access to high-temperature heat sources, energy harvesting still relies
almost exclusively on BiTe-based alloys, which are the only system operating
stably near room temperature. Although many BiTe-based compositions have been
proposed, concerns over reproducibility, reliability, and lifetime continue to
hinder industrial adoption. Here, we aim to develop reference BiTe-based
thermoelectric materials through data-driven analysis of Starrydata2, the
world's largest thermoelectric database. We identify Bi0.46Sb1.54Te3 and
Bi2Te2.7Se0.3 as the most frequently studied ternary compositions. These were
synthesized using hot pressing and spark-plasma sintering. Thermoelectric
properties were evaluated with respect to the processing method and measurement
direction. The results align closely with the median of reported data,
confirming the representativeness of the selected compositions. We propose
these as reference BiTe materials, accompanied by transparent data and
validated benchmarks. Their use can support the standardization of TE legs and
modules while accelerating performance evaluation and industrial integration.
We further estimated the performance of a thermoelectric module made from the
reference composition, which gives the power output of over 2.51 W and an
efficiency of 3.58% at a temperature difference of 120 K.


## Taming Data Challenges in ML-based Security Tasks Lessons from Integrating Generative AI

>Authors: Shravya Kanchi, Neal Mangaokar, Aravind Cheruvu, Sifat Muhammad Abdullah, Shirin Nilizadeh, Atul Prakash, Bimal Viswanath

>2025-07-08

> http://arxiv.org/abs/2507.06092v1

Machine learning-based supervised classifiers are widely used for security
tasks, and their improvement has been largely focused on algorithmic
advancements. We argue that data challenges that negatively impact the
performance of these classifiers have received limited attention. We address
the following research question: Can developments in Generative AI (GenAI)
address these data challenges and improve classifier performance? We propose
augmenting training datasets with synthetic data generated using GenAI
techniques to improve classifier generalization. We evaluate this approach
across 7 diverse security tasks using 6 state-of-the-art GenAI methods and
introduce a novel GenAI scheme called Nimai that enables highly controlled data
synthesis. We find that GenAI techniques can significantly improve the
performance of security classifiers, achieving improvements of up to 32.6% even
in severely data-constrained settings (only ~180 training samples).
Furthermore, we demonstrate that GenAI can facilitate rapid adaptation to
concept drift post-deployment, requiring minimal labeling in the adjustment
process. Despite successes, our study finds that some GenAI schemes struggle to
initialize (train and produce data) on certain security tasks. We also identify
characteristics of specific tasks, such as noisy labels, **overlap**ping class
distributions, and **sparse** feature vectors, which hinder performance boost using
GenAI. We believe that our study will drive the development of future GenAI
tools designed for security tasks.


## QS4D Quantization-aware training for efficient hardware deployment of structured state-space sequential models

>Authors: Sebastian Siegel, Ming-Jay Yang, Younes Bouhadjar, Maxime Fabre, Emre Neftci, John Paul Strachan

>2025-07-08

> http://arxiv.org/abs/2507.06079v1

Structured State Space models (SSM) have recently emerged as a new class of
deep learning models, particularly well-suited for processing long sequences.
Their constant memory footprint, in contrast to the linearly scaling memory
demands of Transformers, makes them attractive candidates for deployment on
resource-constrained edge-computing devices. While recent works have explored
the effect of quantization-aware training (QAT) on SSMs, they typically do not
address its implications for specialized edge hardware, for example, analog
in-memory computing (AIMC) chips. In this work, we demonstrate that QAT can
significantly reduce the complexity of SSMs by up to two orders of magnitude
across various performance metrics. We analyze the relation between model size
and numerical precision, and show that QAT enhances robustness to analog noise
and enables structural **pruning**. Finally, we integrate these techniques to
deploy SSMs on a memristive analog in-memory computing substrate and highlight
the resulting benefits in terms of computational efficiency.


## Hierarchical Interaction Summarization and Contrastive Prompting for Explainable Recommendations

>Authors: Yibin Liu, Ang Li, Shijian Li

>2025-07-08

> http://arxiv.org/abs/2507.06044v1

Explainable recommendations, which use the information of user and item with
interaction to generate a explanation for why the user would interact with the
item, are crucial for improving user trust and decision transparency to the
recommender system. Existing methods primarily rely on encoding features of
users and items to embeddings, which often leads to information loss due to
dimensionality reduction, **sparse** interactions, and so on. With the advancements
of large language models (LLMs) in language comprehension, some methods use
embeddings as LLM inputs for explanation generation. However, since embeddings
lack inherent semantics, LLMs must adjust or extend their parameters to
interpret them, a process that inevitably incurs information loss. To address
this issue, we propose a novel approach combining profile generation via
hierarchical interaction summarization (PGHIS), which leverages a pretrained
LLM to hierarchically summarize user-item interactions, generating structured
textual profiles as explicit representations of user and item characteristics.
Additionally, we propose contrastive prompting for explanation generation
(CPEG) which employs contrastive learning to guide another reasoning language
models in producing high-quality ground truth recommendation explanations.
Finally, we use the textual profiles of user and item as input and high-quality
explanation as output to fine-tune a LLM for generating explanations.
Experimental results on multiple datasets demonstrate that our approach
outperforms existing state-of-the-art methods, achieving a great improvement on
metrics about explainability (e.g., 5% on GPTScore) and text quality.
Furthermore, our generated ground truth explanations achieve a significantly
higher win rate compared to user-written reviews and those produced by other
methods, demonstrating the effectiveness of CPEG in generating high-quality
ground truths.


## Evaluation of Large Language Model-Driven AutoML in Data and Model Management from Human-Centered Perspective

>Authors: Jiapeng Yao, Lantian Zhang, Jiping Huang

>2025-07-08

> http://arxiv.org/abs/2507.05962v1

As organizations increasingly seek to leverage machine learning (ML)
capabilities, the technical complexity of implementing ML solutions creates
significant barriers to adoption and impacts operational efficiency. This
research examines how Large Language Models (LLMs) can transform the
accessibility of ML technologies within organizations through a human-centered
Automated Machine Learning (AutoML) approach. Through a comprehensive user
study involving 15 professionals across various roles and technical
backgrounds, we evaluate the organizational impact of an LLM-based AutoML
framework compared to traditional implementation methods. Our research offers
four significant contributions to both management practice and technical
innovation: First, we present pioneering evidence that LLM-based interfaces can
dramatically improve ML implementation success rates, with 93.34% of users
achieved superior performance in the LLM condition, with 46.67% showing higher
accuracy (10-25% improvement over baseline) and 46.67% demonstrating
significantly higher accuracy (>25% improvement over baseline), while 6.67%
maintained comparable performance levels; and 60% reporting substantially
reduced development time. Second, we demonstrate how natural language
interfaces can effectively bridge the technical skills gap in organizations,
cutting implementation time by 50% while improving accuracy across all
expertise levels. Third, we provide valuable insights for organizations
designing human-AI collaborative systems, showing that our approach reduced
error resolution time by 73% and significantly accelerated employee learning
curves. Finally, we establish empirical support for natural language as an
effective interface for complex technical systems, offering organizations a
path to democratize ML capabilities without compromising quality or
performance.


## Chat-Ghosting A Comparative Study of Methods for Auto-Completion in Dialog Systems

>Authors: Sandeep Mishra, Anubhab Mandal, Bishal Santra, Tushar Abhishek, Pawan Goyal, Manish Gupta

>2025-07-08

> http://arxiv.org/abs/2507.05940v1

Ghosting, the ability to predict a user's intended text input for inline
query auto-completion, is an invaluable feature for modern search engines and
chat interfaces, greatly enhancing user experience. By suggesting completions
to incomplete queries (or prefixes), ghosting aids users with slow typing
speeds, disabilities, or limited language proficiency. Ghosting is a
challenging problem and has become more important with the ubiquitousness of
chat-based systems like ChatGPT, Copilot, etc. Despite the increasing
prominence of chat-based systems utilizing ghosting, this challenging problem
of Chat-Ghosting has received little attention from the NLP/ML research
community. There is a lack of standardized benchmarks and relative performance
analysis of deep learning and non-deep learning methods. We address this
through an open and thorough study of this problem using four publicly
available dialog datasets: two human-human (DailyDialog and DSTC7-Ubuntu) and
two human-bot (Open Assistant and ShareGPT). We experiment with various
existing query auto-completion methods (using tries), n-gram methods and deep
learning methods, with and without dialog context. We also propose a novel
entropy-based dynamic early stopping strategy. Our analysis finds that
statistical n-gram models and tries outperform deep learning based models in
terms of both model performance and inference efficiency for seen prefixes. For
unseen queries, neural models like T5 and Phi-2 lead to better results. Adding
conversational context leads to significant improvements in ghosting quality,
especially for Open-Assistant and ShareGPT. We make code and data publicly
available


## A Wireless Foundation Model for Multi-Task Prediction

>Authors: Yucheng Sheng, Jiacheng Wang, Xingyu Zhou, Le Liang, Hao Ye, Shi Jin, Geoffrey Ye Li

>2025-07-08

> http://arxiv.org/abs/2507.05938v2

With the growing complexity and dynamics of the mobile **communication**
networks, accurately predicting key system parameters, such as channel state
information (CSI), user location, and network traffic, has become essential for
a wide range of physical (PHY)-layer and medium access control (MAC)-layer
tasks. Although traditional deep learning (DL)-based methods have been widely
applied to such prediction tasks, they often struggle to generalize across
different scenarios and tasks. In response, we propose a unified foundation
model for multi-task prediction in wireless networks that supports diverse
prediction intervals. The proposed model enforces univariate decomposition to
unify heterogeneous tasks, encodes granularity for interval awareness, and uses
a causal Transformer backbone for accurate predictions. Additionally, we
introduce a patch masking strategy during training to support arbitrary input
lengths. After trained on large-scale datasets, the proposed foundation model
demonstrates strong generalization to unseen scenarios and achieves zero-shot
performance on new tasks that surpass traditional full-shot baselines.


## Constella Supporting Storywriters' Interconnected Character Creation through LLM-based Multi-Agents

>Authors: Syemin Park, Soobin Park, Youn-kyung Lim

>2025-07-08

> http://arxiv.org/abs/2507.05820v1

Creating a cast of characters by attending to their relational dynamics is a
critical aspect of most long-form storywriting. However, our formative study
(N=14) reveals that writers struggle to envision new characters that could
influence existing ones, to balance similarities and differences among
characters, and to intricately flesh out their relationships. Based on these
observations, we designed Constella, an LLM-based multi-agent tool that
supports storywriters' interconnected character creation process. Constella
suggests related characters (FRIENDS DISCOVERY feature), reveals the inner
mindscapes of several characters simultaneously (JOURNALS feature), and
manifests relationships through inter-character responses (COMMENTS feature).
Our 7-8 day deployment study with storywriters (N=11) shows that Constella
enabled the creation of expansive communities composed of related characters,
facilitated the comparison of characters' thoughts and emotions, and deepened
writers' understanding of character relationships. We conclude by discussing
how multi-agent interactions can help distribute writers' attention and effort
across the character cast.


## Text-Guided Token Communication for Wireless Image Transmission

>Authors: Bole Liu, Li Qiao, Ye Wang, Zhen Gao, Yu Ma, Keke Ying, Tong Qin

>2025-07-08

> http://arxiv.org/abs/2507.05781v1

With the emergence of 6G networks and proliferation of visual applications,
efficient image transmission under adverse channel conditions is critical. We
present a text-guided token **communication** system leveraging pre-trained
foundation models for wireless image transmission with low bandwidth. Our
approach converts images to discrete tokens, applies 5G NR polar coding, and
employs text-guided token prediction for reconstruction. Evaluations on
ImageNet show our method outperforms Deep Source Channel Coding with Attention
Modules (ADJSCC) in perceptual quality and semantic preservation at
Signal-to-Noise Ratios (SNRs) above 0 dB while mitigating the cliff effect at
lower SNRs. Our system requires no scenario-specific retraining and exhibits
superior cross-dataset generalization, establishing a new paradigm for
efficient image transmission aligned with human perceptual priorities.


## A Satellite-Ground Synergistic Large Vision-Language Model System for Earth Observation

>Authors: Yuxin Zhang, Jiahao Yang, Zhe Chen, Wenjun Zhu, Jin Zhao, Yue Gao

>2025-07-08

> http://arxiv.org/abs/2507.05731v1

Recently, large vision-language models (LVLMs) unleash powerful analysis
capabilities for low Earth orbit (LEO) satellite Earth observation images in
the data center. However, fast satellite motion, brief satellite-ground station
(GS) contact windows, and large size of the images pose a data download
challenge. To enable near real-time Earth observation applications (e.g.,
disaster and extreme weather monitoring), we should explore how to deploy LVLM
in LEO satellite networks, and design SpaceVerse, an efficient satellite-ground
synergistic LVLM inference system. To this end, firstly, we deploy compact
LVLMs on satellites for lightweight tasks, whereas regular LVLMs operate on GSs
to handle computationally intensive tasks. Then, we propose a computing and
**communication** co-design framework comprised of a progressive confidence network
and an attention-based multi-scale preprocessing, used to identify on-satellite
inferring data, and reduce data redundancy before satellite-GS transmission,
separately. We implement and evaluate SpaceVerse on real-world LEO satellite
constellations and datasets, achieving a 31.2% average gain in accuracy and a
51.2% reduction in latency compared to state-of-the-art baselines.


## Multi-patch/multiple-scattering frequency-time hybrid solver for interior and exterior wave equation problems

>Authors: Shuai Pan, Gang Bao, Tao Yin, Oscar P. Bruno

>2025-07-08

> http://arxiv.org/abs/2507.05725v1

This paper proposes a new multiple-scattering frequency-time hybrid (FTH-MS)
integral equation solver for problems of wave scattering by obstacles in two
dimensional space, including interior problems in closed cavities and problems
exterior to a set of disconnected open or closed scattering obstacles. The
multiple-scattering FTH-MS method is based on a partition of the domain
boundary into a user-prescribed set of **overlap**ping open arcs, along with a
corresponding sequence of multiple-scattering problems that effectively
decompose the interior problem into a series of open-arc wave equation
subproblems. The new strategy provides a significant extension of the original
FTH-MS algorithm originally presented in [22], in that (1) By allowing for use
of an arbitrary of number of component arcs, and not just two as in the
previous contribution, the new approach affords (1a) A significantly increased
geometric flexibility, as well as, (1b) The use of partitions for which each
open arc leads to small numbers of iterations if iterative linear-algebra
solvers are employed; and, (2) It facilitates parallelization -- as the
subproblem solutions that are needed at each multiple scattering step can be
evaluated in an embarrassingly parallel fashion. Utilizing a
suitably-implemented Fourier transformation, each sub-problem is reduced to a
Helmholtz frequency-domain problem that is tackled via a uniquely-solvable
boundary integral equation. Similar FTH-MS methods are also presented for
problems exterior to a number of bounded obstacles. All of the algorithms
considered incorporate the previously introduced ``time-windowing and
recentering'' methodology (that enables both treatment of incident signals of
long duration and long time simulation), as well as a high-frequency Fourier
transform algorithm that delivers numerically dispersionless,
spectrally-accurate time evolution for arbitrarily long times.


## Large Language Models for Agent-Based Modelling Current and possible uses across the modelling cycle

>Authors: Loïs Vanhée, Melania Borit, Peer-Olaf Siebers, Roger Cremades, Christopher Frantz, Önder Gürcan, František Kalvas, Denisa Reshef Kera, Vivek Nallur, Kavin Narasimhan, Martin Neumann

>2025-07-08

> http://arxiv.org/abs/2507.05723v1

The emergence of Large Language Models (LLMs) with increasingly sophisticated
natural language understanding and generative capabilities has sparked interest
in the Agent-based Modelling (ABM) community. With their ability to summarize,
generate, analyze, categorize, transcribe and translate text, answer questions,
propose explanations, sustain dialogue, extract information from unstructured
text, and perform logical reasoning and problem-solving tasks, LLMs have a good
potential to contribute to the modelling process. After reviewing the current
use of LLMs in ABM, this study reflects on the opportunities and challenges of
the potential use of LLMs in ABM. It does so by following the modelling cycle,
from problem formulation to documentation and **communication** of model results,
and holding a critical stance.


## DRAGON Dynamic RAG Benchmark On News

>Authors: Fedor Chernogorskii, Sergei Averkiev, Liliya Kudraleeva, Zaven Martirosian, Maria Tikhonova, Valentin Malykh, Alena Fenogenova

>2025-07-08

> http://arxiv.org/abs/2507.05713v1

Retrieval-Augmented Generation (RAG) is a widely adopted approach for
improving the factuality of large language models (LLMs) by incorporating
external knowledge at inference time. Although there exist multiple RAG
benchmarks for English, evaluation resources for other languages, including
Russian, remain scarce and static, failing to capture the dynamic nature of
real-world deployments.
  In this work, we present DRAGON (Dynamic RAG Benchmark On News), the first
dynamic benchmark for evaluating RAG systems in Russian on a changing news
corpora. DRAGON is built upon a regularly updated corpus of Russian news and
public documents and supports comprehensive evaluation of both the retriever
and generator components. Question generation is performed automatically with
the use of Knowledge Graph constructed from the corpus and enables the
extraction of four core question types aligned with distinct subgraph patterns.
We release a complete evaluation framework comprising the pipeline for
automatic question generation, evaluation scripts, which are potentially
reusable for other languages and multilingual settings, and benchmark data. We
also launch a public leaderboard to encourage community participation and
comparison.


## LLMs are Introvert

>Authors: Litian Zhang, Xiaoming Zhang, Bingyu Yan, Ziyi Zhou, Bo Zhang, Zhenyu Guan, Xi Zhang, Chaozhuo Li

>2025-07-08

> http://arxiv.org/abs/2507.05638v1

The exponential growth of social media and generative AI has transformed
information dissemination, fostering connectivity but also accelerating the
spread of misinformation. Understanding information propagation dynamics and
developing effective control strategies is essential to mitigate harmful
content. Traditional models, such as SIR, provide basic insights but
inadequately capture the complexities of online interactions. Advanced methods,
including attention mechanisms and graph neural networks, enhance accuracy but
typically overlook user psychology and behavioral dynamics. Large language
models (LLMs), with their human-like reasoning, offer new potential for
simulating psychological aspects of information spread. We introduce an
LLM-based simulation environment capturing agents' evolving attitudes,
emotions, and responses. Initial experiments, however, revealed significant
gaps between LLM-generated behaviors and authentic human dynamics, especially
in stance detection and psychological realism. A detailed evaluation through
Social Information Processing Theory identified major discrepancies in
goal-setting and feedback evaluation, stemming from the lack of emotional
processing in standard LLM training. To address these issues, we propose the
Social Information Processing-based Chain of Thought (SIP-CoT) mechanism
enhanced by emotion-guided memory. This method improves the interpretation of
social cues, personalization of goals, and evaluation of feedback. Experimental
results confirm that SIP-CoT-enhanced LLM agents more effectively process
social information, demonstrating behaviors, attitudes, and emotions closer to
real human interactions. In summary, this research highlights critical
limitations in current LLM-based propagation simulations and demonstrates how
integrating SIP-CoT and emotional memory significantly enhances the social
intelligence and realism of LLM agents.


## Domain adaptation of large language models for geotechnical applications

>Authors: Lei Fan, Fangxue Liu, Cheng Chen

>2025-07-08

> http://arxiv.org/abs/2507.05613v1

Recent developments in large language models (LLMs) are opening up new
opportunities in geotechnical engineering and engineering geology. While
general-purpose LLMs possess broad capabilities, effective application in
geotechnics often requires domain-specific adaptation. Such tailored LLMs are
increasingly employed to streamline geotechnical workflows. This paper presents
the first survey of the adaptation and application of LLMs in geotechnical
engineering. It outlines key methodologies for adaptation to geotechnical
domain, including prompt engineering, retrieval-augmented generation,
domain-adaptive pretraining, and fine-tuning. The survey examines the
state-of-the-art applications of geotechnical-adapted LLMs, including
geological interpretation, subsurface characterization, site planning, design
calculations, numerical modeling, safety and risk assessment, and educational
tutoring. It also analyzes benefits and limitations of geotechnical-adapted
LLMs, and identifies promising directions for future research in this
interdisciplinary discipline. The findings serve as a valuable resource for
practitioners seeking to integrate LLMs into geotechnical practice, while also
providing a foundation to stimulate further investigation within the academic
community.


## Baton Compensate for Missing Wi-Fi Features for Practical Device-free Tracking

>Authors: Yiming Zhao, Xuanqi Meng, Xinyu Tong, Xiulong Liu, Xin Xie, Wenyu Qu

>2025-07-08

> http://arxiv.org/abs/2507.05597v1

Wi-Fi contact-free sensing systems have attracted widespread attention due to
their ubiquity and convenience. The integrated sensing and **communication** (ISAC)
technology utilizes off-the-shelf Wi-Fi **communication** signals for sensing,
which further promotes the deployment of intelligent sensing applications.
However, current Wi-Fi sensing systems often require prolonged and unnecessary
**communication** between transceivers, and brief **communication** interruptions will
lead to significant performance degradation. This paper proposes Baton, the
first system capable of accurately tracking targets even under severe Wi-Fi
feature deficiencies. To be specific, we explore the relevance of the Wi-Fi
feature matrix from both horizontal and vertical dimensions. The horizontal
dimension reveals feature correlation across different Wi-Fi links, while the
vertical dimension reveals feature correlation among different time slots.
Based on the above principle, we propose the Simultaneous Tracking And
Predicting (STAP) algorithm, which enables the seamless transfer of Wi-Fi
features over time and across different links, akin to passing a baton. We
implement the system on commercial devices, and the experimental results show
that our system outperforms existing solutions with a median tracking error of
0.46m, even when the **communication** duty cycle is as low as 20.00%. Compared
with the state-of-the-art, our system reduces the tracking error by 79.19% in
scenarios with severe Wi-Fi feature deficiencies.


## GTRSS Graph-based Top-$k$ Representative Similar Subtrajectory Query

>Authors: Mingchang Ge, Liping Wang, Xuemin Lin, Yuang Zhang, Kunming Wang

>2025-07-07

> http://arxiv.org/abs/2507.05542v1

Trajectory mining has attracted significant attention. This paper addresses
the Top-k Representative Similar Subtrajectory Query (TRSSQ) problem, which
aims to find the k most representative subtrajectories similar to a query.
Existing methods rely on costly filtering-validation frameworks, resulting in
slow response times. Addressing this, we propose GTRSS, a novel Graph-based
Top-k Representative Similar Subtrajectory Query framework. During the offline
phase, GTRSS builds a dual-layer graph index that clusters trajectories
containing similar representative subtrajectories. In the online phase, it
efficiently retrieves results by navigating the graph toward query-relevant
clusters, bypassing full-dataset scanning and heavy computation. To support
this, we introduce the Data Trajectory Similarity Metric (DTSM) to measure the
most similar subtrajectory pair. We further combine R-tree and grid filtering
with DTSM **pruning** rules to speed up index building. To the best of our
knowledge, GTRSS is the first graph-based solution for top-k subtrajectory
search. Experiments on real datasets demonstrate that GTRSS significantly
enhances both efficiency and accuracy, achieving a retrieval accuracy of over
90 percent and up to two orders of magnitude speedup in query performance.


## SenseCF LLM-Prompted Counterfactuals for Intervention and Sensor Data Augmentation

>Authors: Shovito Barua Soumma, Asiful Arefeen, Stephanie M. Carpenter, Melanie Hingle, Hassan Ghasemzadeh

>2025-07-07

> http://arxiv.org/abs/2507.05541v1

Counterfactual explanations (CFs) offer human-centric insights into machine
learning predictions by highlighting minimal changes required to alter an
outcome. Therefore, CFs can be used as (i) interventions for abnormality
prevention and (ii) augmented data for training robust models. In this work, we
explore large language models (LLMs), specifically GPT-4o-mini, for generating
CFs in a zero-shot and three-shot setting. We evaluate our approach on two
datasets: the AI-Readi flagship dataset for stress prediction and a public
dataset for heart disease detection. Compared to traditional methods such as
DiCE, CFNOW, and NICE, our few-shot LLM-based approach achieves high
plausibility (up to 99%), strong validity (up to 0.99), and competitive
**sparsity**. Moreover, using LLM-generated CFs as augmented samples improves
downstream classifier performance (an average accuracy gain of 5%), especially
in low-data regimes. This demonstrates the potential of prompt-based generative
techniques to enhance explainability and robustness in clinical and
physiological prediction tasks. Code base: github.com/anonymous/SenseCF.


## Assessing Methodological Variability in Wastewater Surveillance A Wavelet Decomposition Approach

>Authors: Maria L. Daza-Torres, J. Cricelio Montesinos-Lopez, Rachel Olson, C. Winston Bess, Colleen C. Naughton, Heather N. Bischel, Miriam Nuno

>2025-07-07

> http://arxiv.org/abs/2507.05539v1

Wastewater surveillance has emerged as a critical public health tool,
enabling early detection of infectious disease outbreaks and providing timely,
population-level insights into community health trends. However, variability in
sample collection and processing, for example between wastewater influent and
settled solids, can introduce methodological noise that differentially impacts
true epidemiological signals and limits cross-site comparability. To address
this challenge, we aimed to discern underlying disease trends from
methodological variability in SARS-CoV-2 wastewater data using discrete wavelet
transform (DWT), with a focus on comparing influent and solids samples from the
same geographic locations. We applied DWT to longitudinal SARS-CoV-2 RNA
concentrations in wastewater from five California cities, each with paired
influent and solids samples. DWT decomposes each signal into two components:
(1) approximation coefficients that capture smoothed long-term trends, and (2)
detail coefficients that isolate high-frequency fluctuations and transient
variations in the signal. We reconstructed signals by progressively removing
the high-frequency components and assessed similarity between sample types
using hierarchical clustering. Clustering of raw signals did not yield
city-specific groupings, indicating that methodological noise obscured the
underlying epidemiological signal. Intermediate reconstructions that retained
some high-frequency components continued to show mixed groupings. In contrast,
reconstructions based solely on low-frequency approximation coefficients
revealed clear, city-specific clustering, with influent and solids samples from
the same city aligning closely. These findings support our hypothesis that
high-frequency components are primarily driven by sample processing and
laboratory noise, while low-frequency components reflect shared epidemiological
trends.


## Hybrid Quantum Cryptosystems Integration of Entanglement-Assisted Decryption and Physical Phase Obfuscation

>Authors: Asgar Hosseinnezhad, Hadi Sabri

>2025-07-07

> http://arxiv.org/abs/2507.05464v1

This study introduces a hybrid cryptographic framework for quantum
**communication** that integrates entanglement-assisted decryption with phase-based
physical obfuscation. While conventional quantum protocols often rely on
explicit transmission of decryption keys or phase parameters, such models
expose critical vulnerabilities to eavesdropping. To address this challenge, we
propose a two-stage encryption-decryption mechanism. The first stage employs
randomized phase modulation protected by active electromagnetic shielding to
conceal the quantum signal from unauthorized interception. The second stage
enables legitimate receivers to retrieve encrypted phase data using entangled
quantum states, eliminating the need for classical key transfer. A formal
mathematical framework is developed to describe the two-stage encoding and
decryption process, including phase-modulated entangled states and their
transformation under nonlocal correlation and adversarial noise. Simulation
metrics confirm that the hybrid system preserves quantum coherence with
visibility above 94% and entanglement negativity of 0.86, even under dynamic
shielding and transmission noise. Simulation results demonstrate that the
combined protocol enhances anti-eavesdropping resilience while maintaining
quantum coherence. This architecture is suitable for large-scale secure quantum
networks, where multi-layered defense strategies are essential against
classical and quantum threats.


## GLOSS Group of LLMs for Open-Ended Sensemaking of Passive Sensing Data for Health and Wellbeing

>Authors: Akshat Choube, Ha Le, Jiachen Li, Kaixin Ji, Vedant Das Swain, Varun Mishra

>2025-07-07

> http://arxiv.org/abs/2507.05461v1

The ubiquitous presence of smartphones and wearables has enabled researchers
to build prediction and detection models for various health and behavior
outcomes using passive sensing data from these devices. Achieving a high-level,
holistic understanding of an individual's behavior and context, however,
remains a significant challenge. Due to the nature of passive sensing data,
sensemaking -- the process of interpreting and extracting insights -- requires
both domain knowledge and technical expertise, creating barriers for different
stakeholders. Existing systems designed to support sensemaking are either not
open-ended or cannot perform complex data triangulation. In this paper, we
present a novel sensemaking system, Group of LLMs for Open-ended Sensemaking
(GLOSS), capable of open-ended sensemaking and performing complex multimodal
triangulation to derive insights. We demonstrate that GLOSS significantly
outperforms the commonly used Retrieval-Augmented Generation (RAG) technique,
achieving 87.93% accuracy and 66.19% consistency, compared to RAG's 29.31%
accuracy and 52.85% consistency. Furthermore, we showcase the promise of GLOSS
through four use cases inspired by prior and ongoing work in the UbiComp and
HCI communities. Finally, we discuss the potential of GLOSS, its broader
implications, and the limitations of our work.


## ModelCitizens Representing Community Voices in Online Safety

>Authors: Ashima Suvarna, Christina Chance, Karolina Naranjo, Hamid Palangi, Sophie Hao, Thomas Hartvigsen, Saadia Gabriel

>2025-07-07

> http://arxiv.org/abs/2507.05455v2

Automatic toxic language detection is critical for creating safe, inclusive
online spaces. However, it is a highly subjective task, with perceptions of
toxic language shaped by community norms and lived experience. Existing
toxicity detection models are typically trained on annotations that collapse
diverse annotator perspectives into a single ground truth, erasing important
context-specific notions of toxicity such as reclaimed language. To address
this, we introduce MODELCITIZENS, a dataset of 6.8K social media posts and 40K
toxicity annotations across diverse identity groups. To capture the role of
conversational context on toxicity, typical of social media posts, we augment
MODELCITIZENS posts with LLM-generated conversational scenarios.
State-of-the-art toxicity detection tools (e.g. OpenAI Moderation API,
GPT-o4-mini) underperform on MODELCITIZENS, with further degradation on
context-augmented posts. Finally, we release LLAMACITIZEN-8B and
GEMMACITIZEN-12B, LLaMA- and Gemma-based models finetuned on MODELCITIZENS,
which outperform GPT-o4-mini by 5.5% on in-distribution evaluations. Our
findings highlight the importance of community-informed annotation and modeling
for inclusive content moderation. The data, models and code are available at
https://github.com/asuvarna31/modelcitizens.


## StreamVLN Streaming Vision-and-Language Navigation via SlowFast Context Modeling

>Authors: Meng Wei, Chenyang Wan, Xiqian Yu, Tai Wang, Yuqiang Yang, Xiaohan Mao, Chenming Zhu, Wenzhe Cai, Hanqing Wang, Yilun Chen, Xihui Liu, Jiangmiao Pang

>2025-07-07

> http://arxiv.org/abs/2507.05240v1

Vision-and-Language Navigation (VLN) in real-world settings requires agents
to process continuous visual streams and generate actions with low latency
grounded in language instructions. While Video-based Large Language Models
(Video-LLMs) have driven recent progress, current VLN methods based on
Video-LLM often face trade-offs among fine-grained visual understanding,
long-term context modeling and computational efficiency. We introduce
StreamVLN, a streaming VLN framework that employs a hybrid slow-fast context
modeling strategy to support multi-modal reasoning over interleaved vision,
language and action inputs. The fast-streaming dialogue context facilitates
responsive action generation through a sliding-window of active dialogues,
while the slow-updating memory context compresses historical visual states
using a 3D-aware token **pruning** strategy. With this slow-fast design, StreamVLN
achieves coherent multi-turn dialogue through efficient **KV** cache reuse,
supporting long video streams with bounded context size and inference cost.
Experiments on VLN-CE benchmarks demonstrate state-of-the-art performance with
stable low latency, ensuring robustness and efficiency in real-world
deployment. The project page is:
\href{https://streamvln.github.io/}{https://streamvln.github.io/}.


## Cascade Token-Sharded Private LLM Inference

>Authors: Rahul Thomas, Louai Zahran, Erica Choi, Akilesh Potti, Micah Goldblum, Arka Pal

>2025-07-07

> http://arxiv.org/abs/2507.05228v1

As LLMs continue to increase in parameter size, the computational resources
required to run them are available to fewer parties. Therefore, third-party
inference services -- where LLMs are hosted by third parties with significant
computational resources -- are becoming increasingly popular. However, third
party inference raises critical concerns about user data privacy. To mitigate
these risks, privacy researchers have developed provably secure schemes for
third-party inference, such as Secure Multi-Party Computation (SMPC). However,
SMPC protocols have significant computational and **communication** overhead, and
do not scale to large models. In this work, we propose a new multi-party
inference protocol, Cascade, that avoids these punitive costs by leveraging
sharding in the sequence dimension to maintain privacy, trading off
cryptographic privacy guarantees for increased performance and scalability. We
demonstrate that Cascade is resistant to a generalization of a recent attack
that is highly effective against other statistical privacy schemes, and that it
is further resistant to learning-based attacks. As Cascade is orders of
magnitude faster than existing schemes, our findings offer practical solutions
for secure deployment of modern state-of-the-art LLMs.


## All in One Visual-Description-Guided Unified Point Cloud Segmentation

>Authors: Zongyan Han, Mohamed El Amine Boudjoghra, Jiahua Dong, Jinhong Wang, Rao Muhammad Anwer

>2025-07-07

> http://arxiv.org/abs/2507.05211v1

Unified segmentation of 3D point clouds is crucial for scene understanding,
but is hindered by its **sparse** structure, limited annotations, and the challenge
of distinguishing fine-grained object classes in complex environments. Existing
methods often struggle to capture rich semantic and contextual information due
to limited supervision and a lack of diverse multimodal cues, leading to
suboptimal differentiation of classes and instances. To address these
challenges, we propose VDG-Uni3DSeg, a novel framework that integrates
pre-trained vision-language models (e.g., CLIP) and large language models
(LLMs) to enhance 3D segmentation. By leveraging LLM-generated textual
descriptions and reference images from the internet, our method incorporates
rich multimodal cues, facilitating fine-grained class and instance separation.
We further design a Semantic-Visual Contrastive Loss to align point features
with multimodal queries and a Spatial Enhanced Module to model scene-wide
relationships efficiently. Operating within a closed-set paradigm that utilizes
multimodal knowledge generated offline, VDG-Uni3DSeg achieves state-of-the-art
results in semantic, instance, and panoptic segmentation, offering a scalable
and practical solution for 3D understanding. Our code is available at
https://github.com/Hanzy1996/VDG-Uni3DSeg.


## CREW-WILDFIRE Benchmarking Agentic Multi-Agent Collaborations at Scale

>Authors: Jonathan Hyun, Nicholas R Waytowich, Boyuan Chen

>2025-07-07

> http://arxiv.org/abs/2507.05178v1

Despite rapid progress in large language model (LLM)-based multi-agent
systems, current benchmarks fall short in evaluating their scalability,
robustness, and coordination capabilities in complex, dynamic, real-world
tasks. Existing environments typically focus on small-scale, fully observable,
or low-complexity domains, limiting their utility for developing and assessing
next-generation multi-agent Agentic AI frameworks. We introduce CREW-Wildfire,
an open-source benchmark designed to close this gap. Built atop the human-AI
teaming CREW simulation platform, CREW-Wildfire offers procedurally generated
wildfire response scenarios featuring large maps, heterogeneous agents, partial
observability, stochastic dynamics, and long-horizon planning objectives. The
environment supports both low-level control and high-level natural language
interactions through modular Perception and Execution modules. We implement and
evaluate several state-of-the-art LLM-based multi-agent Agentic AI frameworks,
uncovering significant performance gaps that highlight the unsolved challenges
in large-scale coordination, **communication**, spatial reasoning, and long-horizon
planning under uncertainty. By providing more realistic complexity, scalable
architecture, and behavioral evaluation metrics, CREW-Wildfire establishes a
critical foundation for advancing research in scalable multi-agent Agentic
intelligence. All code, environments, data, and baselines will be released to
support future research in this emerging domain.


## LVM4CSI Enabling Direct Application of Pre-Trained Large Vision Models for Wireless Channel Tasks

>Authors: Jiajia Guo, Peiwen Jiang, Chao-Kai Wen, Shi Jin, Jun Zhang

>2025-07-07

> http://arxiv.org/abs/2507.05121v1

Accurate channel state information (CSI) is critical to the performance of
wireless **communication** systems, especially with the increasing scale and
complexity introduced by 5G and future 6G technologies. While artificial
intelligence (AI) offers a promising approach to CSI acquisition and
utilization, existing methods largely depend on task-specific neural networks
(NNs) that require expert-driven design and large training datasets, limiting
their generalizability and practicality. To address these challenges, we
propose LVM4CSI, a general and efficient framework that leverages the
structural similarity between CSI and computer vision (CV) data to directly
apply large vision models (LVMs) pre-trained on extensive CV datasets to
wireless tasks without any fine-tuning, in contrast to large language
model-based methods that generally necessitate fine-tuning. LVM4CSI maps CSI
tasks to analogous CV tasks, transforms complex-valued CSI into visual formats
compatible with LVMs, and integrates lightweight trainable layers to adapt
extracted features to specific **communication** objectives. We validate LVM4CSI
through three representative case studies, including channel estimation, human
activity recognition, and user localization. Results demonstrate that LVM4CSI
achieves comparable or superior performance to task-specific NNs, including an
improvement exceeding 9.61 dB in channel estimation and approximately 40%
reduction in localization error. Furthermore, it significantly reduces the
number of trainable parameters and eliminates the need for task-specific NN
design.


## Sequential Attention-based Sampling for Histopathological Analysis

>Authors: Tarun G, Naman Malpani, Gugan Thoppe, Sridharan Devarajan

>2025-07-07

> http://arxiv.org/abs/2507.05077v2

Deep neural networks are increasingly applied for automated histopathology.
Yet, whole-slide images (WSIs) are often acquired at gigapixel sizes, rendering
it computationally infeasible to analyze them entirely at high resolution.
Diagnostic labels are largely available only at the slide-level, because expert
annotation of images at a finer (patch) level is both laborious and expensive.
Moreover, regions with diagnostic information typically occupy only a small
fraction of the WSI, making it inefficient to examine the entire slide at full
resolution. Here, we propose SASHA -- {\it S}equential {\it A}ttention-based
{\it S}ampling for {\it H}istopathological {\it A}nalysis -- a deep
reinforcement learning approach for efficient analysis of histopathological
images. First, SASHA learns informative features with a lightweight
hierarchical, attention-based multiple instance learning (MIL) model. Second,
SASHA samples intelligently and zooms selectively into a small fraction
(10-20\%) of high-resolution patches, to achieve reliable diagnosis. We show
that SASHA matches state-of-the-art methods that analyze the WSI fully at
high-resolution, albeit at a fraction of their computational and memory costs.
In addition, it significantly outperforms competing, **sparse** sampling methods.
We propose SASHA as an intelligent sampling model for medical imaging
challenges that involve automated diagnosis with exceptionally large images
containing **sparse**ly informative features.


## Scale Dilation Dynamics in Flexible Bandwidth Needlet Constructions

>Authors: Claudio Durastanti

>2025-07-07

> http://arxiv.org/abs/2507.05075v2

Flexible bandwidth needlets offer a versatile multiscale framework for
analyzing functions on the sphere. A key element in their construction is the
dilation sequence, which controls how the multipole consecutive scales are
spaced and **overlap**ped. At any resolution level, this sequence determines the
center positions of the needlet weight functions and influences their
localization in the spatial domain and spectral concentration properties by
means of the relative bandwidth ratio. In this paper, we explore the different
asymptotic regimes that arise when the dilation sequence exhibits shrinking,
stable (standard), or spreading behavior. Moreover, we assume the dilation
sequence grows regularly enough to ensure well-defined asymptotic properties.
For each regime, we characterize the impact on the geometry of the center
scales and the shape of the multipole windows, with particular attention to
their **overlap** structure and spectral coverage. These insights help to clarify
the trade-offs between localization, redundancy, and scalability in the design
of needlet-type systems, particularly in relation to the study of the
asymptotic uncorrelation of needlet coefficients when applied to random fields.


## From Autonomy to Agency Agentic Vehicles for Human-Centered Mobility Systems

>Authors: Jiangbo Yu

>2025-07-07

> http://arxiv.org/abs/2507.04996v1

Autonomy, from the Greek autos (self) and nomos (law), refers to the capacity
to operate according to internal rules without external control. Accordingly,
autonomous vehicles (AuVs) are defined as systems capable of perceiving their
environment and executing preprogrammed tasks independently of external input.
However, both research and real-world deployments increasingly showcase
vehicles that demonstrate behaviors beyond this definition (including the SAE
levels 1 to 6), such as interaction with humans and machines, goal adaptation,
contextual reasoning, external tool use, and long-term planning, particularly
with the integration of large language models (LLMs) and agentic AI systems.
These developments reveal a conceptual gap between technical autonomy and the
broader cognitive and social capabilities needed for future human-centered
mobility systems. To address this, we introduce the concept of agentic vehicles
(AgVs), referring to vehicles that integrate agentic AI to reason, adapt, and
interact within complex environments. This paper presents a systems-level
framework to characterize AgVs, focusing on their cognitive and communicative
layers and differentiating them from conventional AuVs. It synthesizes relevant
advances in agentic AI, robotics, multi-agent systems, and human-machine
interaction, and highlights how agentic AI, through high-level reasoning and
tool use, can function not merely as computational tools but as interactive
agents embedded in mobility ecosystems. The paper concludes by identifying key
challenges in the development and governance of AgVs, including safety,
real-time control, public acceptance, ethical alignment, and regulatory
frameworks.


## Classification of autoimmune diseases from Peripheral blood TCR repertoires by multimodal multi-instance learning

>Authors: Ruihao Zhang, Mao chen, Fei Ye, Dandan Meng, Yixuan Huang, Xiao Liu

>2025-07-07

> http://arxiv.org/abs/2507.04981v3

T cell receptor (TCR) repertoires encode critical immunological signatures
for autoimmune diseases, yet their clinical application remains limited by
sequence **sparsity** and low witness rates. We developed EAMil, a multi-instance
deep learning framework that leverages TCR sequencing data to diagnose systemic
lupus erythematosus (SLE) and rheumatoid arthritis (RA) with exceptional
accuracy. By integrating PrimeSeq feature extraction with ESMonehot encoding
and enhanced gate attention mechanisms, our model achieved state-of-the-art
performance with AUCs of 98.95% for SLE and 97.76% for RA. EAMil successfully
identified disease-associated genes with over 90% concordance with established
differential analyses and effectively distinguished disease-specific TCR genes.
The model demonstrated robustness in classifying multiple disease categories,
utilizing the SLEDAI score to stratify SLE patients by disease severity as well
as to diagnose the site of damage in SLE patients, and effectively controlling
for confounding factors such as age and gender. This interpretable framework
for immune receptor analysis provides new insights for autoimmune disease
detection and classification with broad potential clinical applications across
immune-mediated conditions.


## The Case for Instance-Optimized LLMs in OLAP Databases

>Authors: Bardia Mohammadi, Laurent Bindschaedler

>2025-07-07

> http://arxiv.org/abs/2507.04967v1

Large Language Models (LLMs) can enhance analytics systems with powerful data
summarization, cleaning, and semantic transformation capabilities. However,
deploying LLMs at scale -- processing millions to billions of rows -- remains
prohibitively expensive in computation and memory. We present IOLM-DB, a novel
system that makes LLM-enhanced database queries practical through
query-specific model optimization. Instead of using general-purpose LLMs,
IOLM-DB generates lightweight, specialized models tailored to each query's
specific needs using representative data samples. IOLM-DB reduces model
footprints by up to 76% and increases throughput by up to 3.31$\times$ while
maintaining accuracy through aggressive compression techniques, including
quantization, sparsification, and structural **pruning**. We further show how our
approach enables higher parallelism on existing hardware and seamlessly
supports caching and batching strategies to reduce overheads. Our prototype
demonstrates that leveraging LLM queries inside analytics systems is feasible
at scale, opening new possibilities for future OLAP applications.


## ArtifactsBench Bridging the Visual-Interactive Gap in LLM Code Generation Evaluation

>Authors: Chenchen Zhang, Yuhang Li, Can Xu, Jiaheng Liu, Ao Liu, Shihui Hu, Dengpeng Wu, Guanhua Huang, Kejiao Li, Qi Yi, Ruibin Xiong, Haotian Zhu, Yuanxing Zhang, Yuhao Jiang, Yue Zhang, Zenan Xu, Bohui Zhai, Guoxiang He, Hebin Li, Jie Zhao, Le Zhang, Lingyun Tan, Pengyu Guo, Xianshu Pang, Yang Ruan, Zhifeng Zhang, Zhonghu Wang, Ziyan Xu, Zuopu Yin, Wiggin Zhou, Chayse Zhou, Fengzong Lian

>2025-07-07

> http://arxiv.org/abs/2507.04952v1

The generative capabilities of Large Language Models (LLMs) are rapidly
expanding from static code to dynamic, interactive visual artifacts. This
progress is bottlenecked by a critical evaluation gap: established benchmarks
focus on algorithmic correctness and are blind to the visual fidelity and
interactive integrity that define modern user experiences. To bridge this gap,
we introduce ArtifactsBench, a new benchmark and paradigm for the automated,
multimodal evaluation of visual code generation. Our framework programmatically
renders each generated artifact and captures its dynamic behavior through
temporal screenshots. This visual evidence, alongside the source code, is then
assessed by a Multimodal LLM (MLLM)-as-Judge, which is rigorously guided by a
fine-grained, per-task checklist to ensure holistic and reproducible scoring.
We construct a new benchmark of 1,825 diverse tasks and evaluate over 30
leading LLMs. Our automated evaluation achieves a striking 94.4% ranking
consistency with WebDev Arena, the gold-standard for human preference in web
development, and over 90% pairwise agreement with human experts. This
establishes ArtifactsBench as the first framework to reliably automate the
assessment of human-perceived quality at scale. Our analysis provides a
high-resolution map of the current SOTA, revealing that generalist models often
outperform domain-specific ones. We open-source ArtifactsBench, including the
benchmark, evaluation harness, and baseline results at
https://artifactsbenchmark.github.io/, to provide the community with a scalable
and accurate tool to accelerate the development of user-centric generative
models.


## LIFT Automating Symbolic Execution Optimization with Large Language Models for AI Networks

>Authors: Ruoxi Wang, Kun Li, Minghui Xu, Yue Zhang, Kaidi Xu, Chunchi Liu, Yinhao Xiao, Xiuzhen Cheng

>2025-07-07

> http://arxiv.org/abs/2507.04931v1

Dynamic Symbolic Execution (DSE) is a key technique in program analysis,
widely used in software testing, vulnerability discovery, and formal
verification. In distributed AI systems, DSE plays a crucial role in
identifying hard-to-detect bugs, especially those arising from complex network
**communication** patterns. However, traditional approaches to symbolic execution
are often hindered by scalability issues and inefficiencies, particularly in
large-scale systems. This paper introduces LIFT (Large-language-model
Integrated Functional-equivalent-IR Transformation), a novel framework that
leverages Large Language Models (LLMs) to automate the optimization of
Intermediate Representations (IRs) in symbolic execution. LIFT addresses the
challenges of symbolic execution by providing a scalable, context-sensitive
solution for IR transformation. The framework consists of two phases: IR
Analysis and Optimization, where LLMs optimize time-intensive IR blocks, and
Symbolic Execution and Validation, which includes benchmarking and semantic
verification to ensure correctness and generalizability. Experiments on
real-world binaries demonstrated significant performance improvements,
including a 53.5\% reduction in execution time for bigtest and a 10.24\%
reduction for random, along with reductions in IR statements, PUT instructions,
and temporary variables. These results demonstrate that LLMs simplify IRs while
maintaining functional correctness, enhancing symbolic execution in distributed
AI systems.


## DoPI Doctor-like Proactive Interrogation LLM for Traditional Chinese Medicine

>Authors: Zewen Sun, Ruoxiang Huang, Jiahe Feng, Rundong Kong, Yuqian Wang, Hengyu Liu, Ziqi Gong, Yuyuan Qin, Yingxue Wang, Yu Wang

>2025-07-07

> http://arxiv.org/abs/2507.04877v1

Enhancing interrogation capabilities in Traditional Chinese Medicine (TCM)
diagnosis through multi-turn dialogues and knowledge graphs presents a
significant challenge for modern AI systems. Current large language models
(LLMs), despite their advancements, exhibit notable limitations in medical
applications, particularly in conducting effective multi-turn dialogues and
proactive questioning. These shortcomings hinder their practical application
and effectiveness in simulating real-world diagnostic scenarios. To address
these limitations, we propose DoPI, a novel LLM system specifically designed
for the TCM domain. The DoPI system introduces a collaborative architecture
comprising a guidance model and an expert model. The guidance model conducts
multi-turn dialogues with patients and dynamically generates questions based on
a knowledge graph to efficiently extract critical symptom information.
Simultaneously, the expert model leverages deep TCM expertise to provide final
diagnoses and treatment plans. Furthermore, this study constructs a multi-turn
doctor-patient dialogue dataset to simulate realistic consultation scenarios
and proposes a novel evaluation methodology that does not rely on manually
collected real-world consultation data. Experimental results show that the DoPI
system achieves an accuracy rate of 84.68 percent in interrogation outcomes,
significantly enhancing the model's **communication** ability during diagnosis
while maintaining professional expertise.


## From Imitation to Innovation The Emergence of AI Unique Artistic Styles and the Challenge of Copyright Protection

>Authors: Zexi Jia, Chuanwei Huang, Yeshuang Zhu, Hongyan Fei, Ying Deng, Zhiqiang Yuan, Jiapei Zhang, Jinchao Zhang, Jie Zhou

>2025-07-07

> http://arxiv.org/abs/2507.04769v1

Current legal frameworks consider AI-generated works eligible for copyright
protection when they meet originality requirements and involve substantial
human intellectual input. However, systematic legal standards and reliable
evaluation methods for AI art copyrights are lacking. Through comprehensive
analysis of legal precedents, we establish three essential criteria for
determining distinctive artistic style: stylistic consistency, creative
uniqueness, and expressive accuracy. To address these challenges, we introduce
ArtBulb, an interpretable and quantifiable framework for AI art copyright
judgment that combines a novel style description-based multimodal clustering
method with multimodal large language models (MLLMs). We also present AICD, the
first benchmark dataset for AI art copyright annotated by artists and legal
experts. Experimental results demonstrate that ArtBulb outperforms existing
models in both quantitative and qualitative evaluations. Our work aims to
bridge the gap between the legal and technological communities and bring
greater attention to the societal issue of AI art copyrights.


## FurniMAS Language-Guided Furniture Decoration using Multi-Agent System

>Authors: Toan Nguyen, Tri Le, Quang Nguyen, Anh Nguyen

>2025-07-07

> http://arxiv.org/abs/2507.04770v1

Furniture decoration is an important task in various industrial applications.
However, achieving a high-quality decorative result is often time-consuming and
requires specialized artistic expertise. To tackle these challenges, we explore
how multi-agent systems can assist in automating the decoration process. We
propose FurniMAS, a multi-agent system for automatic furniture decoration.
Specifically, given a human prompt and a household furniture item such as a
working desk or a TV stand, our system suggests relevant assets with
appropriate styles and materials, and arranges them on the item, ensuring the
decorative result meets functionality, aesthetic, and ambiance preferences.
FurniMAS assembles a hybrid team of LLM-based and non-LLM agents, each
fulfilling distinct roles in a typical decoration project. These agents
collaborate through **communication**, logical reasoning, and validation to
transform the requirements into the final outcome. Extensive experiments
demonstrate that our FurniMAS significantly outperforms other baselines in
generating high-quality 3D decor.


## A Tale of Two Scripts Transliteration and Post-Correction for Judeo-Arabic

>Authors: Juan Moreno Gonzalez, Bashar Alhafni, Nizar Habash

>2025-07-07

> http://arxiv.org/abs/2507.04746v1

Judeo-Arabic refers to Arabic variants historically spoken by Jewish
communities across the Arab world, primarily during the Middle Ages. Unlike
standard Arabic, it is written in Hebrew script by Jewish writers and for
Jewish audiences. Transliterating Judeo-Arabic into Arabic script is
challenging due to ambiguous letter mappings, inconsistent orthographic
conventions, and frequent code-switching into Hebrew and Aramaic. In this
paper, we introduce a two-step approach to automatically transliterate
Judeo-Arabic into Arabic script: simple character-level mapping followed by
post-correction to address grammatical and orthographic errors. We also present
the first benchmark evaluation of LLMs on this task. Finally, we show that
transliteration enables Arabic NLP tools to perform morphosyntactic tagging and
machine translation, which would have not been feasible on the original texts.


## Who's the Mole? Modeling and Detecting Intention-Hiding Malicious Agents in LLM-Based Multi-Agent Systems

>Authors: Yizhe Xie, Congcong Zhu, Xinyue Zhang, Minghao Wang, Chi Liu, Minglu Zhu, Tianqing Zhu

>2025-07-07

> http://arxiv.org/abs/2507.04724v1

Multi-agent systems powered by Large Language Models (LLM-MAS) demonstrate
remarkable capabilities in collaborative problem-solving. While LLM-MAS exhibit
strong collaborative abilities, the security risks in their **communication** and
coordination remain underexplored. We bridge this gap by systematically
investigating intention-hiding threats in LLM-MAS, and design four
representative attack paradigms that subtly disrupt task completion while
maintaining high concealment. These attacks are evaluated in centralized,
decentralized, and layered **communication** structures. Experiments conducted on
six benchmark datasets, including MMLU, MMLU-Pro, HumanEval, GSM8K, arithmetic,
and biographies, demonstrate that they exhibit strong disruptive capabilities.
To identify these threats, we propose a psychology-based detection framework
AgentXposed, which combines the HEXACO personality model with the Reid
Technique, using progressive questionnaire inquiries and behavior-based
monitoring. Experiments conducted on six types of attacks show that our
detection framework effectively identifies all types of malicious behaviors.
The detection rate for our intention-hiding attacks is slightly lower than that
of the two baselines, Incorrect Fact Injection and Dark Traits Injection,
demonstrating the effectiveness of intention concealment. Our findings reveal
the structural and behavioral risks posed by intention-hiding attacks and offer
valuable insights into securing LLM-based multi-agent systems through
psychological perspectives, which contributes to a deeper understanding of
multi-agent safety. The code and data are available at
https://anonymous.4open.science/r/AgentXposed-F814.


## LOOM-Scope a comprehensive and efficient LOng-cOntext Model evaluation framework

>Authors: Zecheng Tang, Haitian Wang, Quantong Qiu, Baibei Ji, Ruoxi Sun, Keyan Zhou, Juntao Li, Min Zhang

>2025-07-07

> http://arxiv.org/abs/2507.04723v1

Long-context processing has become a fundamental capability for large
language models~(LLMs). To assess model's long-context performance, numerous
long-context evaluation benchmarks have been proposed. However, variations in
evaluation settings across these benchmarks lead to inconsistent results,
making it difficult to draw reliable comparisons. Besides, the high
computational cost of long-context evaluation poses a significant barrier for
the community to conduct comprehensive assessments of long-context models. In
this paper, we propose LOOM-Scope, a comprehensive and efficient framework for
long-context evaluation. LOOM-Scope standardizes evaluation settings across
diverse benchmarks, supports deployment of efficient long-context inference
**acceleration** methods, and introduces a holistic yet lightweight benchmark suite
to evaluate models comprehensively. Homepage: https://loomscope.github.io


## LumiCRS Asymmetric Contrastive Prototype Learning for Long-Tail Conversational Movie Recommendation

>Authors: Jinzhi Wang, Bin Li, Qingke Peng, Haozhou Li, Zeyuan Zeng, Ruimeng Li, Biyi Zhou

>2025-07-07

> http://arxiv.org/abs/2507.04722v1

Conversational recommender systems (CRSs) often suffer from an extreme
long-tail distribution of dialogue data, causing a strong bias toward
head-frequency blockbusters that sacrifices diversity and exacerbates the
cold-start problem. An empirical analysis of DCRS and statistics on the REDIAL
corpus show that only 10% of head movies account for nearly half of all
mentions, whereas about 70% of tail movies receive merely 26% of the attention.
This imbalance gives rise to three critical challenges: head over-fitting, body
representation drift, and tail **sparsity**. To address these issues, we propose
LumiCRS, an end-to-end framework that mitigates long-tail imbalance through
three mutually reinforcing layers: (i) an Adaptive Comprehensive Focal Loss
(ACFL) that dynamically adjusts class weights and focusing factors to curb head
over-fitting and reduce popularity bias; (ii) Prototype Learning for Long-Tail
Recommendation, which selects semantic, affective, and contextual prototypes to
guide clustering and stabilize body and tail representations; and (iii) a
GPT-4o-driven prototype-guided dialogue augmentation module that automatically
generates diverse long-tail conversational snippets to alleviate tail **sparsity**
and distribution shift. Together, these strategies enable LumiCRS to markedly
improve recommendation accuracy, diversity, and fairness: on the REDIAL and
INSPIRED benchmarks, LumiCRS boosts Recall@10 and Tail-Recall@10 by 7-15% over
fifteen strong baselines, while human evaluations confirm superior fluency,
informativeness, and long-tail relevance. These results demonstrate the
effectiveness of multi-layer collaboration in building an efficient and fair
long-tail conversational recommender.


## VectorLLM Human-like Extraction of Structured Building Contours vis Multimodal LLMs

>Authors: Tao Zhang, Shiqing Wei, Shihao Chen, Wenling Yu, Muying Luo, Shunping Ji

>2025-07-07

> http://arxiv.org/abs/2507.04664v1

Automatically extracting vectorized building contours from remote sensing
imagery is crucial for urban planning, population estimation, and disaster
assessment. Current state-of-the-art methods rely on complex multi-stage
pipelines involving pixel segmentation, vectorization, and polygon refinement,
which limits their scalability and real-world applicability. Inspired by the
remarkable reasoning capabilities of Large Language Models (LLMs), we introduce
VectorLLM, the first Multi-modal Large Language Model (MLLM) designed for
regular building contour extraction from remote sensing images. Unlike existing
approaches, VectorLLM performs corner-point by corner-point regression of
building contours directly, mimicking human annotators' labeling process. Our
architecture consists of a vision foundation backbone, an MLP connector, and an
LLM, enhanced with learnable position embeddings to improve spatial
understanding capability. Through comprehensive exploration of training
strategies including pretraining, supervised fine-tuning, and preference
optimization across WHU, WHU-Mix, and CrowdAI datasets, VectorLLM significantly
outperformed the previous SOTA methods by 5.6 AP, 7.1 AP, 13.6 AP, respectively
in the three datasets. Remarkably, VectorLLM exhibits strong zero-shot
performance on unseen objects including aircraft, water bodies, and oil tanks,
highlighting its potential for unified modeling of diverse remote sensing
object contour extraction tasks. Overall, this work establishes a new paradigm
for vector extraction in remote sensing, leveraging the topological reasoning
capabilities of LLMs to achieve both high accuracy and exceptional
generalization. All the codes and weights will be published for promoting
community development.


## Simultaneous Localization and Mapping Using Active mmWave Sensing in 5G NR

>Authors: Tao Du, Jie Yang, Fan Liu, Jiaxiang Guo, Shuqiang Xia, Chao-Kai Wen, Shi Jin

>2025-07-07

> http://arxiv.org/abs/2507.04662v1

Millimeter-wave (mmWave) 5G New Radio (NR) **communication** systems, with their
high-resolution antenna arrays and extensive bandwidth, offer a transformative
opportunity for high-throughput data transmission and advanced environmental
sensing. Although passive sensing-based SLAM techniques can estimate user
locations and environmental reflections simultaneously, their effectiveness is
often constrained by assumptions of specular reflections and oversimplified map
representations. To overcome these limitations, this work employs a mmWave 5G
NR system for active sensing, enabling it to function similarly to a laser
scanner for point cloud generation. Specifically, point clouds are extracted
from the power delay profile estimated from each beam direction using a binary
search approach. To ensure accuracy, hardware delays are calibrated with
multiple predefined target points. Pose variations of the terminal are then
estimated from point cloud data gathered along continuous trajectory viewpoints
using point cloud registration algorithms. Loop closure detection and pose
graph optimization are subsequently applied to refine the sensing results,
achieving precise terminal localization and detailed radio map reconstruction.
The system is implemented and validated through both simulations and
experiments, confirming the effectiveness of the proposed approach.


## Enhancing Data Processing Efficiency in Blockchain Enabled Metaverse over Wireless Communications

>Authors: Liangxin Qian, Jun Zhao

>2025-07-07

> http://arxiv.org/abs/2507.04657v1

In the rapidly evolving landscape of the Metaverse, enhanced by blockchain
technology, the efficient processing of data has emerged as a critical
challenge, especially in wireless **communication** systems. Addressing this
challenge, our paper introduces the innovative concept of data processing
efficiency (DPE), aiming to maximize processed bits per unit of resource
consumption in blockchain-empowered Metaverse environments. To achieve this, we
propose the DPE-Aware User Association and Resource Allocation (DAUR)
algorithm, a tailored optimization framework for blockchain-enabled Metaverse
wireless **communication** systems characterized by joint computing and
**communication** resource constraints. The DAUR algorithm transforms the nonconvex
problem of maximizing the sum of DPE ratios into a solvable convex optimization
problem. It alternates the optimization of key variables, including user
association, work offloading ratios, task-specific computing resource
distribution, bandwidth allocation, user power usage ratios, and server
computing resource allocation ratios. Our extensive numerical results
demonstrate the DAUR algorithm's effectiveness in DPE.


## LTMSformer A Local Trend-Aware Attention and Motion State Encoding Transformer for Multi-Agent Trajectory Prediction

>Authors: Yixin Yan, Yang Li, Yuanfan Wang, Xiaozhou Zhou, Beihao Xia, Manjiang Hu, Hongmao Qin

>2025-07-07

> http://arxiv.org/abs/2507.04634v1

It has been challenging to model the complex temporal-spatial dependencies
between agents for trajectory prediction. As each state of an agent is closely
related to the states of adjacent time steps, capturing the local temporal
dependency is beneficial for prediction, while most studies often overlook it.
Besides, learning the high-order motion state attributes is expected to enhance
spatial interaction modeling, but it is rarely seen in previous works. To
address this, we propose a lightweight framework, LTMSformer, to extract
temporal-spatial interaction features for multi-modal trajectory prediction.
Specifically, we introduce a Local Trend-Aware Attention mechanism to capture
the local temporal dependency by leveraging a convolutional attention mechanism
with hierarchical local time boxes. Next, to model the spatial interaction
dependency, we build a Motion State Encoder to incorporate high-order motion
state attributes, such as **acceleration**, jerk, heading, etc. To further refine
the trajectory prediction, we propose a Lightweight Proposal Refinement Module
that leverages Multi-Layer Perceptrons for trajectory embedding and generates
the refined trajectories with fewer model parameters. Experiment results on the
Argoverse 1 dataset demonstrate that our method outperforms the baseline
HiVT-64, reducing the minADE by approximately 4.35%, the minFDE by 8.74%, and
the MR by 20%. We also achieve higher accuracy than HiVT-128 with a 68%
reduction in model size.


## Can Prompt Difficulty be Online Predicted for Accelerating RL Finetuning of Reasoning Models?

>Authors: Yun Qu, Qi Cheems Wang, Yixiu Mao, Vincent Tao Hu, Xiangyang Ji

>2025-07-07

> http://arxiv.org/abs/2507.04632v1

Recent advances have witnessed the effectiveness of reinforcement learning
(RL) finetuning in enhancing the reasoning capabilities of large language
models (LLMs). The optimization process often requires numerous iterations to
achieve satisfactory performance, resulting in high computational costs due to
the need for frequent prompt evaluations under intensive LLM interactions and
repeated policy updates. Appropriate online prompt selection methods reduce
iteration steps by prioritizing informative prompts during training, while the
pipeline's reliance on exhaustive prompt evaluation and subset selection for
optimization still incurs substantial computational overhead due to frequent
LLM inference calls. Distinguished from these direct evaluate-then-select
schemes, this work investigates iterative approximate evaluation for arbitrary
prompts and introduces Model Predictive Prompt Selection (MoPPS), a Bayesian
risk-predictive framework that online estimates prompt difficulty without
requiring costly LLM interactions. Technically, MoPPS models each prompt's
success rate as a latent variable, performs streaming Bayesian inference, and
employs posterior sampling in a constructed multi-armed bandit machine,
enabling sample efficient and adaptive prompt selection. Extensive experiments
across mathematics, planning, and vision-based geometry tasks show that MoPPS
reliably predicts prompt difficulty and accelerates training with significantly
reduced LLM rollouts.


## Multimodal LLM Integrated Semantic Communications for 6G Immersive Experiences

>Authors: Yusong Zhang, Yuxuan Sun, Lei Guo, Wei Chen, Bo Ai, Deniz Gunduz

>2025-07-07

> http://arxiv.org/abs/2507.04621v1

6G networks promise revolutionary immersive **communication** experiences
including augmented reality (AR), virtual reality (VR), and holographic
**communication**s. These applications demand high-dimensional multimodal data
transmission and intelligent data processing in real-time, which is extremely
challenging over resource-limited wireless **communication** systems. Moreover, a
joint understanding of the environment, context, and user intent is essential
to deliver task-relevant content effectively. This article presents a novel
multimodal large language model (MLLM) integrated semantic **communication**s
framework, termed MLLM-SC, which fully leverages reasoning and generative
capabilities of pre-trained foundation models for context-aware and
task-oriented wireless **communication**. The MLLM-SC framework adopts a
device-edge collaborative architecture. At the edge, MLLM-empowered semantic
guidance module analyzes multimodal inputs, user intents, and channel
conditions to generate importance-aware attention maps prioritizing
semantically critical information. An importance-aware semantic encoder and a
resource-adaptive semantic decoder are jointly designed and optimized, which
can utilize the semantic guidance for adaptive bandwidth allocation and
high-quality content reconstruction or generation. Extensive case studies on
visual question answering for AR/VR applications and diffusion-driven image
generation validate the effectiveness of MLLM-SC.

