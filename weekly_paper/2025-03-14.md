# 2025-03-14

# Table of Contents
* [BIMBA Selective-Scan Compression for Long-Range Video Question Answering](#BIMBA-Selective-Scan-Compression-for-Long-Range-Video-Question-Answering)
* [The R2D2 Deep Neural Network Series for Scalable Non-Cartesian Magnetic Resonance Imaging](#The-R2D2-Deep-Neural-Network-Series-for-Scalable-Non-Cartesian-Magnetic-Resonance-Imaging)
* [ViM-VQ Efficient Post-Training Vector Quantization for Visual Mamba](#ViM-VQ-Efficient-Post-Training-Vector-Quantization-for-Visual-Mamba)
* [Context-aware Constrained Reinforcement Learning Based Energy-Efficient Power Scheduling for Non-stationary XR Data Traffic](#Context-aware-Constrained-Reinforcement-Learning-Based-Energy-Efficient-Power-Scheduling-for-Non-stationary-XR-Data-Traffic)
* [SCOPE-DTI Semi-Inductive Dataset Construction and Framework Optimization for Practical Usability Enhancement in Deep Learning-Based Drug Target Interaction Prediction](#SCOPE-DTI-Semi-Inductive-Dataset-Construction-and-Framework-Optimization-for-Practical-Usability-Enhancement-in-Deep-Learning-Based-Drug-Target-Interaction-Prediction)
* [NAMI Efficient Image Generation via Progressive Rectified Flow Transformers](#NAMI-Efficient-Image-Generation-via-Progressive-Rectified-Flow-Transformers)
* [Efficient UAV Swarm-Based Multi-Task Federated Learning with Dynamic Task Knowledge Sharing](#Efficient-UAV-Swarm-Based-Multi-Task-Federated-Learning-with-Dynamic-Task-Knowledge-Sharing)
* [Discovering Influential Neuron Path in Vision Transformers](#Discovering-Influential-Neuron-Path-in-Vision-Transformers)
* [LLMs Know What to Drop Self-Attention Guided KV Cache Eviction for Efficient Long-Context Inference](#LLMs-Know-What-to-Drop-Self-Attention-Guided-KV-Cache-Eviction-for-Efficient-Long-Context-Inference)
* [QuoTA Query-oriented Token Assignment via CoT Query Decouple for Long Video Comprehension](#QuoTA-Query-oriented-Token-Assignment-via-CoT-Query-Decouple-for-Long-Video-Comprehension)
* [Efficient Many-Shot In-Context Learning with Dynamic Block-Sparse Attention](#Efficient-Many-Shot-In-Context-Learning-with-Dynamic-Block-Sparse-Attention)
* [3D Point Cloud Generation via Autoregressive Up-sampling](#3D-Point-Cloud-Generation-via-Autoregressive-Up-sampling)
* [Additive Frequency Diverse Active Incoherent Millimeter-Wave Imaging](#Additive-Frequency-Diverse-Active-Incoherent-Millimeter-Wave-Imaging)
* [FastCache Optimizing Multimodal LLM Serving through Lightweight KV-Cache Compression Framework](#FastCache-Optimizing-Multimodal-LLM-Serving-through-Lightweight-KV-Cache-Compression-Framework)
* [KAP MLLM-assisted OCR Text Enhancement for Hybrid Retrieval in Chinese Non-Narrative Documents](#KAP-MLLM-assisted-OCR-Text-Enhancement-for-Hybrid-Retrieval-in-Chinese-Non-Narrative-Documents)
* [V-Max Making RL practical for Autonomous Driving](#V-Max-Making-RL-practical-for-Autonomous-Driving)
* [Prototype-Based Multiple Instance Learning for Gigapixel Whole Slide Image Classification](#Prototype-Based-Multiple-Instance-Learning-for-Gigapixel-Whole-Slide-Image-Classification)
* [Layton Latent Consistency Tokenizer for 1024-pixel Image Reconstruction and Generation by 256 Tokens](#Layton-Latent-Consistency-Tokenizer-for-1024-pixel-Image-Reconstruction-and-Generation-by-256-Tokens)
* [Diffusion Transformer Meets Random Masks An Advanced PET Reconstruction Framework](#Diffusion-Transformer-Meets-Random-Masks-An-Advanced-PET-Reconstruction-Framework)
* [Polar perturbations in Kantowski-Sachs spacetimes and hybrid quantum cosmology](#Polar-perturbations-in-Kantowski-Sachs-spacetimes-and-hybrid-quantum-cosmology)
* [S3R-GS Streamlining the Pipeline for Large-Scale Street Scene Reconstruction](#S3R-GS-Streamlining-the-Pipeline-for-Large-Scale-Street-Scene-Reconstruction)
* [Route Sparse Autoencoder to Interpret Large Language Models](#Route-Sparse-Autoencoder-to-Interpret-Large-Language-Models)
* [OASIS Order-Augmented Strategy for Improved Code Search](#OASIS-Order-Augmented-Strategy-for-Improved-Code-Search)
* [Large Scale Multi-Task Bayesian Optimization with Large Language Models](#Large-Scale-Multi-Task-Bayesian-Optimization-with-Large-Language-Models)
* [Accelerate 3D Object Detection Models via Zero-Shot Attention Key Pruning](#Accelerate-3D-Object-Detection-Models-via-Zero-Shot-Attention-Key-Pruning)
* [MVGSR Multi-View Consistency Gaussian Splatting for Robust Surface Reconstruction](#MVGSR-Multi-View-Consistency-Gaussian-Splatting-for-Robust-Surface-Reconstruction)
* [A Bi-channel Aided Stitching of Atomic Force Microscopy Images](#A-Bi-channel-Aided-Stitching-of-Atomic-Force-Microscopy-Images)
* [Accurate INT8 Training Through Dynamic Block-Level Fallback](#Accurate-INT8-Training-Through-Dynamic-Block-Level-Fallback)
* [Multi-Cue Adaptive Visual Token Pruning for Large Vision-Language Models](#Multi-Cue-Adaptive-Visual-Token-Pruning-for-Large-Vision-Language-Models)
* [A Landmark-Aided Navigation Approach Using Side-Scan Sonar](#A-Landmark-Aided-Navigation-Approach-Using-Side-Scan-Sonar)
* [Training Domain Draft Models for Speculative Decoding Best Practices and Insights](#Training-Domain-Draft-Models-for-Speculative-Decoding-Best-Practices-and-Insights)
* [SEAP Training-free Sparse Expert Activation Pruning Unlock the Brainpower of Large Language Models](#SEAP-Training-free-Sparse-Expert-Activation-Pruning-Unlock-the-Brainpower-of-Large-Language-Models)
* [Queueing, Predictions, and LLMs Challenges and Open Problems](#Queueing,-Predictions,-and-LLMs-Challenges-and-Open-Problems)
* [TokenButler Token Importance is Predictable](#TokenButler-Token-Importance-is-Predictable)
* [EigenGS Representation From Eigenspace to Gaussian Image Space](#EigenGS-Representation-From-Eigenspace-to-Gaussian-Image-Space)
* [Open-Set Gait Recognition from Sparse mmWave Radar Point Clouds](#Open-Set-Gait-Recognition-from-Sparse-mmWave-Radar-Point-Clouds)
* [Multi-set variational quantum dynamics algorithm for simulating nonadiabatic dynamics on quantum computers](#Multi-set-variational-quantum-dynamics-algorithm-for-simulating-nonadiabatic-dynamics-on-quantum-computers)
* [Evaluation of Alignment-Regularity Characteristics in Deformable Image Registration](#Evaluation-of-Alignment-Regularity-Characteristics-in-Deformable-Image-Registration)
* [Exposure Bias Reduction for Enhancing Diffusion Transformer Feature Caching](#Exposure-Bias-Reduction-for-Enhancing-Diffusion-Transformer-Feature-Caching)
* [Quantizing Large Language Models for Code Generation A Differentiated Replication](#Quantizing-Large-Language-Models-for-Code-Generation-A-Differentiated-Replication)
* [TIDE  Temporal-Aware Sparse Autoencoders for Interpretable Diffusion Transformers in Image Generation](#TIDE--Temporal-Aware-Sparse-Autoencoders-for-Interpretable-Diffusion-Transformers-in-Image-Generation)
* [DatawiseAgent A Notebook-Centric LLM Agent Framework for Automated Data Science](#DatawiseAgent-A-Notebook-Centric-LLM-Agent-Framework-for-Automated-Data-Science)
* [EasyControl Adding Efficient and Flexible Control for Diffusion Transformer](#EasyControl-Adding-Efficient-and-Flexible-Control-for-Diffusion-Transformer)
* [PLADIS Pushing the Limits of Attention in Diffusion Models at Inference Time by Leveraging Sparsity](#PLADIS-Pushing-the-Limits-of-Attention-in-Diffusion-Models-at-Inference-Time-by-Leveraging-Sparsity)
* [Aligning Instance-Semantic Sparse Representation towards Unsupervised Object Segmentation and Shape Abstraction with Repeatable Primitives](#Aligning-Instance-Semantic-Sparse-Representation-towards-Unsupervised-Object-Segmentation-and-Shape-Abstraction-with-Repeatable-Primitives)
* [LLaFEA Frame-Event Complementary Fusion for Fine-Grained Spatiotemporal Understanding in LMMs](#LLaFEA-Frame-Event-Complementary-Fusion-for-Fine-Grained-Spatiotemporal-Understanding-in-LMMs)
* [Post-Training Quantization for Diffusion Transformer via Hierarchical Timestep Grouping](#Post-Training-Quantization-for-Diffusion-Transformer-via-Hierarchical-Timestep-Grouping)
* [From Reusing to Forecasting Accelerating Diffusion Models with TaylorSeers](#From-Reusing-to-Forecasting-Accelerating-Diffusion-Models-with-TaylorSeers)
* [Se-HiLo Noise-Resilient Semantic Communication with High-and-Low Frequency Decomposition](#Se-HiLo-Noise-Resilient-Semantic-Communication-with-High-and-Low-Frequency-Decomposition)
* [Maximum Inner Product is Query-Scaled Nearest Neighbor](#Maximum-Inner-Product-is-Query-Scaled-Nearest-Neighbor)
* [ResMoE Space-efficient Compression of Mixture of Experts LLMs via Residual Restoration](#ResMoE-Space-efficient-Compression-of-Mixture-of-Experts-LLMs-via-Residual-Restoration)
* [Enhancing Time Series Forecasting via Logic-Inspired Regularization](#Enhancing-Time-Series-Forecasting-via-Logic-Inspired-Regularization)
* [FIGLUT An Energy-Efficient Accelerator Design for FP-INT GEMM Using Look-Up Tables](#FIGLUT-An-Energy-Efficient-Accelerator-Design-for-FP-INT-GEMM-Using-Look-Up-Tables)
* [Stochastic Optimal Control of an Epidemic Under Partial Information](#Stochastic-Optimal-Control-of-an-Epidemic-Under-Partial-Information)
* [Seeing Delta Parameters as JPEG Images Data-Free Delta Compression with Discrete Cosine Transform](#Seeing-Delta-Parameters-as-JPEG-Images-Data-Free-Delta-Compression-with-Discrete-Cosine-Transform)
* [Beyond Decoder-only Large Language Models Can be Good Encoders for Machine Translation](#Beyond-Decoder-only-Large-Language-Models-Can-be-Good-Encoders-for-Machine-Translation)
* [QuantCache Adaptive Importance-Guided Quantization with Hierarchical Latent and Layer Caching for Video Generation](#QuantCache-Adaptive-Importance-Guided-Quantization-with-Hierarchical-Latent-and-Layer-Caching-for-Video-Generation)
* [Identifying point sources for biharmonic wave equation from the scattered fields at sparse sensors](#Identifying-point-sources-for-biharmonic-wave-equation-from-the-scattered-fields-at-sparse-sensors)
* [SAQ-SAM Semantically-Aligned Quantization for Segment Anything Model](#SAQ-SAM-Semantically-Aligned-Quantization-for-Segment-Anything-Model)
* [SP3D Boosting Sparsely-Supervised 3D Object Detection via Accurate Cross-Modal Semantic Prompts](#SP3D-Boosting-Sparsely-Supervised-3D-Object-Detection-via-Accurate-Cross-Modal-Semantic-Prompts)
* [Seesaw High-throughput LLM Inference via Model Re-sharding](#Seesaw-High-throughput-LLM-Inference-via-Model-Re-sharding)
* [Graph Retrieval-Augmented LLM for Conversational Recommendation Systems](#Graph-Retrieval-Augmented-LLM-for-Conversational-Recommendation-Systems)
* [Pre-Training Meta-Rule Selection Policy for Visual Generative Abductive Learning](#Pre-Training-Meta-Rule-Selection-Policy-for-Visual-Generative-Abductive-Learning)
* [FEDS Feature and Entropy-Based Distillation Strategy for Efficient Learned Image Compression](#FEDS-Feature-and-Entropy-Based-Distillation-Strategy-for-Efficient-Learned-Image-Compression)
* [How LLMs Learn Tracing Internal Representations with Sparse Autoencoders](#How-LLMs-Learn-Tracing-Internal-Representations-with-Sparse-Autoencoders)
* [X-LRM X-ray Large Reconstruction Model for Extremely Sparse-View Computed Tomography Recovery in One Second](#X-LRM-X-ray-Large-Reconstruction-Model-for-Extremely-Sparse-View-Computed-Tomography-Recovery-in-One-Second)
* [MoEMoE Question Guided Dense and Scalable Sparse Mixture-of-Expert for Multi-source Multi-modal Answering](#MoEMoE-Question-Guided-Dense-and-Scalable-Sparse-Mixture-of-Expert-for-Multi-source-Multi-modal-Answering)
* [IteRABRe Iterative Recovery-Aided Block Reduction](#IteRABRe-Iterative-Recovery-Aided-Block-Reduction)
* [MAD-MAX Modular And Diverse Malicious Attack MiXtures for Automated LLM Red Teaming](#MAD-MAX-Modular-And-Diverse-Malicious-Attack-MiXtures-for-Automated-LLM-Red-Teaming)
* [Rethinking Lanes and Points in Complex Scenarios for Monocular 3D Lane Detection](#Rethinking-Lanes-and-Points-in-Complex-Scenarios-for-Monocular-3D-Lane-Detection)
* [Sample-aware Adaptive Structured Pruning for Large Language Models](#Sample-aware-Adaptive-Structured-Pruning-for-Large-Language-Models)
* [Lightweight Software Kernels and Hardware Extensions for Efficient Sparse Deep Neural Networks on Microcontrollers](#Lightweight-Software-Kernels-and-Hardware-Extensions-for-Efficient-Sparse-Deep-Neural-Networks-on-Microcontrollers)
* [FlowMP Learning Motion Fields for Robot Planning with Conditional Flow Matching](#FlowMP-Learning-Motion-Fields-for-Robot-Planning-with-Conditional-Flow-Matching)
* [PointDiffuse A Dual-Conditional Diffusion Model for Enhanced Point Cloud Semantic Segmentation](#PointDiffuse-A-Dual-Conditional-Diffusion-Model-for-Enhanced-Point-Cloud-Semantic-Segmentation)
* [Disrupting Model Merging A Parameter-Level Defense Without Sacrificing Accuracy](#Disrupting-Model-Merging-A-Parameter-Level-Defense-Without-Sacrificing-Accuracy)
* [Multi-view Spectral Clustering on the Grassmannian Manifold With Hypergraph Representation](#Multi-view-Spectral-Clustering-on-the-Grassmannian-Manifold-With-Hypergraph-Representation)
* [SmartBench Is Your LLM Truly a Good Chinese Smartphone Assistant?](#SmartBench-Is-Your-LLM-Truly-a-Good-Chinese-Smartphone-Assistant?)
* [Analyzing the Role of Permutation Invariance in Linear Mode Connectivity](#Analyzing-the-Role-of-Permutation-Invariance-in-Linear-Mode-Connectivity)
* [TPU-Gen LLM-Driven Custom Tensor Processing Unit Generator](#TPU-Gen-LLM-Driven-Custom-Tensor-Processing-Unit-Generator)
* [CASP Compression of Large Multimodal Models Based on Attention Sparsity](#CASP-Compression-of-Large-Multimodal-Models-Based-on-Attention-Sparsity)
* [A Survey on Sparse Autoencoders Interpreting the Internal Mechanisms of Large Language Models](#A-Survey-on-Sparse-Autoencoders-Interpreting-the-Internal-Mechanisms-of-Large-Language-Models)
* [Mol-CADiff Causality-Aware Autoregressive Diffusion for Molecule Generation](#Mol-CADiff-Causality-Aware-Autoregressive-Diffusion-for-Molecule-Generation)
* [Benchmarking LLMs in Recommendation Tasks A Comparative Evaluation with Conventional Recommenders](#Benchmarking-LLMs-in-Recommendation-Tasks-A-Comparative-Evaluation-with-Conventional-Recommenders)
* [SplitQuantV2 Enhancing Low-Bit Quantization of LLMs Without GPUs](#SplitQuantV2-Enhancing-Low-Bit-Quantization-of-LLMs-Without-GPUs)
* [Deep Frequency Attention Networks for Single Snapshot Sparse Array Interpolation](#Deep-Frequency-Attention-Networks-for-Single-Snapshot-Sparse-Array-Interpolation)
* [Linear-MoE Linear Sequence Modeling Meets Mixture-of-Experts](#Linear-MoE-Linear-Sequence-Modeling-Meets-Mixture-of-Experts)
* [Accelerating Earth Science Discovery via Multi-Agent LLM Systems](#Accelerating-Earth-Science-Discovery-via-Multi-Agent-LLM-Systems)
* [Multi-Grained Feature Pruning for Video-Based Human Pose Estimation](#Multi-Grained-Feature-Pruning-for-Video-Based-Human-Pose-Estimation)
* [MatrixFlow System-Accelerator co-design for high-performance transformer applications](#MatrixFlow-System-Accelerator-co-design-for-high-performance-transformer-applications)
* [MM-StoryAgent Immersive Narrated Storybook Video Generation with a Multi-Agent Paradigm across Text, Image and Audio](#MM-StoryAgent-Immersive-Narrated-Storybook-Video-Generation-with-a-Multi-Agent-Paradigm-across-Text,-Image-and-Audio)
* [SplatPose Geometry-Aware 6-DoF Pose Estimation from Single RGB Image via 3D Gaussian Splatting](#SplatPose-Geometry-Aware-6-DoF-Pose-Estimation-from-Single-RGB-Image-via-3D-Gaussian-Splatting)
* [GaussianCAD Robust Self-Supervised CAD Reconstruction from Three Orthographic Views Using 3D Gaussian Splatting](#GaussianCAD-Robust-Self-Supervised-CAD-Reconstruction-from-Three-Orthographic-Views-Using-3D-Gaussian-Splatting)
* [Accelerating Diffusion Transformer via Gradient-Optimized Cache](#Accelerating-Diffusion-Transformer-via-Gradient-Optimized-Cache)
* [MergeQuant Accurate 4-bit Static Quantization of Large Language Models by Channel-wise Calibration](#MergeQuant-Accurate-4-bit-Static-Quantization-of-Large-Language-Models-by-Channel-wise-Calibration)
* [HexPlane Representation for 3D Semantic Scene Understanding](#HexPlane-Representation-for-3D-Semantic-Scene-Understanding)
* [SpecServe Efficient and SLO-Aware Large Language Model Serving with Adaptive Speculative Decoding](#SpecServe-Efficient-and-SLO-Aware-Large-Language-Model-Serving-with-Adaptive-Speculative-Decoding)
* [Lightweight Hypercomplex MRI Reconstruction A Generalized Kronecker-Parameterized Approach](#Lightweight-Hypercomplex-MRI-Reconstruction-A-Generalized-Kronecker-Parameterized-Approach)


## BIMBA Selective-Scan Compression for Long-Range Video Question Answering

>Authors: Md Mohaiminul Islam, Tushar Nagarajan, Huiyu Wang, Gedas Bertasius, Lorenzo Torresani

>2025-03-12

> http://arxiv.org/abs/2503.09590v2

Video Question Answering (VQA) in long videos poses the key challenge of
extracting relevant information and modeling long-range dependencies from many
redundant frames. The self-attention mechanism provides a general solution for
sequence modeling, but it has a prohibitive cost when applied to a massive
number of spatiotemporal tokens in long videos. Most prior methods rely on
compression strategies to lower the computational cost, such as reducing the
input length via **sparse** frame sampling or compressing the output sequence
passed to the large language model (LLM) via space-time pooling. However, these
naive approaches over-represent redundant information and often miss salient
events or fast-occurring space-time patterns. In this work, we introduce BIMBA,
an efficient state-space model to handle long-form videos. Our model leverages
the selective scan algorithm to learn to effectively select critical
information from high-dimensional video and transform it into a reduced token
sequence for efficient LLM processing. Extensive experiments demonstrate that
BIMBA achieves state-of-the-art accuracy on multiple long-form VQA benchmarks,
including PerceptionTest, NExT-QA, EgoSchema, VNBench, LongVideoBench, and
Video-MME. Code, and models are publicly available at
https://sites.google.com/view/bimba-mllm.


## The R2D2 Deep Neural Network Series for Scalable Non-Cartesian Magnetic Resonance Imaging

>Authors: Yiwei Chen, Amir Aghabiglou, Shijie Chen, Motahare Torki, Chao Tang, Ruud B. van Heeswijk, Yves Wiaux

>2025-03-12

> http://arxiv.org/abs/2503.09559v2

We introduce the R2D2 Deep Neural Network (DNN) series paradigm for fast and
scalable image reconstruction from highly-accelerated non-Cartesian k-space
acquisitions in Magnetic Resonance Imaging (MRI). While unrolled DNN
architectures provide a robust image formation approach via data-consistency
layers, embedding non-uniform fast Fourier transform operators in a DNN can
become impractical to train at large scale, e.g in 2D MRI with a large number
of coils, or for higher-dimensional imaging. Plug-and-play approaches that
alternate a learned denoiser blind to the measurement setting with a
data-consistency step are not affected by this limitation but their highly
iterative nature implies slow reconstruction. To address this scalability
challenge, we leverage the R2D2 paradigm that was recently introduced to enable
ultra-fast reconstruction for large-scale Fourier imaging in radio astronomy.
R2D2's reconstruction is formed as a series of residual images iteratively
estimated as outputs of DNN modules taking the previous iteration's data
residual as input. The method can be interpreted as a learned version of the
Matching Pursuit algorithm. A series of R2D2 DNN modules were sequentially
trained in a supervised manner on the fastMRI dataset and validated for 2D
multi-coil MRI in simulation and on real data, targeting highly under-sampled
radial k-space sampling. Results suggest that a series with only few DNNs
achieves superior reconstruction quality over its unrolled incarnation R2D2-Net
(whose training is also much less scalable), and over the state-of-the-art
diffusion-based "Decomposed Diffusion Sampler" approach (also characterised by
a slower reconstruction process).


## ViM-VQ Efficient Post-Training Vector Quantization for Visual Mamba

>Authors: Juncan Deng, Shuaiting Li, Zeyu Wang, Kedong Xu, Hong Gu, Kejie Huang

>2025-03-12

> http://arxiv.org/abs/2503.09509v1

Visual Mamba networks (ViMs) extend the selective space state model (Mamba)
to various vision tasks and demonstrate significant potential. Vector
**quantization** (VQ), on the other hand, decomposes network weights into codebooks
and assignments, significantly reducing memory usage and computational latency
to enable ViMs deployment on edge devices. Although existing VQ methods have
achieved extremely **low-bit** **quantization** (e.g., 3-bit, 2-bit, and 1-bit) in
convolutional neural networks and Transformer-based networks, directly applying
these methods to ViMs results in unsatisfactory accuracy. We identify several
key challenges: 1) The weights of Mamba-based blocks in ViMs contain numerous
outliers, significantly amplifying **quantization** errors. 2) When applied to
ViMs, the latest VQ methods suffer from excessive memory consumption, lengthy
calibration procedures, and suboptimal performance in the search for optimal
codewords. In this paper, we propose ViM-VQ, an efficient post-training vector
**quantization** method tailored for ViMs. ViM-VQ consists of two innovative
components: 1) a fast convex combination optimization algorithm that
efficiently updates both the convex combinations and the convex hulls to search
for optimal codewords, and 2) an incremental vector **quantization** strategy that
incrementally confirms optimal codewords to mitigate truncation errors.
Experimental results demonstrate that ViM-VQ achieves state-of-the-art
performance in **low-bit** **quantization** across various visual tasks.


## Context-aware Constrained Reinforcement Learning Based Energy-Efficient Power Scheduling for Non-stationary XR Data Traffic

>Authors: Kexuan Wang, An Liu

>2025-03-12

> http://arxiv.org/abs/2503.09391v1

In XR downlink transmission, energy-efficient power scheduling (EEPS) is
essential for conserving power resource while delivering large data packets
within hard-latency constraints. Traditional constrained reinforcement learning
(CRL) algorithms show promise in EEPS but still struggle with non-convex
stochastic constraints, non-stationary data traffic, and **sparse** delayed packet
dropout feedback (rewards) in XR. To overcome these challenges, this paper
models the EEPS in XR as a dynamic parameter-constrained Markov decision
process (DP-CMDP) with a varying transition function linked to the
non-stationary data traffic and solves it by a proposed context-aware
constrained reinforcement learning (CACRL) algorithm, which consists of a
context inference (CI) module and a CRL module. The CI module trains an encoder
and multiple potential networks to characterize the current transition function
and reshape the packet dropout rewards according to the context, transforming
the original DP-CMDP into a general CMDP with immediate dense rewards. The CRL
module employs a policy network to make EEPS decisions under this CMDP and
optimizes the policy using a constrained stochastic successive convex
approximation (CSSCA) method, which is better suited for non-convex stochastic
constraints. Finally, theoretical analyses provide deep insights into the CADAC
algorithm, while extensive simulations demonstrate that it outperforms advanced
baselines in both power conservation and satisfying packet dropout constraints.


## SCOPE-DTI Semi-Inductive Dataset Construction and Framework Optimization for Practical Usability Enhancement in Deep Learning-Based Drug Target Interaction Prediction

>Authors: Yigang Chen, Xiang Ji, Ziyue Zhang, Yuming Zhou, Yang-Chi-Dung Lin, Hsi-Yuan Huang, Tao Zhang, Yi Lai, Ke Chen, Chang Su, Xingqiao Lin, Zihao Zhu, Yanggyi Zhang, Kangping Wei, Jiehui Fu, Yixian Huang, Shidong Cui, Shih-Chung Yen, Ariel Warshel, Hsien-Da Huang

>2025-03-12

> http://arxiv.org/abs/2503.09251v1

Deep learning-based drug-target interaction (DTI) prediction methods have
demonstrated strong performance; however, real-world applicability remains
constrained by limited data diversity and modeling complexity. To address these
challenges, we propose SCOPE-DTI, a unified framework combining a large-scale,
balanced semi-inductive human DTI dataset with advanced deep learning modeling.
Constructed from 13 public repositories, the SCOPE dataset expands data volume
by up to 100-fold compared to common benchmarks such as the Human dataset. The
SCOPE model integrates three-dimensional protein and compound representations,
graph neural networks, and bilinear attention mechanisms to effectively capture
cross domain interaction patterns, significantly outperforming state-of-the-art
methods across various DTI prediction tasks. Additionally, SCOPE-DTI provides a
user-friendly interface and database. We further validate its effectiveness by
experimentally identifying anticancer targets of Ginsenoside Rh1. By offering
comprehensive data, advanced modeling, and accessible tools, SCOPE-DTI
accelerates drug discovery research.


## NAMI Efficient Image Generation via Progressive Rectified Flow Transformers

>Authors: Yuhang Ma, Bo Cheng, Shanyuan Liu, Ao Ma, Xiaoyu Wu, Liebucha Wu, Dawei Leng, Yuhui Yin

>2025-03-12

> http://arxiv.org/abs/2503.09242v1

Flow-based transformer models for image generation have achieved
state-of-the-art performance with larger model parameters, but their inference
deployment cost remains high. To enhance inference performance while
maintaining generation quality, we propose progressive rectified flow
transformers. We divide the rectified flow into different stages according to
resolution, using fewer transformer layers at the low-resolution stages to
generate image layouts and concept contours, and progressively adding more
layers as the resolution increases. Experiments demonstrate that our approach
achieves fast convergence and reduces inference time while ensuring generation
quality. The main contributions of this paper are summarized as follows: (1) We
introduce progressive rectified flow transformers that enable multi-resolution
training, accelerating model convergence; (2) NAMI leverages piecewise flow and
spatial cascading of Diffusion Transformer (DiT) to rapidly generate images,
reducing inference time by 40% to generate a 1024 resolution image; (3) We
propose NAMI-1K benchmark to evaluate human preference performance, aiming to
mitigate distributional bias and prevent data leakage from open-source
benchmarks. The results show that our model is competitive with
state-of-the-art models.


## Efficient UAV Swarm-Based Multi-Task Federated Learning with Dynamic Task Knowledge Sharing

>Authors: Yubo Yang, Tao Yang, Xiaofeng Wu, Ziyu Guo, Bo Hu

>2025-03-12

> http://arxiv.org/abs/2503.09144v1

UAV swarms are widely used in emergency communications, area monitoring, and
disaster relief. Coordinated by control centers, they are ideal for federated
learning (FL) frameworks. However, current UAV-assisted FL methods primarily
focus on single tasks, overlooking the need for multi-task training. In
disaster relief scenarios, UAVs perform tasks such as crowd detection, road
feasibility analysis, and disaster assessment, which exhibit time-varying
demands and potential correlations. In order to meet the time-varying
requirements of tasks and complete multiple tasks efficiently under resource
constraints, in this paper, we propose a UAV swarm based multi-task FL
framework, where ground emergency vehicles (EVs) collaborate with UAVs to
accomplish multiple tasks efficiently under constrained energy and bandwidth
resources. Through theoretical analysis, we identify key factors affecting task
performance and introduce a task attention mechanism to dynamically evaluate
task importance, thereby achieving efficient resource allocation. Additionally,
we propose a task affinity (TA) metric to capture the dynamic correlation among
tasks, thereby promoting task knowledge sharing to accelerate training and
improve the generalization ability of the model in different scenarios. To
optimize resource allocation, we formulate a two-layer optimization problem to
jointly optimize UAV transmission power, computation frequency, bandwidth
allocation, and UAV-EV associations. For the inner problem, we derive
closed-form solutions for transmission power, computation frequency, and
bandwidth allocation and apply a block coordinate descent method for
optimization. For the outer problem, a two-stage algorithm is designed to
determine optimal UAV-EV associations. Furthermore, theoretical analysis
reveals a trade-off between UAV energy consumption and multi-task performance.


## Discovering Influential Neuron Path in Vision Transformers

>Authors: Yifan Wang, Yifei Liu, Yingdong Shi, Changming Li, Anqi Pang, Sibei Yang, Jingyi Yu, Kan Ren

>2025-03-12

> http://arxiv.org/abs/2503.09046v1

Vision Transformer models exhibit immense power yet remain opaque to human
understanding, posing challenges and risks for practical applications. While
prior research has attempted to demystify these models through input
attribution and neuron role analysis, there's been a notable gap in considering
layer-level information and the holistic path of information flow across
layers. In this paper, we investigate the significance of influential neuron
paths within vision Transformers, which is a path of neurons from the model
input to output that impacts the model inference most significantly. We first
propose a joint influence measure to assess the contribution of a set of
neurons to the model outcome. And we further provide a layer-progressive neuron
locating approach that efficiently selects the most influential neuron at each
layer trying to discover the crucial neuron path from input to output within
the target model. Our experiments demonstrate the superiority of our method
finding the most influential neuron path along which the information flows,
over the existing baseline solutions. Additionally, the neuron paths have
illustrated that vision Transformers exhibit some specific inner working
mechanism for processing the visual information within the same image category.
We further analyze the key effects of these neurons on the image classification
task, showcasing that the found neuron paths have already preserved the model
capability on downstream tasks, which may also shed some lights on real-world
applications like model **pruning**. The project website including implementation
code is available at https://foundation-model-research.github.io/NeuronPath/.


## LLMs Know What to Drop Self-Attention Guided KV Cache Eviction for Efficient Long-Context Inference

>Authors: Guangtao Wang, Shubhangi Upasani, Chen Wu, Darshan Gandhi, Jonathan Li, Changran Hu, Bo Li, Urmish Thakker

>2025-03-11

> http://arxiv.org/abs/2503.08879v1

Efficient long-context inference is critical as large language models (LLMs)
adopt context windows of ranging from 128K to 1M tokens. However, the growing
key-value (**KV**) cache and the high computational complexity of attention create
significant bottlenecks in memory usage and latency. In this paper, we find
that attention in diverse long-context tasks exhibits **sparsity**, and LLMs
implicitly "know" which tokens can be dropped or evicted at the head level
after the pre-filling stage. Based on this insight, we propose Self-Attention
Guided Eviction~(SAGE-**KV**), a simple and effective **KV** eviction cache method for
long-context inference. After prefilling, our method performs a one-time top-k
selection at both the token and head levels to compress the **KV** cache, enabling
efficient inference with the reduced cache. Evaluations on LongBench and three
long-context LLMs (Llama3.1-8B-Instruct-128k, Llama3-8B-Prolong-512k-Instruct,
and Qwen2.5-7B-Instruct-128k) show that SAGE-**KV** maintains accuracy comparable
to full attention while significantly improving efficiency. Specifically,
SAGE-**KV** achieves 4x higher memory efficiency with improved accuracy over the
static **KV** cache selection method StreamLLM, and 2x higher memory efficiency
with better accuracy than the dynamic **KV** cache selection method Quest.


## QuoTA Query-oriented Token Assignment via CoT Query Decouple for Long Video Comprehension

>Authors: Yongdong Luo, Wang Chen, Xiawu Zheng, Weizhong Huang, Shukang Yin, Haojia Lin, Chaoyou Fu, Jinfa Huang, Jiayi Ji, Jiebo Luo, Rongrong Ji

>2025-03-11

> http://arxiv.org/abs/2503.08689v1

Recent advances in long video understanding typically mitigate visual
redundancy through visual token **pruning** based on attention distribution.
However, while existing methods employ post-hoc low-response token **pruning** in
decoder layers, they overlook the input-level semantic correlation between
visual tokens and instructions (query). In this paper, we propose QuoTA, an
ante-hoc training-free modular that extends existing large video-language
models (LVLMs) for visual token assignment based on query-oriented frame-level
importance assessment. The query-oriented token selection is crucial as it
aligns visual processing with task-specific requirements, optimizing token
budget utilization while preserving semantically relevant content.
Specifically, (i) QuoTA strategically allocates frame-level importance scores
based on query relevance, enabling one-time visual token assignment before
cross-modal interactions in decoder layers, (ii) we decouple the query through
Chain-of-Thoughts reasoning to facilitate more precise LVLM-based frame
importance scoring, and (iii) QuoTA offers a plug-and-play functionality that
extends to existing LVLMs. Extensive experimental results demonstrate that
implementing QuoTA with LLaVA-Video-7B yields an average performance
improvement of 3.2% across six benchmarks (including Video-MME and MLVU) while
operating within an identical visual token budget as the baseline. Codes are
open-sourced at https://github.com/MAC-AutoML/QuoTA.


## Efficient Many-Shot In-Context Learning with Dynamic Block-Sparse Attention

>Authors: Emily Xiao, Chin-Jou Li, Yilin Zhang, Graham Neubig, Amanda Bertsch

>2025-03-11

> http://arxiv.org/abs/2503.08640v1

Many-shot in-context learning has recently shown promise as an alternative to
finetuning, with the major advantage that the same model can be served for
multiple tasks. However, this shifts the computational burden from
training-time to inference-time, making deployment of many-shot ICL challenging
to justify in-practice. This cost is further increased if a custom
demonstration set is retrieved for each inference example. We present Dynamic
Block-Sparse Attention, a training-free framework for retrieval-based many-shot
in-context learning. By combining carefully designed block-**sparse** attention and
retrieval of cached groups of demonstrations, we achieve comparable per-example
latency to finetuning while maintaining on average >95% of the best method's
accuracy across strong ICL and finetuning baselines. We hope that this will
further enable the deployment of many-shot ICL at scale.


## 3D Point Cloud Generation via Autoregressive Up-sampling

>Authors: Ziqiao Meng, Qichao Wang, Zhipeng Zhou, Irwin King, Peilin Zhao

>2025-03-11

> http://arxiv.org/abs/2503.08594v1

We introduce a pioneering autoregressive generative model for 3D point cloud
generation. Inspired by visual autoregressive modeling (VAR), we conceptualize
point cloud generation as an autoregressive up-sampling process. This leads to
our novel model, PointARU, which progressively refines 3D point clouds from
coarse to fine scales. PointARU follows a two-stage training paradigm: first,
it learns multi-scale discrete representations of point clouds, and then it
trains an autoregressive transformer for next-scale prediction. To address the
inherent unordered and irregular structure of point clouds, we incorporate
specialized point-based up-sampling network modules in both stages and
integrate 3D absolute positional encoding based on the decoded point cloud at
each scale during the second stage. Our model surpasses state-of-the-art (SoTA)
diffusion-based approaches in both generation quality and parameter efficiency
across diverse experimental settings, marking a new milestone for
autoregressive methods in 3D point cloud generation. Furthermore, PointARU
demonstrates exceptional performance in completing partial 3D shapes and
up-sampling **sparse** point clouds, outperforming existing generative models in
these tasks.


## Additive Frequency Diverse Active Incoherent Millimeter-Wave Imaging

>Authors: Jorge R. Colon-Berrios, Jeffrey A. Nanzer

>2025-03-11

> http://arxiv.org/abs/2503.08556v1

We present an approach for improving spatial frequency sampling in active
incoherent millimeter-wave (AIM) imaging systems using frequency diversity. AIM
imaging relies on active transmission of spatio-temporally incoherent signals
to illuminate a scene, from which interferometric Fourier-domain imaging can be
implemented using a **sparse** receiving antenna array. One of the benefits of
Fourier domain imaging is the **sparsity** of the receiving array, which can form
images with equivalent resolution to traditional filled beamsteering arrays,
but with a small fraction of the elements. The hardware reduction afforded by
the **sparse** array often leads to an undersampled Fourier space, where even
though image formation is possible, the image reconstruction may be degraded
when viewing complex objects. To address this challenge without requiring
additional receiver channels, we explore the use of frequency diversity in the
illuminating and receiving systems. Fourier domain spatial frequency samples
are determined by the electrical spacing and rotation of the receiving
elements, thus by changing the frequency the sampled spatial frequencies also
change. We implement an additive technique where the spatial frequency samples
are summed prior to Fourier transform image formation. Importantly, because the
system is active, a consistent signal-to-noise ratio is maintained across all
frequencies, which may not be possible in traditional passive Fourier-domain
imagers.


## FastCache Optimizing Multimodal LLM Serving through Lightweight KV-Cache Compression Framework

>Authors: Jianian Zhu, Hang Wu, Haojie Wang, Yinghui Li, Biao Hou, Ruixuan Li, Jidong Zhai

>2025-03-11

> http://arxiv.org/abs/2503.08461v1

Multi-modal Large Language Models (MLLMs) serving systems commonly employ
**KV**-cache compression to reduce memory footprint. However, existing compression
methods introduce significant processing overhead and queuing delays,
particularly in concurrent serving scenarios. We present \texttt{FastCache}, a
novel serving framework that effectively addresses these challenges through two
key innovations: (1) a dynamic batching strategy that optimizes request
scheduling across prefill, compression, and decode stages, and (2) an efficient
**KV**-cache memory pool mechanism that eliminates memory fragmentation while
maintaining high GPU utilization. Our comprehensive experiments on the GQA and
MileBench datasets demonstrate that \texttt{FastCache} achieves up to
19.3$\times$ reduction in Time-To-First-Token (TTFT) and 12.1$\times$
improvement in throughput compared to state-of-the-art baselines. The system
maintains stable performance under high-concurrency scenarios (up to 40 req/s)
while reducing average memory consumption by 20\%. These results establish
\texttt{FastCache} as an efficient solution for real-world LLM serving systems
with **KV**-cache compression.


## KAP MLLM-assisted OCR Text Enhancement for Hybrid Retrieval in Chinese Non-Narrative Documents

>Authors: Hsin-Ling Hsu, Ping-Sheng Lin, Jing-Di Lin, Jengnan Tzeng

>2025-03-11

> http://arxiv.org/abs/2503.08452v1

We propose Knowledge-Aware Preprocessing (KAP), a two-stage preprocessing
framework tailored for Traditional Chinese non-narrative documents, designed to
enhance retrieval accuracy in Hybrid Retrieval systems. Hybrid Retrieval, which
integrates Sparse Retrieval (e.g., BM25) and Dense Retrieval (e.g., vector
embeddings), has become a widely adopted approach for improving search
effectiveness. However, its performance heavily depends on the quality of input
text, which is often degraded when dealing with non-narrative documents such as
PDFs containing financial statements, contractual clauses, and tables. KAP
addresses these challenges by integrating Multimodal Large Language Models
(MLLMs) with LLM-driven post-OCR processing, refining extracted text to reduce
OCR noise, restore table structures, and optimize text format. By ensuring
better compatibility with Hybrid Retrieval, KAP improves the accuracy of both
Sparse and Dense Retrieval methods without modifying the retrieval architecture
itself.


## V-Max Making RL practical for Autonomous Driving

>Authors: Valentin Charraut, Thomas Tournaire, Waël Doulazmi, Thibault Buhet

>2025-03-11

> http://arxiv.org/abs/2503.08388v1

Learning-based decision-making has the potential to enable generalizable
Autonomous Driving (AD) policies, reducing the engineering overhead of
rule-based approaches. Imitation Learning (IL) remains the dominant paradigm,
benefiting from large-scale human demonstration datasets, but it suffers from
inherent limitations such as distribution shift and imitation gaps.
Reinforcement Learning (RL) presents a promising alternative, yet its adoption
in AD remains limited due to the lack of standardized and efficient research
frameworks. To this end, we introduce V-Max, an open research framework
providing all the necessary tools to make RL practical for AD. V-Max is built
on Waymax, a hardware-accelerated AD simulator designed for large-scale
experimentation. We extend it using ScenarioNet's approach, enabling the fast
simulation of diverse AD datasets. V-Max integrates a set of observation and
reward functions, transformer-based encoders, and training pipelines.
Additionally, it includes adversarial evaluation settings and an extensive set
of evaluation metrics. Through a large-scale benchmark, we analyze how network
architectures, observation functions, training data, and reward shaping impact
RL performance.


## Prototype-Based Multiple Instance Learning for Gigapixel Whole Slide Image Classification

>Authors: Susu Sun, Dominique van Midden, Geert Litjens, Christian F. Baumgartner

>2025-03-11

> http://arxiv.org/abs/2503.08384v1

Multiple Instance Learning (MIL) methods have succeeded remarkably in
histopathology whole slide image (WSI) analysis. However, most MIL models only
offer attention-based explanations that do not faithfully capture the model's
decision mechanism and do not allow human-model interaction. To address these
limitations, we introduce ProtoMIL, an inherently interpretable MIL model for
WSI analysis that offers user-friendly explanations and supports human
intervention. Our approach employs a **sparse** autoencoder to discover
human-interpretable concepts from the image feature space, which are then used
to train ProtoMIL. The model represents predictions as linear combinations of
concepts, making the decision process transparent. Furthermore, ProtoMIL allows
users to perform model interventions by altering the input concepts.
Experiments on two widely used pathology datasets demonstrate that ProtoMIL
achieves a classification performance comparable to state-of-the-art MIL models
while offering intuitively understandable explanations. Moreover, we
demonstrate that our method can eliminate reliance on diagnostically irrelevant
information via human intervention, guiding the model toward being right for
the right reason. Code will be publicly available at
https://github.com/ss-sun/ProtoMIL.


## Layton Latent Consistency Tokenizer for 1024-pixel Image Reconstruction and Generation by 256 Tokens

>Authors: Qingsong Xie, Zhao Zhang, Zhe Huang, Yanhao Zhang, Haonan Lu, Zhenyu Yang

>2025-03-11

> http://arxiv.org/abs/2503.08377v2

Image tokenization has significantly advanced visual generation and
multimodal modeling, particularly when paired with autoregressive models.
However, current methods face challenges in balancing efficiency and fidelity:
high-resolution image reconstruction either requires an excessive number of
tokens or compromises critical details through token reduction. To resolve
this, we propose Latent Consistency Tokenizer (Layton) that bridges discrete
visual tokens with the compact latent space of pre-trained Latent Diffusion
Models (LDMs), enabling efficient representation of 1024x1024 images using only
256 tokens-a 16 times compression over VQGAN. Layton integrates a transformer
encoder, a **quantize**d codebook, and a latent consistency decoder. Direct
application of LDM as the decoder results in color and brightness
discrepancies. Thus, we convert it to latent consistency decoder, reducing
multi-step sampling to 1-2 steps for direct pixel-level supervision.
Experiments demonstrate Layton's superiority in high-fidelity reconstruction,
with 10.8 reconstruction Frechet Inception Distance on MSCOCO-2017 5K benchmark
for 1024x1024 image reconstruction. We also extend Layton to a text-to-image
generation model, LaytonGen, working in autoregression. It achieves 0.73 score
on GenEval benchmark, surpassing current state-of-the-art methods. Project
homepage: https://github.com/OPPO-Mente-Lab/Layton


## Diffusion Transformer Meets Random Masks An Advanced PET Reconstruction Framework

>Authors: Bin Huang, Binzhong He, Yanhan Chen, Zhili Liu, Xinyue Wang, Binxuan Li, Qiegen Liu

>2025-03-11

> http://arxiv.org/abs/2503.08339v1

Deep learning has significantly advanced PET image re-construction, achieving
remarkable improvements in image quality through direct training on sinogram or
image data. Traditional methods often utilize masks for inpainting tasks, but
their incorporation into PET reconstruction frameworks introduces
transformative potential. In this study, we pro-pose an advanced PET
reconstruction framework called Diffusion tRansformer mEets rAndom Masks
(DREAM). To the best of our knowledge, this is the first work to integrate mask
mechanisms into both the sinogram domain and the latent space, pioneering their
role in PET reconstruction and demonstrating their ability to enhance
reconstruction fidelity and efficiency. The framework employs a
high-dimensional stacking approach, transforming masked data from two to three
dimensions to expand the solution space and enable the model to capture richer
spatial rela-tionships. Additionally, a mask-driven latent space is de-signed
to accelerate the diffusion process by leveraging sinogram-driven and
mask-driven compact priors, which reduce computational complexity while
preserving essen-tial data characteristics. A hierarchical masking strategy is
also introduced, guiding the model from focusing on fi-ne-grained local details
in the early stages to capturing broader global patterns over time. This
progressive ap-proach ensures a balance between detailed feature preservation
and comprehensive context understanding. Experimental results demonstrate that
DREAM not only improves the overall quality of reconstructed PET images but
also preserves critical clinical details, highlighting its potential to advance
PET imaging technology. By inte-grating compact priors and hierarchical
masking, DREAM offers a promising and efficient avenue for future research and
application in PET imaging. The open-source code is available at:
https://github.com/yqx7150/DREAM.


## Polar perturbations in Kantowski-Sachs spacetimes and hybrid quantum cosmology

>Authors: Guillermo A. Mena Marugán, Andrés Mínguez-Sánchez

>2025-03-11

> http://arxiv.org/abs/2503.08281v1

An increasing attention has been recently devoted to the study of
Kantowski-Sachs spacetime as a way to explore the interior of a Schwarzschild
black hole. In this work, we construct a Hamiltonian formulation for polar
perturbations of this spacetime in the presence of a perturbative massless
scalar field. Our analysis is based on a truncated action at quadratic order in
perturbations. Both background and perturbative degrees of freedom are treated
dynamically, forming a combined system that is endowed with the canonical
structure obtained from our truncated action. First-order perturbations of the
metric and the matter field are described using perturbative gauge-invariants,
linear perturbative constraints, and their corresponding canonical variables.
For the quantum description, we adopt a hybrid approach where the background is
**quantize**d with loop quantum gravity techniques, and the perturbations with
conventional quantum field methods.


## S3R-GS Streamlining the Pipeline for Large-Scale Street Scene Reconstruction

>Authors: Guangting Zheng, Jiajun Deng, Xiaomeng Chu, Yu Yuan, Houqiang Li, Yanyong Zhang

>2025-03-11

> http://arxiv.org/abs/2503.08217v1

Recently, 3D Gaussian Splatting (3DGS) has reshaped the field of
photorealistic 3D reconstruction, achieving impressive rendering quality and
speed. However, when applied to large-scale street scenes, existing methods
suffer from rapidly escalating per-viewpoint reconstruction costs as scene size
increases, leading to significant computational overhead. After revisiting the
conventional pipeline, we identify three key factors accounting for this issue:
unnecessary local-to-global transformations, excessive 3D-to-2D projections,
and inefficient rendering of distant content. To address these challenges, we
propose S3R-GS, a 3DGS framework that Streamlines the pipeline for large-scale
Street Scene Reconstruction, effectively mitigating these limitations.
Moreover, most existing street 3DGS methods rely on ground-truth 3D bounding
boxes to separate dynamic and static components, but 3D bounding boxes are
difficult to obtain, limiting real-world applicability. To address this, we
propose an alternative solution with 2D boxes, which are easier to annotate or
can be predicted by off-the-shelf vision foundation models. Such designs
together make S3R-GS readily adapt to large, in-the-wild scenarios. Extensive
experiments demonstrate that S3R-GS enhances rendering quality and
significantly accelerates reconstruction. Remarkably, when applied to videos
from the challenging Argoverse2 dataset, it achieves state-of-the-art PSNR and
SSIM, reducing reconstruction time to below 50%--and even 20%--of competing
methods.


## Route Sparse Autoencoder to Interpret Large Language Models

>Authors: Wei Shi, Sihang Li, Tao Liang, Mingyang Wan, Gojun Ma, Xiang Wang, Xiangnan He

>2025-03-11

> http://arxiv.org/abs/2503.08200v1

Mechanistic interpretability of large language models (LLMs) aims to uncover
the internal processes of information propagation and reasoning. Sparse
autoencoders (SAEs) have demonstrated promise in this domain by extracting
interpretable and monosemantic features. However, prior works primarily focus
on feature extraction from a single layer, failing to effectively capture
activations that span multiple layers. In this paper, we introduce Route Sparse
Autoencoder (RouteSAE), a new framework that integrates a routing mechanism
with a shared SAE to efficiently extract features from multiple layers. It
dynamically assigns weights to activations from different layers, incurring
minimal parameter overhead while achieving high interpretability and
flexibility for targeted feature manipulation. We evaluate RouteSAE through
extensive experiments on Llama-3.2-1B-Instruct. Specifically, under the same
**sparsity** constraint of 64, RouteSAE extracts 22.5% more features than baseline
SAEs while achieving a 22.3% higher interpretability score. These results
underscore the potential of RouteSAE as a scalable and effective method for LLM
interpretability, with applications in feature discovery and model
intervention. Our codes are available at https://github.com/swei2001/RouteSAEs.


## OASIS Order-Augmented Strategy for Improved Code Search

>Authors: Zuchen Gao, Zizheng Zhan, Xianming Li, Erxin Yu, Haotian Zhang, Bin Chen, Yuqun Zhang, Jing Li

>2025-03-11

> http://arxiv.org/abs/2503.08161v2

Code embeddings capture the semantic representations of code and are crucial
for various code-related large language model (LLM) applications, such as code
search. Previous training primarily relies on optimizing the InfoNCE loss by
comparing positive natural language (NL)-code pairs with in-batch negatives.
However, due to the **sparse** nature of code contexts, training solely by
comparing the major differences between positive and negative pairs may fail to
capture deeper semantic nuances. To address this issue, we propose a novel
order-augmented strategy for improved code search (OASIS). It leverages
order-based similarity labels to train models to capture subtle differences in
similarity among negative pairs. Extensive benchmark evaluations demonstrate
that our OASIS model significantly outperforms previous state-of-the-art models
focusing solely on major positive-negative differences. It underscores the
value of exploiting subtle differences among negative pairs with order labels
for effective code embedding training.


## Large Scale Multi-Task Bayesian Optimization with Large Language Models

>Authors: Yimeng Zeng, Natalie Maus, Haydn Thomas Jones, Jeffrey Tao, Fangping Wan, Marcelo Der Torossian Torres, Cesar de la Fuente-Nunez, Ryan Marcus, Osbert Bastani, Jacob R. Gardner

>2025-03-11

> http://arxiv.org/abs/2503.08131v1

In multi-task Bayesian optimization, the goal is to leverage experience from
optimizing existing tasks to improve the efficiency of optimizing new ones.
While approaches using multi-task Gaussian processes or deep kernel transfer
exist, the performance improvement is marginal when scaling to more than a
moderate number of tasks. We introduce a novel approach leveraging large
language models (LLMs) to learn from, and improve upon, previous optimization
trajectories, scaling to approximately 2000 distinct tasks. Specifically, we
propose an iterative framework in which an LLM is fine-tuned using the high
quality solutions produced by BayesOpt to generate improved initializations
that accelerate convergence for future optimization tasks based on previous
search trajectories. We evaluate our method on two distinct domains: database
query optimization and antimicrobial peptide design. Results demonstrate that
our approach creates a positive feedback loop, where the LLM's generated
initializations gradually improve, leading to better optimization performance.
As this feedback loop continues, we find that the LLM is eventually able to
generate solutions to new tasks in just a few shots that are better than the
solutions produced by "from scratch" by Bayesian optimization while
simultaneously requiring significantly fewer oracle calls.


## Accelerate 3D Object Detection Models via Zero-Shot Attention Key Pruning

>Authors: Lizhen Xu, Xiuxiu Bai, Xiaojun Jia, Jianwu Fang, Shanmin Pang

>2025-03-11

> http://arxiv.org/abs/2503.08101v2

Query-based methods with dense features have demonstrated remarkable success
in 3D object detection tasks. However, the computational demands of these
models, particularly with large image sizes and multiple transformer layers,
pose significant challenges for efficient running on edge devices. Existing
**pruning** and distillation methods either need retraining or are designed for ViT
models, which are hard to migrate to 3D detectors. To address this issue, we
propose a zero-shot runtime **pruning** method for transformer decoders in 3D
object detection models. The method, termed tgGBC (trim keys gradually Guided
By Classification scores), systematically trims keys in transformer modules
based on their importance. We expand the classification score to multiply it
with the attention map to get the importance score of each key and then prune
certain keys after each transformer layer according to their importance scores.
Our method achieves a 1.99x speedup in the transformer decoder of the latest
ToC3D model, with only a minimal performance loss of less than 1%.
Interestingly, for certain models, our method even enhances their performance.
Moreover, we deploy 3D detectors with tgGBC on an edge device, further
validating the effectiveness of our method. The code can be found at
https://github.com/iseri27/tg_gbc.


## MVGSR Multi-View Consistency Gaussian Splatting for Robust Surface Reconstruction

>Authors: Chenfeng Hou, Qi Xun Yeo, Mengqi Guo, Yongxin Su, Yanyan Li, Gim Hee Lee

>2025-03-11

> http://arxiv.org/abs/2503.08093v2

3D Gaussian Splatting (3DGS) has gained significant attention for its
high-quality rendering capabilities, ultra-fast training, and inference speeds.
However, when we apply 3DGS to surface reconstruction tasks, especially in
environments with dynamic objects and distractors, the method suffers from
floating artifacts and color errors due to inconsistency from different
viewpoints. To address this challenge, we propose Multi-View Consistency
Gaussian Splatting for the domain of Robust Surface Reconstruction
(\textbf{MVGSR}), which takes advantage of lightweight Gaussian models and a
{heuristics-guided distractor masking} strategy for robust surface
reconstruction in non-static environments. Compared to existing methods that
rely on MLPs for distractor segmentation strategies, our approach separates
distractors from static scene elements by comparing multi-view feature
consistency, allowing us to obtain precise distractor masks early in training.
Furthermore, we introduce a **pruning** measure based on multi-view contributions
to reset transmittance, effectively reducing floating artifacts. Finally, a
multi-view consistency loss is applied to achieve high-quality performance in
surface reconstruction tasks. Experimental results demonstrate that MVGSR
achieves competitive geometric accuracy and rendering fidelity compared to the
state-of-the-art surface reconstruction algorithms. More information is
available on our project page (https://mvgsr.github.io).


## A Bi-channel Aided Stitching of Atomic Force Microscopy Images

>Authors: Huanhuan Zhao, Ruben Millan Solsona, Marti Checa, Spenser R. Brown, Jennifer L. Morrell-Falvey, Liam Collins, Arpan Biswas

>2025-03-11

> http://arxiv.org/abs/2503.08735v1

Microscopy is an essential tool in scientific research, enabling the
visualization of structures at micro- and nanoscale resolutions. However, the
field of microscopy often encounters limitations in field-of-view (FOV),
restricting the amount of sample that can be imaged in a single capture. To
overcome this limitation, image stitching techniques have been developed to
seamlessly merge multiple overlapping images into a single, high-resolution
composite. The images collected from microscope need to be optimally stitched
before accurate physical information can be extracted from post analysis.
However, the existing stitching tools either struggle to stitch images together
when the microscopy images are feature **sparse** or cannot address all the
transformations of images. To address these issues, we propose a bi-channel
aided feature-based image stitching method and demonstrate its use on AFM
generated biofilm images. The topographical channel image of AFM data captures
the morphological details of the sample, and a stitched topographical image is
desired for researchers. We utilize the amplitude channel of AFM data to
maximize the matching features and to estimate the position of the original
topographical images and show that the proposed bi-channel aided stitching
method outperforms the traditional stitching approach. Furthermore, we found
that the differentiation of the topographical images along the x-axis provides
similar feature information to the amplitude channel image, which generalizes
our approach when the amplitude images are not available. Here we demonstrated
the application on AFM, but similar approaches could be employed of optical
microscopy with brightfield and fluorescence channels. We believe this proposed
workflow will benefit the experimentalist to avoid erroneous analysis and
discovery due to incorrect stitching.


## Accurate INT8 Training Through Dynamic Block-Level Fallback

>Authors: Pengle Zhang, Jia Wei, Jintao Zhang, Jun Zhu, Jianfei Chen

>2025-03-11

> http://arxiv.org/abs/2503.08040v2

Transformer models have achieved remarkable success across various AI
applications but face significant training costs. Low-bit training, such as
INT8 training, can leverage computational units with higher throughput, and has
already demonstrated its effectiveness on GPT2 models with block-level
**quantization**. However, it struggles with modern Transformer variants
incorporating GLU units. This is because those variants demonstrate complex
distributions of activation outliers. To address the challenge, we propose
Fallback Quantization, implementing mixed-precision GEMM that dynamically falls
back 8-bit to 16-bit for activation blocks containing outliers. Experiments
show that our approach is robustly competent in both fine-tuning and
pretraining settings. Moreover, our method achieves a 1.57x end-to-end training
speedup on RTX4090 GPUs.


## Multi-Cue Adaptive Visual Token Pruning for Large Vision-Language Models

>Authors: Bozhi Luan, Wengang Zhou, Hao Feng, Zhe Wang, Xiaosong Li, Houqiang Li

>2025-03-11

> http://arxiv.org/abs/2503.08019v1

As the computational needs of Large Vision-Language Models (LVLMs) increase,
visual token **pruning** has proven effective in improving inference speed and
memory efficiency. Traditional **pruning** methods in LVLMs predominantly focus on
attention scores to determine token relevance, overlooking critical aspects
such as spatial position and token similarity. To this end, we introduce
AdaptPrune, a novel plug-and-play training-free **pruning** method that builds on
conventional attention-based **pruning** by integrating spatial distance and token
similarity with an adaptive NMS approach. Our method is based on several
observed phenomena in large models: the positional bias in the model's image
attention and the redundancy of token information ignored by previous
approaches. By integrating attention, spatial, and similarity information, our
approach ensures a comprehensive evaluation of token importance and
substantially refines the **pruning** decisions. Our method has been extensively
tested across various LVLMs and benchmarks, confirming its robustness and
adaptability. The results demonstrate that AdaptPrune consistently outperforms
existing methods across various **pruning** ratios. Code is available at
https://github.com/bzluan/AdaptPrune.


## A Landmark-Aided Navigation Approach Using Side-Scan Sonar

>Authors: Ellen Davenport, Khoa Nguyen, Junsu Jang, Clair Ma, Sean Fish, Luc Lenain, Florian Meyer

>2025-03-10

> http://arxiv.org/abs/2503.07900v1

Cost-effective localization methods for Autonomous Underwater Vehicle (AUV)
navigation are key for ocean monitoring and data collection at high resolution
in time and space. Algorithmic solutions suitable for real-time processing that
handle nonlinear measurement models and different forms of measurement
uncertainty will accelerate the development of field-ready technology. This
paper details a Bayesian estimation method for landmark-aided navigation using
a Side-scan Sonar (SSS) sensor. The method bounds navigation filter error in
the GPS-denied undersea environment and captures the highly nonlinear nature of
slant range measurements while remaining computationally tractable. Combining a
novel measurement model with the chosen statistical framework facilitates the
efficient use of SSS data and, in the future, could be used in real time. The
proposed filter has two primary steps: a prediction step using an unscented
transform and an update step utilizing particles. The update step performs
probabilistic association of sonar detections with known landmarks. We evaluate
algorithm performance and tractability using synthetic data and real data
collected field experiments. Field experiments were performed using two
different marine robotic platforms with two different SSS and at two different
sites. Finally, we discuss the computational requirements of the proposed
method and how it extends to real-time applications.


## Training Domain Draft Models for Speculative Decoding Best Practices and Insights

>Authors: Fenglu Hong, Ravi Raju, Jonathan Lingjie Li, Bo Li, Urmish Thakker, Avinash Ravichandran, Swayambhoo Jain, Changran Hu

>2025-03-10

> http://arxiv.org/abs/2503.07807v1

Speculative decoding is an effective method for accelerating inference of
large language models (LLMs) by employing a small draft model to predict the
output of a target model. However, when adapting speculative decoding to
domain-specific target models, the acceptance rate of the generic draft model
drops significantly due to domain shift. In this work, we systematically
investigate knowledge distillation techniques for training domain draft models
to improve their speculation accuracy. We compare white-box and black-box
distillation approaches and explore their effectiveness in various data
accessibility scenarios, including historical user queries, curated domain
data, and synthetically generated alignment data. Our experiments across
Function Calling, Biology, and Chinese domains show that offline distillation
consistently outperforms online distillation by 11% to 25%, white-box
distillation surpasses black-box distillation by 2% to 10%, and data scaling
trends hold across domains. Additionally, we find that synthetic data can
effectively align draft models and achieve 80% to 93% of the performance of
training on historical user queries. These findings provide practical
guidelines for training domain-specific draft models to improve speculative
decoding efficiency.


## SEAP Training-free Sparse Expert Activation Pruning Unlock the Brainpower of Large Language Models

>Authors: Xun Liang, Hanyu Wang, Huayi Lai, Simin Niu, Shichao Song, Jiawei Yang, Jihao Zhao, Feiyu Xiong, Bo Tang, Zhiyu Li

>2025-03-10

> http://arxiv.org/abs/2503.07605v1

Large Language Models have achieved remarkable success across various natural
language processing tasks, yet their high computational cost during inference
remains a major bottleneck. This paper introduces Sparse Expert Activation
Pruning (SEAP), a training-free **pruning** method that selectively retains
task-relevant parameters to reduce inference overhead. Inspired by the
clustering patterns of hidden states and activations in LLMs, SEAP identifies
task-specific expert activation patterns and prunes the model while preserving
task performance and enhancing computational efficiency. Experimental results
demonstrate that SEAP significantly reduces computational overhead while
maintaining competitive accuracy. Notably, at 50% **pruning**, SEAP surpasses both
WandA and FLAP by over 20%, and at 20% **pruning**, it incurs only a 2.2%
performance drop compared to the dense model. These findings highlight SEAP's
scalability and effectiveness, making it a promising approach for optimizing
large-scale LLMs.


## Queueing, Predictions, and LLMs Challenges and Open Problems

>Authors: Michael Mitzenmacher, Rana Shahout

>2025-03-10

> http://arxiv.org/abs/2503.07545v1

Queueing systems present many opportunities for applying machine-learning
predictions, such as estimated service times, to improve system performance.
This integration raises numerous open questions about how predictions can be
effectively leveraged to improve scheduling decisions. Recent studies explore
queues with predicted service times, typically aiming to minimize job time in
the system. We review these works, highlight the effectiveness of predictions,
and present open questions on queue performance. We then move to consider an
important practical example of using predictions in scheduling, namely Large
Language Model (LLM) systems, which presents novel scheduling challenges and
highlights the potential for predictions to improve performance. In particular,
we consider LLMs performing inference. Inference requests (jobs) in LLM systems
are inherently complex; they have variable inference times, dynamic memory
footprints that are constrained by key-value (**KV**) store memory limitations, and
multiple possible preemption approaches that affect performance differently. We
provide background on the important aspects of scheduling in LLM systems, and
introduce new models and open problems that arise from them. We argue that
there are significant opportunities for applying insights and analysis from
queueing theory to scheduling in LLM systems.


## TokenButler Token Importance is Predictable

>Authors: Yash Akhauri, Ahmed F AbouElhamayed, Yifei Gao, Chi-Chih Chang, Nilesh Jain, Mohamed S. Abdelfattah

>2025-03-10

> http://arxiv.org/abs/2503.07518v1

Large Language Models (LLMs) rely on the Key-Value (**KV**) Cache to store token
history, enabling efficient decoding of tokens. As the **KV**-Cache grows, it
becomes a major memory and computation bottleneck, however, there is an
opportunity to alleviate this bottleneck, especially because prior research has
shown that only a small subset of tokens contribute meaningfully to each
decoding step. A key challenge in finding these critical tokens is that they
are dynamic, and heavily input query-dependent. Existing methods either risk
quality by evicting tokens permanently, or retain the full **KV**-Cache but rely on
retrieving chunks (pages) of tokens at generation, failing at dense,
context-rich tasks. Additionally, many existing **KV**-Cache **sparsity** methods rely
on inaccurate proxies for token importance. To address these limitations, we
introduce TokenButler, a high-granularity, query-aware predictor that learns to
identify these critical tokens. By training a light-weight predictor with less
than 1.2% parameter overhead, TokenButler prioritizes tokens based on their
contextual, predicted importance. This improves perplexity & downstream
accuracy by over 8% relative to SoTA methods for estimating token importance.
We evaluate TokenButler on a novel synthetic small-context co-referential
retrieval task, demonstrating near-oracle accuracy. Code, models and
benchmarks: https://github.com/abdelfattah-lab/TokenButler


## EigenGS Representation From Eigenspace to Gaussian Image Space

>Authors: Lo-Wei Tai, Ching-En Li, Cheng-Lin Chen, Chih-Jung Tsai, Hwann-Tzong Chen, Tyng-Luh Liu

>2025-03-10

> http://arxiv.org/abs/2503.07446v2

Principal Component Analysis (PCA), a classical dimensionality reduction
technique, and 2D Gaussian representation, an adaptation of 3D Gaussian
Splatting for image representation, offer distinct approaches to modeling
visual data. We present EigenGS, a novel method that bridges these paradigms
through an efficient transformation pipeline connecting eigenspace and
image-space Gaussian representations. Our approach enables instant
initialization of Gaussian parameters for new images without requiring
per-image optimization from scratch, dramatically accelerating convergence.
EigenGS introduces a frequency-aware learning mechanism that encourages
Gaussians to adapt to different scales, effectively modeling varied spatial
frequencies and preventing artifacts in high-resolution reconstruction.
Extensive experiments demonstrate that EigenGS not only achieves superior
reconstruction quality compared to direct 2D Gaussian fitting but also reduces
necessary parameter count and training time. The results highlight EigenGS's
effectiveness and generalization ability across images with varying resolutions
and diverse categories, making Gaussian-based image representation both
high-quality and viable for real-time applications.


## Open-Set Gait Recognition from Sparse mmWave Radar Point Clouds

>Authors: Riccardo Mazzieri, Jacopo Pegoraro, Michele Rossi

>2025-03-10

> http://arxiv.org/abs/2503.07435v1

The adoption of Millimeter-Wave (mmWave) radar devices for human sensing,
particularly gait recognition, has recently gathered significant attention due
to their efficiency, resilience to environmental conditions, and
privacy-preserving nature. In this work, we tackle the challenging problem of
Open-set Gait Recognition (OSGR) from **sparse** mmWave radar point clouds. Unlike
most existing research, which assumes a closed-set scenario, our work considers
the more realistic open-set case, where unknown subjects might be present at
inference time, and should be correctly recognized by the system. Point clouds
are well-suited for edge computing applications with resource constraints, but
are more significantly affected by noise and random fluctuations than other
representations, like the more common micro-Doppler signature. This is the
first work addressing open-set gait recognition with **sparse** point cloud data.
To do so, we propose a novel neural network architecture that combines
supervised classification with unsupervised reconstruction of the point clouds,
creating a robust, rich, and highly regularized latent space of gait features.
To detect unknown subjects at inference time, we introduce a probabilistic
novelty detection algorithm that leverages the structured latent space and
offers a tunable trade-off between inference speed and prediction accuracy.
Along with this paper, we release mmGait10, an original human gait dataset
featuring over five hours of measurements from ten subjects, under varied
walking modalities. Extensive experimental results show that our solution
attains F1-Score improvements by 24% over state-of-the-art methods, on average,
and across multiple openness levels.


## Multi-set variational quantum dynamics algorithm for simulating nonadiabatic dynamics on quantum computers

>Authors: Jingjing Li, Weitang Li, Xiaoxiao Xiao, Limin Liu, Zhendong Li, Jiajun Ren, Weihai Fang

>2025-03-10

> http://arxiv.org/abs/2503.07388v1

Accelerating quantum dynamical simulations with quantum computing has
received considerable attention but remains a significant challenge. In
variational quantum algorithms for quantum dynamics, designing an expressive
and shallow-depth parameterized quantum circuit (PQC) is a key difficulty.
Here, we proposed a multi-set variational quantum dynamics algorithm (MS-VQD)
tailored for nonadiabatic dynamics involving multiple electronic states. MS-VQD
employs multiple PQCs to represent the electronic-nuclear coupled wavefunction,
with each circuit adapting to the motion of nuclear wavepacket on a specific
potential energy surface. By simulating excitation energy transfer dynamics in
molecular aggregates described by the Frenkel-Holstein model, we demonstrated
that MS-VQD achieves the same accuracy as traditional VQD while requiring
significantly shallower PQCs. Notably, its advantage increases with the number
of electronic states, making it suitable for simulating nonadiabatic quantum
dynamics in complex molecular systems.


## Evaluation of Alignment-Regularity Characteristics in Deformable Image Registration

>Authors: Vasiliki Sideri-Lampretsa, Daniel Rueckert, Huaqi Qiu

>2025-03-10

> http://arxiv.org/abs/2503.07185v1

Evaluating deformable image registration (DIR) is challenging due to the
inherent trade-off between achieving high alignment accuracy and maintaining
deformation regularity. In this work, we introduce a novel evaluation scheme
based on the alignment-regularity characteristic (ARC) to systematically
capture and analyze this trade-off. We first introduce the ARC curves, which
describe the performance of a given registration algorithm as a spectrum
measured by alignment and regularity metrics. We further adopt a
HyperNetwork-based approach that learns to continuously interpolate across the
full regularization range, accelerating the construction and improving the
sample density of ARC curves. We empirically demonstrate our evaluation scheme
using representative learning-based deformable image registration methods with
various network architectures and transformation models on two public datasets.
We present a range of findings not evident from existing evaluation practices
and provide general recommendations for model evaluation and selection using
our evaluation scheme. All code relevant is made publicly available.


## Exposure Bias Reduction for Enhancing Diffusion Transformer Feature Caching

>Authors: Zhen Zou, Hu Yu, Jie Xiao, Feng Zhao

>2025-03-10

> http://arxiv.org/abs/2503.07120v1

Diffusion Transformer (DiT) has exhibited impressive generation capabilities
but faces great challenges due to its high computational complexity. To address
this problem, various methods, notably feature caching, have been introduced.
However, these approaches focus on aligning non-cache diffusion without
analyzing the impact of caching on the generation of intermediate processes. So
the lack of exploration provides us with room for analysis and improvement. In
this paper, we analyze the impact of caching on the SNR of the diffusion
process and discern that feature caching intensifies the denoising procedure,
and we further identify this as a more severe exposure bias issue. Drawing on
this insight, we introduce EB-Cache, a joint cache strategy that aligns the
Non-exposure bias (which gives us a higher performance ceiling) diffusion
process. Our approach incorporates a comprehensive understanding of caching
mechanisms and offers a novel perspective on leveraging caches to expedite
diffusion processes. Empirical results indicate that EB-Cache optimizes model
performance while concurrently facilitating **acceleration**. Specifically, in the
50-step generation process, EB-Cache achieves 1.49$\times$ **acceleration** with
0.63 FID reduction from 3.69, surpassing prior **acceleration** methods. Code will
be available at
\href{https://github.com/aSleepyTree/EB-Cache}{https://github.com/aSleepyTree/EB-Cache}.


## Quantizing Large Language Models for Code Generation A Differentiated Replication

>Authors: Alessandro Giagnorio, Antonio Mastropaolo, Saima Afrin, Massimiliano Di Penta, Gabriele Bavota

>2025-03-10

> http://arxiv.org/abs/2503.07103v1

Large Language Models (LLMs) have shown an impressive capability in code
generation and, specifically, to automatically implement requirements described
in natural language. The LLM effectiveness generally increases with its size:
The higher the number of LLM's trainable parameters the better its ability to
implement code. However, when it comes to deploying LLM-based code generators,
larger LLMs pose significant challenges related to their memory (and,
consequently, carbon) footprint. A previous work by Wei et al. proposed to
leverage **quantization** techniques to reduce the memory footprint of LLM-based
code generators without substantially degrading their effectiveness. In short,
they studied LLMs featuring up to 16B parameters, quantizing their precision
from floating point 32 bits down to int 8 bits and showing their limited impact
on code generation performance. Given the fast pace at which LLM capabilities
and **quantization** techniques are evolving, in this work we present a
differentiated replication of the work by Wei et al. in which we consider (i)
on the one side, more recent and larger code-related LLMs, of up to 34B
parameters; (ii) the latest advancements in model **quantization** techniques,
which allow pushing the compression to the extreme **quantization** level of 2 bits
per model parameter and; (iii) different types of calibration datasets to guide
the **quantization** process, including code-specific ones. Our empirical
evaluation reveals that the new frontier for LLM **quantization** is 4-bit
precision, resulting in an average memory footprint reduction of 70% compared
to the original model without observing any significant decrease in
performance. Additionally, when the **quantization** becomes even more extreme (3
and 2 bits), a code-specific calibration dataset helps to limit the loss of
performance.


## TIDE  Temporal-Aware Sparse Autoencoders for Interpretable Diffusion Transformers in Image Generation

>Authors: Victor Shea-Jay Huang, Le Zhuo, Yi Xin, Zhaokai Wang, Peng Gao, Hongsheng Li

>2025-03-10

> http://arxiv.org/abs/2503.07050v1

Diffusion Transformers (DiTs) are a powerful yet underexplored class of
generative models compared to U-Net-based diffusion models. To bridge this gap,
we introduce TIDE (Temporal-aware Sparse Autoencoders for Interpretable
Diffusion transformErs), a novel framework that enhances temporal
reconstruction within DiT activation layers across denoising steps. TIDE
employs Sparse Autoencoders (SAEs) with a **sparse** bottleneck layer to extract
interpretable and hierarchical features, revealing that diffusion models
inherently learn hierarchical features at multiple levels (e.g., 3D, semantic,
class) during generative pre-training. Our approach achieves state-of-the-art
reconstruction performance, with a mean squared error (MSE) of 1e-3 and a
cosine similarity of 0.97, demonstrating superior accuracy in capturing
activation dynamics along the denoising trajectory. Beyond interpretability, we
showcase TIDE's potential in downstream applications such as **sparse**
activation-guided image editing and style transfer, enabling improved
controllability for generative systems. By providing a comprehensive training
and evaluation protocol tailored for DiTs, TIDE contributes to developing more
interpretable, transparent, and trustworthy generative models.


## DatawiseAgent A Notebook-Centric LLM Agent Framework for Automated Data Science

>Authors: Ziming You, Yumiao Zhang, Dexuan Xu, Yiwei Lou, Yandong Yan, Wei Wang, Huaming Zhang, Yu Huang

>2025-03-10

> http://arxiv.org/abs/2503.07044v1

Data Science tasks are multifaceted, dynamic, and often domain-specific.
Existing LLM-based approaches largely concentrate on isolated phases,
neglecting the interdependent nature of many data science tasks and limiting
their capacity for comprehensive end-to-end support. We propose DatawiseAgent,
a notebook-centric LLM agent framework that unifies interactions among user,
agent and the computational environment through markdown and executable code
cells, supporting flexible and adaptive automated data science. Built on a
Finite State Transducer(FST), DatawiseAgent orchestrates four stages, including
DSF-like planning, incremental execution, self-debugging, and post-filtering.
Specifically, the DFS-like planning stage systematically explores the solution
space, while incremental execution harnesses real-time feedback and
accommodates LLM's limited capabilities to progressively complete tasks. The
self-debugging and post-filtering modules further enhance reliability by
diagnosing and correcting errors and **pruning** extraneous information. Extensive
experiments on diverse tasks, including data analysis, visualization, and data
modeling, show that DatawiseAgent consistently outperforms or matches
state-of-the-art methods across multiple model settings. These results
highlight its potential to generalize across data science scenarios and lay the
groundwork for more efficient, fully automated workflows.


## EasyControl Adding Efficient and Flexible Control for Diffusion Transformer

>Authors: Yuxuan Zhang, Yirui Yuan, Yiren Song, Haofan Wang, Jiaming Liu

>2025-03-10

> http://arxiv.org/abs/2503.07027v1

Recent advancements in Unet-based diffusion models, such as ControlNet and
IP-Adapter, have introduced effective spatial and subject control mechanisms.
However, the DiT (Diffusion Transformer) architecture still struggles with
efficient and flexible control. To tackle this issue, we propose EasyControl, a
novel framework designed to unify condition-guided diffusion transformers with
high efficiency and flexibility. Our framework is built on three key
innovations. First, we introduce a lightweight Condition Injection LoRA Module.
This module processes conditional signals in isolation, acting as a
plug-and-play solution. It avoids modifying the base model weights, ensuring
compatibility with customized models and enabling the flexible injection of
diverse conditions. Notably, this module also supports harmonious and robust
zero-shot multi-condition generalization, even when trained only on
single-condition data. Second, we propose a Position-Aware Training Paradigm.
This approach standardizes input conditions to fixed resolutions, allowing the
generation of images with arbitrary aspect ratios and flexible resolutions. At
the same time, it optimizes computational efficiency, making the framework more
practical for real-world applications. Third, we develop a Causal Attention
Mechanism combined with the **KV** Cache technique, adapted for conditional
generation tasks. This innovation significantly reduces the latency of image
synthesis, improving the overall efficiency of the framework. Through extensive
experiments, we demonstrate that EasyControl achieves exceptional performance
across various application scenarios. These innovations collectively make our
framework highly efficient, flexible, and suitable for a wide range of tasks.


## PLADIS Pushing the Limits of Attention in Diffusion Models at Inference Time by Leveraging Sparsity

>Authors: Kwanyoung Kim, Byeongsu Sim

>2025-03-10

> http://arxiv.org/abs/2503.07677v1

Diffusion models have shown impressive results in generating high-quality
conditional samples using guidance techniques such as Classifier-Free Guidance
(CFG). However, existing methods often require additional training or neural
function evaluations (NFEs), making them incompatible with guidance-distilled
models. Also, they rely on heuristic approaches that need identifying target
layers. In this work, we propose a novel and efficient method, termed PLADIS,
which boosts pre-trained models (U-Net/Transformer) by leveraging **sparse**
attention. Specifically, we extrapolate query-key correlations using softmax
and its **sparse** counterpart in the cross-attention layer during inference,
without requiring extra training or NFEs. By leveraging the noise robustness of
**sparse** attention, our PLADIS unleashes the latent potential of text-to-image
diffusion models, enabling them to excel in areas where they once struggled
with newfound effectiveness. It integrates seamlessly with guidance techniques,
including guidance-distilled models. Extensive experiments show notable
improvements in text alignment and human preference, offering a highly
efficient and universally applicable solution.


## Aligning Instance-Semantic Sparse Representation towards Unsupervised Object Segmentation and Shape Abstraction with Repeatable Primitives

>Authors: Jiaxin Li, Hongxing Wang, Jiawei Tan, Zhilong Ou, Junsong Yuan

>2025-03-10

> http://arxiv.org/abs/2503.06947v1

Understanding 3D object shapes necessitates shape representation by object
parts abstracted from results of instance and semantic segmentation. Promising
shape representations enable computers to interpret a shape with meaningful
parts and identify their repeatability. However, supervised shape
representations depend on costly annotation efforts, while current unsupervised
methods work under strong semantic priors and involve multi-stage training,
thereby limiting their generalization and deployment in shape reasoning and
understanding. Driven by the tendency of high-dimensional semantically similar
features to lie in or near low-dimensional subspaces, we introduce a one-stage,
fully unsupervised framework towards semantic-aware shape representation. This
framework produces joint instance segmentation, semantic segmentation, and
shape abstraction through **sparse** representation and feature alignment of object
parts in a high-dimensional space. For **sparse** representation, we devise a
**sparse** latent membership pursuit method that models each object part feature as
a **sparse** convex combination of point features at either the semantic or
instance level, promoting part features in the same subspace to exhibit similar
semantics. For feature alignment, we customize an attention-based strategy in
the feature space to align instance- and semantic-level object part features
and reconstruct the input shape using both of them, ensuring geometric
reusability and semantic consistency of object parts. To firm up semantic
disambiguation, we construct cascade unfrozen learning on geometric parameters
of object parts.


## LLaFEA Frame-Event Complementary Fusion for Fine-Grained Spatiotemporal Understanding in LMMs

>Authors: Hanyu Zhou, Gim Hee Lee

>2025-03-10

> http://arxiv.org/abs/2503.06934v1

Large multimodal models (LMMs) excel in scene understanding but struggle with
fine-grained spatiotemporal reasoning due to weak alignment between linguistic
and visual representations. Existing methods map textual positions and
durations into the visual space encoded from frame-based videos, but suffer
from temporal **sparsity** that limits language-vision temporal coordination. To
address this issue, we introduce LLaFEA (Large Language and Frame-Event
Assistant) to leverage event cameras for temporally dense perception and
frame-event fusion. Our approach employs a cross-attention mechanism to
integrate complementary spatial and temporal features, followed by
self-attention matching for global spatio-temporal associations. We further
embed textual position and duration tokens into the fused visual space to
enhance fine-grained alignment. This unified framework ensures robust
spatio-temporal coordinate alignment, enabling LMMs to interpret scenes at any
position and any time. In addition, we construct a dataset of real-world
frames-events with coordinate instructions and conduct extensive experiments to
validate the effectiveness of the proposed method.


## Post-Training Quantization for Diffusion Transformer via Hierarchical Timestep Grouping

>Authors: Ning Ding, Jing Han, Yuchuan Tian, Chao Xu, Kai Han, Yehui Tang

>2025-03-10

> http://arxiv.org/abs/2503.06930v1

Diffusion Transformer (DiT) has now become the preferred choice for building
image generation models due to its great generation capability. Unlike previous
convolution-based UNet models, DiT is purely composed of a stack of transformer
blocks, which renders DiT excellent in scalability like large language models.
However, the growing model size and multi-step sampling paradigm bring about
considerable pressure on deployment and inference. In this work, we propose a
post-training **quantization** framework tailored for Diffusion Transforms to
tackle these challenges. We firstly locate that the **quantization** difficulty of
DiT mainly originates from the time-dependent channel-specific outliers. We
propose a timestep-aware shift-and-scale strategy to smooth the activation
distribution to reduce the **quantization** error. Secondly, based on the
observation that activations of adjacent timesteps have similar distributions,
we utilize a hierarchical clustering scheme to divide the denoising timesteps
into multiple groups. We further design a re-parameterization scheme which
absorbs the **quantization** parameters into nearby module to avoid redundant
computations. Comprehensive experiments demonstrate that out PTQ method
successfully **quantize** the Diffusion Transformer into 8-bit weight and 8-bit
activation (W8A8) with state-of-the-art FiD score. And our method can further
**quantize** DiT model into 4-bit weight and 8-bit activation (W4A8) without
sacrificing generation quality.


## From Reusing to Forecasting Accelerating Diffusion Models with TaylorSeers

>Authors: Jiacheng Liu, Chang Zou, Yuanhuiyi Lyu, Junjie Chen, Linfeng Zhang

>2025-03-10

> http://arxiv.org/abs/2503.06923v1

Diffusion Transformers (DiT) have revolutionized high-fidelity image and
video synthesis, yet their computational demands remain prohibitive for
real-time applications. To solve this problem, feature caching has been
proposed to accelerate diffusion models by caching the features in the previous
timesteps and then reusing them in the following timesteps. However, at
timesteps with significant intervals, the feature similarity in diffusion
models decreases substantially, leading to a pronounced increase in errors
introduced by feature caching, significantly harming the generation quality. To
solve this problem, we propose TaylorSeer, which firstly shows that features of
diffusion models at future timesteps can be predicted based on their values at
previous timesteps. Based on the fact that features change slowly and
continuously across timesteps, TaylorSeer employs a differential method to
approximate the higher-order derivatives of features and predict features in
future timesteps with Taylor series expansion. Extensive experiments
demonstrate its significant effectiveness in both image and video synthesis,
especially in high **acceleration** ratios. For instance, it achieves an almost
lossless **acceleration** of 4.99$\times$ on FLUX and 5.00$\times$ on HunyuanVideo
without additional training. On DiT, it achieves $3.41$ lower FID compared with
previous SOTA at $4.53$$\times$ **acceleration**. %Our code is provided in the
supplementary materials and will be made publicly available on GitHub. Our
codes have been released in Github:https://github.com/Shenyi-Z/TaylorSeer


## Se-HiLo Noise-Resilient Semantic Communication with High-and-Low Frequency Decomposition

>Authors: Zhiyuan Xi, Kun Zhu, Yuanyuan Xu

>2025-03-10

> http://arxiv.org/abs/2503.06883v1

Semantic communication has emerged as a transformative paradigm in
next-generation communication systems, leveraging advanced artificial
intelligence (AI) models to extract and transmit semantic representations for
efficient information exchange. Nevertheless, the presence of unpredictable
semantic noise, such as ambiguity and distortions in transmitted
representations, often undermines the reliability of received information.
Conventional approaches primarily adopt adversarial training with noise
injection to mitigate the adverse effects of noise. However, such methods
exhibit limited adaptability to varying noise levels and impose additional
computational overhead during model training. To address these challenges, this
paper proposes Noise-Resilient \textbf{Se}mantic Communication with
\textbf{Hi}gh-and-\textbf{Lo}w Frequency Decomposition (Se-HiLo) for image
transmission. The proposed Se-HiLo incorporates a Finite Scalar Quantization
(FSQ) based noise-resilient module, which bypasses adversarial training by
enforcing encoded representations within predefined spaces to enhance noise
resilience. While FSQ improves robustness, it compromise representational
diversity. To alleviate this trade-off, we adopt a transformer-based
high-and-low frequency decomposition module that decouples image
representations into high-and-low frequency components, mapping them into
separate FSQ representation spaces to preserve representational diversity.
Extensive experiments demonstrate that Se-HiLo achieves superior noise
resilience and ensures accurate semantic communication across diverse noise
environments.


## Maximum Inner Product is Query-Scaled Nearest Neighbor

>Authors: Tingyang Chen, Cong Fu, Kun Wang, Xiangyu Ke, Yunjun Gao, Wenchao Zhou, Yabo Ni, Anxiang Zeng

>2025-03-10

> http://arxiv.org/abs/2503.06882v1

Maximum Inner Product Search (MIPS) for high-dimensional vectors is pivotal
across databases, information retrieval, and artificial intelligence. Existing
methods either reduce MIPS to Nearest Neighbor Search (NNS) while suffering
from harmful vector space transformations, or attempt to tackle MIPS directly
but struggle to mitigate redundant computations due to the absence of the
triangle inequality. This paper presents a novel theoretical framework that
equates MIPS with NNS without requiring space transformation, thereby allowing
us to leverage advanced graph-based indices for NNS and efficient edge **pruning**
strategies, significantly reducing unnecessary computations. Despite a strong
baseline set by our theoretical analysis, we identify and address two
persistent challenges to further refine our method: the introduction of the
Proximity Graph with Spherical Pathway (PSP), designed to mitigate the issue of
MIPS solutions clustering around large-norm vectors, and the implementation of
Adaptive Early Termination (AET), which efficiently curtails the excessive
exploration once an accuracy bottleneck is reached. Extensive experiments
reveal the superiority of our method over existing state-of-the-art techniques
in search efficiency, scalability, and practical applicability. Compared with
state-of-the-art graph based methods, it achieves an average 35% speed-up in
query processing and a 3x reduction in index size. Notably, our approach has
been validated and deployed in the search engines of Shopee, a well-known
online shopping platform. Our code and an industrial-scale dataset for offline
evaluation will also be released to address the absence of e-commerce data in
public benchmarks.


## ResMoE Space-efficient Compression of Mixture of Experts LLMs via Residual Restoration

>Authors: Mengting Ai, Tianxin Wei, Yifan Chen, Zhichen Zeng, Ritchie Zhao, Girish Varatkar, Bita Darvish Rouhani, Xianfeng Tang, Hanghang Tong, Jingrui He

>2025-03-10

> http://arxiv.org/abs/2503.06881v1

Mixture-of-Experts (MoE) Transformer, the backbone architecture of multiple
phenomenal language models, leverages **sparsity** by activating only a fraction of
model parameters for each input token. The **sparse** structure, while allowing
constant time costs, results in space inefficiency: we still need to load all
the model parameters during inference. We introduce ResMoE, an innovative MoE
approximation framework that utilizes Wasserstein barycenter to extract a
common expert (barycenter expert) and approximate the residuals between this
barycenter expert and the original ones. ResMoE enhances the space efficiency
for inference of large-scale MoE Transformers in a one-shot and data-agnostic
manner without retraining while maintaining minimal accuracy loss, thereby
paving the way for broader accessibility to large language models. We
demonstrate the effectiveness of ResMoE through extensive experiments on Switch
Transformer, Mixtral, and DeepSeekMoE models. The results show that ResMoE can
reduce the number of parameters in an expert by up to 75% while maintaining
comparable performance. The code is available at
https://github.com/iDEA-iSAIL-Lab-UIUC/ResMoE.


## Enhancing Time Series Forecasting via Logic-Inspired Regularization

>Authors: Jianqi Zhang, Jingyao Wang, Xingchen Shen, Wenwen Qiang

>2025-03-10

> http://arxiv.org/abs/2503.06867v1

Time series forecasting (TSF) plays a crucial role in many applications.
Transformer-based methods are one of the mainstream techniques for TSF.
Existing methods treat all token dependencies equally. However, we find that
the effectiveness of token dependencies varies across different forecasting
scenarios, and existing methods ignore these differences, which affects their
performance. This raises two issues: (1) What are effective token dependencies?
(2) How can we learn effective dependencies? From a logical perspective, we
align Transformer-based TSF methods with the logical framework and define
effective token dependencies as those that ensure the tokens as atomic formulas
(Issue 1). We then align the learning process of Transformer methods with the
process of obtaining atomic formulas in logic, which inspires us to design a
method for learning these effective dependencies (Issue 2). Specifically, we
propose Attention Logic Regularization (Attn-L-Reg), a plug-and-play method
that guides the model to use fewer but more effective dependencies by making
the attention map **sparse**, thereby ensuring the tokens as atomic formulas and
improving prediction performance. Extensive experiments and theoretical
analysis confirm the effectiveness of Attn-L-Reg.


## FIGLUT An Energy-Efficient Accelerator Design for FP-INT GEMM Using Look-Up Tables

>Authors: Gunho Park, Hyeokjun Kwon, Jiwoo Kim, Jeongin Bae, Baeseong Park, Dongsoo Lee, Youngjoo Lee

>2025-03-10

> http://arxiv.org/abs/2503.06862v1

Weight-only **quantization** has emerged as a promising solution to the
deployment challenges of large language models (LLMs). However, it necessitates
FP-INT operations, which make implementation on general-purpose hardware like
GPUs difficult. In this paper, we propose FIGLUT, an efficient look-up table
(LUT)-based GEMM accelerator architecture. Instead of performing traditional
arithmetic operations, FIGLUT retrieves precomputed values from an LUT based on
weight patterns, significantly reducing the computational complexity. We also
introduce a novel LUT design that addresses the limitations of conventional
memory architectures. To further improve LUT-based operations, we propose a
half-size LUT combined with a dedicated decoding and multiplexing unit. FIGLUT
efficiently supports different bit precisions and **quantization** methods using a
single fixed hardware configuration. For the same 3-bit weight precision,
FIGLUT demonstrates 59% higher TOPS/W and 20% lower perplexity than
state-of-the-art accelerator designs. When targeting the same perplexity,
FIGLUT achieves 98% higher TOPS/W by performing 2.4-bit operations.


## Stochastic Optimal Control of an Epidemic Under Partial Information

>Authors: Ibrahim Mbouandi Njiasse, Florent Ouabo Kamkumo, Ralf Wunderlich

>2025-03-09

> http://arxiv.org/abs/2503.06804v1

In this paper, we address a social planner's optimal control problem for a
partially observable stochastic epidemic model. The control measures include
social distancing, testing, and vaccination. Using a diffusion approximation
for the state dynamics of the epidemic, we apply filtering arguments to
transform the partially observable stochastic optimal control problem into an
optimal control problem with complete information. This transformed problem is
treated as a Markov decision process. The associated Bellman equation is solved
numerically using optimal **quantization** methods for approximating the
expectations involved to mitigate the curse of dimensionality. We implement two
approaches, the first involves state discretization coupled with linear
interpolation of the value function at non-grid points. The second utilizes a
parametrization of the value function with educated ansatz functions. Extensive
numerical experiments are presented to demonstrate the efficacy of both
methods.


## Seeing Delta Parameters as JPEG Images Data-Free Delta Compression with Discrete Cosine Transform

>Authors: Chenyu Huang, Peng Ye, Xiaohui Wang, Shenghe Zheng, Biqing Qi, Lei Bai, Wanli Ouyang, Tao Chen

>2025-03-09

> http://arxiv.org/abs/2503.06676v1

With transformer-based models and the pretrain-finetune paradigm becoming
mainstream, the high storage and deployment costs of individual finetuned
models on multiple tasks pose critical challenges. Delta compression attempts
to lower the costs by reducing the redundancy of delta parameters (i.e., the
difference between the finetuned and pre-trained model weights). However,
existing methods usually face problems including data accessibility and
training requirements. To tackle this issue, we introduce Delta-DCT, the first
data-free delta compression method inspired by classic JPEG image compression,
leveraging the Discrete Cosine Transform (DCT). We first (a) group delta
parameters within a layer into patches. Then we (b) assess the importance of
each patch and allocate them with different **quantization** bit-widths.
Afterwards, we (c) convert these patches to the DCT domain and conduct
**quantization** to each patch based on the allocated bit-width. The proposed
Delta-DCT does not require any training or data calibration, while achieving
performance comparable to or even surpassing original finetuned models under
1-bit equivalent delta compression ratios on different kinds of models
including: (1) recently-released LLMs of different sizes from 7B to 13B, (2)
relatively smaller language models including RoBERTa and T5 models, (3)
variants of vision transformer models, and (4) multi-modal BEiT-3 models.


## Beyond Decoder-only Large Language Models Can be Good Encoders for Machine Translation

>Authors: Yingfeng Luo, Tong Zheng, Yongyu Mu, Bei Li, Qinghong Zhang, Yongqi Gao, Ziqiang Xu, Peinan Feng, Xiaoqian Liu, Tong Xiao, Jingbo Zhu

>2025-03-09

> http://arxiv.org/abs/2503.06594v1

The field of neural machine translation (NMT) has changed with the advent of
large language models (LLMs). Much of the recent emphasis in natural language
processing (NLP) has been on modeling machine translation and many other
problems using a single pre-trained Transformer decoder, while encoder-decoder
architectures, which were the standard in earlier NMT models, have received
relatively less attention. In this paper, we explore translation models that
are universal, efficient, and easy to optimize, by marrying the world of LLMs
with the world of NMT. We apply LLMs to NMT encoding and leave the NMT decoder
unchanged. We also develop methods for adapting LLMs to work better with the
NMT decoder. Furthermore, we construct a new dataset involving multiple tasks
to assess how well the machine translation system generalizes across various
tasks. Evaluations on the WMT and our datasets show that results using our
method match or surpass a range of baselines in terms of translation quality,
but achieve $2.4 \sim 6.5 \times$ inference speedups and a $75\%$ reduction in
the memory footprint of the **KV** cache. It also demonstrates strong
generalization across a variety of translation-related tasks.


## QuantCache Adaptive Importance-Guided Quantization with Hierarchical Latent and Layer Caching for Video Generation

>Authors: Junyi Wu, Zhiteng Li, Zheng Hui, Yulun Zhang, Linghe Kong, Xiaokang Yang

>2025-03-09

> http://arxiv.org/abs/2503.06545v1

Recently, Diffusion Transformers (DiTs) have emerged as a dominant
architecture in video generation, surpassing U-Net-based models in terms of
performance. However, the enhanced capabilities of DiTs come with significant
drawbacks, including increased computational and memory costs, which hinder
their deployment on resource-constrained devices. Current **acceleration**
techniques, such as **quantization** and cache mechanism, offer limited speedup and
are often applied in isolation, failing to fully address the complexities of
DiT architectures. In this paper, we propose QuantCache, a novel training-free
inference **acceleration** framework that jointly optimizes hierarchical latent
caching, adaptive importance-guided **quantization**, and structural
redundancy-aware **pruning**. QuantCache achieves an end-to-end latency speedup of
6.72$\times$ on Open-Sora with minimal loss in generation quality. Extensive
experiments across multiple video generation benchmarks demonstrate the
effectiveness of our method, setting a new standard for efficient DiT
inference. The code and models will be available at
https://github.com/JunyiWuCode/QuantCache.


## Identifying point sources for biharmonic wave equation from the scattered fields at sparse sensors

>Authors: Xiaodong Liu, Qingxiang Shi, Jing Wang

>2025-03-09

> http://arxiv.org/abs/2503.06524v1

This work is dedicated to uniqueness and numerical algorithms for determining
the point sources of the biharmonic wave equation using scattered fields at
**sparse** sensors. We first show that the point sources in both $\mathbb{R}^2$ and
$\mathbb{R}^3$ can be uniquely determined from the multifrequency **sparse**
scattered fields. In particular, to deal with the challenges arising from the
fundamental solution of the biharmonic wave equation in $\mathbb{R}^2$, we
present an innovative approach that leverages the Fourier transform and
Funk-Hecke formula. Such a technique can also be applied for identifying the
point sources of the Helmholtz equation. Moreover, we present the uniqueness
results for identifying multiple point sources in $\mathbb{R}^3$ from the
scattered fields at **sparse** sensors with finitely many frequencies. Based on the
constructive uniqueness proofs, we propose three numerical algorithms for
identifying the point sources by using multifrequency **sparse** scattered fields.
The numerical experiments are presented to verify the effectiveness and
robustness of the algorithms.


## SAQ-SAM Semantically-Aligned Quantization for Segment Anything Model

>Authors: Jing Zhang, Zhikai Li, Qingyi Gu

>2025-03-09

> http://arxiv.org/abs/2503.06515v1

Segment Anything Model (SAM) exhibits remarkable zero-shot segmentation
capability; however, its prohibitive computational costs make edge deployment
challenging. Although post-training **quantization** (PTQ) offers a promising
compression solution, existing methods yield unsatisfactory results when
applied to SAM, owing to its specialized model components and promptable
workflow: (i) The mask decoder's attention exhibits extreme outliers, and we
find that aggressive clipping (ranging down to even 100$\times$), instead of
smoothing or isolation, is effective in suppressing outliers while maintaining
semantic capabilities. Unfortunately, traditional metrics (e.g., MSE) fail to
provide such large-scale clipping. (ii) Existing reconstruction methods
potentially neglect prompts' intention, resulting in distorted visual encodings
during prompt interactions. To address the above issues, we propose SAQ-SAM in
this paper, which boosts PTQ of SAM with semantic alignment. Specifically, we
propose Perceptual-Consistency Clipping, which exploits attention focus overlap
as clipping metric, to significantly suppress outliers. Furthermore, we propose
Prompt-Aware Reconstruction, which incorporates visual-prompt interactions by
leveraging cross-attention responses in mask decoder, thus facilitating
alignment in both distribution and semantics. To ensure the interaction
efficiency, we also introduce a layer-skipping strategy for visual tokens.
Extensive experiments are conducted on different segmentation tasks and SAMs of
various sizes, and the results show that the proposed SAQ-SAM consistently
outperforms baselines. For example, when quantizing SAM-B to 4-bit, our method
achieves 11.7% higher mAP than the baseline in instance segmentation task.


## SP3D Boosting Sparsely-Supervised 3D Object Detection via Accurate Cross-Modal Semantic Prompts

>Authors: Shijia Zhao, Qiming Xia, Xusheng Guo, Pufan Zou, Maoji Zheng, Hai Wu, Chenglu Wen, Cheng Wang

>2025-03-09

> http://arxiv.org/abs/2503.06467v1

Recently, **sparse**ly-supervised 3D object detection has gained great attention,
achieving performance close to fully-supervised 3D objectors while requiring
only a few annotated instances. Nevertheless, these methods suffer challenges
when accurate labels are extremely absent. In this paper, we propose a boosting
strategy, termed SP3D, explicitly utilizing the cross-modal semantic prompts
generated from Large Multimodal Models (LMMs) to boost the 3D detector with
robust feature discrimination capability under **sparse** annotation settings.
Specifically, we first develop a Confident Points Semantic Transfer (CPST)
module that generates accurate cross-modal semantic prompts through
boundary-constrained center cluster selection. Based on these accurate semantic
prompts, which we treat as seed points, we introduce a Dynamic Cluster
Pseudo-label Generation (DCPG) module to yield pseudo-supervision signals from
the geometry shape of multi-scale neighbor points. Additionally, we design a
Distribution Shape score (DS score) that chooses high-quality supervision
signals for the initial training of the 3D detector. Experiments on the KITTI
dataset and Waymo Open Dataset (WOD) have validated that SP3D can enhance the
performance of **sparse**ly supervised detectors by a large margin under meager
labeling conditions. Moreover, we verified SP3D in the zero-shot setting, where
its performance exceeded that of the state-of-the-art methods. The code is
available at https://github.com/xmuqimingxia/SP3D.


## Seesaw High-throughput LLM Inference via Model Re-sharding

>Authors: Qidong Su, Wei Zhao, Xin Li, Muralidhar Andoorveedu, Chenhao Jiang, Zhanda Zhu, Kevin Song, Christina Giannoula, Gennady Pekhimenko

>2025-03-09

> http://arxiv.org/abs/2503.06433v1

To improve the efficiency of distributed large language model (LLM)
inference, various parallelization strategies, such as tensor and pipeline
parallelism, have been proposed. However, the distinct computational
characteristics inherent in the two stages of LLM inference-prefilling and
decoding-render a single static parallelization strategy insufficient for the
effective optimization of both stages. In this work, we present Seesaw, an LLM
inference engine optimized for throughput-oriented tasks. The key idea behind
Seesaw is dynamic model re-sharding, a technique that facilitates the dynamic
reconfiguration of parallelization strategies across stages, thereby maximizing
throughput at both phases. To mitigate re-sharding overhead and optimize
computational efficiency, we employ tiered **KV** cache buffering and
transition-minimizing scheduling. These approaches work synergistically to
reduce the overhead caused by frequent stage transitions while ensuring maximum
batching efficiency. Our evaluation demonstrates that Seesaw achieves a
throughput increase of up to 1.78x (1.36x on average) compared to vLLM, the
most widely used state-of-the-art LLM inference engine.


## Graph Retrieval-Augmented LLM for Conversational Recommendation Systems

>Authors: Zhangchi Qiu, Linhao Luo, Zicheng Zhao, Shirui Pan, Alan Wee-Chung Liew

>2025-03-09

> http://arxiv.org/abs/2503.06430v1

Conversational Recommender Systems (CRSs) have emerged as a transformative
paradigm for offering personalized recommendations through natural language
dialogue. However, they face challenges with knowledge **sparsity**, as users often
provide brief, incomplete preference statements. While recent methods have
integrated external knowledge sources to mitigate this, they still struggle
with semantic understanding and complex preference reasoning. Recent Large
Language Models (LLMs) demonstrate promising capabilities in natural language
understanding and reasoning, showing significant potential for CRSs.
Nevertheless, due to the lack of domain knowledge, existing LLM-based CRSs
either produce hallucinated recommendations or demand expensive domain-specific
training, which largely limits their applicability. In this work, we present
G-CRS (Graph Retrieval-Augmented Large Language Model for Conversational
Recommender Systems), a novel training-free framework that combines graph
retrieval-augmented generation and in-context learning to enhance LLMs'
recommendation capabilities. Specifically, G-CRS employs a two-stage
retrieve-and-recommend architecture, where a GNN-based graph reasoner first
identifies candidate items, followed by Personalized PageRank exploration to
jointly discover potential items and similar user interactions. These retrieved
contexts are then transformed into structured prompts for LLM reasoning,
enabling contextually grounded recommendations without task-specific training.
Extensive experiments on two public datasets show that G-CRS achieves superior
recommendation performance compared to existing methods without requiring
task-specific training.


## Pre-Training Meta-Rule Selection Policy for Visual Generative Abductive Learning

>Authors: Yu Jin, Jingming Liu, Zhexu Luo, Yifei Peng, Ziang Qin, Wang-Zhou Dai, Yao-Xiang Ding, Kun Zhou

>2025-03-09

> http://arxiv.org/abs/2503.06427v1

Visual generative abductive learning studies jointly training symbol-grounded
neural visual generator and inducing logic rules from data, such that after
learning, the visual generation process is guided by the induced logic rules. A
major challenge for this task is to reduce the time cost of logic abduction
during learning, an essential step when the logic symbol set is large and the
logic rule to induce is complicated. To address this challenge, we propose a
pre-training method for obtaining meta-rule selection policy for the recently
proposed visual generative learning approach AbdGen [Peng et al., 2023], aiming
at significantly reducing the candidate meta-rule set and **pruning** the search
space. The selection model is built based on the embedding representation of
both symbol grounding of cases and meta-rules, which can be effectively
integrated with both neural model and logic reasoning system. The pre-training
process is done on pure symbol data, not involving symbol grounding learning of
raw visual inputs, making the entire learning process low-cost. An additional
interesting observation is that the selection policy can rectify symbol
grounding errors unseen during pre-training, which is resulted from the
memorization ability of attention mechanism and the relative stability of
symbolic patterns. Experimental results show that our method is able to
effectively address the meta-rule selection problem for visual abduction,
boosting the efficiency of visual generative abductive learning. Code is
available at https://github.com/future-item/metarule-select.


## FEDS Feature and Entropy-Based Distillation Strategy for Efficient Learned Image Compression

>Authors: Haisheng Fu, Jie Liang, Zhenman Fang, Jingning Han

>2025-03-09

> http://arxiv.org/abs/2503.06399v2

Learned image compression (LIC) methods have recently outperformed
traditional codecs such as VVC in rate-distortion performance. However, their
large models and high computational costs have limited their practical
adoption. In this paper, we first construct a high-capacity teacher model by
integrating Swin-Transformer V2-based attention modules, additional residual
blocks, and expanded latent channels, thus achieving enhanced compression
performance. Building on this foundation, we propose a \underline{F}eature and
\underline{E}ntropy-based \underline{D}istillation \underline{S}trategy
(\textbf{FEDS}) that transfers key knowledge from the teacher to a lightweight
student model. Specifically, we align intermediate feature representations and
emphasize the most informative latent channels through an entropy-based loss. A
staged training scheme refines this transfer in three phases: feature
alignment, channel-level distillation, and final fine-tuning. Our student model
nearly matches the teacher across Kodak (1.24\% BD-Rate increase), Tecnick
(1.17\%), and CLIC (0.55\%) while cutting parameters by about 63\% and
accelerating encoding/decoding by around 73\%. Moreover, ablation studies
indicate that FEDS generalizes effectively to transformer-based networks. The
experimental results demonstrate our approach strikes a compelling balance
among compression performance, speed, and model parameters, making it
well-suited for real-time or resource-limited scenarios.


## How LLMs Learn Tracing Internal Representations with Sparse Autoencoders

>Authors: Tatsuro Inaba, Kentaro Inui, Yusuke Miyao, Yohei Oseki, Benjamin Heinzerling, Yu Takagi

>2025-03-09

> http://arxiv.org/abs/2503.06394v1

Large Language Models (LLMs) demonstrate remarkable multilingual capabilities
and broad knowledge. However, the internal mechanisms underlying the
development of these capabilities remain poorly understood. To investigate
this, we analyze how the information encoded in LLMs' internal representations
evolves during the training process. Specifically, we train **sparse** autoencoders
at multiple checkpoints of the model and systematically compare the
interpretative results across these stages. Our findings suggest that LLMs
initially acquire language-specific knowledge independently, followed by
cross-linguistic correspondences. Moreover, we observe that after mastering
token-level knowledge, the model transitions to learning higher-level, abstract
concepts, indicating the development of more conceptual understanding.


## X-LRM X-ray Large Reconstruction Model for Extremely Sparse-View Computed Tomography Recovery in One Second

>Authors: Guofeng Zhang, Ruyi Zha, Hao He, Yixun Liang, Alan Yuille, Hongdong Li, Yuanhao Cai

>2025-03-09

> http://arxiv.org/abs/2503.06382v1

Sparse-view 3D CT reconstruction aims to recover volumetric structures from a
limited number of 2D X-ray projections. Existing feedforward methods are
constrained by the limited capacity of CNN-based architectures and the scarcity
of large-scale training datasets. In this paper, we propose an X-ray Large
Reconstruction Model (X-LRM) for extremely **sparse**-view (<10 views) CT
reconstruction. X-LRM consists of two key components: X-former and X-triplane.
Our X-former can handle an arbitrary number of input views using an MLP-based
image tokenizer and a Transformer-based encoder. The output tokens are then
upsampled into our X-triplane representation, which models the 3D radiodensity
as an implicit neural field. To support the training of X-LRM, we introduce
Torso-16K, a large-scale dataset comprising over 16K volume-projection pairs of
various torso organs. Extensive experiments demonstrate that X-LRM outperforms
the state-of-the-art method by 1.5 dB and achieves 27x faster speed and better
flexibility. Furthermore, the downstream evaluation of lung segmentation tasks
also suggests the practical value of our approach. Our code, pre-trained
models, and dataset will be released at https://github.com/caiyuanhao1998/X-LRM


## MoEMoE Question Guided Dense and Scalable Sparse Mixture-of-Expert for Multi-source Multi-modal Answering

>Authors: Vinay Kumar Verma, Shreyas Sunil Kulkarni, Happy Mittal, Deepak Gupta

>2025-03-08

> http://arxiv.org/abs/2503.06296v1

Question Answering (QA) and Visual Question Answering (VQA) are well-studied
problems in the language and vision domain. One challenging scenario involves
multiple sources of information, each of a different modality, where the answer
to the question may exist in one or more sources. This scenario contains richer
information but is highly complex to handle. In this work, we formulate a novel
question-answer generation (QAG) framework in an environment containing
multi-source, multimodal information. The answer may belong to any or all
sources; therefore, selecting the most prominent answer source or an optimal
combination of all sources for a given question is challenging. To address this
issue, we propose a question-guided attention mechanism that learns attention
across multiple sources and decodes this information for robust and unbiased
answer generation. To learn attention within each source, we introduce an
explicit alignment between questions and various information sources, which
facilitates identifying the most pertinent parts of the source information
relative to the question. Scalability in handling diverse questions poses a
challenge. We address this by extending our model to a **sparse**
mixture-of-experts (**sparse**-MoE) framework, enabling it to handle thousands of
question types. Experiments on T5 and Flan-T5 using three datasets demonstrate
the model's efficacy, supported by ablation studies.


## IteRABRe Iterative Recovery-Aided Block Reduction

>Authors: Haryo Akbarianto Wibowo, Haiyue Song, Hideki Tanaka, Masao Utiyama, Alham Fikri Aji, Raj Dabre

>2025-03-08

> http://arxiv.org/abs/2503.06291v1

Large Language Models (LLMs) have grown increasingly expensive to deploy,
driving the need for effective model compression techniques. While block
**pruning** offers a straightforward approach to reducing model size, existing
methods often struggle to maintain performance or require substantial
computational resources for recovery. We present IteRABRe, a simple yet
effective iterative **pruning** method that achieves superior compression results
while requiring minimal computational resources. Using only 2.5M tokens for
recovery, our method outperforms baseline approaches by ~3% on average when
compressing the Llama3.1-8B and Qwen2.5-7B models. IteRABRe demonstrates
particular strength in the preservation of linguistic capabilities, showing an
improvement 5% over the baselines in language-related tasks. Our analysis
reveals distinct **pruning** characteristics between these models, while also
demonstrating preservation of multilingual capabilities.


## MAD-MAX Modular And Diverse Malicious Attack MiXtures for Automated LLM Red Teaming

>Authors: Stefan Schoepf, Muhammad Zaid Hameed, Ambrish Rawat, Kieran Fraser, Giulio Zizzo, Giandomenico Cornacchia, Mark Purcell

>2025-03-08

> http://arxiv.org/abs/2503.06253v1

With LLM usage rapidly increasing, their vulnerability to jailbreaks that
create harmful outputs are a major security risk. As new jailbreaking
strategies emerge and models are changed by fine-tuning, continuous testing for
security vulnerabilities is necessary. Existing Red Teaming methods fall short
in cost efficiency, attack success rate, attack diversity, or extensibility as
new attack types emerge. We address these challenges with Modular And Diverse
Malicious Attack MiXtures (MAD-MAX) for Automated LLM Red Teaming. MAD-MAX uses
automatic assignment of attack strategies into relevant attack clusters,
chooses the most relevant clusters for a malicious goal, and then combines
strategies from the selected clusters to achieve diverse novel attacks with
high attack success rates. MAD-MAX further merges promising attacks together at
each iteration of Red Teaming to boost performance and introduces a similarity
filter to prune out similar attacks for increased cost efficiency. The MAD-MAX
approach is designed to be easily extensible with newly discovered attack
strategies and outperforms the prominent Red Teaming method Tree of Attacks
with Pruning (TAP) significantly in terms of Attack Success Rate (ASR) and
queries needed to achieve jailbreaks. MAD-MAX jailbreaks 97% of malicious goals
in our benchmarks on GPT-4o and Gemini-Pro compared to TAP with 66%. MAD-MAX
does so with only 10.9 average queries to the target LLM compared to TAP with
23.3.
  WARNING: This paper contains contents which are offensive in nature.


## Rethinking Lanes and Points in Complex Scenarios for Monocular 3D Lane Detection

>Authors: Yifan Chang, Junjie Huang, Xiaofeng Wang, Yun Ye, Zhujin Liang, Yi Shan, Dalong Du, Xingang Wang

>2025-03-08

> http://arxiv.org/abs/2503.06237v1

Monocular 3D lane detection is a fundamental task in autonomous driving.
Although **sparse**-point methods lower computational load and maintain high
accuracy in complex lane geometries, current methods fail to fully leverage the
geometric structure of lanes in both lane geometry representations and model
design. In lane geometry representations, we present a theoretical analysis
alongside experimental validation to verify that current **sparse** lane
representation methods contain inherent flaws, resulting in potential errors of
up to 20 m, which raise significant safety concerns for driving. To address
this issue, we propose a novel patching strategy to completely represent the
full lane structure. To enable existing models to match this strategy, we
introduce the EndPoint head (EP-head), which adds a patching distance to
endpoints. The EP-head enables the model to predict more complete lane
representations even with fewer preset points, effectively addressing existing
limitations and paving the way for models that are faster and require fewer
parameters in the future. In model design, to enhance the model's perception of
lane structures, we propose the PointLane attention (PL-attention), which
incorporates prior geometric knowledge into the attention mechanism. Extensive
experiments demonstrate the effectiveness of the proposed methods on various
state-of-the-art models. For instance, in terms of the overall F1-score, our
methods improve Persformer by 4.4 points, Anchor3DLane by 3.2 points, and LATR
by 2.8 points. The code will be available soon.


## Sample-aware Adaptive Structured Pruning for Large Language Models

>Authors: Jun Kong, Xinge Ma, Jin Wang, Xuejie Zhang

>2025-03-08

> http://arxiv.org/abs/2503.06184v1

Large language models (LLMs) have achieved outstanding performance in natural
language processing, but enormous model sizes and high computational costs
limit their practical deployment. Structured **pruning** can effectively reduce the
resource demands for deployment by removing redundant model parameters.
However, the randomly selected calibration data and fixed single importance
estimation metrics in existing structured **pruning** methods lead to degraded
performance of pruned models. This study introduces AdaPruner, a sample-aware
adaptive structured **pruning** framework for LLMs, aiming to optimize the
calibration data and importance estimation metrics in the structured **pruning**
process. Specifically, AdaPruner effectively removes redundant parameters from
LLMs by constructing a structured **pruning** solution space and then employing
Bayesian optimization to adaptively search for the optimal calibration data and
importance estimation metrics. Experimental results show that the AdaPruner
outperforms existing structured **pruning** methods on a family of LLMs with
varying **pruning** ratios, demonstrating its applicability and robustness.
Remarkably, at a 20\% **pruning** ratio, the model pruned with AdaPruner maintains
97\% of the performance of the unpruned model.


## Lightweight Software Kernels and Hardware Extensions for Efficient Sparse Deep Neural Networks on Microcontrollers

>Authors: Francesco Daghero, Daniele Jahier Pagliari, Francesco Conti, Luca Benini, Massimo Poncino, Alessio Burrello

>2025-03-08

> http://arxiv.org/abs/2503.06183v1

The **acceleration** of pruned Deep Neural Networks (DNNs) on edge devices such
as Microcontrollers (MCUs) is a challenging task, given the tight area- and
power-constraints of these devices. In this work, we propose a three-fold
contribution to address this problem. First, we design a set of optimized
software kernels for N:M pruned layers, targeting ultra-low-power, multicore
RISC-V MCUs, which are up to 2.1x and 3.4x faster than their dense counterparts
at 1:8 and 1:16 **sparsity**, respectively. Then, we implement a lightweight
Instruction-Set Architecture (ISA) extension to accelerate the indirect load
and non-zero indices decompression operations required by our kernels,
obtaining up to 1.9x extra speedup, at the cost of a 5% area overhead. Lastly,
we extend an open-source DNN compiler to utilize our **sparse** kernels for
complete networks, showing speedups of 3.21x and 1.81x on a ResNet18 and a
Vision Transformer (ViT), with less than 1.5% accuracy drop compared to a dense
baseline.


## FlowMP Learning Motion Fields for Robot Planning with Conditional Flow Matching

>Authors: Khang Nguyen, An T. Le, Tien Pham, Manfred Huber, Jan Peters, Minh Nhat Vu

>2025-03-08

> http://arxiv.org/abs/2503.06135v1

Prior flow matching methods in robotics have primarily learned velocity
fields to morph one distribution of trajectories into another. In this work, we
extend flow matching to capture second-order trajectory dynamics, incorporating
**acceleration** effects either explicitly in the model or implicitly through the
learning objective. Unlike diffusion models, which rely on a noisy forward
process and iterative denoising steps, flow matching trains a continuous
transformation (flow) that directly maps a simple prior distribution to the
target trajectory distribution without any denoising procedure. By modeling
trajectories with second-order dynamics, our approach ensures that generated
robot motions are smooth and physically executable, avoiding the jerky or
dynamically infeasible trajectories that first-order models might produce. We
empirically demonstrate that this second-order conditional flow matching yields
superior performance on motion planning benchmarks, achieving smoother
trajectories and higher success rates than baseline planners. These findings
highlight the advantage of learning **acceleration**-aware motion fields, as our
method outperforms existing motion planning methods in terms of trajectory
quality and planning success.


## PointDiffuse A Dual-Conditional Diffusion Model for Enhanced Point Cloud Semantic Segmentation

>Authors: Yong He, Hongshan Yu, Mingtao Feng, Tongjia Chen, Zechuan Li, Anwaar Ulhaq, Saeed Anwar, Ajmal Saeed Mian

>2025-03-08

> http://arxiv.org/abs/2503.06094v2

Diffusion probabilistic models are traditionally used to generate colors at
fixed pixel positions in 2D images. Building on this, we extend diffusion
models to point cloud semantic segmentation, where point positions also remain
fixed, and the diffusion model generates point labels instead of colors. To
accelerate the denoising process in reverse diffusion, we introduce a noisy
label embedding mechanism. This approach integrates semantic information into
the noisy label, providing an initial semantic reference that improves the
reverse diffusion efficiency. Additionally, we propose a point frequency
transformer that enhances the adjustment of high-level context in point clouds.
To reduce computational complexity, we introduce the position condition into
MLP and propose denoising PointNet to process the high-resolution point cloud
without sacrificing geometric details. Finally, we integrate the proposed noisy
label embedding, point frequency transformer and denoising PointNet in our
proposed dual conditional diffusion model-based network (PointDiffuse) to
perform large-scale point cloud semantic segmentation. Extensive experiments on
five benchmarks demonstrate the superiority of PointDiffuse, achieving the
state-of-the-art mIoU of 74.2\% on S3DIS Area 5, 81.2\% on S3DIS 6-fold and
64.8\% on SWAN dataset.


## Disrupting Model Merging A Parameter-Level Defense Without Sacrificing Accuracy

>Authors: Wei Junhao, Yu Zhe, Sakuma Jun

>2025-03-08

> http://arxiv.org/abs/2503.07661v1

Model merging is a technique that combines multiple finetuned models into a
single model without additional training, allowing a free-rider to cheaply
inherit specialized capabilities. This study investigates methodologies to
suppress unwanted model merging by free-riders. Existing methods such as model
watermarking or fingerprinting can only detect merging in hindsight. In
contrast, we propose a first proactive defense against model merging.
Specifically, our defense method modifies the model parameters so that the
model is disrupted if the model is merged with any other model, while its
functionality is kept unchanged if not merged with others. Our approach
consists of two modules, rearranging MLP parameters and scaling attention
heads, which push the model out of the shared basin in parameter space, causing
the merging performance with other models to degrade significantly. We conduct
extensive experiments on image classification, image generation, and text
classification to demonstrate that our defense severely disrupts merging while
retaining the functionality of the post-protect model. Moreover, we analyze
potential adaptive attacks and further propose a dropout-based **pruning** to
improve our proposal's robustness.


## Multi-view Spectral Clustering on the Grassmannian Manifold With Hypergraph Representation

>Authors: Murong Yang, Shihui Ying, Xin-Jian Xu, Yue Gao

>2025-03-08

> http://arxiv.org/abs/2503.06066v1

Graph-based multi-view spectral clustering methods have achieved notable
progress recently, yet they often fall short in either oversimplifying pairwise
relationships or struggling with inefficient spectral decompositions in
high-dimensional Euclidean spaces. In this paper, we introduce a novel approach
that begins to generate hypergraphs by leveraging **sparse** representation
learning from data points. Based on the generated hypergraph, we propose an
optimization function with orthogonality constraints for multi-view hypergraph
spectral clustering, which incorporates spectral clustering for each view and
ensures consistency across different views. In Euclidean space, solving the
orthogonality-constrained optimization problem may yield local maxima and
approximation errors. Innovately, we transform this problem into an
unconstrained form on the Grassmannian manifold. Finally, we devise an
alternating iterative Riemannian optimization algorithm to solve the problem.
To validate the effectiveness of the proposed algorithm, we test it on four
real-world multi-view datasets and compare its performance with seven
state-of-the-art multi-view clustering algorithms. The experimental results
demonstrate that our method outperforms the baselines in terms of clustering
performance due to its superior low-dimensional and resilient feature
representation.


## SmartBench Is Your LLM Truly a Good Chinese Smartphone Assistant?

>Authors: Xudong Lu, Haohao Gao, Renshou Wu, Shuai Ren, Xiaoxin Chen, Hongsheng Li, Fangyuan Li

>2025-03-08

> http://arxiv.org/abs/2503.06029v1

Large Language Models (LLMs) have become integral to daily life, especially
advancing as intelligent assistants through on-device deployment on
smartphones. However, existing LLM evaluation benchmarks predominantly focus on
objective tasks like mathematics and coding in English, which do not
necessarily reflect the practical use cases of on-device LLMs in real-world
mobile scenarios, especially for Chinese users. To address these gaps, we
introduce SmartBench, the first benchmark designed to evaluate the capabilities
of on-device LLMs in Chinese mobile contexts. We analyze functionalities
provided by representative smartphone manufacturers and divide them into five
categories: text summarization, text Q\&A, information extraction, content
creation, and notification management, further detailed into 20 specific tasks.
For each task, we construct high-quality datasets comprising 50 to 200
question-answer pairs that reflect everyday mobile interactions, and we develop
automated evaluation criteria tailored for these tasks. We conduct
comprehensive evaluations of on-device LLMs and MLLMs using SmartBench and also
assess their performance after **quantize**d deployment on real smartphone NPUs.
Our contributions provide a standardized framework for evaluating on-device
LLMs in Chinese, promoting further development and optimization in this
critical area. Code and data will be available at
https://github.com/Lucky-Lance/SmartBench.


## Analyzing the Role of Permutation Invariance in Linear Mode Connectivity

>Authors: Keyao Zhan, Puheng Li, Lei Wu

>2025-03-08

> http://arxiv.org/abs/2503.06001v2

It was empirically observed in Entezari et al. (2021) that when accounting
for the permutation invariance of neural networks, there is likely no loss
barrier along the linear interpolation between two SGD solutions -- a
phenomenon known as linear mode connectivity (LMC) modulo permutation. This
phenomenon has sparked significant attention due to both its theoretical
interest and practical relevance in applications such as model merging. In this
paper, we provide a fine-grained analysis of this phenomenon for two-layer ReLU
networks under a teacher-student setup. We show that as the student network
width $m$ increases, the LMC loss barrier modulo permutation exhibits a double
descent behavior. Particularly, when $m$ is sufficiently large, the barrier
decreases to zero at a rate $O(m^{-1/2})$. Notably, this rate does not suffer
from the curse of dimensionality and demonstrates how substantial permutation
can reduce the LMC loss barrier. Moreover, we observe a sharp transition in the
**sparsity** of GD/SGD solutions when increasing the learning rate and investigate
how this **sparsity** preference affects the LMC loss barrier modulo permutation.
Experiments on both synthetic and MNIST datasets corroborate our theoretical
predictions and reveal a similar trend for more complex network architectures.


## TPU-Gen LLM-Driven Custom Tensor Processing Unit Generator

>Authors: Deepak Vungarala, Mohammed E. Elbtity, Sumiya Syed, Sakila Alam, Kartik Pandit, Arnob Ghosh, Ramtin Zand, Shaahin Angizi

>2025-03-07

> http://arxiv.org/abs/2503.05951v1

The increasing complexity and scale of Deep Neural Networks (DNNs)
necessitate specialized tensor accelerators, such as Tensor Processing Units
(TPUs), to meet various computational and energy efficiency requirements.
Nevertheless, designing optimal TPU remains challenging due to the high domain
expertise level, considerable manual design time, and lack of high-quality,
domain-specific datasets. This paper introduces TPU-Gen, the first Large
Language Model (LLM) based framework designed to automate the exact and
approximate TPU generation process, focusing on systolic array architectures.
TPU-Gen is supported with a meticulously curated, comprehensive, and
open-source dataset that covers a wide range of spatial array designs and
approximate multiply-and-accumulate units, enabling design reuse, adaptation,
and customization for different DNN workloads. The proposed framework leverages
Retrieval-Augmented Generation (RAG) as an effective solution for a data-scare
hardware domain in building LLMs, addressing the most intriguing issue,
hallucinations. TPU-Gen transforms high-level architectural specifications into
optimized low-level implementations through an effective hardware generation
pipeline. Our extensive experimental evaluations demonstrate superior
performance, power, and area efficiency, with an average reduction in area and
power of 92\% and 96\% from the manual optimization reference values. These
results set new standards for driving advancements in next-generation design
automation tools powered by LLMs.


## CASP Compression of Large Multimodal Models Based on Attention Sparsity

>Authors: Mohsen Gholami, Mohammad Akbari, Kevin Cannons, Yong Zhang

>2025-03-07

> http://arxiv.org/abs/2503.05936v1

In this work, we propose an extreme compression technique for Large
Multimodal Models (LMMs). While previous studies have explored **quantization** as
an efficient post-training compression method for Large Language Models (LLMs),
**low-bit** compression for multimodal models remains under-explored. The redundant
nature of inputs in multimodal models results in a highly **sparse** attention
matrix. We theoretically and experimentally demonstrate that the attention
matrix's **sparsity** bounds the compression error of the Query and Key weight
matrices. Based on this, we introduce CASP, a model compression technique for
LMMs. Our approach performs a data-aware low-rank decomposition on the Query
and Key weight matrix, followed by **quantization** across all layers based on an
optimal bit allocation process. CASP is compatible with any **quantization**
technique and enhances state-of-the-art 2-bit **quantization** methods (AQLM and
QuIP#) by an average of 21% on image- and video-language benchmarks.


## A Survey on Sparse Autoencoders Interpreting the Internal Mechanisms of Large Language Models

>Authors: Dong Shu, Xuansheng Wu, Haiyan Zhao, Daking Rai, Ziyu Yao, Ninghao Liu, Mengnan Du

>2025-03-07

> http://arxiv.org/abs/2503.05613v1

Large Language Models (LLMs) have revolutionized natural language processing,
yet their internal mechanisms remain largely opaque. Recently, mechanistic
interpretability has attracted significant attention from the research
community as a means to understand the inner workings of LLMs. Among various
mechanistic interpretability approaches, Sparse Autoencoders (SAEs) have
emerged as a particularly promising method due to their ability to disentangle
the complex, superimposed features within LLMs into more interpretable
components. This paper presents a comprehensive examination of SAEs as a
promising approach to interpreting and understanding LLMs. We provide a
systematic overview of SAE principles, architectures, and applications
specifically tailored for LLM analysis, covering theoretical foundations,
implementation strategies, and recent developments in **sparsity** mechanisms. We
also explore how SAEs can be leveraged to explain the internal workings of
LLMs, steer model behaviors in desired directions, and develop more transparent
training methodologies for future models. Despite the challenges that remain
around SAE implementation and scaling, they continue to provide valuable tools
for understanding the internal mechanisms of large language models.


## Mol-CADiff Causality-Aware Autoregressive Diffusion for Molecule Generation

>Authors: Md Atik Ahamed, Qiang Ye, Qiang Cheng

>2025-03-07

> http://arxiv.org/abs/2503.05499v1

The design of novel molecules with desired properties is a key challenge in
drug discovery and materials science. Traditional methods rely on
trial-and-error, while recent deep learning approaches have accelerated
molecular generation. However, existing models struggle with generating
molecules based on specific textual descriptions. We introduce Mol-CADiff, a
novel diffusion-based framework that uses causal attention mechanisms for
text-conditional molecular generation. Our approach explicitly models the
causal relationship between textual prompts and molecular structures,
overcoming key limitations in existing methods. We enhance dependency modeling
both within and across modalities, enabling precise control over the generation
process. Our extensive experiments demonstrate that Mol-CADiff outperforms
state-of-the-art methods in generating diverse, novel, and chemically valid
molecules, with better alignment to specified properties, enabling more
intuitive language-driven molecular design.


## Benchmarking LLMs in Recommendation Tasks A Comparative Evaluation with Conventional Recommenders

>Authors: Qijiong Liu, Jieming Zhu, Lu Fan, Kun Wang, Hengchang Hu, Wei Guo, Yong Liu, Xiao-Ming Wu

>2025-03-07

> http://arxiv.org/abs/2503.05493v1

In recent years, integrating large language models (LLMs) into recommender
systems has created new opportunities for improving recommendation quality.
However, a comprehensive benchmark is needed to thoroughly evaluate and compare
the recommendation capabilities of LLMs with traditional recommender systems.
In this paper, we introduce RecBench, which systematically investigates various
item representation forms (including unique identifier, text, semantic
embedding, and semantic identifier) and evaluates two primary recommendation
tasks, i.e., click-through rate prediction (CTR) and sequential recommendation
(SeqRec). Our extensive experiments cover up to 17 large models and are
conducted across five diverse datasets from fashion, news, video, books, and
music domains. Our findings indicate that LLM-based recommenders outperform
conventional recommenders, achieving up to a 5% AUC improvement in the CTR
scenario and up to a 170% NDCG@10 improvement in the SeqRec scenario. However,
these substantial performance gains come at the expense of significantly
reduced inference efficiency, rendering the LLM-as-RS paradigm impractical for
real-time recommendation environments. We aim for our findings to inspire
future research, including recommendation-specific model **acceleration** methods.
We will release our code, data, configurations, and platform to enable other
researchers to reproduce and build upon our experimental results.


## SplitQuantV2 Enhancing Low-Bit Quantization of LLMs Without GPUs

>Authors: Jaewoo Song, Fangzhen Lin

>2025-03-07

> http://arxiv.org/abs/2503.07657v1

The **quantization** of large language models (LLMs) is crucial for deploying
them on devices with limited computational resources. While advanced
**quantization** algorithms offer improved performance compared to the basic linear
**quantization**, they typically require high-end graphics processing units (GPUs),
are often restricted to specific deep neural network (DNN) frameworks, and
require calibration datasets. This limitation poses challenges for using such
algorithms on various neural processing units (NPUs) and edge AI devices, which
have diverse model formats and frameworks. In this paper, we show SplitQuantV2,
an innovative algorithm designed to enhance **low-bit** linear **quantization** of
LLMs, can achieve results comparable to those of advanced algorithms.
SplitQuantV2 preprocesses models by splitting linear and convolution layers
into functionally equivalent, **quantization**-friendly structures. The algorithm's
platform-agnostic, concise, and efficient nature allows for implementation
without the need for GPUs. Our evaluation on the Llama 3.2 1B Instruct model
using the AI2's Reasoning Challenge (ARC) dataset demonstrates that
SplitQuantV2 improves the accuracy of the INT4 **quantization** model by 11.76%p,
matching the performance of the original floating-point model. Remarkably,
SplitQuantV2 took only 2 minutes 6 seconds to preprocess the 1B model and
perform linear INT4 **quantization** using only an Apple M4 CPU. SplitQuantV2
provides a practical solution for **low-bit** **quantization** on LLMs, especially when
complex, computation-intensive algorithms are inaccessible due to hardware
limitations or framework incompatibilities.


## Deep Frequency Attention Networks for Single Snapshot Sparse Array Interpolation

>Authors: Ruxin Zheng, Shunqiao Sun, Hongshan Liu

>2025-03-07

> http://arxiv.org/abs/2503.05486v1

Sparse arrays have been widely exploited in radar systems because of their
advantages in achieving large array aperture at low hardware cost, while
significantly reducing mutual coupling. However, **sparse** arrays suffer from high
sidelobes which may lead to false detections. Missing elements in **sparse** arrays
can be interpolated using the **sparse** array measurements. In snapshot-limited
scenarios, such as automotive radar, it is challenging to utilize difference
coarrays which require a large number of snapshots to construct a covariance
matrix for interpolation. For single snapshot **sparse** array interpolation,
traditional model-based methods, while effective, require expert knowledge for
hyperparameter tuning, lack task-specific adaptability, and incur high
computational costs. In this paper, we propose a novel deep learning-based
single snapshot **sparse** array interpolation network that addresses these
challenges by leveraging a frequency-domain attention mechanism. The proposed
approach transforms the **sparse** signal into the frequency domain, where the
attention mechanism focuses on key spectral regions, enabling improved
interpolation of missing elements even in low signal-to-noise ratio (SNR)
conditions. By minimizing computational costs and enhancing interpolation
accuracy, the proposed method demonstrates superior performance compared to
traditional approaches, making it well-suited for automotive radar
applications.


## Linear-MoE Linear Sequence Modeling Meets Mixture-of-Experts

>Authors: Weigao Sun, Disen Lan, Tong Zhu, Xiaoye Qu, Yu Cheng

>2025-03-07

> http://arxiv.org/abs/2503.05447v1

Linear Sequence Modeling (LSM) like linear attention, state space models and
linear RNNs, and Mixture-of-Experts (MoE) have recently emerged as significant
architectural improvements. In this paper, we introduce Linear-MoE, a
production-level system for modeling and training large-scale models that
integrate LSM with MoE. Linear-MoE leverages the advantages of both LSM modules
for linear-complexity sequence modeling and MoE layers for **sparse**ly activation,
aiming to offer high performance with efficient training. The Linear-MoE system
comprises: 1) Modeling subsystem, which provides a unified framework supporting
all instances of LSM. and 2) Training subsystem, which facilitates efficient
training by incorporating various advanced parallelism technologies,
particularly Sequence Parallelism designed for Linear-MoE models. Additionally,
we explore hybrid models that combine Linear-MoE layers with standard
Transformer-MoE layers with its Sequence Parallelism to further enhance model
flexibility and performance. Evaluations on two model series, A0.3B-2B and
A1B-7B, demonstrate Linear-MoE achieves efficiency gains while maintaining
competitive performance on various benchmarks, showcasing its potential as a
next-generation foundational model architecture. Code:
https://github.com/OpenSparseLLMs/Linear-MoE.


## Accelerating Earth Science Discovery via Multi-Agent LLM Systems

>Authors: Dmitrii Pantiukhin, Boris Shapkin, Ivan Kuznetsov, Antonia Anna Jost, Nikolay Koldunov

>2025-03-07

> http://arxiv.org/abs/2503.05854v1

This Perspective explores the transformative potential of Multi-Agent Systems
(MAS) powered by Large Language Models (LLMs) in the geosciences. Users of
geoscientific data repositories face challenges due to the complexity and
diversity of data formats, inconsistent metadata practices, and a considerable
number of unprocessed datasets. MAS possesses transformative potential for
improving scientists' interaction with geoscientific data by enabling
intelligent data processing, natural language interfaces, and collaborative
problem-solving capabilities. We illustrate this approach with "PANGAEA GPT", a
specialized MAS pipeline integrated with the diverse PANGAEA database for Earth
and Environmental Science, demonstrating how MAS-driven workflows can
effectively manage complex datasets and accelerate scientific discovery. We
discuss how MAS can address current data challenges in geosciences, highlight
advancements in other scientific fields, and propose future directions for
integrating MAS into geoscientific data processing pipelines. In this
Perspective, we show how MAS can fundamentally improve data accessibility,
promote cross-disciplinary collaboration, and accelerate geoscientific
discoveries.


## Multi-Grained Feature Pruning for Video-Based Human Pose Estimation

>Authors: Zhigang Wang, Shaojing Fan, Zhenguang Liu, Zheqi Wu, Sifan Wu, Yingying Jiao

>2025-03-07

> http://arxiv.org/abs/2503.05365v1

Human pose estimation, with its broad applications in action recognition and
motion capture, has experienced significant advancements. However, current
Transformer-based methods for video pose estimation often face challenges in
managing redundant temporal information and achieving fine-grained perception
because they only focus on processing low-resolution features. To address these
challenges, we propose a novel multi-scale resolution framework that encodes
spatio-temporal representations at varying granularities and executes
fine-grained perception compensation. Furthermore, we employ a density peaks
clustering method to dynamically identify and prioritize tokens that offer
important semantic information. This strategy effectively prunes redundant
feature tokens, especially those arising from multi-frame features, thereby
optimizing computational efficiency without sacrificing semantic richness.
Empirically, it sets new benchmarks for both performance and efficiency on
three large-scale datasets. Our method achieves a 93.8% improvement in
inference speed compared to the baseline, while also enhancing pose estimation
accuracy, reaching 87.4 mAP on the PoseTrack2017 dataset.


## MatrixFlow System-Accelerator co-design for high-performance transformer applications

>Authors: Qunyou Liu, Marina Zapater, David Atienza

>2025-03-07

> http://arxiv.org/abs/2503.05290v1

Transformers are central to advances in artificial intelligence (AI),
excelling in fields ranging from computer vision to natural language
processing. Despite their success, their large parameter count and
computational demands challenge efficient **acceleration**. To address these
limitations, this paper proposes MatrixFlow, a novel co-designed
system-accelerator architecture based on a loosely coupled systolic array
including a new software mapping approach for efficient transformer code
execution. MatrixFlow is co-optimized via a novel dataflow-based matrix
multiplication technique that reduces memory overhead. These innovations
significantly improve data throughput, which is critical for handling the
extensive computations required by transformers. We validate our approach
through full system simulation using gem5 across various BERT and ViT
Transformer models featuring different data types, demonstrating significant
application-wide speed-ups. Our method achieves up to a 22x improvement
compared to a many-core CPU system, and outperforms the closest
state-of-the-art loosely-coupled and tightly-coupled accelerators by over 5x
and 8x, respectively.


## MM-StoryAgent Immersive Narrated Storybook Video Generation with a Multi-Agent Paradigm across Text, Image and Audio

>Authors: Xuenan Xu, Jiahao Mei, Chenliang Li, Yuning Wu, Ming Yan, Shaopeng Lai, Ji Zhang, Mengyue Wu

>2025-03-07

> http://arxiv.org/abs/2503.05242v1

The rapid advancement of large language models (LLMs) and artificial
intelligence-generated content (AIGC) has accelerated AI-native applications,
such as AI-based storybooks that automate engaging story production for
children. However, challenges remain in improving story attractiveness,
enriching storytelling expressiveness, and developing open-source evaluation
benchmarks and frameworks. Therefore, we propose and opensource MM-StoryAgent,
which creates immersive narrated video storybooks with refined plots,
role-consistent images, and multi-channel audio. MM-StoryAgent designs a
multi-agent framework that employs LLMs and diverse expert tools (generative
models and APIs) across several modalities to produce expressive storytelling
videos. The framework enhances story attractiveness through a multi-stage
writing pipeline. In addition, it improves the immersive storytelling
experience by integrating sound effects with visual, music and narrative
assets. MM-StoryAgent offers a flexible, open-source platform for further
development, where generative modules can be substituted. Both objective and
subjective evaluation regarding textual story quality and alignment between
modalities validate the effectiveness of our proposed MM-StoryAgent system. The
demo and source code are available.


## SplatPose Geometry-Aware 6-DoF Pose Estimation from Single RGB Image via 3D Gaussian Splatting

>Authors: Linqi Yang, Xiongwei Zhao, Qihao Sun, Ke Wang, Ao Chen, Peng Kang

>2025-03-07

> http://arxiv.org/abs/2503.05174v1

6-DoF pose estimation is a fundamental task in computer vision with
wide-ranging applications in augmented reality and robotics. Existing single
RGB-based methods often compromise accuracy due to their reliance on initial
pose estimates and susceptibility to rotational ambiguity, while approaches
requiring depth sensors or multi-view setups incur significant deployment
costs. To address these limitations, we introduce SplatPose, a novel framework
that synergizes 3D Gaussian Splatting (3DGS) with a dual-branch neural
architecture to achieve high-precision pose estimation using only a single RGB
image. Central to our approach is the Dual-Attention Ray Scoring Network
(DARS-Net), which innovatively decouples positional and angular alignment
through geometry-domain attention mechanisms, explicitly modeling directional
dependencies to mitigate rotational ambiguity. Additionally, a coarse-to-fine
optimization pipeline progressively refines pose estimates by aligning dense 2D
features between query images and 3DGS-synthesized views, effectively
correcting feature misalignment and depth errors from **sparse** ray sampling.
Experiments on three benchmark datasets demonstrate that SplatPose achieves
state-of-the-art 6-DoF pose estimation accuracy in single RGB settings,
rivaling approaches that depend on depth or multi-view images.


## GaussianCAD Robust Self-Supervised CAD Reconstruction from Three Orthographic Views Using 3D Gaussian Splatting

>Authors: Zheng Zhou, Zhe Li, Bo Yu, Lina Hu, Liang Dong, Zijian Yang, Xiaoli Liu, Ning Xu, Ziwei Wang, Yonghao Dang, Jianqin Yin

>2025-03-07

> http://arxiv.org/abs/2503.05161v1

The automatic reconstruction of 3D computer-aided design (CAD) models from
CAD sketches has recently gained significant attention in the computer vision
community. Most existing methods, however, rely on vector CAD sketches and 3D
ground truth for supervision, which are often difficult to be obtained in
industrial applications and are sensitive to noise inputs. We propose viewing
CAD reconstruction as a specific instance of **sparse**-view 3D reconstruction to
overcome these limitations. While this reformulation offers a promising
perspective, existing 3D reconstruction methods typically require natural
images and corresponding camera poses as inputs, which introduces two major
significant challenges: (1) modality discrepancy between CAD sketches and
natural images, and (2) difficulty of accurate camera pose estimation for CAD
sketches. To solve these issues, we first transform the CAD sketches into
representations resembling natural images and extract corresponding masks.
Next, we manually calculate the camera poses for the orthographic views to
ensure accurate alignment within the 3D coordinate system. Finally, we employ a
customized **sparse**-view 3D reconstruction method to achieve high-quality
reconstructions from aligned orthographic views. By leveraging raster CAD
sketches for self-supervision, our approach eliminates the reliance on vector
CAD sketches and 3D ground truth. Experiments on the Sub-Fusion360 dataset
demonstrate that our proposed method significantly outperforms previous
approaches in CAD reconstruction performance and exhibits strong robustness to
noisy inputs.


## Accelerating Diffusion Transformer via Gradient-Optimized Cache

>Authors: Junxiang Qiu, Lin Liu, Shuo Wang, Jinda Lu, Kezhou Chen, Yanbin Hao

>2025-03-07

> http://arxiv.org/abs/2503.05156v1

Feature caching has emerged as an effective strategy to accelerate diffusion
transformer (DiT) sampling through temporal feature reuse. It is a challenging
problem since (1) Progressive error accumulation from cached blocks
significantly degrades generation quality, particularly when over 50\% of
blocks are cached; (2) Current error compensation approaches neglect dynamic
perturbation patterns during the caching process, leading to suboptimal error
correction. To solve these problems, we propose the Gradient-Optimized Cache
(GOC) with two key innovations: (1) Cached Gradient Propagation: A gradient
queue dynamically computes the gradient differences between cached and
recomputed features. These gradients are weighted and propagated to subsequent
steps, directly compensating for the approximation errors introduced by
caching. (2) Inflection-Aware Optimization: Through statistical analysis of
feature variation patterns, we identify critical inflection points where the
denoising trajectory changes direction. By aligning gradient updates with these
detected phases, we prevent conflicting gradient directions during error
correction. Extensive evaluations on ImageNet demonstrate GOC's superior
trade-off between efficiency and quality. With 50\% cached blocks, GOC achieves
IS 216.28 (26.3\% higher) and FID 3.907 (43\% lower) compared to baseline DiT,
while maintaining identical computational costs. These improvements persist
across various cache ratios, demonstrating robust adaptability to different
**acceleration** requirements.


## MergeQuant Accurate 4-bit Static Quantization of Large Language Models by Channel-wise Calibration

>Authors: Jinguang Wang, Jingyu Wang, Haifeng Sun, Tingting Yang, Zirui Zhuang, Wanyi Ning, Yuexi Yin, Qi Qi, Jianxin Liao

>2025-03-07

> http://arxiv.org/abs/2503.07654v1

Quantization has been widely used to compress and accelerate inference of
large language models (LLMs). Existing methods focus on exploring the per-token
dynamic calibration to ensure both inference **acceleration** and model accuracy
under 4-bit **quantization**. However, in autoregressive generation inference of
long sequences, the overhead of repeated dynamic **quantization** and
de**quantization** steps becomes considerably expensive. In this work, we propose
MergeQuant, an accurate and efficient per-channel static **quantization**
framework. MergeQuant integrates the per-channel **quantization** steps with the
corresponding scalings and linear mappings through a Quantization Step
Migration (QSM) method, thereby eliminating the **quantization** overheads before
and after matrix multiplication. Furthermore, in view of the significant
differences between the different channel ranges, we propose dimensional
reconstruction and adaptive clipping to address the non-uniformity of
**quantization** scale factors and redistribute the channel variations to the
subsequent modules to balance the parameter distribution under QSM. Within the
static **quantization** setting of W4A4, MergeQuant reduces the accuracy gap on
zero-shot tasks compared to FP16 baseline to 1.3 points on Llama-2-70B model.
On Llama-2-7B model, MergeQuant achieves up to 1.77x speedup in decoding, and
up to 2.06x speedup in end-to-end compared to FP16 baseline.


## HexPlane Representation for 3D Semantic Scene Understanding

>Authors: Zeren Chen, Yuenan Hou, Yulin Chen, Li Liu, Xiao Sun, Lu Sheng

>2025-03-07

> http://arxiv.org/abs/2503.05127v1

In this paper, we introduce the HexPlane representation for 3D semantic scene
understanding. Specifically, we first design the View Projection Module (VPM)
to project the 3D point cloud into six planes to maximally retain the original
spatial information. Features of six planes are extracted by the 2D encoder and
sent to the HexPlane Association Module (HAM) to adaptively fuse the most
informative information for each point. The fused point features are further
fed to the task head to yield the ultimate predictions. Compared to the popular
point and voxel representation, the HexPlane representation is efficient and
can utilize highly optimized 2D operations to process **sparse** and unordered 3D
point clouds. It can also leverage off-the-shelf 2D models, network weights,
and training recipes to achieve accurate scene understanding in 3D space. On
ScanNet and SemanticKITTI benchmarks, our algorithm, dubbed HexNet3D, achieves
competitive performance with previous algorithms. In particular, on the ScanNet
3D segmentation task, our method obtains 77.0 mIoU on the validation set,
surpassing Point Transformer V2 by 1.6 mIoU. We also observe encouraging
results in indoor 3D detection tasks. Note that our method can be seamlessly
integrated into existing voxel-based, point-based, and range-based approaches
and brings considerable gains without bells and whistles. The codes will be
available upon publication.


## SpecServe Efficient and SLO-Aware Large Language Model Serving with Adaptive Speculative Decoding

>Authors: Kaiyu Huang, Hao Wu, Zhubo Shi, Han Zou, Minchen Yu, Qingjiang Shi

>2025-03-07

> http://arxiv.org/abs/2503.05096v1

Large Language Model (LLM) services often face challenges in achieving low
inference latency and meeting Service Level Objectives (SLOs) under dynamic
request patterns. Speculative decoding, which exploits lightweight models for
drafting and LLMs for verification, has emerged as a compelling technique to
accelerate LLM inference. However, existing speculative decoding solutions
often fail to adapt to varying workloads and system environments, resulting in
performance variability and SLO violations. In this paper, we introduce
SpecServe, an efficient LLM inference system that dynamically adjusts
speculative strategies according to real-time request loads and system
configurations. SpecServe proposes a theoretical model to understand and
predict the efficiency of speculative decoding across diverse scenarios.
Additionally, it implements intelligent drafting and verification algorithms to
guarantee optimal performance while achieving high SLO attainment. Experimental
results on real-world LLM traces demonstrate that SpecServe consistently meets
SLOs and achieves substantial performance improvements, yielding
1.14$\times$-14.3$\times$ speedups over state-of-the-art speculative inference
systems.


## Lightweight Hypercomplex MRI Reconstruction A Generalized Kronecker-Parameterized Approach

>Authors: Haosen Zhang, Jiahao Huang, Yinzhe Wu, Congren Dai, Fanwen Wang, Zhenxuan Zhang, Guang Yang

>2025-03-07

> http://arxiv.org/abs/2503.05063v2

Magnetic Resonance Imaging (MRI) is crucial for clinical diagnostics but is
hindered by prolonged scan times. Current deep learning models enhance MRI
reconstruction but are often memory-intensive and unsuitable for
resource-limited systems. This paper introduces a lightweight MRI
reconstruction model leveraging Kronecker-Parameterized Hypercomplex Neural
Networks to achieve high performance with reduced parameters. By integrating
Kronecker-based modules, including Kronecker MLP, Kronecker Window Attention,
and Kronecker Convolution, the proposed model efficiently extracts spatial
features while preserving representational power. We introduce Kronecker U-Net
and Kronecker SwinMR, which maintain high reconstruction quality with
approximately 50% fewer parameters compared to existing models. Experimental
evaluation on the FastMRI dataset demonstrates competitive PSNR, SSIM, and
LPIPS metrics, even at high **acceleration** factors (8x and 16x), with no
significant performance drop. Additionally, Kronecker variants exhibit superior
generalization and reduced overfitting on limited datasets, facilitating
efficient MRI reconstruction on hardware-constrained systems. This approach
sets a new benchmark for parameter-efficient medical imaging models.

